"#","No","Issue Title","Issue Details","State","Labels","User name","created","Updated"
"","9108","KAFKA-9273: Extract testShouldAutoShutdownOnIncompleteMetadata from S…","…treamTableJoinIntegrationTest into its own test  The main goal is to remove usage of embedded broker (EmbeddedKafkaCluster) in AbstractJoinIntegrationTest and its subclasses. This is because the tests under this class are no longer using the embedded broker, except for two. testShouldAutoShutdownOnIncompleteMetadata is one of such tests. Furthermore, this test does not actually perfom stream-table join; it is testing an edge case of joining with a non-existent topic, so it should be in a separate test.  Testing strategy: run existing unit and integration test  @bbejeck   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","albert02lowis","2020-07-31T04:35:15Z","2020-08-16T06:06:21Z"
"","9236","MINOR: Log warn message with details when there's kerberos login issue","…though we will still retry  Currently, we just capture the exception and retry later, we can't figure out what happened at runtime, it would be helpful to log a warn message with details.  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.* Minor logging change, so no extra test is required.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","cnZach","2020-09-01T07:41:53Z","2020-09-19T13:31:35Z"
"","9235","KAFKA-10449: Add some important parameter desc in connect-distributed.properties","…rties.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","tinawenqiao","2020-08-31T21:56:01Z","2021-02-26T11:02:44Z"
"","8784","KAFKA-9788: Use distinct names for transaction and group load time se…","…nsors  Sensor objects are stored in the Kafka metrics registry and keyed by name. If a new sensor is created with the same name as an existing one, the existing one is returned rather than a new object being created. The partition load time sensors for the transaction and group coordinators used the same name, so data recorded to either was stored in the same object. This meant that the metrics values for both metrics were identical and consisted of the combined data. This patch changes the names to be distinct so that the data will be stored in separate Sensor objects.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","bob-barrett","2020-06-02T16:57:44Z","2020-06-04T00:53:31Z"
"","8543","[KAFKA-9826] Handle an unaligned first dirty offset during log cleani…","…ng. (#8469)  In KAFKA-9826, a log whose first dirty offset was past the start of the active segment and past the last cleaned point resulted in an endless cycle of picking the segment to clean and discarding it. Though this didn't interfere with cleaning other log segments, it kept the log cleaner thread continuously busy (potentially wasting CPU and impacting other running threads) and filled the logs with lots of extraneous messages.  This was determined to be because the active segment was getting mistakenly picked for cleaning, and because the logSegments code handles (start == end) cases only for (start, end) on a segment boundary: the intent is to return a null list, but if they're not on a segment boundary, the routine returns that segment.  This fix has two parts:  It changes logSegments to handle start==end by returning an empty List always.  It changes the definition of calculateCleanableBytes to not consider anything past the UncleanableOffset; previously, it would potentially shift the UncleanableOffset to match the firstDirtyOffset even if the firstDirtyOffset was past the firstUncleanableOffset. This has no real effect now in the context of the fix for (1) but it makes the code read more like the model that the code is attempting to follow.  These changes require modifications to a few test cases that handled this particular test case; they were introduced in the context of KAFKA-8764. Those situations are now handled elsewhere in code, but the tests themselves allowed a DirtyOffset in the active segment, and expected an active segment to be selected for cleaning.  Reviewer: Jun Rao   *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","steverod","2020-04-24T01:12:54Z","2020-04-29T18:10:13Z"
"","8542","[KAFKA-9826] Handle an unaligned first dirty offset during log cleani…","…ng. (#8469)  In KAFKA-9826, a log whose first dirty offset was past the start of the active segment and past the last cleaned point resulted in an endless cycle of picking the segment to clean and discarding it. Though this didn't interfere with cleaning other log segments, it kept the log cleaner thread continuously busy (potentially wasting CPU and impacting other running threads) and filled the logs with lots of extraneous messages.  This was determined to be because the active segment was getting mistakenly picked for cleaning, and because the logSegments code handles (start == end) cases only for (start, end) on a segment boundary: the intent is to return a null list, but if they're not on a segment boundary, the routine returns that segment.  This fix has two parts:  It changes logSegments to handle start==end by returning an empty List always.  It changes the definition of calculateCleanableBytes to not consider anything past the UncleanableOffset; previously, it would potentially shift the UncleanableOffset to match the firstDirtyOffset even if the firstDirtyOffset was past the firstUncleanableOffset. This has no real effect now in the context of the fix for (1) but it makes the code read more like the model that the code is attempting to follow.  These changes require modifications to a few test cases that handled this particular test case; they were introduced in the context of KAFKA-8764. Those situations are now handled elsewhere in code, but the tests themselves allowed a DirtyOffset in the active segment, and expected an active segment to be selected for cleaning.  Reviewer: Jun Rao   *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","steverod","2020-04-24T01:11:50Z","2020-04-29T22:15:58Z"
"","9306","KAFKA-10477: Enabling the same behavior of NULL JsonNodeType to MISSI…","…NG JsonNodeType in JsonConverter.  From v2.10.0 onwards, in jackson lib, ObjectMapper.readTree(input) started to return JsonNode of type MISSING for empty input, as mentioned in the issue: https://github.com/FasterXML/jackson-databind/issues/2211.  This caused to throw a `DataException[""Unknown schema type: null""]` when an empty message key was parsed to be converted to Connect format via JsonConverter. The `schemaType` for `MISSING` type of JsonNode was returned as null, which resulted in this exception.    As part of this PR, made changes in JsonParser to incorporate the Jackson's ObjectMapper treatment of empty input from v2.10.0 onwards. Treating MISSING JsonNodeType in a similar fashion as that of NULL JsonNodeType. Added a unit test for this.  Related Jira ticket captures further details: https://issues.apache.org/jira/browse/KAFKA-10477  All unit tests passed locally.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","shaikzakiriitm","2020-09-18T18:22:21Z","2020-10-02T14:21:12Z"
"","9122","KAFKA-10314: KafkaStorageException on reassignment when offline log d…","…irectories exist  Make sure that we set the isNew field in LeaderAndIsrRequest correctly for brokers that gets added to the replica set on reassignment.  This is tested by creating a variant of ControllerIntergationTest.testPartitionReassignment() that makes one of the log directories on the target broker offline before initiating the reassignment. Without the change to the way isNew is set, this fails after a timeout. With the change, it succeeds.  To facilitate calling causeLogDirFailure() both from ControllerIntegrationTest and LogDirFailureTest, the method was moved to TestUtils along with the other helper methods that deals with interacting with KafkaServer instances for test cases.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","nresare","2020-08-04T11:26:09Z","2020-09-04T15:34:32Z"
"","8753","KAFKA-10043:Some parameters will be overwritten which was configured …","…in consumer.config  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","SweetMojito","2020-05-29T08:47:47Z","2020-12-28T05:38:23Z"
"","9057","KAFKA-10299: Implementing Kafka Connect Hash SMT to allow for hashing…","… of message key or value.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","kip,","brbrown25","2020-07-22T17:52:54Z","2020-11-05T12:45:55Z"
"","9188","break when dst is full so that unwrap isn't called when appreadbuffer…","… may have data  There are a couple of different situations which can result in BUFFER_OVERFLOW on read with the current implementation, due to the while loop structure (such as TLS compression with identical buffer sizes, or buffers sizes that differ to optimize modes where the cipher text is larger than the plain text.)  The JDK documentation indicates that a buffer of getApplicationBufferSize() bytes will be enough for a single unwrap operation, but the SslTransportLayer loop may call unwrap with an application buffer which isn't empty.  The current implementation will check dst for space and then move data from the application buffer.  It will then continue the loop and may try to unwrap() again without verifying that there are getApplicationBufferSize() bytes free in the application buffer. If, instead, the loop moves data into dst, and then breaks the loop if dst is full, then unwrap() should never be called with data in the application buffer.","open","","Spatterjaaay","2020-08-17T01:47:26Z","2022-07-07T19:49:11Z"
"","9018","Performance degradation while fetching a key from a single partition","WrappingStoreProvider does not take into account withPartition parameter and always return all existing stores, thus causing significant performance degradation to the caller, in case state store has many partitions.  https://issues.apache.org/jira/browse/KAFKA-10271","closed","","dima5rr","2020-07-14T14:48:10Z","2020-07-14T15:03:52Z"
"","8967","[WIP] KAFKA-6520: Add DISCONNECTED state to Kafka Streams","Work in progress,  appreciate any feedback on my initial approach.   Adding a disconnect status to Kafka streams. This is achieved by introducing by recording fetch disconnectedExceptions in Fetcher and then measuring them through 2 new metrics _fetchRequestSuccessPercent_ and _fetchRequestFailurePercent_. Currently when the percentage of failed fetches is above an arbitrary threshold we transition the streamThread to a disconnected state. Then when percentage of failed fetches dips below another arbitrary threshold we transition the streamThread to it's previous state.   If my approach is satisfactory, I'll start writing tests.    ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","kip,","VinceMu","2020-07-01T14:46:56Z","2021-01-13T01:02:14Z"
"","8872","Fix log message for transition from standby to active","Without this fix the log message is  ```  task [0_2] Transitioning state manager for ACTIVE task 0_2 to ACTIVE  ``` but it should probably be  ``` task [0_2] Transitioning state manager for STANDBY task 0_2 to ACTIVE  ```  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","cadonna","2020-06-15T12:24:58Z","2020-07-29T08:03:25Z"
"","8983","KAFKA-8398: Prevent NPE in `forceUnmap`","Without this change, we would catch the NPE and log it. This was misleading and could cause excessive log volume.  The NPE can happen after `AlterReplicaLogDirs` completes successfully and when unmapping older regions. Example stacktrace:  ```text [2019-05-20 14:08:13,999] ERROR Error unmapping index /tmp/kafka-logs/test-0.567a0d8ff88b45ab95794020d0b2e66f-delete/00000000000000000000.index (kafka.log.OffsetIndex) java.lang.NullPointerException at org.apache.kafka.common.utils.MappedByteBuffers.unmap(MappedByteBuffers.java:73) at kafka.log.AbstractIndex.forceUnmap(AbstractIndex.scala:318) at kafka.log.AbstractIndex.safeForceUnmap(AbstractIndex.scala:308) at kafka.log.AbstractIndex.$anonfun$closeHandler$1(AbstractIndex.scala:257) at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:251) at kafka.log.AbstractIndex.closeHandler(AbstractIndex.scala:257) at kafka.log.AbstractIndex.deleteIfExists(AbstractIndex.scala:226) at kafka.log.LogSegment.$anonfun$deleteIfExists$6(LogSegment.scala:597) at kafka.log.LogSegment.delete$1(LogSegment.scala:585) at kafka.log.LogSegment.$anonfun$deleteIfExists$5(LogSegment.scala:597) at kafka.utils.CoreUtils$.$anonfun$tryAll$1(CoreUtils.scala:115) at kafka.utils.CoreUtils$.$anonfun$tryAll$1$adapted(CoreUtils.scala:114) at scala.collection.immutable.List.foreach(List.scala:392) at kafka.utils.CoreUtils$.tryAll(CoreUtils.scala:114) at kafka.log.LogSegment.deleteIfExists(LogSegment.scala:599) at kafka.log.Log.$anonfun$delete$3(Log.scala:1762) at kafka.log.Log.$anonfun$delete$3$adapted(Log.scala:1762) at scala.collection.Iterator.foreach(Iterator.scala:941) at scala.collection.Iterator.foreach$(Iterator.scala:941) at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) at scala.collection.IterableLike.foreach(IterableLike.scala:74) at scala.collection.IterableLike.foreach$(IterableLike.scala:73) at scala.collection.AbstractIterable.foreach(Iterable.scala:56) at kafka.log.Log.$anonfun$delete$2(Log.scala:1762) at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) at kafka.log.Log.maybeHandleIOException(Log.scala:2013) at kafka.log.Log.delete(Log.scala:1759) at kafka.log.LogManager.deleteLogs(LogManager.scala:761) at kafka.log.LogManager.$anonfun$deleteLogs$6(LogManager.scala:775) at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:114) at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:63) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) ```  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-07-06T00:57:31Z","2020-07-06T21:51:42Z"
"","8687","MINOR: updated MacOS compatibility statement for RocksDB","With https://issues.apache.org/jira/browse/KAFKA-9225 Kafka Streams 2.6.0 requires MacOS 10.15.","closed","docs,","mjsax","2020-05-18T17:25:59Z","2020-05-18T19:43:40Z"
"","9398","MINOR update comments and docs to be gender-neutral","While this is not technically part of KIP-629, I believe this makes our codebase more inclusive as well.  cc @gwenshap","closed","","xvrl","2020-10-08T23:16:54Z","2020-10-13T19:48:44Z"
"","9068","MINOR: INFO log4j when request re-join","While debugging a rebalance scenario I found that inside rejoinNeededOrPending when we trigger rebalance due to metadata or subscription changes it is not logged, and hence it's actually a bit tricky to find out the reason of the triggered rebalance. I'm adding two INFO log4j entries to fill in the gap.  Other requestRejoin() calls are already covered.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-07-23T23:33:43Z","2020-07-26T23:45:17Z"
"","8994","KAFKA-10247: Correctly reset state when task is corrupted","When we detect a task as corrupted, we need to not only close, clean up, and recover the local store, but we also need to reset the consumer to the last committed position so that after recovery we can start processing from the correct position.  We also need to detect such repaired tasks in the StreamThread processing loop so they can be re-initialized and recovered, even when the thread is already in RUNNING.  Also, I fixed a bug in which we would incorrectly always consider a task as corrupted when it contains both persistent and in-memory stores.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-07-08T17:43:12Z","2020-07-11T19:31:38Z"
"","9407","KAFKA-10611: Merge log error to avoid double error","When using an error tracking system, 2 errors means 2 different alerts. It's best to group the logs and have one error with all information.  For example when using with [Sentry](https://sentry.io/welcome/), this double line of log.error will create 2 different Issues. One can merge the issues but it will be simpler to have a single error log line  I feel this is a trivial change, so following [Contribution rules](https://cwiki.apache.org/confluence/display/KAFKA/Contributing+Code+Changes#ContributingCodeChanges-PullRequest) I didn't create a Jira ticket but simply open a pull request  If I'm wrong, please feel free to indicate me the correct process.","closed","connect,","bmaggi","2020-10-09T15:33:34Z","2020-10-16T05:38:12Z"
"","9123","MINOR: optimize fetchablePartitions check by performing cheap check first","When the consumer fetches a lot of partitions at once the isAvailable check can become expensive due to a high number of contains check. We might as well perform the isFetchable check first as this is clearly much cheaper.  This will help most with partitions that are paused or are otherwise not in a state where they are fetchable.","closed","","lbradstreet","2020-08-04T16:55:36Z","2020-08-07T17:55:41Z"
"","8536","KAFKA-9883: Add better error message when REST API forwards a request and leader is not known","When the Connect worker forwards a REST API request to the leader, it might get back a `RequestTargetException` that suggests the worker should forward the request to a different worker. This can happen when the leader changes, and the worker that receives the original request forwards the request to the worker that it thinks is the current leader, but that worker is not the current leader. In this case. In most cases, the worker that received the forwarded request includes the URL of the current leader, but it is possible (albeit rare) that the worker doesn’t know the current leader and will include a null leader URL in the resulting `RequestTargetException`.  When this rare case happens, the user gets a null pointer exception in their response and the NPE is logged. Instead, the worker should catch this condition and provide a more useful error message that is similar to other existing error messages that might occur.  Added a unit test that verifies this corner case is caught and this particular NPE does not occur.  I recommend this be backported a few branches, as is typical for bug fixes.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","rhauch","2020-04-22T19:54:20Z","2020-04-23T18:37:46Z"
"","9389","KAFKA-7334: Suggest changing config for state.dir in case of FileNotFoundException","When state.dir is left at default configuration, there is a chance that certain files under the state directory are cleaned by OS since the default dir starts with /tmp/kafka-streams.  I've added suggestion to change state.dir config in the exception message. (https://issues.apache.org/jira/browse/KAFKA-7334)","closed","","voffcheg109","2020-10-07T17:35:24Z","2020-10-07T17:41:46Z"
"","9380","KAFKA-7334: Suggest changing config for state.dir in case of FileNotF…","When state.dir is left at default configuration, there is a chance that certain files under the state directory are cleaned by OS since the default dir starts with /tmp/kafka-streams.  I've added suggestion to change state.dir config in the exception message. (https://issues.apache.org/jira/browse/KAFKA-7334)","closed","streams,","voffcheg109","2020-10-06T11:21:52Z","2020-10-09T07:26:34Z"
"","8675","KAFKA-10004: ConfigCommand fails to find default broker configs without ZK","When running `bin/kafka-configs.sh --describe --bootstrap-server localhost:9092 --entity-type brokers` the output will be: Dynamic configs for broker 0 are: .... Dynamic configs for broker  are: **The entity name for brokers must be a valid integer broker id, found: **  I found it's because we set the default entity name for broker as ``, which should be empty string """". Also add the missing tests for the describe broker without entity name case.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-05-15T14:03:22Z","2020-05-22T01:22:43Z"
"","8504","KAFKA-9298: reuse mapped stream error in joins","When performing a join with a stream that needs repartitioning, Kafka Streams automatically creates a repartition topic.  If the user does not use `StreamJoined` to name to repartition topic, Kafka Streams uses the generated name of the KStream instance for the repartition topic name.    If the KStream instance requiring the repartition participates in another join, the second repartition topic is created using the name of the operator. This name reuse is what causes the `InvalidTopologyException.`  The error occurs because the `InternalTopologyBuilder` has already registered the repartition source name previously.  For example, this topology will cause an error because Kafka Streams will attempt to create two repartition topics (which is correct behavior) but using the _**same name**_ each time which causes the error. ``` java KStream newStream = stream1.map((k, v) -> new KeyValue<>(v, k)); newStream.join(stream2, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100))).to(""out-one""); // using newStream in another join here causes the error newStream.join(stream3, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100))).to(""out-to""); ``` However this topology, which is the same except the user has provided repartition topic names, is fine.  Note the use of `StreamJoined.withName` here ```java KStream newStream = stream1.map((k, v) -> new KeyValue<>(v, k)); final StreamJoined streamJoined = StreamJoined.with(Serdes.String(), Serdes.String(), Serdes.String()); newStream.join(stream2, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100)), streamJoined.withName(""first-join"")).to(""out-one""); // using newStream in another join here is fine because the name of the repartition topic is unique newStream.join(stream3, (value1, value2) -> value1 + value2, JoinWindows.of(ofMillis(100)), streamJoined.withName(""second-join"")).to(""out-two""); ``` This bug has been present for some time as I tested this out on `2.0` before we added the optimization layer.  Ideally, the fix should be to generate a repartition topic name each time to avoid such issues.  But IMHO that ship has already sailed because by introducing a new name generation will cause compatibility issues for existing topologies.  So generating new names is out for now, at least.  The proposed fix is:  1.  For KStream objects needing repartitioning _**and  using generated names**_, reuse the repartition topic node in any additional joins. 2. For KStream instances needing repartitioning _**using user-provided names**_ always create a new repartition topic node for each join as each one will have a unique name    I've added tests confirming the expected behavior.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","bbejeck","2020-04-17T03:25:23Z","2020-05-27T23:30:36Z"
"","8827","KAFKA-9849: Fix issue with worker.unsync.backoff.ms creating zombie workers when incremental cooperative rebalancing is used","When Incremental Cooperative Rebalancing is enabled and a worker fails to read to the end of the config topic, it needs to voluntarily revoke its locally running tasks on time, before these tasks get assigned to another worker, creating a situation where redundant tasks are running in the Connect cluster.   Additionally, instead of using the delay `worker.unsync.backoff.ms` that was defined for the eager rebalancing protocol and has a long default value (which coincidentally is equal to the default value of the rebalance delay of the incremental cooperative protocol), the worker should quickly attempt to re-read the config topic and backoff for a fraction of the rebalance delay. After this fix, the worker will retry for a maximum time of 5 times before it revokes its running assignment and for a cumulative delay less than the configured `scheduled.rebalance.max.delay.ms`.  Unit tests are added to cover the backoff logic with incremental cooperative rebalancing.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","kkonstantine","2020-06-07T19:46:29Z","2020-06-09T20:02:40Z"
"","9016","the error of run script","when i use the startup script of  `zookeeper-server-start.sh`，i will success, and then i want to startup kafka service occur the error:  ```java  Exception thrown by the agent : java.rmi.server.ExportException: Port already in use: 9988 ```","closed","","zhangptang","2020-07-14T09:23:37Z","2020-07-23T03:35:03Z"
"","8579","KAFKA-9930: Prevent ReplicaFetcherThread from throwing UnknownTopicOrPartitionException upon topic creation and deletion.","When does UnknownTopicOrPartitionException typically occur?  * Upon a topic creation, a follower broker of a new partition starts replica fetcher before the prospective leader broker of the new partition receives the leadership information from the controller (see [KAFKA-6221](https://issues.apache.org/jira/browse/KAFKA-6221)).  * Upon a topic deletion, a follower broker of a to-be-deleted partition starts replica fetcher after the leader broker of the to-be-deleted partition processes the deletion information from the controller.  * As expected, clusters with frequent topic creation and deletion report UnknownTopicOrPartitionException with relatively higher frequency.  What is the impact?  * Exception tracking systems identify the error logs with UnknownTopicOrPartitionException as an exception. This results in a lot of noise for a transient issue that is expected to recover by itself and a natural process in Kafka due to its asynchronous state propagation.  Why not move it to a lower than warn-level log?  * Despite typically being a transient issue, UnknownTopicOrPartitionException may also indicate real issues if it doesn't fix itself after a short period of time. To ensure detection of such scenarios, we set the log level to warn.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","efeg","2020-04-29T01:39:15Z","2020-07-07T01:50:25Z"
"","8530","KAFKA-9388: Refactor integration tests to always use different application ids","When debugging KAFKA-9388, I found the reason that the second test method test takes much longer (10s) than the previous one (~500ms) is because they used the same app.id. When the previous clients are shutdown, they would not send leave-group and hence we are still depending on the session timeout (10s) for the members to be removed out of the group.  When the second test is triggered, they will join the same group because of the same application id, and the `prepare-rebalance` phase would would for the full rebalance timeout before it kicks out the previous members.  Setting different application ids could resolve such issues for integration tests --- I did a quick search and found some other integration tests have the same issue. And after this PR my local unit test runtime reduced from about 14min to 7min.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-04-22T06:25:27Z","2020-04-22T21:29:34Z"
"","8711","KAFKA-9904:Use ThreadLocalConcurrent to Replace Random","When applicable, use of ThreadLocalRandom rather than shared Random objects in concurrent programs will typically encounter much less overhead and contention.  Change-Id: Idf56adc8cbb4c611e327e639a49d90827a23d947 Signed-off-by: Jiamei Xie   *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jiameixie","2020-05-22T07:50:04Z","2020-06-11T01:52:18Z"
"","8663","KAFKA-9985: Sink connector may exhaust broker when writing in DLQ","When a sink connector is configured with a DLQ and its topic is the same (or matches) as the topic in which the connector reads, the broker and/or connector might be exhausted in case the record send to the topic is invalid.  Based on the broker/connect config, the connector might fail throwing a RecordTooLargeException previous to exhaust the broker/connector.  This patch also adds a test case for this.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","mmolimar","2020-05-13T02:58:53Z","2020-06-11T00:58:01Z"
"","8837","KAFKA-10125 The partition which is removing should be considered to b…","When a reassignment is still in progress, the replica which is either removing or adding should be considered to be under reassignment. However, TopicCommand still print the partition which is removing.  issue: https://issues.apache.org/jira/browse/KAFKA-10125 related to d63eaaaa0181bb7b9b4f5ed088abc00d7b32aeb0  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-06-09T06:36:43Z","2020-10-27T12:35:05Z"
"","8873","Avoid WARN log message when re-init from checkpoint skipped","When a re-initialisation from checkpoint is skipped the following log messages appear in the logs.   ``` DEBUG stream-thread [EosTest-a2c3b21b-7af1-4dce-a3e0-6dc10932e5a2-StreamThread-1] task [0_2] Skipping re-initialization of offset from checkpoint for recycled store KSTREAM-AGGREGATE-STATE-STORE-0000000003 (org.apache.kafka.streams.processor.internals.ProcessorStateManager) DEBUG stream-thread [EosTest-a2c3b21b-7af1-4dce-a3e0-6dc10932e5a2-StreamThread-1] task [0_2] Skipping re-initialization of offset from checkpoint for recycled store KSTREAM-AGGREGATE-STATE-STORE-0000000007  WARN stream-thread [EosTest-a2c3b21b-7af1-4dce-a3e0-6dc10932e5a2-StreamThread-1] task [0_2] Some loaded checkpoint offsets cannot find their corresponding state stores: {EosTest-KSTREAM-AGGREGATE-STATE-STORE-0000000003-changelog-2=1491, EosTest-KSTREAM-AGGREGATE-STATE-STORE-0000000007-changelog-2=1491}  ```  The warning appears because the skipped offsets are not removed from the checkpoint. However, there is nothing to warn about, because the offset found there corresponding state stores and they were skipped.     ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","cadonna","2020-06-15T12:37:51Z","2020-07-29T08:03:17Z"
"","9416","MINOR: more log4j entry on elect / resignation of coordinators","When a coordinator module is being elected / resigned, our log entry is usually associated with a background scheduler on loading / unloading entries and hence it is unclear at the exact time when the election or resignation happens, and we have to then compare with the KafkaAPI's log entry for leaderAndISR / StopReplica to infer the actual time. I think add a couple new log entries indicating the exact time when it happens is helpful.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-10-12T22:23:25Z","2020-10-15T17:08:56Z"
"","9326","KAFKA-10460: ReplicaListValidator format checking is incomplete","What? :: See https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/server/ConfigHandler.scala#L220 . The logic is supposed to accept only two cases:  list of k:v pairs a single '*' But in practice, since the disjunction's second part only checks that the head is '*', the case where a k:v list is headed by a star is also accepted (and then later broker dies at startup, refusing the value).  JIRA: https://issues.apache.org/jira/browse/KAFKA-10460  @viktorsomogyi Can you please review this?","closed","","ankit-kumar-25","2020-09-23T11:47:29Z","2020-12-03T14:36:49Z"
"","9314","KAFKA-8360: Docs do not mention RequestQueueSize JMX metric","What? :: Mentioning ""Request Queue Size"" under the Monitoring tab. RequestQueueSize is an important metric to monitor the number of requests in the queue. As a crowded queue might face issue processing incoming or outgoing requests  @viktorsomogyi  can you please review this?  Thanks!!","closed","","ankit-kumar-25","2020-09-21T15:25:00Z","2020-09-23T11:02:52Z"
"","9325","KAFKA-8360: Docs do not mention RequestQueueSize JMX metric","What? :: Mentioning ""Request Queue Size"" under Monitoring tab. RequestQueueSize is an important metric to monitor the number of requests in the queue. As a crowded queue might face issue processing incoming or outgoing requests  @viktorsomogyi Can you please review this?  Thanks!!","closed","","ankit-kumar-25","2020-09-23T11:22:01Z","2020-09-29T08:34:32Z"
"","9247","KAFKA-10362: When resuming Streams active task with EOS, the checkpoint file is deleted","What was the issue? https://issues.apache.org/jira/browse/KAFKA-10362   Deleted the checkpoint file before the transition from SUSPENDED state to RESTORING state  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","DOJI45","2020-09-02T18:32:20Z","2021-02-02T20:06:29Z"
"","8562","Test compilation fixes for Scala 2.11","What ==== Earlier log test changes went into trunk (for KAFKA-9807, KAFKA-9838) and were cherry-picked to 2.4, but they broke the Scala 2.11 build. This change cherry-picks the fixes needed to make those tests build for 2.11.  Testing ===== These are compilation errors; rebuild and ran unit tests.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","steverod","2020-04-27T17:49:15Z","2020-04-28T21:49:33Z"
"","9065","KAFKA-10301: Do not clear Partition#remoteReplicasMap during partition assignment updates","We would previously update the map by adding the new replicas to the map and then removing the old ones. During a recent refactoring, we changed the logic to first clear the map and then add all the replicas to it.  While this is done in a write lock, not all callers that access the map structure use a lock. It is safer to revert to the previous behavior of showing the intermediate state of the map with extra replicas, rather than an intermediate state of the map with no replicas.","closed","","stanislavkozlovski","2020-07-23T15:14:05Z","2020-07-24T19:03:11Z"
"","9184","KAFKA-8033; Wait for NoOffsetForPartitionException in testFetchInvalidOffset","We wait only 50ms in consumer.poll() and expect NoOffsetForPartitionException, but the exception is thrown only when initializing partition offsets after coordinator is known. Increased poll timeout to make test reliable.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rajinisivaram","2020-08-14T18:12:27Z","2020-08-16T09:51:29Z"
"","8708","MINOR: avoid unnecessary seq iteration in ApiVersion.lastVersion","We unnecessarily iterate the versions seq each time we lookup lastVersion, including in the hotpath Log.appendAsFollower. Given that allVersions is a constant, this is unnecessary.","closed","","lbradstreet","2020-05-21T14:12:07Z","2020-05-26T04:51:15Z"
"","8632","KAFKA-9972: Only commit tasks with valid states","We spotted a case in the soak test where a standby task could be in `CREATED` state during commit, which causes an illegal state exception. To prevent this from happening, the solution is to always enforce a state check.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","abbccdda","2020-05-08T05:59:14Z","2020-05-11T19:12:53Z"
"","8696","KAFKA-6145: KIP-441: Enforce Standby Task Stickiness","We should treat standbys similarly to active stateful tasks and re-assign them to instances that are already caught-up on them while we warm them up on the desired destination, instead of immediately moving them to the destination.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","vvcephei","2020-05-19T21:27:00Z","2020-06-12T23:08:53Z"
"","8883","KAFKA-9896: fix flaky StandbyTaskEOSIntegrationTest","We seem to typically fail on waiting for the first record to be processed, which we only give 15s. 15s to process a single record is reasonable, but we don't wait for the instances to reach the RUNNIG state until _after_ we wait for the record to be processed.  We should first make sure the instance reaches running (for which a 60s timeout seems to be the common case in other integration tests), and then wait on the record to be processed.","closed","tests,","ableegoldman","2020-06-16T20:52:05Z","2020-06-18T02:28:42Z"
"","9033","MINOR: Fix flaky system test assertion after static member fencing","We see the test case `OffsetValidationTest.test_fencing_static_consumer` failing periodically due to this error: ``` Traceback (most recent call last):   File ""/home/jenkins/workspace/system-test-kafka_2.6/kafka/venv/lib/python2.7/site-packages/ducktape-0.7.8-py2.7.egg/ducktape/tests/runner_client.py"", line 134, in run     data = self.run_test()   File ""/home/jenkins/workspace/system-test-kafka_2.6/kafka/venv/lib/python2.7/site-packages/ducktape-0.7.8-py2.7.egg/ducktape/tests/runner_client.py"", line 192, in run_test     return self.test_context.function(self.test)   File ""/home/jenkins/workspace/system-test-kafka_2.6/kafka/venv/lib/python2.7/site-packages/ducktape-0.7.8-py2.7.egg/ducktape/mark/_mark.py"", line 429, in wrapper     return functools.partial(f, *args, **kwargs)(*w_args, **w_kwargs)   File ""/home/jenkins/workspace/system-test-kafka_2.6/kafka/tests/kafkatest/tests/client/consumer_test.py"", line 257, in test_fencing_static_consumer     assert len(consumer.dead_nodes()) == num_conflict_consumers AssertionError ``` When a consumer stops, there is some latency between when the shutdown is observed by the service and when the node is actually added to the dead nodes. This patch fixes the problem by giving some time for the assertion to be satisfied.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-07-17T02:36:46Z","2020-07-17T18:27:34Z"
"","8849","KAFKA-10144: clean up corrupted standby tasks before attempting a commit","We need to make sure that corrupted standby tasks are actually cleaned up upon a TaskCorruptedException. However due to the `commit` prior to invoking `handleCorruption`, it's possible to throw a TaskMigratedException before actually cleaning up any of the corrupted tasks.  This is fine for active tasks since `handleLostAll` will finish up the job, but it does nothing with standby tasks. We should make sure that standby tasks are handled before attempting to commit (which we can do, since we don't need to commit anything for the corrupted standbys)  Must be cherry-picked to 2.6","closed","streams,","ableegoldman","2020-06-11T02:24:51Z","2020-06-26T22:40:46Z"
"","9173","KAFKA-10122: Consumer should allow heartbeat during rebalance","We launched a Streams application reading from a single 3000-partition topic and saw continuous rebalancing. Digging into the logs, every time the leader sent a SyncGroup request it would discover that it had dropped out of the group and needed to rejoin. The assignment seemed to take slightly longer than 10s, the session interval, so it seemed to be getting kicked due to heartbeat expiration while the heartbeat thread was disabled.  I redeployed the app with this exact patch and saw it stabilize at last. The application was left running for ~20 hours or so and never rebalanced again after the last pod was rolled","closed","","ableegoldman","2020-08-12T19:34:02Z","2020-08-12T22:35:51Z"
"","8924","KAFKA-10198: guard against recycling dirty state","We just needed to add the check in `StreamTask#closeClean`  to `closeAndRecycleState` as well. I also renamed `closeAndRecycleState` to `closeCleanAndRecycleState` to drive this point home: it needs to be clean.  This should be cherry-picked back to the 2.6 branch","closed","streams,","ableegoldman","2020-06-24T22:44:58Z","2020-06-26T22:40:30Z"
"","8978","KAFKA-10234 The key/value deserializer used by ConsoleConsumer is not…","We instantiate, configure and use them but them are never closed.  issue: https://issues.apache.org/jira/browse/KAFKA-10234  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","chia7712","2020-07-03T15:37:32Z","2020-12-03T06:24:32Z"
"","8905","KAFKA-10173: Fix suppress changelog binary schema compatibility","We inadvertently changed the binary schema of the suppress buffer changelog in 2.4.0 without bumping the schema version number. As a result, it is impossible to upgrade from 2.3.x to 2.4+ if you are using suppression.  * Refactor the schema compatibility test to use serialized data from older versions as a more foolproof compatibility test. * Refactor the upgrade system test to use the smoke test application so that we actually exercise a significant portion of the Streams API during upgrade testing * Add more recent versions to the upgrade system test matrix * Fix the compatibility bug by bumping the schema version to 3  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-06-19T22:14:09Z","2020-06-27T03:50:47Z"
"","8913","KAFKA-10191 fix flaky StreamsOptimizedTest","We have to call ```KafkaStreams#cleanUp``` to reset local state before starting application up the second run.  issue: https://issues.apache.org/jira/browse/KAFKA-10191  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-06-23T06:35:09Z","2020-07-10T19:21:02Z"
"","8996","KAFKA-10249: don't try to read un-checkpointed offsets of in-memory stores","We have this asymmetry in how the ProcessorStateManager handles in-memory stores: we explicitly skip over them when writing offsets to the checkpoint file, but don't do the same when reading from the checkpoint file to initialize offsets. With eos, this is taken to mean that the state is dirty, and thus we mistakenly mark the entire task as corrupted.","closed","streams,","ableegoldman","2020-07-08T21:56:18Z","2020-07-10T15:20:35Z"
"","8749","KAFKA-10061; Fix flaky `ReassignPartitionsIntegrationTest.testCancellation`","We have seen this test failing from time to time. In spite of the low quota, it is possible for one or more of the reassignments to complete before verification that the reassignment is in progress. The patch makes this less likely by reducing the quota even further and increasing the amount of data in the topic.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-05-28T23:24:04Z","2020-05-29T19:09:10Z"
"","8700","MINOR: Increase gradle daemon’s heap size to 2g","We have seen out of memory error in builds. This PR is to increase the gradle heap memory to 2g.   ``` [Error] : Error while emitting kafka/log/LogTest [2020-05-20T11:33:15.133Z] GC overhead limit exceeded [2020-05-20T11:33:15.133Z] one error found      ``` ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","omkreddy","2020-05-20T18:34:58Z","2020-05-21T01:48:27Z"
"","8801","KAFKA-10100; LiveLeaders field in LeaderAndIsrRequest is not used anymore","We have noticed that the `LiveLeaders` field in the LeaderAndIsrRequest is not used anywhere but still populated by the controller.  It seems that that field was introduced in AK `0.8.0` and was supposed to be removed in AK `0.8.1`: https://github.com/apache/kafka/blob/0.8.0/core/src/main/scala/kafka/cluster/Partition.scala#L194. It has not been used since then.  This PR proposes to simply stop populating the field for any version > 0. It avoids to compute the live leaders set and also reduces the size of the request on the wire.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-06-04T19:43:58Z","2020-12-18T16:06:14Z"
"","9298","MINOR: Replace Java 14 with Java 15 in the README","We have been testing with the Java 15 release candidate for a few weeks and it has now been declared final.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-09-17T13:21:04Z","2020-10-15T07:47:14Z"
"","8736","KAFKA-9802; Increase transaction timeout in system tests to reduce flakiness","We have been seeing increased flakiness in transaction system tests. I believe the cause might be due to KIP-537, which increased the default zk session timeout from 6s to 18s and the default replica lag timeout from 10s to 30s. In the system test, we use the default transaction timeout of 10s. However, since the system test involves hard failures, the Produce request could be blocking for as long as the max of these two in order to wait for an ISR shrink. Hence this patch increases the timeout to 30s.  Note this patch also includes a minor logging fix in `Partition`. Previously we would see messages like the following: ``` [Broker id=3] Leader output-topic-0 starts at leader epoch 0 from offset 0 with high watermark 0 ISR 3,2,1 addingReplicas  removingReplicas .Previous leader epoch was -1. ``` This patch fixes the log to print as the following: ``` [Broker id=3] Leader output-topic-0 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [3,2,1] addingReplicas []  removingReplicas []. Previous leader epoch was -1. ```   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-05-27T23:41:53Z","2020-05-28T03:54:10Z"
"","9406","KAFKA-10520; Ensure transactional producers poll if leastLoadedNode not available with max.in.flight=1","We currently stop polling in `Sender` in a transactional producer if there is only one broker in the bootstrap server list and `max.in.flight.requests.per.connection=1` and Metadata response is pending when InitProducerId request is ready to be sent. In this scenario, we attempt to send FindCoordinator to `leastLoadedNode`, but since that is blocked due to `max.in.flight=1` as a result of the pending metadata response, we never unblock unless we poll. This PR ensures we poll in this case.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rajinisivaram","2020-10-09T13:42:23Z","2020-10-22T09:19:07Z"
"","8603","MINOR: Fix ProcessorContext JavaDocs","We changed how ""stream time"" is computed in `2.3` release. This should be cherry-picked to older branches.","closed","streams,","mjsax","2020-05-02T20:49:54Z","2020-05-12T22:19:53Z"
"","8952","MINOR: Add toString for RocksDbWindowBytesStoreSupplier","We are missing a `toString` logic in the RocksDbWindowBytesStoreSupplier, such that the error log wasn't able to print out the supplier's actual config:  ``` Exception in thread ""main"" org.apache.kafka.streams.errors.StreamsException: Window settings mismatch. WindowBytesStoreSupplier settings org.apache.kafka.streams.state.internals.RocksDbWindowBytesStoreSupplier@61f8bee4 must match JoinWindows settings JoinWindows{beforeMs=500, afterMs=500, graceMs=-1, maintainDurationMs=86400000, segments=3}         at org.apache.kafka.streams.kstream.internals.KStreamImplJoin.assertWindowSettings(KStreamImplJoin.java:173)         at org.apache.kafka.streams.kstream.internals.KStreamImplJoin.join(KStreamImplJoin.java:96)         at org.apache.kafka.streams.kstream.internals.KStreamImpl.doJoin(KStreamImpl.java:969)         at org.apache.kafka.streams.kstream.internals.KStreamImpl.join(KStreamImpl.java:858)         at io.confluent.streams.bench.table.App.getStreamStreamJoinTopology(App.java:1231)         at io.confluent.streams.bench.table.App.main(App.java:609) ```  This PR amends this gap by providing an implementation for RocksDbWindowBytesStoreSupplier `toString`  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-06-29T17:30:14Z","2020-07-06T21:04:28Z"
"","9168","MINOR: Ensure same version of scala library is used for compile and at runtime","We are forcing runtime scala-library dependency to be the one used by Kafka in https://github.com/apache/kafka/commit/3fdf1523a369e9e2f03e215f39c0ed987b2a16c5, but we still seem to include the version in jackson for compile. This PR explicitly excludes it.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rajinisivaram","2020-08-12T08:00:25Z","2020-08-12T22:39:22Z"
"","8941","KAFKA-10195: Move offset management code out of ConsumerCoordinator","We are adding new features to `ConsumerCoordinator` and it's becoming more and more complex, the offset management code in `ConsumerCoordinator` can be moved to a new class because ""offset management"" almost don't interact with ""partition assignment"".  Below is the code change list:  1. move offset management code to `OffsetManageCoordinator` 2. remain methods which are used in `KafkaConsumer` but just a proxy method. 3. add methods in `OffsetManageCoordinator` for interacting with ""assigning offset code""  Below is UML class diagram: ![image](https://user-images.githubusercontent.com/26023240/85947857-c7113400-b97f-11ea-83e2-61a92fa2c22d.png)   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dengziming","2020-06-28T12:41:57Z","2021-09-11T23:29:21Z"
"","8577","use appropriate fn for readability. (maybe)","using the min, max might make the code a little easier to read.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","fantayeneh","2020-04-28T21:33:37Z","2020-05-02T00:18:44Z"
"","8775","KAFKA-10079: improve thread-level stickiness","Uses a similar (but slightly different) algorithm as in [KAFKA-9987](https://issues.apache.org/jira/browse/KAFKA-9987) to produce a maximally sticky -- and perfectly balanced -- assignment of tasks to threads within a single client. This is important for in-memory stores which get wiped out when transferred between threads.  Must be cherrypicked to 2.6","closed","streams,","ableegoldman","2020-06-02T05:23:55Z","2020-06-26T22:39:54Z"
"","9212","MINOR: don't keep reference of receive buffer when the value of head …","Users, who try to avoid null variable, can replace null by empty array to build header to be a kind of ""flag"". The ```RecordHeader#value()``` may be never called (as users only want to check existence of header) and so the receive buffer can't be released by GC until users get rid of ```Header```.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-08-24T16:40:36Z","2020-09-26T07:53:27Z"
"","8970","MINOR: Improve logging around initial log loading","Users often get confused after an unclean shutdown when log recovery takes a long time. This patch attempts to make the logging clearer and provide a simple indication of loading progress.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-07-01T19:13:11Z","2020-07-06T17:30:17Z"
"","8752","KAFKA-10036 early check singleton ProcessorSupplier and improve docs","User provided **ProcessorSupplier** may have chances to always return the same instance. Multiple ProcessorContext tried to register in a same processor instance, but processor instance could only have one ProcessorContext to callback. So the time StreamThread who owns each ProcessorContext dispatch records to processor instance and callback somewhere else(not its thread local ProcessorContext). And it led to inconsistency. Wrong samples here: https://stackoverflow.com/questions/61790984/kafka-stream-forward-method-throwing-nullpointerexception-because-processornode/61978396 ``` .addProcessor(""Process"", () -> fileExtractProcessorObject , ""sourceProcessor"") ```  So this commit  * check violation of our **Supplier** pattern during initialization.  * improve java docs * add a section in official docucment to explicitly remind users  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","jodaburro","2020-05-29T04:50:48Z","2020-08-04T01:34:22Z"
"","8666","KAFKA-9479: Describe consumer group --state --all-groups  show header once","Used the  [previous PR ](https://github.com/apache/kafka/pull/8096) made by vetler as a starting point.  Updated the  printState() method in ConsumerGroup command to only print the header once when the following options are set `--describe --state --all-groups`.  Modified testDescribeAllExistingGroups test in DescribeConsumerGroupTest so that we take into account the case where we only print the header once. In this case number of lines is equal to the length of DescribeTypes + 1.   Tagging @hachikuji @jeffkbkim as they reviewed the previous PR for this ticket.  ### Committer Checklist (excluded from commit message) - [x] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","VinceMu","2020-05-14T14:43:58Z","2020-06-20T08:26:41Z"
"","9229","MINOR: Reduce allocations in requests via buffer caching","Use a caching `BufferSupplier` per request handler thread so that decompression buffers are cached if supported by the underlying `CompressionType`. This achieves a similar outcome as #9220, but with less contention.  We introduce a `RequestLocal` class to make it easier to introduce new request scoped stateful instances (one example we discussed previously was an `ActionQueue` that could be used to avoid some of the complex group coordinator locking).  This is a small win for zstd (no synchronization or soft references) and a more significant win for lz4. In particular, it reduces allocations significantly when the number of partitions is high. The decompression buffer size is typically 64 KB, so a produce request with 1000 partitions results in 64 MB of allocations even if each produce batch is small (likely, when there are so many partitions).  I did a quick producer perf local test with 5000 partitions, 1 KB record size, 1 broker, lz4 and ~0.5 for the producer compression rate metric:  Before this change: > 20000000 records sent, 346314.349535 records/sec (330.27 MB/sec), 148.33 ms avg latency, 2267.00 ms max latency, 115 ms 50th, 383 ms 95th, 777 ms 99th, 1514 ms 99.9th.  After this change: > 20000000 records sent, 431956.113259 records/sec (411.95 MB/sec), 117.79 ms avg latency, 1219.00 ms max latency, 99 ms 50th, 295 ms 95th, 440 ms 99th, 662 ms 99.9th.  That's a 25% throughput improvement and p999 latency was reduced to under half (in this test).  Default arguments will be removed in a subsequent PR.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-08-29T20:14:29Z","2021-05-30T19:16:39Z"
"","8790","MINOR: Upgrade spotbugs and spotbugsPlugin","Upgrade spotbugsPlugin to have clear error output to indicate where the error is.   When investigating KAFKA-10081, I found the error output of spotbugs is very poor. It doesn't even tell you where the error is and how many errors found, it will take a lot of time for the developers to find out where the error is, and then fix it. ![image](https://user-images.githubusercontent.com/43372967/83590263-efc42a80-a587-11ea-95cf-e9097d9a662e.png) https://builds.apache.org/blue/organizations/jenkins/kafka-trunk-jdk8/detail/kafka-trunk-jdk8/4596/pipeline/  Then, I found out there's a bug in spotbugsPlugin in V4.0.x, and got fixed in V4.2.x https://github.com/spotbugs/spotbugs-gradle-plugin/issues/210  So, after upgrading to V4.2.x (I followed to the latest version V4.2.4), the output is like this: ![image](https://user-images.githubusercontent.com/43372967/83590913-60b81200-a589-11ea-9a04-1449d693c2f2.png) So you know there's 1 error and you can also open the report file to find out the error.  I think this is very important to save the developer's time to fix the spotBug issues while developing. Thanks.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-06-03T02:55:46Z","2020-06-03T20:17:32Z"
"","8859","MINOR: Upgrade jetty to 9.4.27.v20200227 and jersey to 2.31","Upgrade jetty to 9.4.27.v20200227 and jersey to 2.31  Also remove the workaround used on previous version from Connect's SSLUtils.  (Reverts KAFKA-9771 - commit ee832d7d)  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","akatona84","2020-06-12T07:34:20Z","2020-06-30T22:28:52Z"
"","9039","KAFKA-5636: SlidingWindows (KIP-450)","Updating basic classes for SlidingWindows implementation, WIP and POC, things will shift as KIP discussion continues.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","lct45","2020-07-17T18:34:40Z","2020-08-31T22:24:03Z"
"","9248","MINOR: Patch for KStreamAggregationIntegrationTest.shouldAggregateSlidingWindows","Updated number of expected messages  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","lct45","2020-09-02T18:33:22Z","2020-09-02T22:19:40Z"
"","8726","MINOR: Remove unused `Json.legacyEncodeAsString`","Updated a couple of test usages not to rely on it and removed the tests for the removed method.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-05-26T11:53:49Z","2020-05-27T12:51:02Z"
"","9141","MINOR: Improve checks for CogroupedStreamAggregateBuilder","Updated `CogroupedStreamAggregateBuilder` to have individual builders depending on the windowed aggregation, or lack thereof. This replaced passing in all options into the builder, with all but the current type of aggregation set to null and then checking to see which value was not null.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","lct45","2020-08-07T17:54:17Z","2020-08-10T22:33:11Z"
"","8560","MINOR: Update raft broken link","Update the raft introduction link. The old link is not accessible now. Update to the official usenix conference link where the raft paper published. It also contains the paper introduction, paper pdf, and presentation video/audio in this link.  old broken link: https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf new link: https://www.usenix.org/conference/atc14/technical-sessions/presentation/ongaro  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-04-27T13:58:28Z","2020-04-28T06:29:49Z"
"","8760","Kafka-10064 Add documentation for KIP-571","Update the documentation to describe the change in KIP-571  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","feyman2016","2020-05-30T12:17:47Z","2020-06-02T06:28:26Z"
"","9131","KAFKA-10367: Allow running the Streams demo app with a config file","Update the 3 WordCount demos to accept a configuration file. I kept the changes to the minimum as the point of these samples is not to add a lot of logic for parsing arguments and handling usage errors.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","mimaison","2020-08-06T09:35:01Z","2020-08-22T16:00:06Z"
"","8804","KAFKA-9851: Revoking Connect tasks due to connectivity issues should also clear the running assignment","Until recently revocation of connectors and tasks was the result of a rebalance that contained a new assignment. Therefore the view of the running assignment was kept consistent outside the call to `RebalanceListener#onRevoke`. However, after KAFKA-9184 the need appeared for the worker to revoke tasks voluntarily and proactively without having received a new assignment.   This commit will allow the worker to restart tasks that have been stopped as a result of voluntary revocation after a rebalance reassigns these tasks to the work.   The fix is tested with an integration test but we should consider adding coordinator tests that now that the logic of the worker coordinator includes revocation of tasks.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","kkonstantine","2020-06-05T06:54:08Z","2020-06-05T22:56:07Z"
"","8902","KAFKA-10179: Pass correct changelog topic to state serdes","Until now we always passed the default changelog topic name to the state serdes. However, for optimized source tables and global tables the changelog topic is the source topic.  Most serdes do not use the topic name passed to them. However, if the serdes actually use the topic name for (de)serialization, e.g., when Kafka Streams is used with Confluent's Schema Registry, a org.apache.kafka.common.errors.SerializationException is thrown.  This commits passed the correct changelog topic to the state serdes of the metered state stores.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","cadonna","2020-06-19T15:04:12Z","2020-07-29T08:02:52Z"
"","8689","KAFKA-6145: Add unit tests to verify fix of bug KAFKA-9173","Unit tests - `shouldAssignActiveStatefulTasksEvenlyOverClientsAndStreamThreadsWithMoreStreamThreadsThanTasks()` - `shouldAssignWarmUpTasksIfStatefulActiveTasksBalancedOverStreamThreadsButNotOverClients()` - `shouldEvenlyAssignActiveStatefulTasksIfClientsAreWarmedUpToBalanceTaskOverClients()` verify that bug KAFKA-9173 is fixed with the new `HighAvailabilityTaskAssignor`.  `shouldAssignActiveStatefulTasksEvenlyOverClientsAndStreamThreadsWithMoreStreamThreadsThanTasks()` ensures that tasks are evenly assigned over clients when all overprovisioned clients join simultaneously.  `shouldAssignWarmUpTasksIfStatefulActiveTasksBalancedOverStreamThreadsButNotOverClients()` ensures that warm-up tasks are assigned to two new clients that join the group although the assignment is already balanced over stream threads.  `shouldEvenlyAssignActiveStatefulTasksIfClientsAreWarmedUpToBalanceTaskOverClients()` ensures that stateful active tasks are balanced over previous and warmed-up client although it the previous assignment is balanced over stream threads.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","cadonna","2020-05-18T22:22:12Z","2020-05-20T08:07:04Z"
"","9312","KAFKA-10505: Fix parsing of generation log string.","Two tests fails with the same reason: ```   File ""/opt/kafka-dev/tests/kafkatest/tests/streams/streams_upgrade_test.py"", line 533, in extract_highest_generation     return int(found_generations[-1]) ValueError: invalid literal for int() with base 10: ""Generation{generationId=6,memberId='StreamsUpgradeTest-8a6ac110-1c65-40eb-af05-8bee270f1701-StreamThread-1-consumer-207de872-6588-407a-8485-101a19ba2bf0',protocol='stream'}\n"" ``` ```   File ""/opt/kafka-dev/tests/kafkatest/tests/streams/streams_static_membership_test.py"", line 86, in test_rolling_bounces_will_not_trigger_rebalance_under_static_membership     generation = int(generation) ValueError: invalid literal for int() with base 10: ""Generation{generationId=5,memberId='consumer-A-2-3e9cc50c-9835-4772-b282-29e07b2f9ad6',protocol='stream'}\n"" ```  This PR fix the above errors by extracting the correct number from the log string.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","nizhikov","2020-09-21T08:24:02Z","2020-09-27T03:43:46Z"
"","8962","KAFKA-10166: checkpoint recycled standbys and ignore empty rocksdb base directory","Two more edge cases I found producing extra TaskcorruptedException while playing around with the failing eos-beta upgrade test (sadly these are unrelated problems, as the test still fails with these fixes in place).  1. Need to write the checkpoint when recycling a standby: although we do preserve the changelog offsets when recycling a task, and should therefore write the offsets when the new task is itself closed, we do NOT write the checkpoint for uninitialized tasks. So if the new task is ultimately closed before it gets out of the CREATED state, the offsets will not be written and we can get a TaskCorruptedException 2. With the change in task locking to address some Windows-related nonsense (am I remembering that correctly?), we don't delete entire task directories but just clear the inner state. With EOS, during initialization we check if the state directory is non-empty and the checkpoint is missing, and throw a TaskCorrupted if so. But just opening a rocksdb store creates a `rocksdb` base dir in the task directory, so the `taskDirIsEmpty` check always fails and we always throw TaskCorrupted even if there's nothing there. We can fix this for rocksdb (and custom stores) by searching through the task directory for any actual contents: we just do a BFS looking for any file that isn't itself a directory or sst file specifically if rocksdb  Note: fix 2 is not perfect but it helps. It's not a correctness issue, just an annoyance.","closed","","ableegoldman","2020-06-30T22:30:47Z","2020-07-07T19:12:03Z"
"","8861","MINOR: clean up unused checkstyle suppressions for Streams","Turns out there are a number of checkstyle suppressions that aren't being actively used. Did a quick scan by removing everything and running checkstyle, then left in only those that produced an error.  Should be able to further remove some TaskManager suppressions once [pull/8856](https://github.com/apache/kafka/pull/8856) is merged","closed","streams,","ableegoldman","2020-06-12T21:10:03Z","2020-06-26T22:40:24Z"
"","8738","MINOR: remove unnecessary timeout for admin request","Turns out `future.get()` actually does apply the admin's `default.api.timeout.ms` config internally, so we don't need to worry about providing a timeout of our own. Who knew","closed","","ableegoldman","2020-05-28T04:12:14Z","2020-06-01T17:50:16Z"
"","9436","MINOR: Check for active controller in UpdateFeatures request processing logic","Tuned the code a bit to check for active controller upfront in UpdateFeatures request processing logic, before the event is queued.  **Tests:**  Relying on existing test, particularly: `UpdateFeaturesTest.testShouldFailRequestIfNotController`.","closed","","kowshik","2020-10-14T18:59:40Z","2020-10-15T17:23:06Z"
"","9113","Fix trogdor coordinator client","Trogdor coordinator client is not able to shutdown remote coordinator, so fixed that issue.  ### Committer Checklist (excluded from commit message) - [x] Verify design and implementation  - [x] Verify test coverage and CI build status - [x] Verify documentation (including upgrade notes)","open","","amitbhoraniya","2020-08-03T11:28:06Z","2020-08-03T11:28:06Z"
"","9343","KAFKA-10332: Update MM2 refreshTopicPartitions() logic","Trigger task reconfiguration when: - topic-partitions are created or deleted on source cluster - topic-partitions are missing on target cluster  Co-authored-by: Mickael Maison  Co-authored-by: Edoardo Comar    ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","mimaison","2020-09-28T10:50:34Z","2020-10-19T16:25:43Z"
"","9147","MINOR: supervise TransactionalMessageCopier producer","transactions_test and group_mode_transactions_test have proven quite brittle around timeouts (see 67f5b5de77d67c02edb335737215312d099a1cac, e099b58df5b3e4f87173fc55880f9c343308739f, d9fe30dab0fc56318b012731c348ed1ddae2ec04, 07db26c20fcbccbf758591607864f7fd4bd8975f). This fights a losing battle, especially if we want to increase the types of nemesis checks that we want to perform on transaction support (e.g. iptables based partitioning). This PR creates a new producer when the prior one is in an unrecoverable state and still allows us to still test the EOS invariants required for this test.","open","","lbradstreet","2020-08-09T14:17:52Z","2020-08-12T00:40:24Z"
"","8645","KAFKA-9953","TransactionManager now supports caching of multiple consumerGroupCoordinator nodes avoiding the need find coordinators again when multiple consumer groups are used with a single transactional KafkaProducer  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","jwijgerd","2020-05-11T06:56:23Z","2020-08-17T09:45:07Z"
"","9477","MINOR: TopologyTestDriver should not require dummy parameters","TopologyTestDriver comes with a paper cut that it passes through a config requirement that application.id and bootstrap.servers must be configured. But these configs are not required in the context of TopologyTestDriver specifically. This change relaxes the requirement.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-10-21T22:07:48Z","2020-10-22T14:53:19Z"
"","9052","MINOR: TopologyTestDriver should not require dummy parameters","TopologyTestDriver comes with a paper cut that it passes through a config requirement that application.id and bootstrap.servers must be configured. But these configs are _not_ required in the context of TopologyTestDriver specifically. This change relaxes the requirement.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-07-22T15:44:17Z","2020-10-21T22:08:34Z"
"","9473","KAFKA-10545: Create topic IDs in ZooKeeper and Controller","Topic IDs must be created for all new topics and all existing topics that do not yet have a topic ID. In ZooKeeper, the ID is written to the TopicZNode, and in the controller, it is stored in a map.   This is a preliminary change before the second part of KAFKA-10545, which will propagate these IDs to brokers.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jolshan","2020-10-21T17:23:28Z","2021-01-27T06:38:33Z"
"","9464","KAFKA-10616: Always call prepare-commit before suspending for active tasks","Today for active tasks we the following active task suspension:  1) closeAndRevive in handleTaskCorruption. 2) closeClean in assignor#onAssignment. 3) closeClean in shutdown. 4) closeDirty in assignor#onAssignment. 5) closeDirty in listener#onPartitionsLost. 6) closeDirty in shutdown. 7) suspend in listener#onPartitionsRevoked.  Among those, 1/4/5/6 do not call prepareCommit which would `stateManager#flushCache` and may cause illegal state manager. This PR would require a prepareCommit triggered before suspend.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-10-20T17:55:21Z","2020-10-26T22:31:49Z"
"","8946","To avoid potential dead loop in KafkaConsumerProducerDemo","To avoid potential dead loop in KafkaConsumerProducerDemo  Motivation:  If main throws InterruptedException After consumerThread start , the consumerThread will not shutdown .  Modification:  Place latch.await(5, TimeUnit.MINUTES) in the try-finally block.  Result:  Advoid potential dead loop.","open","","prgitpr","2020-06-29T08:16:19Z","2020-07-09T02:18:30Z"
"","8945","To avoid potential  dead loop in  KafkaConsumerProducerDemo","To avoid potential  dead loop in  KafkaConsumerProducerDemo    Motivation:  If  main throws InterruptedException  After consumerThread start  , the  consumerThread  will not  shutdown  .  Modification:  Place latch.await(5, TimeUnit.MINUTES) in the try-finally block.  Result:  Advoid potential dead loop.","closed","","prgitpr","2020-06-29T08:06:39Z","2020-06-29T08:08:04Z"
"","9377","MINOR: Move `RaftRequestHandler` to `tools` package","To avoid confusion since it is only used by `TestRaftServer`, this PR moves `RaftRequestHandler` to the `tools` package and renames it to `TestRaftRequestHandler`.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-10-05T21:33:36Z","2020-10-06T00:15:28Z"
"","8550","KAFKA-9850 Move KStream#repartition operator validation during Topolo…","Tickets: KAFKA-9850  - Add  repartition operator validation during topology.build() - Move one repartition operator validation test from IntegrationTest to UnitTest","closed","streams,","zhaohaidao","2020-04-25T08:47:35Z","2020-05-14T00:36:13Z"
"","8665","KAFKA-9984 Should fail the subscription when pattern is empty","Ticket: KAFKA-9984 It indicates a configuration error when consumer subscribes an empty pattern: ```  [Consumer ...  ] Subscribed to pattern:  ''  ``` The `consumer.subscribe(pattern)` call should fail with illegal argument for this case.","closed","","zhaohaidao","2020-05-14T05:55:04Z","2020-05-14T21:19:07Z"
"","9304","KAFKA-10502:TimestampRouter may occur  threadlocal leak","Threadlocal  may can not set null,because it may create a memory leak, you can see the link: https://stackoverflow.com/questions/12424838/threadlocal-remove, so I think weather we can invoke thread local.remove instead it  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","huangyiminghappy","2020-09-18T17:10:21Z","2020-09-28T08:30:10Z"
"","8918","MINOR: Use debug level logging for noisy log messages in Connect","This very simply reduces the log level for these very frequently logged, very infrequently useful log messages to debug level. My experience operating these connectors is that these logs make reading info level logs quite cluttered. The MDC context certainly helps filter, but I think debug is more appropriate here -- if the log level were debug and someone wanted to promote it to info, that certainly would be an odd desire!  Debug is recommended here over Trace, since these do not really help trace specific messages or paths, and give kind of general debug information at a regular cadence (volume of these log messages does not grow with throughput). That said, if there is strong support for Trace I think that would be an improvement over Info, too.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","cyrusv","2020-06-23T18:48:01Z","2020-10-16T16:01:58Z"
"","9481","KAFKA-10284: Disable static membership test in 2.4","This test was fixed in https://github.com/apache/kafka/pull/9270 for 2.5+, but the code in 2.4 is too different to have a clean backport. Rather than risk introducing a worse bug in 2.4, and also because the probability of a new bugfix release for 2.4 seems low, I'm proposing just to disable this test in the 2.4 branch.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-10-22T18:13:23Z","2020-10-23T18:16:50Z"
"","9252","KAFKA-10241: Add test for message compatibility","This test compares the current working tree version of protocol/message json files with the same versions of those files as released in previous versions of Kafka (and in git HEAD). As such it can detect when a message format is  changed in an incompabile way, for example by adding a field to an existing  API version. The verification implements all the rules mentioned in the  protocol README.md plus a few others.  The test is factored into an abstract test class, which means it can be used in other places where message JSON is used. I added a test for Kafka Streams, for example.  Because the test works by looking at git tags it wouldn't be robust to certain refactorings (e.g. changing the directory in which the message JSON files reside). It also currently doesn't cope with refactoring field names.","open","","tombentley","2020-09-04T15:44:11Z","2020-09-17T06:16:50Z"
"","8602","KAFKA-9947; Ensure proper shutdown of components in `TransactionsBounceTest`","This test case should ensure that clients and the bounce scheduler get shutdown properly.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-05-02T00:09:24Z","2020-05-06T22:22:59Z"
"","8540","KAFKA-9127: don't create StreamThreads for global-only topology","This should fix the flaky `GlobalKTableIntegrationTest.shouldRestoreGlobalInMemoryKTableOnRestart` as well as address the issue on the ticket (avoid unnecessary group coordination overhead).  The deeper issue (and root cause of the test's flakiness) is that currently every StreamThread in a global-only topology will hit IllegalStateException upon trying to poll. Once they all died, the KafkaStreams instance goes into the ERROR state despite the global thread being alive and well.   The fix is to check whether the topology is global-only and overwrite the num.threads to 0 in that case. This PR also adds a check for topologies with nothing whatsoever, and throws an exception to fail fast.  edit: turns out this patch also happens to fix a regression introduced in 2.5, when we switched over to using collection subscription (for which an empty subscription is illegal) from the previous pattern subscription (for which an empty subscription is mysteriously considered fine). **This should be cherrypicked back to 2.5**","closed","streams,","ableegoldman","2020-04-23T21:25:30Z","2020-05-27T19:23:08Z"
"","9117","MINOR: Add 2.6.0 upgrade instructions that were added to kafka-site first rather than to the kafka repo","This should be backported to the `2.6` branch.  See #9118 for the fix to the 2.5.0 upgrade notes. See #9119 for the fix to the 2.7.0 upgrade notes.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","rhauch","2020-08-04T03:12:46Z","2020-08-04T03:20:53Z"
"","8744","MINOR: Update documentation.html to refer to 2.5","This should be backported to the `2.5` branch, which currently refers to 2.4.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rhauch","2020-05-28T17:33:35Z","2020-05-28T17:52:05Z"
"","8926","KAFKA-10166: always write checkpoint before closing an (initialized) task","This should address at least some of the excessive TaskCorruptedExceptions we've been seeing lately. Basically, at the moment we only commit tasks if `commitNeeded` is true -- this seems obvious by definition. But the problem is we do some essential cleanup in `postCommit` that should always be done before a task is closed:  1. clear the PartitionGroup 2. write the checkpoint  2 is actually fine to skip when `commitNeeded = false` with ALOS, as we will have already written a checkpoint during the last commit. But for EOS, we _only_ write the checkpoint before a close -- so even if there is no new pending data since the last commit, we have to write the current offsets. If we don't, the task will be assumed dirty and we will run into our friend the TaskCorruptedException during (re)initialization.  To fix this, we should just always call `prepareCommit` and `postCommit` at the TaskManager level. Within the task, it can decide whether or not to actually do something in those methods based on `commitNeeded`.   One subtle issue is that we still need to avoid checkpointing a task that was still in CREATED, to avoid potentially overwriting an existing checkpoint with uninitialized empty offsets. Unfortunately we always suspend a task before closing and committing, so we lose the information about whether the task as in CREATED or RUNNING/RESTORING by the time we get to the checkpoint. For this we introduce a special flag to keep track of whether a suspended task should actually be checkpointed or not","closed","streams,","ableegoldman","2020-06-25T01:37:13Z","2020-06-26T22:13:16Z"
"","9119","MINOR: Add 2.7.0 upgrade instructions that are needed for every release","This should **not** be backported.  See #9118 for the fix to the 2.5.0 upgrade notes. See #9117 for the fix to the 2.6.0 upgrade notes.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","rhauch","2020-08-04T03:13:40Z","2020-08-04T03:15:36Z"
"","8662","HOTFIX: skip listOffsets request for newly created changelog topics","This seems to be the final piece in the EosBetaUpgradeTest flakiness puzzle. From time to time the listOffsets request would fail during the initial startup rebalance, causing a probing rebalance to be scheduled for 10 min later (rather than immediately after). The assignor was newly creating the changelogs and then almost immediately calling `listOffsets` which then failed as the internal topics were not yet ready.  To avoid this race condition, we keep track of which changelogs we just created and skip fetching the end offsets for them. If a changelog did not exist before this moment, we can safely assume that its end offset is zero.","closed","","ableegoldman","2020-05-12T22:45:01Z","2020-05-15T01:01:08Z"
"","9118","MINOR: Restore 2.5.0 upgrade instructions that were added to kafka-site rather than kafka repo","This section was added to the [kafka-site repository](https://github.com/apache/kafka-site/pull/260#pullrequestreview-460468503) as part of the 2.5.0 release, but it should have been added to this repository. (The kafka-site for each release is generated from this repository.)  This should be backported to the `2.6` and `2.5` branches so that future versions on those branches will be correct.  See #9117 for the fix to the 2.6.0 upgrade notes. See #9119 for the fix to the 2.7.0 upgrade notes.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","rhauch","2020-08-04T03:13:31Z","2020-08-04T03:20:35Z"
"","9197","Revert KAFKA-9309: Add the ability to translate Message to JSON","This reverts commit bf6dffe93bbe0fe33ad076ebccebb840d66b936d","closed","","cmccabe","2020-08-18T19:46:28Z","2020-08-19T18:39:48Z"
"","8868","Revert ""KAFKA-9983: KIP-613: add INFO level e2e latency metrics (#8697)""","This reverts commit 83c616f70694637627edb6b1215738c78b74a50d.  The percentiles metrics seem to be leaking memory and caused our soak applications to hit OOM and crash several times. We should revert the metrics altogether (including the seemingly non-problematic min/max e2e latency metrics) while we investigate the root cause. Above all we want to make sure that 2.6 is stable","closed","","ableegoldman","2020-06-13T20:28:47Z","2020-06-17T23:25:50Z"
"","8595","KAFKA-8410: Revert Part 1: processor context bounds (#8414)","This reverts commit 29e08fd2c2d3349ba5cbd8fe5a9d35a0cea02b85. There turned out to be more than expected problems with adding the parameter list.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-04-30T22:11:36Z","2020-05-01T19:26:46Z"
"","9366","KAFKA-10571 Replace blackout with backoff for KIP-629","This replaces code and comment occurrences as described in the KIP","closed","","xvrl","2020-10-02T20:46:06Z","2020-10-12T21:09:07Z"
"","8810","MINOR: Change the order that Connect calls `config()` and `validate()`","This reorders two existing checks to avoid validating the configuration if the connector doesn't even have a ConfigDef.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","rhauch","2020-06-05T15:10:21Z","2020-06-05T20:02:12Z"
"","9440","MINOR: Upgrade to gradle 6.7","This release includes a key fix: * Zinc leaks its dependencies to user classpath (https://github.com/gradle/gradle/issues/14168)  Release notes: https://docs.gradle.org/6.7/release-notes.html  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-10-15T08:05:29Z","2020-10-15T14:54:44Z"
"","9081","KAFKA-10309: KafkaProducer's sendOffsetsToTransaction should not block infinitively","This PR will change KafkaProducer#sendOffsetsToTransaction to be affected by max.block.ms to avoid blocking infinitively.","closed","","sasakitoa","2020-07-26T15:55:24Z","2020-07-29T22:38:28Z"
"","8525","KAFKA-9885; Evict last members of a group when the maximum allowed is reached","This PR updates the algorithm which limits the number of members within a group (`group.max.size`) to fix the following two issues: 1. As described in KAFKA-9885, we found out that multiple members of a group can be evicted if the leader of the consumer offset partition changes before the group is persisted. This happens because the current evection logic always evict the first member rejoining the group. 2. We also found out that dynamic members, when required to have a known member id, are not always limited. The caveat is that the current logic only considers unknown members and uses the group size, which does not include the so called pending members, to accept or reject a member. In this case, when they rejoins, they are not unknown member anymore and thus could bypass the limit. See `testDynamicMembersJoinGroupWithMaxSizeAndRequiredKnownMember` for the whole scenario.  This PR changes the logic to address the above two issues and extends the tests coverage to cover all the member types.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-04-21T09:09:08Z","2020-10-06T20:10:00Z"
"","8522","KAFKA-9868: Reduce transaction log partitions for embed broker","This PR tries to fix the flaky EOSUncleanShutdownIntegrationTest.shouldWorkWithUncleanShutdownWipeOutStateStore by making the bootstrapping of the test to be less painful with fewer number of partitions of txn log.  The integration test time on local also reduced one second.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","abbccdda","2020-04-20T20:45:45Z","2020-04-21T15:24:25Z"
"","9074","KAFKA-10287: PROPOSAL: safe offset tracking","This PR should be targeted to trunk, but it's not a trivial task. I just wanted to propose this approach.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-07-24T20:24:17Z","2020-08-17T14:39:07Z"
"","8613","KAFKA-6145: Set HighAvailabilityTaskAssignor as default in streams_upgrade_test.py","This PR sets HighAvailabilityTaskAssignor as default task assignor in streams_upgrade_test.py. The verification of the test needed to be modified to because the HighAvailabilityTaskAssignor surfaced a flakiness in the test. More precisely, the verifications assume that the last client that is bounced joins the group before the other two clients are able to rebalance without the last client. This assumption does not always hold.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","cadonna","2020-05-04T14:44:18Z","2020-05-20T08:07:04Z"
"","8954","MINOR; Move quota integration tests to using the new quota API.","This PR refactors the various quota integration tests in the `kafka.api` package and migrates them to using the new quota API instead of writing the quota to ZK directly.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-06-30T09:05:33Z","2020-07-21T14:56:45Z"
"","9098","KAFKA-9924: Prepare RocksDB and metrics for RocksDB properties recording","This PR refactors the RocksDB store and the metrics infrastructure in Streams  in preparation of the recordings of the RocksDB properties specified in KIP-607.  The refactoring includes: - wrapper around `BlockedBasedTableConfig` to make the cache accessible to the     RocksDB metrics recorder - RocksDB metrics recorder now takes also the DB instance and the cache in addition    to the statistics - The value providers for the metrics are added to the RockDB metrics recorder also if    the recording level is INFO. - The creation of the RocksDB metrics recording trigger is moved to `StreamsMetricsImpl`      ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","cadonna","2020-07-29T11:46:15Z","2020-08-13T19:40:45Z"
"","8769","KAFKA-10074: Improve performance of `matchingAcls`","This PR reduces allocations by using a plain old `foreach` in `matchingAcls` and improves `AclSeqs.find` to only search the inner collections that are required to find a match (instead of searching all of them).  A recent change (90bbeedf52) in `matchingAcls` to remove `filterKeys` in favor of filtering inside `flatMap` caused a performance regression in cases where there are large number of topics, prefix ACLs and TreeMap.from/to filtering is ineffective. In such cases, we rely on string comparisons to exclude entries from the ACL cache that are not relevant.  This issue is not present in any release yet, so we should include the simple fix in the 2.6 branch.  The original benchmark did not show a performance difference, so I adjusted the benchmark to stress the relevant code more. More specifically, `aclCacheSnapshot.from(...).to(...)` returns nearly 20000 entries where each map value contains 1000 AclEntries. Out of the 200k AclEntries, only 1050 are retained due to the `startsWith` filtering.  This is the case where the implementation in master is least efficient when compared to the previous version and the version in this PR.  The adjusted benchmark results for testAuthorizer are 4.532ms for master, 2.903ms for the previous version and 2.877ms for this PR. Normalized allocation rate was 593 KB/op for master, 597 KB/op for the previous version and 101 KB/s for this PR. Full results follow:  master with adjusted benchmark: ``` Benchmark                                                                 (aclCount)  (resourceCount)  Mode  Cnt          Score          Error   Units AclAuthorizerBenchmark.testAclsIterator                                           50           200000  avgt    5        680.805 ±       44.318   ms/op AclAuthorizerBenchmark.testAclsIterator:·gc.alloc.rate                            50           200000  avgt    5        549.879 ±       36.259  MB/sec AclAuthorizerBenchmark.testAclsIterator:·gc.alloc.rate.norm                       50           200000  avgt    5  411457042.000 ±     4805.461    B/op AclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Eden_Space                   50           200000  avgt    5        331.110 ±       95.821  MB/sec AclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Eden_Space.norm              50           200000  avgt    5  247799480.320 ± 72877192.319    B/op AclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Survivor_Space               50           200000  avgt    5          0.891 ±        3.183  MB/sec AclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Survivor_Space.norm          50           200000  avgt    5     667593.387 ±  2369888.357    B/op AclAuthorizerBenchmark.testAclsIterator:·gc.count                                 50           200000  avgt    5         28.000                 counts AclAuthorizerBenchmark.testAclsIterator:·gc.time                                  50           200000  avgt    5       3458.000                     ms AclAuthorizerBenchmark.testAuthorizer                                             50           200000  avgt    5          4.532 ±        0.546   ms/op AclAuthorizerBenchmark.testAuthorizer:·gc.alloc.rate                              50           200000  avgt    5        119.036 ±       14.261  MB/sec AclAuthorizerBenchmark.testAuthorizer:·gc.alloc.rate.norm                         50           200000  avgt    5     593524.310 ±       22.452    B/op AclAuthorizerBenchmark.testAuthorizer:·gc.churn.G1_Eden_Space                     50           200000  avgt    5        117.091 ±     1008.188  MB/sec AclAuthorizerBenchmark.testAuthorizer:·gc.churn.G1_Eden_Space.norm                50           200000  avgt    5     598574.303 ±  5153905.271    B/op AclAuthorizerBenchmark.testAuthorizer:·gc.churn.G1_Survivor_Space                 50           200000  avgt    5          0.034 ±        0.291  MB/sec AclAuthorizerBenchmark.testAuthorizer:·gc.churn.G1_Survivor_Space.norm            50           200000  avgt    5        173.001 ±     1489.593    B/op AclAuthorizerBenchmark.testAuthorizer:·gc.count                                   50           200000  avgt    5          1.000                 counts AclAuthorizerBenchmark.testAuthorizer:·gc.time                                    50           200000  avgt    5         13.000                     ms ```  master with filterKeys like 90bbeedf52 and adjusted benchmark: ``` Benchmark                                                                 (aclCount)  (resourceCount)  Mode  Cnt          Score          Error   Units AclAuthorizerBenchmark.testAclsIterator                                           50           200000  avgt    5        729.163 ±       20.842   ms/op AclAuthorizerBenchmark.testAclsIterator:·gc.alloc.rate                            50           200000  avgt    5        513.005 ±       13.966  MB/sec AclAuthorizerBenchmark.testAclsIterator:·gc.alloc.rate.norm                       50           200000  avgt    5  411459778.400 ±     3178.045    B/op AclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Eden_Space                   50           200000  avgt    5        307.041 ±       94.544  MB/sec AclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Eden_Space.norm              50           200000  avgt    5  246385400.686 ± 82294899.881    B/op AclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Survivor_Space               50           200000  avgt    5          1.571 ±        2.590  MB/sec AclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Survivor_Space.norm          50           200000  avgt    5    1258291.200 ±  2063669.849    B/op AclAuthorizerBenchmark.testAclsIterator:·gc.count                                 50           200000  avgt    5         33.000                 counts AclAuthorizerBenchmark.testAclsIterator:·gc.time                                  50           200000  avgt    5       3266.000                     ms AclAuthorizerBenchmark.testAuthorizer                                             50           200000  avgt    5          2.903 ±        0.175   ms/op AclAuthorizerBenchmark.testAuthorizer:·gc.alloc.rate                              50           200000  avgt    5        187.088 ±       11.301  MB/sec AclAuthorizerBenchmark.testAuthorizer:·gc.alloc.rate.norm                         50           200000  avgt    5     597962.743 ±       14.237    B/op AclAuthorizerBenchmark.testAuthorizer:·gc.churn.G1_Eden_Space                     50           200000  avgt    5        118.602 ±     1021.202  MB/sec AclAuthorizerBenchmark.testAuthorizer:·gc.churn.G1_Eden_Space.norm                50           200000  avgt    5     383359.632 ±  3300842.044    B/op AclAuthorizerBenchmark.testAuthorizer:·gc.count                                   50           200000  avgt    5          1.000                 counts AclAuthorizerBenchmark.testAuthorizer:·gc.time                                    50           200000  avgt    5         14.000                     ms ```  This PR with adjusted benchmark: ``` Benchmark                                                                 (aclCount)  (resourceCount)  Mode  Cnt          Score          Error   Units AclAuthorizerBenchmark.testAclsIterator                                           50           200000  avgt    5        706.774 ±       32.353   ms/op AclAuthorizerBenchmark.testAclsIterator:·gc.alloc.rate                            50           200000  avgt    5        529.879 ±       25.416  MB/sec AclAuthorizerBenchmark.testAclsIterator:·gc.alloc.rate.norm                       50           200000  avgt    5  411458751.497 ±     4424.187    B/op AclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Eden_Space                   50           200000  avgt    5        310.559 ±      112.310  MB/sec AclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Eden_Space.norm              50           200000  avgt    5  241364219.611 ± 97317733.967    B/op AclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Old_Gen                      50           200000  avgt    5          0.690 ±        5.937  MB/sec AclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Old_Gen.norm                 50           200000  avgt    5     531278.507 ±  4574468.166    B/op AclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Survivor_Space               50           200000  avgt    5          2.550 ±       17.243  MB/sec AclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Survivor_Space.norm          50           200000  avgt    5    1969325.592 ± 13278191.648    B/op AclAuthorizerBenchmark.testAclsIterator:·gc.count                                 50           200000  avgt    5         32.000                 counts AclAuthorizerBenchmark.testAclsIterator:·gc.time                                  50           200000  avgt    5       3489.000                     ms AclAuthorizerBenchmark.testAuthorizer                                             50           200000  avgt    5          2.877 ±        0.530   ms/op AclAuthorizerBenchmark.testAuthorizer:·gc.alloc.rate                              50           200000  avgt    5         31.963 ±        5.912  MB/sec AclAuthorizerBenchmark.testAuthorizer:·gc.alloc.rate.norm                         50           200000  avgt    5     101057.225 ±        9.468    B/op AclAuthorizerBenchmark.testAuthorizer:·gc.count                                   50           200000  avgt    5            ≈ 0                 counts ```  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-06-01T02:06:06Z","2020-06-01T14:01:19Z"
"","8486","KAFKA-9840: Skip End Offset validation when the leader epoch is not reliable","This PR provides two fixes: 1. Complete offset validation if the leader epoch is not reliable 2. Refresh metadata when the return offset or epoch is not defined  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-04-14T17:03:56Z","2020-06-05T22:53:14Z"
"","8897","MINOR; Use the automated protocol for the Consumer Protocol's subscriptions and assignments","This PR moves the consumer protocol to using the automated protocol instead of using plain old structs.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-06-18T21:11:10Z","2020-09-25T16:22:24Z"
"","8523","Adding github whitelist","This PR is meant to add ConcurrencyPractitioner to the Jenkins whitelist so that this user can trigger tests.","closed","","ConcurrencyPractitioner","2020-04-20T21:24:49Z","2020-04-20T21:43:00Z"
"","8832","KAFKA-9377: Refactor StreamsPartitionAssignor Repartition Count Logic","This PR is mainly to make StreamsPartitionAssignor more efficient in repartition count logic.  **Method to be refactored:** ```     private void setRepartitionTopicMetadataNumberOfPartitions(final Map repartitionTopicMetadata,                                                                final Map topicGroups,                                                                final Cluster metadata) ```  What do we need to achieve? Calc the number of repartitions for all `repartitionSourceTopics` in all the `TopicsInfo` provided.  Rule:  1) If a topic is one of the sink topics of a TopicInfo, use the maximum of all the TopicInfo's source topic partitions as the number of partitions. 2) If a topic is contained by more than one TopicInfos, use the maximum of all these TopicInfos' source topic partitions as the number of partitions. To be more concrete, see the graph below, we will have(We use `tx` to refer to `NumOfPartition(TopicNode(""tx"") )` for simplicity):  ```      t3 = max(t1,t2)      t4 = max(max(t1,t2), max(t6,t7)) ``` In this PR, we create the `TopicNode` to represent the topic node.  The simple example of a graph built of `TopicNode` and `TopicsInfo` ```      TopicNode(""t1"")      TopicNode(""t2"")                       TopicNode(""t6"")          TopicNode(""t7"")                              \           /                                                            \                           /     TopicsInfo(source = (t1,t2), sink = (t3,t4))                    TopicsInfo(source = (t6,t7),sink = (t4))                                 /           \                                                                        /                              /                 \                                                          /                           /                        \                                           /                       /                                \                           /                  /                                       \            /      TopicNode(""t3"")                      TopicNode(""t4"")             \      TopicsInfo(source = (t3), sink = ()) ```  How do we achieve it? We can solve this by recursion with memoization. 1) Build the graph constructed with `TopicNode` and `TopicsInfo`, collect all the topics that need to calculate repartition count  2) For all the topics to be calculated, find the corresponding `TopicNode`, use the maximum of all its upstream `TopicsInfo` number of partitions as its number of partitions. 3) For a given `TopicsInfo`, use the maximum of all its `sourceTopics` number of partitions as its number of partitions. So basically it's a mutual recursion. 4) For the topics that have no upstream `TopicInfo`, it should be the ending of the recursion and we can find the partition count of these topics in the parameter `metadata`.  **NB:** 1) We didn't mention the memoization part in the above algo description, but we have it in the impl for efficiency.  **Assumptions(my understanding, please correct me if it is not the case ):** 1) There should be no cycle dependency 2) All the `TopicsInfo` will have non-empty `sourceTopics`, but some `TopicsInfo` may have empty `sinkTopics`, we can deduce that the top level node in the graph must be `TopicNode`, so we can definitely terminate the recursive function.     ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","streams,","feyman2016","2020-06-08T14:50:02Z","2020-07-25T05:44:48Z"
"","8589","KAFKA-9146: KIP-571 Add option to force delete active members in StreamsResetter","This PR is mainly to enhance https://issues.apache.org/jira/browse/KAFKA-9146.  - `KafkaAdminClient#removeMembersFromConsumerGroup` now support ""removeAll"" members in a given group - New cmdline option: --force for StreamsResetter is introduced, if --force specified when using the StreamsResetter, then all the active static/dynamic members will be removed.  Related KIP: KIP-571: https://cwiki.apache.org/confluence/display/KAFKA/KIP-571%3A+Add+option+to+force+remove+members+in+StreamsResetter ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","feyman2016","2020-04-30T06:38:57Z","2020-06-12T23:09:44Z"
"","8757","KAFKA-8104: Consumer cannot rejoin to the group after rebalancing","This PR is a backport of #7460 for 2.3. It also contains part of #7451.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-05-29T18:17:37Z","2020-05-29T21:25:42Z"
"","8758","KAFKA-8104: Consumer cannot rejoin to the group after rebalancing","This PR is a backport of #7460 for 2.2. It also contains part of #7451.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-05-29T20:05:27Z","2020-05-29T22:21:42Z"
"","8968","KAFKA-10164; Throttle Create Topic, Create Partition and Delete Topic Operations (KIP-599, Part II, Admin Changes)","This PR introduces the admin client changes related to KIP-599.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-07-01T15:59:54Z","2020-07-22T18:17:51Z"
"","9469","MINOR: replace FetchRequest.TopicAndPartitionData by Map.Entry","This PR includes two changes.  1. replace FetchRequest.TopicAndPartitionData by Map.Entry (to reduce duplicate code) 1. move ```batchByTopic``` to ```FetchResponse```   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-10-21T09:42:41Z","2020-10-27T12:25:13Z"
"","8605","MINOR: align the constructor of KafkaConsumer to KafkaProducer","This PR includes following changes.  ~1. remove KafkaProducer#propsToMap~ ~2. align the constructor of KafkaProducer and KafkaConsumer~  1. move KafkaProducer#propsToMap to Utils#propsToMap 1. apply Utils#propsToMap to constructor of KafkaConsumer  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-05-03T13:41:51Z","2020-05-31T21:36:28Z"
"","8604","KIP-597: MirrorMaker2 internal topics Formatters","This PR includes 3 MessageFormatters for MirrorMaker2 internal topics: - HeartbeatFormatter - CheckpointFormatter - OffsetSyncFormatter  This also introduces a new public interface org.apache.kafka.common.MessageFormatter that users can implement to build custom formatters.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","mimaison","2020-05-03T11:09:15Z","2020-07-03T11:58:29Z"
"","9110","MINOR: Ensure a reason is logged for all segment deletion operations","This PR improves the logging for segment deletion to ensure that a reason is logged for segment deletions via all code paths. It also updates the logging so we can log a reason for an entire batch of deletions instead of logging one message per segment.  Sample log output: ``` [2020-08-05 11:56:35,826] INFO [Log partition=foo-0, dir=/tmp/kafka-logs] Deleting segment LogSegment(baseOffset=219030, size=1042252, lastModifiedTime=1596653795000, largestRecordTimestamp=Some(1596653795374)) due to retention time 1ms breach based on the largest record timestamp in the segment (kafka.log.Log) [2020-08-05 11:56:35,826] INFO [Log partition=foo-0, dir=/tmp/kafka-logs] Deleting segment LogSegment(baseOffset=220035, size=1042252, lastModifiedTime=1596653795000, largestRecordTimestamp=Some(1596653795384)) due to retention time 1ms breach based on the largest record timestamp in the segment (kafka.log.Log) ... ```","closed","","dhruvilshah3","2020-08-01T02:21:28Z","2020-08-07T23:03:37Z"
"","8768","KAFKA-10023: Enforce broker-wide and per-listener connection creation…","This PR implements the part of KIP-612 that adds broker configurations for broker-wide and per-listener connection creation rate limits and enforces these limits.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","apovzner","2020-06-01T00:02:20Z","2020-08-17T13:35:28Z"
"","9386","KAFKA-10024: Add dynamic configuration and enforce quota for per-IP connection rate limits (KIP-612, part 2)","This PR implements the part of KIP-612 for adding IP throttling enforcement, and a ZK entity for configuring dynamic IP throttles.  I will add `kafka-configs` support as well as `KafkaApi` reconfiguration support in a follow-up PR.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","splett2","2020-10-06T20:44:56Z","2020-11-19T15:32:22Z"
"","8933","KAFKA-10163; Throttle Create Topic, Create Partition and Delete Topic Operations (KIP-599, Part I, Broker Changes)","This PR implements the broker side changes of KIP-599, except the changes of the Rate implementation which will be addressed separately.  The PR changes/introduces the following: - It introduces the protocol changes. - It introduces a new quota manager `ControllerMutationQuotaManager` which is another specialization of the `ClientQuotaManager`. - It enforces the quota in the `KafkaApis` and in the `AdminManager`. This part handles new and old clients as described in the KIP.  The PR is a good shape. The tests coverage is good. I will add few more unit tests for the api layer later one.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-06-26T12:43:58Z","2020-07-22T15:50:23Z"
"","9409","KAFKA-10599: Implement basic CLI tool for feature versioning system","This PR implements a basic CLI tool for feature versioning system. The [KIP-584 write up](https://cwiki.apache.org/confluence/display/KAFKA/KIP-584%3A+Versioning+scheme+for+features#KIP584:Versioningschemeforfeatures-Toolingsupport) has been updated to suit this PR. The following is implemented in this PR:  - `--describe`:     - Describe supported and finalized features.     - Usage: `$> ./bin/kafka-features.sh --bootstrap-server host1:port1, host2:port2 --describe [--from-controller] [--command-config ]`     - Optionally, use the `--from-controller` option to get features from the controller.  - `--upgrade-all`:      - Upgrades all features known to the tool to their highest max version levels.      - Usage: `$> ./bin/kafka-features.sh --bootstrap-server host1:port1, host2:port2 --upgrade-all [--dry-run] [--command-config ]`      - Optionally, use the `--dry-run` CLI option to preview the feature updates without actually applying them.  - `--downgrade-all`:     -  Downgrades existing finalized features to the highest max version levels known to this tool.     - Usage: `$> ./bin/kafka-features.sh --bootstrap-server host1:port1, host2:port2  --downgrade-all [--dry-run] [--command-config ]`.     - Optionally, use the `--dry-run` CLI option to preview the feature updates without actually applying them.    **Tests:** Added a new `FeatureCommand` integration test suite to test the CLI tool.","closed","","kowshik","2020-10-11T09:49:09Z","2020-10-19T16:24:27Z"
"","9413","MINOR: Fix typos in DefaultSslEngineFactory javadoc","This PR fixes two typos in the Javadoc for `DefaultSslEngineFactory.PemParser` class.","closed","","AndreyBozhko","2020-10-11T20:27:01Z","2020-10-15T13:49:17Z"
"","9272","KAFKA-10458; Updating controller quota does not work since Token Bucket","This PR fixes two issues that have been introduced by https://github.com/apache/kafka/pull/9114.  * When I switched the metric from `Rate` to `TokenBucket` in the `ControllerMutationQuotaManager`, I have mixed up the metrics. That broke the quota update path.  * When a quota is updated, the `ClientQuotaManager` updates the `MetricConfig` of the `KafkaMetric`. That update was not reflected into the `Sensor` so the `Sensor` was still using the `MetricConfig` that it has been created with.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-09-09T13:29:23Z","2020-09-14T19:24:54Z"
"","8857","KAFKA-10157: Fix broken tests due to InterruptedException from FinalizedFeatureChangeListener","This PR fixes the cause of failing tests mentioned in the jira:  - `kafka.network.DynamicConnectionQuotaTest`  - `kafka.api.CustomQuotaCallbackTest`  - `kafka.server.DynamicBrokerReconfigurationTest`  **Issue:** The call to `ChangeNotificationProcessorThread.queue.take()` could throw an `InterruptedException`.  While the queue is empty and the thread is blocking on taking an item from the queue, a concurrent call to `FinalizedFeatureChangeListener.close()` could interrupt the thread and cause an `InterruptedException` to be raised from `queue.take()`. In such a case, it is safe to ignore the exception since the thread is being shutdown. Definitely ignoring the `InterruptedException` for the above reason was the intent of the code that used the `ignoring` clause for the same. But it seems unfortunately the `ignoring` clause does not ignore `InterruptedException`, so that doesn't work for us. To confirm this theory, I found the following code in `scala.util.control.Exception.scala`: https://github.com/scala/scala/blob/v2.12.0/src/library/scala/util/control/Exception.scala#L167-L176.  **Fix:** The fix in this PR is to just not use the `ignoring` clause. We rely on existing mechanism in `ShutdownableThread` that ignores the exception during shutdown.  **Test plan:** Ran the unit and integration tests and found that the test failures are gone now. I will wait for CI to pass before merging this PR.","closed","","kowshik","2020-06-12T05:51:36Z","2020-06-12T21:17:20Z"
"","8671","KAFKA-9859 / Add topics generated by KTable FK join to internal topic matching logic","This PR fixes kafka-streams-application-reset tool. Before, kafka-streams-application-reset tool wasn't taking into account topics generated by KTable foreign key join operation.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tools,","lkokhreidze","2020-05-15T08:07:49Z","2020-05-20T17:03:58Z"
"","8568","KAFKA-9176: Retry on getting local stores from KafkaStreams","This PR fixes and improves two major issues:  1. When calling `KafkaStreams#store` we can always get an InvalidStateStoreException, and even waiting for Streams state to become RUNNING is not sufficient (this is also how OptimizedKTableIntegrationTest failed). So I wrapped all the function with a Util wrapper that captures and retries on that exception.  2. While trouble-shooting this issue, I also realized a potential bug in test-util's `produceKeyValuesSynchronously`, which creates a new producer for each of the record to send in that batch --- i.e. if you are sending N records with a single call, within that call it will create N producers used to send one record each, which is very slow and costly.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-04-28T04:58:55Z","2020-04-28T22:04:39Z"
"","8990","KAFKA-10243; ConcurrentModificationException while processing connection setup timeouts","This PR fixes a bug introduced in https://github.com/apache/kafka/pull/8683/.  While processing connection set up timeouts, we are iterating through the connecting nodes to process timeouts and we disconnect within the loop, removing the entry from the set in the loop that it iterating over the set. That raises an `ConcurrentModificationException` exception. The current unit test did not catch this because it was using only one node.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-07-07T09:54:32Z","2020-07-07T18:24:34Z"
"","9334","KAFKA-10516; Disable automatic retry of `THROTTLING_QUOTA_EXCEEDED` errors in the `kafka-topics` command (KIP-599)","This PR does two things: * As stated in KIP-599, we'd like to disable the automatic retry of `THROTTLING_QUOTA_EXCEEDED` errors in order to avoid letting the command hangs until `default.api.timeout.ms` is reached. * Change the default value of `ErrorMessage` to `null` in the `DeleteTopicsResponse`. I have noted that it defaults to an empty string at the moment. The Admin client only uses the default message when the `ErrorMessage` is `null` so we end up with an empty message provided back to the user when `ErrorMessage` is not explicitly set by the broker.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-09-24T08:47:58Z","2020-09-25T14:58:32Z"
"","8977","KAFKA-10162; Quota Enhancements (KIP-599)","This PR does two things:  1. It introduces `QuotaEnforcementType` which allows to choose when the quota enforcement is done within the `Sensor`. The default `Permissive` mode works as previously. It enforces the quota after having accounted the new value. The new `Strict` mode enforces the quota before and thus does not account the value if the quota is violated.  2. It introduces a new `SampledStat` named `TokenBucket`. Our current quota enforcement mechanism does not cope well with bursty workloads, especially when the burst is significantly larger than the quota. The reason is that a large recorded burst remains in the samples until it gets pasted the window. During this time, the computed rate remains the same until it gets dropped. The `TokenBucket` sampled stat alleviate this issue by decreasing each sample by Quota * the time between itself and the previous sample. This mimics the token bucket algorithm which gives back credits at every second.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-07-03T10:20:16Z","2020-10-06T20:08:26Z"
"","9053","MINOR: Revert KAFKA-10191 fix flaky StreamsOptimizedTest (#8913)","This PR depends on features of the reset tool that are not present in 2.5  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-07-22T16:22:47Z","2020-07-22T20:51:20Z"
"","8724","KAFKA-10040; Make computing the PreferredReplicaImbalanceCount metric more efficient","This PR changes the way `PreferredReplicaImbalanceCount` is computed. It moves from re-computing after the processing of each event in the controller to continuously maintaining the count.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-05-25T15:26:33Z","2020-06-05T05:32:07Z"
"","9042","(Back-up draft) redirection with version bump","This PR adds support for redirections of the following RPCs:   1. AlterConfigs   2. IncrementalAlterConfigs   3. AlterClientQuotas   4. CreateTopics  The specific changes include:  1. Use the flag `RequestContext.fromPrivilegedListener` to indicate whether a request is **possibly** coming from the inter broker communication, details in this [PR](https://github.com/apache/kafka/pull/9144). When a request is from a privileged listener, we would do a separate round of `CLUSTER_ACTION` authorization for a forwarding request.  2. Add initial principal name and initial client id to the request header for audit logging and throttling during request forwarding. Note that initial principal name should not be used for authorization purpose.  3. Add checks for forward request. The criteria is based on:   3.1 whether the request is from a privileged listener   3.2 whether the request header is equipped with initial principal name and initial client id.  4. Add a separate authorization of a forward request when the original authorization fails. Broker will authorize the request with CLUSTER_ACTION separately.  5. Checks for the mentioned RPCs to do the redirection. Will do the forwarding when the request is not forwarded and the current broker is not the controller.  6. Add broker IBP to guard against redirection. If IBP is low, any broker would still try to mutate ZK data with admin manager.  7. Bump AlterConfigs and AlterClientQuotas version by 1 to enable flexible versions for redirection fields in header.  We also built a template called `ForwardRequestHandler` to formulate the workflow of forward request handling. To make sure it works, we choose to firstly migrate the multi-resource RPCs such as AlterConfigs and CreateTopics.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-07-19T23:58:46Z","2020-11-19T00:53:00Z"
"","9103","KAFKA-10181: Use Envelope RPC to do redirection for (Incremental)AlterConfig, AlterClientQuota and CreateTopics","This PR adds support for redirections of the following RPCs:   1. AlterConfigs   2. IncrementalAlterConfigs   3. AlterClientQuotas   4. CreateTopics  The specific changes include:  1. Use the flag `RequestContext.fromPrivilegedListener` to indicate whether a request is **possibly** coming from the inter broker communication, details in this [PR](https://github.com/apache/kafka/pull/9144). When a request is from a privileged listener, we would do a separate round of `CLUSTER_ACTION` authorization for a forwarding request.  2. Add Envelope RPC for the request forwarding, and corresponding handling logic in KafkaApis  3. Add forwarding support in the BrokerToControllerChannelManager   4. Add a separate authorization of a forward request in the AuthorizableContext with a forwarding principal, and audit logging changes.  5. Checks for the mentioned RPCs to do the redirection. Will do the forwarding when the request is not forwarded and the current broker is not the controller.  6. Add broker IBP to guard against redirection. If IBP is low, any broker would still try to mutate ZK data with admin manager.  7. Add support for principal serialization as an extendable interface called `KafkaPrincipalSerde`  8. Built a template called `ForwardRequestHandler` to formulate the workflow of forward request handling   9. Add SSL truststore/keystore path augment/trim logic to trigger file reload upon ZK notification  10. Add IBP constraint tests for redirected RPCs since version 2.8, and KIP-500 flag to disable redirection.  Co-authored-by: Jason Gustafson   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-07-30T04:55:03Z","2020-11-04T22:21:45Z"
"","9378","MINOR: ACLs for secured cluster system tests","This PR adds missing broker ACLs required to create topics and SCRAM credentials when ACLs are enabled for a system test.   These ACLs were missed for system tests in the PR for KAFKA-10131 (https://github.com/apache/kafka/pull/9274/).  This PR also adds support for using PLAINTEXT as the inter broker security protocol when using SCRAM from the client in a system test with a secured cluster-- without this it would always be necessary to set both the inter-broker and client mechanisms to a SCRAM mechanism.","closed","","rondagostino","2020-10-06T00:58:47Z","2020-10-09T15:18:04Z"
"","9317","KAFKA-10509: Added throttle connection accept rate metric (KIP-612)","This PR adds metric to track throttle time of connection accept rate (when hitting connection attempt rate quota), which is a part of KIP-612: > kafka.network:type=socket-server-metrics,name=connection-accept-throttle-time,listener={listenerName} > Type: SampledStat.Avg > Description: Average throttle time due to violating per-listener or broker-wide connection acceptance rate quota on a given listener.  This PR also does 2 fixes: * Ensures that per-listener connection quotas are configured on broker startup (from static broker config, if one is set).  * Reduces quota values used in testDynamicListenerConnectionCreationRateQuota test, and the duration of `verifyConnectionRate` (that creates connections and verifies rate). We observed once that this test exhausted ephemeral port count. I reduced quotas used in this test by half, since this does not change the correctness of the test, while it also reduces the number of connections made by this test.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","apovzner","2020-09-22T03:18:42Z","2020-09-28T19:30:26Z"
"","9238","KAFKA-10444: Configure PR builds via Jenkinsfile","This PR adds a Jenkinsfile to the build to replace the existing jenkins.sh script.  The build makes use of the parallel directive to run the JDK 8, 11, and 15 builds in parallel. Each build will report status to PRs in Github including which tests failed.  Only users with write access to the repository (i.e., committers) will be able to modify Jenkinsfile through pull requests, otherwise the build will use the Jenkinsfile on the target branch.","closed","","mumrah","2020-09-01T15:16:26Z","2020-09-01T22:12:10Z"
"","9226","KAFKA-10444: Jenkinsfile testing","This PR adds a Jenkinsfile to the build to replace the existing jenkins.sh script.  The build makes use of the `parallel` directive to run the JDK 8, 11, and 14 builds in parallel. Each build will report separate statuses here in Github like:  ![image](https://user-images.githubusercontent.com/55116/91722487-51d10380-eb68-11ea-9c09-26736bcf8cd1.png)  Only users with write access to the repository (i.e., committers) will be able to modify Jenkinsfile through pull requests, otherwise the build will use the Jenkinsfile on the target branch.  Here's a build result showing our typical flaky tests https://ci-builds.apache.org/job/Kafka/job/kafka-pr/view/change-requests/job/PR-9226/57/#showFailuresLink","closed","","mumrah","2020-08-27T18:04:15Z","2020-09-01T15:16:46Z"
"","9302","KAFKA-10149: Allow auto preferred leader election when partitions are reassigning","This patch removes the check for reassigning partitions when determining whether to trigger automatic leader election. This check can cause problems during long-running reassignments because a crashed broker can leave the partition leaderships in an unexpectedly unbalanced state.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","bob-barrett","2020-09-18T05:58:37Z","2021-06-04T06:23:08Z"
"","9164","MINOR: Remove `PartitionHeader` abstraction from `FetchResponse` schema","This patch removes the `PartitionHeader` grouping from the `Fetch` response. With old versions of the protocol, there was no cost for this grouping, but once we add flexible version support, then it adds an extra byte to the schema for tagged fields with little apparent benefit.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-08-11T17:42:22Z","2020-08-11T23:38:08Z"
"","8493","MINOR: Serialize state change logs for handling LeaderAndIsr and StopReplica requests","This patch moves the state change logger logs for handling a LeaderAndIsr/StopReplica request inside the replicaStateChangeLock in order to serialize the logs. This helps to tell apart per-partition actions of concurrent LAIR/StopReplica requests in cases where requests pile up waiting on the lock","closed","","stanislavkozlovski","2020-04-15T15:08:03Z","2020-04-15T16:50:38Z"
"","9324","MINOR: Install ""iproute2"" explicitly in Dockerfile","this patch is similar to https://github.com/apache/kafka/commit/ee68b999c49cbbf514940a81282ff894e6cf50d9  the tool ""iproute2"" is required by ```round_trip_fault_test.py``` and it is not in openjdk:11  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-09-23T10:59:58Z","2020-12-17T11:10:26Z"
"","9038","KAFKA-10134: Check heartbeat timeout for poll fetches [DO NOT MERGE]","This patch is only for trouble shooting purposes.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-07-17T18:11:54Z","2020-08-25T02:23:06Z"
"","9371","KAFKA-10510: Validate replication factor consistency on reassignment","This patch introduces server-side validation that checks if applying requested reassignment won't lead to a situation where different partitions of the same topic have different replication factors.   If a given partition has a pending reassignment, then the target replication factor is used by the validator.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","piotrrzysko","2020-10-04T18:39:44Z","2020-10-06T17:27:37Z"
"","9163","KAFKA-10386; Fix flexible version support for `records` type","This patch fixes the generated serde logic for the 'records' type so that it uses the compact byte array representation consistently when flexible versions are enabled.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-08-11T16:34:01Z","2020-08-13T16:52:24Z"
"","8596","KAFKA-9821: persist followup rebalance in assignment and consolidate rebalance triggering mechanisms","This patch fixes KAFKA-9821 for Streams by persisting the required rebalance in the assignment. If a member fails and restarts it will receive its last assignment and notify the thread to trigger a new rebalance, even with static membership.  Note: in the consumer client, the member who has to _revoke_ some partitions is responsible for triggering the followup rebalance. Here we are actually encoding the required rebalance for the member who was supposed to _receive_ these partitions. Since this only signals to the client to request a rebalance upon the next poll in both cases, and the rebalance schedule is reset in `onAssignment`, this should not result in extra (unnecessary) rebalances even if one member lags the other in requesting this.  This patch also consolidates the two rebalancing triggering mechanisms currently used by the Streams partition assignor: the `AssignorError` and the newly introduced `nextScheduleRebalanceMs`. Since the latter encompasses the former, we can remove the `REBALANCE_NEEDED` assignor error and just schedule the next rebalance for `0L` ms to trigger it immediately. This has the nice side effect of removing the only recoverable AssignorError, so we no longer have to worry about handling this error and can just assume it to be fatal and shut down.","closed","streams,","ableegoldman","2020-05-01T01:33:14Z","2020-05-12T23:01:31Z"
"","9279","MINOR: Fix common struct `JsonConverter` and `Schema` generation","This patch fixes a couple problems with the use of the `StructRegistry`. First, it fixes registration so that it is consistently based on the typename of the struct. Previously structs were registered under the field name which meant that fields which referred to common structs resulted in multiple entries. Second, the patch fixes `SchemaGenerator` so that common structs are considered first.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-09-10T20:45:08Z","2020-09-17T21:37:52Z"
"","8822","KAFKA-10113; Specify fetch offsets correctly in LogTruncationException","This patch fixes a bug in the constructor of `LogTruncationException`. We were passing the divergent offsets to the super constructor as the fetch offsets. There is no way to fix this without breaking compatibility, but the harm is probably minimal since this exception was not getting raised properly until KAFKA-9840 anyway.  Note that I have also moved the check for unknown offset and epoch into `SubscriptionState`, which ensures that the partition is still awaiting validation and that the fetch offset hasn't changed. Finally, I made some minor improvements to the logging and exception messages to ensure that we always have the fetch offset and epoch as well as the divergent offset and epoch included.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-06-06T19:18:36Z","2020-06-19T01:10:06Z"
"","9155","MINOR: Ensure a single version of scala-library is used","This patch ensures we use a force resolution strategy for the scala-library dependency  I've tested this locally and saw a difference in the output: With the change (using 2.4 and the jackson library **2.10.5**): ``` ./core/build/dependant-libs-2.12.10/scala-java8-compat_2.12-0.9.0.jar ./core/build/dependant-libs-2.12.10/scala-collection-compat_2.12-2.1.2.jar ./core/build/dependant-libs-2.12.10/scala-reflect-2.12.10.jar ./core/build/dependant-libs-2.12.10/scala-logging_2.12-3.9.2.jar ./core/build/dependant-libs-2.12.10/scala-library-2.12.10.jar ``` Without (using 2.4 and the jackson library **2.10.5**): ```  find . -name 'scala*.jar' ./core/build/dependant-libs-2.12.10/scala-java8-compat_2.12-0.9.0.jar ./core/build/dependant-libs-2.12.10/scala-collection-compat_2.12-2.1.2.jar ./core/build/dependant-libs-2.12.10/scala-reflect-2.12.10.jar ./core/build/dependant-libs-2.12.10/scala-logging_2.12-3.9.2.jar ./core/build/dependant-libs-2.12.10/scala-library-2.12.12.jar ```","closed","","stanislavkozlovski","2020-08-10T15:33:16Z","2020-08-11T07:14:33Z"
"","9290","KAFKA-10487; Fetch response should return diverging epoch and end offset","This patch changes the Fetch response schema to include both the diverging epoch and its end offset rather than just the offset. This allows for more accurate truncation on the follower. This is the schema that was originally specified in KIP-595, but we altered it during the discussion.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-09-16T01:18:16Z","2020-09-16T16:05:09Z"
"","9275","KAFKA-10435; Fetch protocol changes for KIP-595","This patch bumps the `Fetch` protocol as specified by KIP-595: https://cwiki.apache.org/confluence/display/KAFKA/KIP-595%3A+A+Raft+Protocol+for+the+Metadata+Quorum. The main differences are the following:  - Truncation detection  - Leader discovery through the response - Flexible version support  The most notable change is truncation detection. This patch adds logic in the request handling path to detect truncation, but it does not change the replica fetchers to make use of this capability. We are planning to do this separately.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip-500,","hachikuji","2020-09-09T21:27:56Z","2021-08-11T13:19:18Z"
"","9268","KAFKA-10442; Add transaction admin APIs for KIP-664","This patch adds support for the new transactional APIs from KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions#KIP664:Providetoolingtodetectandaborthangingtransactions-DescribeTransactions.   Note that this does not include support for the `--find-hanging` action. I will add this separately.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-09-08T18:00:47Z","2021-01-29T06:57:40Z"
"","9352","KAFKA-10533; KafkaRaftClient should flush log after appends","This patch adds missing flush logic to `KafkaRaftClient`. The initial flushing behavior is simplistic. We guarantee that the leader will not replicate above the last flushed offset and we guarantee that the follower will not fetch data above its own flush point. More sophisticated flush behavior is proposed in KAFKA-10526.  We have also extended the simulation test so that it covers flush behavior. When a node is shutdown, all unflushed data is lost. We were able to confirm that the monotonic high watermark invariant fails without the added `flush` calls.  This patch also piggybacks a fix to the `TestRaftServer` implementation. The initial check-in contained a bug which caused `RequestChannel` to fail sending responses because the disabled APIs did not have metrics registered. As a result of this, it is impossible to elect leaders.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-09-29T18:40:19Z","2020-10-13T15:59:03Z"
"","9447","MINOR: Fixed comment to refer to UpdateMetadataPartitionState","This part of the code is a little confusing, so I thought I should fix this comment.   When creating a builder for UpdateMetadataRequest, the topic name is set in UpdateMetadataPartitionState. For versions 5 and onward, the topic name is added to the UpdateMetadataTopicState, and this code does not null out the topic name in the   UpdateMetadataPartitionState when it does this.","closed","","jolshan","2020-10-15T23:53:01Z","2020-10-19T19:35:57Z"
"","8707","Simplify KafkaConsumer constructor logic","This mirrors how the KafkaProducer constructors are organised and reduce code duplication.  More specifically this PR makes the following changes without changing any behaviour or public API:  1. Move the helper method `propsToMap()` from `KafkaProducer` to `Utils` with the other similar helpers `mkMap()` and `mkProperties()`, as this is now both used by `KafkaConsumer` and `KafkaProducer`. 2. Move the `ConsumerConfig` instantiation to the constructor that actually does the work. 3. Remove the `addDeserializerToConfig()` that operates on `Properties` and it's two tests, as all of those are very similar to the ones that operate on `Map` instances. 4. Have the `KafkaConsumer` constructors that accept `Properties` parameter convert those early to `Map` instances.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","nresare","2020-05-21T12:49:27Z","2020-05-30T15:32:35Z"
"","8494","MINOR: Use streaming iterator with decompression buffer when building offset map","This makes it consistent with the `filterTo` methods.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-04-15T16:17:29Z","2020-04-16T13:00:44Z"
"","8774","KAFKA-10081: Remove an unused local variable to pass spotbugsMain check","This issue can also reproduce in local environment. I Investigated why the spotbugs failed, and found that there's a warning to an unused local variable. > Dead store to isFreshAssignment in org.apache.kafka.clients.consumer.internals.AbstractStickyAssignor.generalAssign(Map, Map)     ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-06-02T04:28:00Z","2020-06-02T23:13:01Z"
"","9101","KAFKA-10325: KIP-649 implementation","This is the initial implementation of [KIP-649](https://cwiki.apache.org/confluence/display/KAFKA/KIP-649%3A+Dynamic+Client+Configuration) which implements dynamic client configuration. This work is still in progress.  TODO:   1. Add supporting types to org.apache.kafka.common.config for the new network protocol instead of reusing the types in org.apache.kafka.common.quota.  2. Have clients register supported configs to an internal topic so that compatibility information and static client configs can be returned to the administrator or processed with an external tool (e.g. Apache Druid). Set a log retention time on the topic and send the retention time back to each client that requests dynamic configs. Have clients register supported configs every time they pull their dynamic configs on an interval equal to the log retention time so that only compatibility information of active clients is kept in the internal topic.  ### [Benchmarks](https://gist.github.com/dielhennr/08c956c85cba0b4bd0372ac0f0df5132)","open","","dielhennr","2020-07-29T22:39:10Z","2020-10-02T19:05:50Z"
"","9130","KAFKA-10492; Core Kafka Raft Implementation (KIP-595)","This is the core Raft implementation specified by KIP-595: https://cwiki.apache.org/confluence/display/KAFKA/KIP-595%3A+A+Raft+Protocol+for+the+Metadata+Quorum. We have created a separate ""raft"" module where most of the logic resides. The new APIs introduced in this patch in order to support Raft election and such are disabled in the server until the integration with the controller is complete. Until then, there is a standalone server which can be used for testing the performance of the Raft implementation. See `raft/README.md` for details.  Co-authored-by: Boyang Chen  Co-authored-by: Guozhang Wang    ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip-500,","hachikuji","2020-08-05T15:23:31Z","2021-08-11T13:19:18Z"
"","8745","MINOR: Update documentation.html to refer to 2.6","This is based upon #8744 for the 2.5 change.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rhauch","2020-05-28T17:35:31Z","2020-05-28T17:56:31Z"
"","9210","KAFKA-10369 [WIP] KIP-655 implementation","This is an incomplete, proof-of-concept implementation of [KIP-655](https://cwiki.apache.org/confluence/display/KAFKA/KIP-655:+Windowed+Distinct+Operation+for+Kafka+Streams+API) for the sake of discussion/review only.    ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","inponomarev","2020-08-23T22:42:22Z","2021-02-06T21:25:17Z"
"","9193","KAFKA-10281: [WIP] Add log compression analysis tool KIP-640","This is a starting point for the implementation of the tool proposed in [KIP-640](https://cwiki.apache.org/confluence/display/KAFKA/KIP-640%3A+Add+log+compression+analysis+tool).  I consider this to be a work in progress, though we've been using this tool internally for some time with success. I haven't included any tests with this initial pass on the implementation, but I will follow up on this as the discussion moves along.","open","","chrisbeard","2020-08-17T20:00:45Z","2020-08-17T20:00:45Z"
"","8499","[WIP] KAFKA-9590: Add configuration to limit number of partitions","This is a prototype (which works) for the Admin API path for creating topics and adding partitions to existing topics. The goal is to motivate the discussion of the KIP 578 (https://cwiki.apache.org/confluence/display/KAFKA/KIP-578%3A+Add+configuration+to+limit+number+of+partitions), so that reviewers have some more concrete details on approach.  For now, I have tested manually. Once the KIP is approved, I will write some unit and integration tests.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","grsubramanian","2020-04-16T10:13:02Z","2020-04-16T10:13:02Z"
"","8669","MINOR: consolidate processor context for active/standby","This is a prerequisite for [KAFKA-9501](https://github.com/apache/kafka/pull/8248/) and will also be useful for [KAFKA-9603](https://github.com/apache/kafka/pull/8661)  There should be no logical changes here: the main difference is the removal of `StandbyContextImpl` in preparation for contexts to transition between active and standby.   Also includes some minor cleanup, eg pulling the ReadOnly/ReadWrite decorators out into a separate file.","closed","","ableegoldman","2020-05-14T22:18:52Z","2020-05-18T23:30:55Z"
"","8492","KAFKA-9739: Fix for 2.5 branch","This is a port of #8400 for the 2.5 branch  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","bbejeck","2020-04-15T14:53:55Z","2020-04-15T19:49:24Z"
"","8630","KAFKA-9969: Exclude ConnectorClientConfigRequest from class loading isolation","This is a partner to #6796 that applied the same change but for `ConnectorClientConfigOverridePolicy`.  Signed-off-by: Greg Harris   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","gharris1727","2020-05-07T20:07:15Z","2020-06-10T22:04:37Z"
"","8566","Fix minor code issue","This is a minor follower up PR of #8524 I wrap the line because I think it will be too long otherwise, more than 120 columns.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","leonardge","2020-04-27T22:29:48Z","2020-04-28T17:03:44Z"
"","9411","MINOR: Ensure broker advertises features only when versioning system is enabled","This is a fix that ensures the broker advertises features to ZK only when versioning system is enabled.","closed","","kowshik","2020-10-11T19:50:30Z","2020-10-11T19:50:44Z"
"","9412","MINOR: Ensure broker advertises features only when versioning system is enabled","This is a fix that ensures the broker advertises features to ZK only when the feature versioning system is enabled.","closed","","kowshik","2020-10-11T19:51:26Z","2020-10-12T17:19:00Z"
"","8881","KIP-557: Add emit on change support to Kafka Streams","This is a continuation of the previous PR #8254, and will move to implement emit on change support more extensively and cover most basic KTable operations.","closed","kip,","ConcurrencyPractitioner","2020-06-16T17:10:47Z","2021-06-30T17:45:30Z"
"","9467","KAFKA-10515: Properly initialize nullable Serdes with default values","This is a cherry pick of PR #9338 on branch 2.6.  Also introduced the notion of WrappingNullableSerdes (aligned to the concept of WrappingNullableSerializer and WrappingNullableDeserializer) and centralized initialization in WrappingNullables.  The added integeration test KTableKTableForeignKeyJoinDistributedTest tests whether all serdes are now correctly set on all stream clients.  Reviewers: John Roesler   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","thake","2020-10-21T04:39:17Z","2020-10-29T22:38:46Z"
"","9245","MINOR: Fix build scala 2.12 build after KAFKA-10020","This is a build fix after [KAFKA-10020](https://github.com/apache/kafka/pull/8955).   It looks like scala 2.12 and 2.13 have different import shadowing algorithms. On 2.12 explicit import of `org.apache.kafka.streams.scala.serialization.Serdes` has less priority than `org.apache.kafka.streams.scala.Serdes` in tests inside `org.apache.kafka.streams.scala` package.  I fixed this by using explicit renaming in import.","closed","","LMnet","2020-09-02T12:01:51Z","2020-09-02T17:50:42Z"
"","8599","HOTFIX: ambiguous reference of Properties#putAll in java 11 and scala…","this is a bug of scala 2.12 (https://github.com/scala/bug/issues/10418#issuecomment-524582693).   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-05-01T07:31:37Z","2020-05-01T09:39:53Z"
"","8989","KAFKA-10239: Make GroupInstanceId ignorable in DescribeGroups","This is a bug fix for older admin clients using static membership and call DescribeGroups. By making `groupInstanceId` ignorable, it would not crash upon handling the response.  Added test coverages for DescribeGroups, and some side cleanups.  Verified that the test `testGroupInstanceIdIgnorableInDescribeGroupsResponse` would fail without the `ignorable` flag: ``` org.apache.kafka.common.errors.UnsupportedVersionException: Attempted to write a non-default groupInstanceId at version 0 ```  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","core,","abbccdda","2020-07-06T21:10:53Z","2020-07-07T03:34:57Z"
"","9134","MINOR: set initial capacity for all array buffers in converting produ…","this is a bit optimization of converting producer responses. Those array buffers need initial capacity to avoid growing continually if the request carries a bunch of small messages and those messages are sent to different partitions.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-08-07T08:07:03Z","2020-09-26T07:53:38Z"
"","8688","MINOR: Introduce separate methods in KafkaApis for consumer and follower fetch handling","This is a bit odd in that it's not needed from a semantics perspective, but it would make it much easier to distinguish the cost of follower fetches versus consumer fetches when profiling.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-05-18T18:37:28Z","2020-05-18T18:58:17Z"
"","9329","Backport Jenkinsfile to 2.4 branch","This is a backport of the Jenkinsfile for 2.4 so we can use the PR builder job. Also includes one test which was failing to compile for Scala 2.11","closed","","mumrah","2020-09-23T15:25:28Z","2020-10-20T17:53:07Z"
"","8888","KAFKA-9150; DescribeGroup uses member assignment as metadata","This is a backport of @dajac's fix for KAFKA-9150. The regression was discovered in 2.3 but the fix was only merged to trunk and backported to 2.4. This PR proposes to also backport to the 2.3 branch.  Author: David Jacot   Reviewers: Jason Gustafson   Closes #7658 from dajac/KAFKA-9150  (cherry picked from commit 54f8d0c3fcd9c61126e005835c4f91756cb399e5) Signed-off-by: Dominic Evans","closed","","dnwe","2020-06-17T13:24:45Z","2020-06-24T13:34:31Z"
"","9150","KAFKA-9839; Broker should accept control requests with newer broker epoch","This is a backport of #8509.  A broker throws IllegalStateException if the broker epoch in the LeaderAndIsr/UpdateMetadataRequest/StopReplicaRequest is larger than its current broker epoch. However, there is no guarantee that the broker would receive the latest broker epoch before the controller: when the broker registers with ZK, there are few more instructions to process before this broker ""knows"" about its epoch, while the controller may already get notified and send UPDATE_METADATA request (as an example) with the new epoch. This will result in clients getting stale metadata from this broker.  With this PR, a broker accepts LeaderAndIsr/UpdateMetadataRequest/StopReplicaRequest if the broker epoch is newer than the current epoch.  Reviewers: David Jacot , Jason Gustafson   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","viktorsomogyi","2020-08-10T07:53:02Z","2022-01-10T13:23:44Z"
"","8594","KAFKA-9830: Backport ""Implement AutoCloseable in ErrorReporter and subclasses""","This is a backport of #8442 for the 2.0 and 2.1 branches.  In these versions, producer.close(Duration) does not exist, and producer.close(long, TimeUnit) is not deprecated. The tests are adjusted to use the older API.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","gharris1727","2020-04-30T21:55:40Z","2020-05-01T06:32:04Z"
"","8734","Backport KAFKA-9724 to 2.5","This is a backport of #8376 for 2.5  There were no conflicts during the cherry-pick","closed","","mumrah","2020-05-27T21:16:55Z","2020-05-27T21:24:18Z"
"","9370","KAFKA-9234: Added Nullability Annotations to Admin","This introduces a new **compile-only** dependency on [JetBrains Java Annotations](https://github.com/JetBrains/java-annotations). I decided to go for this particular dependency because it does not introduce any visible change to our users, nor does it introduce any additional overhead to the build process. If we get an annotation wrong, nothing bad happens because it is totally up to the code to actually validate things. (This also means that no KIP is required.)  One downside (some might say upside) is that absolutely everything must be annotated. I personally think this is a good thing because it forces people to actually think about `null`, same is the case in Kotlin where I also have to define whether `null` is permitted or not absolutely everywhere. Kotlin is also the main reason why I am interested in this, and also why I am interested in having this everywhere.  I was not able to test all possible NPE situations because some require the call to actually be executed. For those where I was able to prove that `null` is invalid we could think about adding `Objects.requireNonNull` guards right at the beginning. For all others it is simple, if we prove it we can add the guards too. This might be wasteful for collections (especially if those collections contain collections). A possible way out here is to use `assert` and live with the fact that some NPEs are thrown much later and will make it hard to find the source. This, sadly, is not Kotlin, so there is no easy way for this.  ## Bugfix ~This PR also contains a bug fix. `Admin.describeUserScramCredentials()` (without any arguments) is passing `null` to `Admin.describeUserScramCredentials(List)` which is permitted but leads to an NPE. Maybe there is another ticket for this, or nobody ever called this method (which would raise the question why it exists). In any event, I changed `KafkaAdminClient` to use an empty list if `null` is passed.~ See https://github.com/apache/kafka/pull/9374, I will update the description and this branch once the other PR is in trunk.  ----  **PS:** I am willing to continue this endeavor if it is decided to accept this PR (also if we decide to opt for another library that provides the ability to add null checks, e.g. Checker Framework, Lombok), simply because the experience in Kotlin with Kafka and the missing nullability information is horrid.  **PPS:** The JetBrains annotations contain additional annotations for [`@Unmodifiable`](https://javadoc.io/doc/org.jetbrains/annotations/latest/org/jetbrains/annotations/Unmodifiable.html), [`@ApiStatus.Internal`](https://javadoc.io/doc/org.jetbrains/annotations/latest/org/jetbrains/annotations/ApiStatus.Internal.html), [`@RegExp`](https://javadoc.io/doc/org.jetbrains/annotations/latest/org/intellij/lang/annotations/RegExp.html), and [many more](https://javadoc.io/doc/org.jetbrains/annotations/latest/index.html) that ease development work tremendously. I think it would be more than worthwhile to start using them as well if we decide to go with these annotations.  — [KAFKA-9234](https://issues.apache.org/jira/browse/KAFKA-9234)","closed","","Fleshgrinder","2020-10-04T16:31:15Z","2021-06-17T06:16:55Z"
"","8553","KAFKA-9891: Add integration test to replicate standby task failover","This integration test is trying to mimic the scenario where the active task writes an invalid record while the standby task replicates it under at_least_once. For EOS, it should not happen because the data is not committed.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-04-25T16:54:32Z","2020-06-19T21:52:31Z"
"","8972","MINOR: Update Netty to 4.1.50.Final","This includes important fixes. Netty is required by ZooKeeper if TLS is enabled.  I verified that the netty jars were changed from 4.1.48 to 4.1.50 with this PR, `find . -name '*netty*'`:  ```text ./core/build/dependant-libs-2.13.3/netty-handler-4.1.50.Final.jar ./core/build/dependant-libs-2.13.3/netty-transport-native-epoll-4.1.50.Final.jar ./core/build/dependant-libs-2.13.3/netty-codec-4.1.50.Final.jar ./core/build/dependant-libs-2.13.3/netty-transport-native-unix-common-4.1.50.Final.jar ./core/build/dependant-libs-2.13.3/netty-transport-4.1.50.Final.jar ./core/build/dependant-libs-2.13.3/netty-resolver-4.1.50.Final.jar ./core/build/dependant-libs-2.13.3/netty-buffer-4.1.50.Final.jar ./core/build/dependant-libs-2.13.3/netty-common-4.1.50.Final.jar ```  Note that the previous netty exclude no longer worked since we upgraded to ZooKeeper 3.5.x as it switched to Netty 4 which has different module names. Also, the Netty dependency is needed by ZooKeeper for TLS support so we cannot exclude it.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-07-01T20:10:33Z","2020-07-02T05:56:31Z"
"","8869","KAFKA-9781: Allow to specify a time zone when converting a timestamp to string","This implements the proposal from [KAFKA-9781].  TimeZone matters when converting a date to a string (and vice versa).  ### Committer Checklist (excluded from commit message) - [x] Verify design and implementation  - [x] Verify test coverage and CI build status - [x] Verify documentation (including upgrade notes)","closed","connect,","fml2","2020-06-13T21:17:44Z","2022-07-21T20:08:40Z"
"","9381","KIP-675: Convert KTable to a KStream using the previous value","This gives the possibility of converting a table into a stream using a mapper with the new and old values as arguments.  [KIP-675](https://cwiki.apache.org/confluence/display/KAFKA/KIP-675%3A+Convert+KTable+to+a+KStream+using+the+previous+value)  KTableImpl tests complete with new methods.  ","open","","javierfreire","2020-10-06T13:17:24Z","2020-10-08T16:29:10Z"
"","8885","KAFKA-8264: decrease the record size for flaky test","This flaky test exists for a long time, and it happened more frequently recently. (also happened in my PR testing!! :(  ) In KAFKA-8264 and KAFKA-8460, it described the issue for this test is that  > Timed out before consuming expected 2700 records. The number consumed was xxxx  I did some investigation. This test is to test:  > we consume all partitions if fetch max bytes and max.partition.fetch.bytes are low.   And what it did, is to create 3 topics and 30 partitions for each. And then, iterate through all 90 partitions to send 30 records for each. Finally, verify the we can consume all the records successfully.   What the error message saying is that it cannot consume all the records in time (might be the busy system) So, we can actually decrease the record size to avoid it. I checked all the error messages we collected in KAFKA-8264 and KAFKA-8460, the failed cases can always consume at least 1440 up (total is 2700). So, I set the records half size of the original setting, it'll become 1350 records in total. It should make this test more stable.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","showuon","2020-06-17T03:29:32Z","2020-07-23T04:33:22Z"
"","8678","Update Gradle to 6.4.1","This fixes critical bugs in Gradle 6.4:  * Regression: Different daemons are used between IDE and CLI builds for the same project * Regression: Main-Class attribute always added to jar manifest when using application plugin * Fix potential NPE if code is executed concurrently  More details: https://github.com/gradle/gradle/releases/tag/v6.4.1  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-05-17T01:57:06Z","2020-05-17T18:02:58Z"
"","8487","MINOR: Upgrade ducktape to 0.7.7","This fixes a version pinning issue where a transitive dependency had a major version upgrade that a dependency did not account for, breaking the build.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ewencp","2020-04-14T20:26:49Z","2020-04-15T00:02:25Z"
"","9376","MINOR: Remove `TargetVoters` from `DescribeQuorum`","This field is leftover from the early days of the KIP when it covered reassignment. Since the API is not exposed yet, should be no harm updating the first version.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-10-05T20:58:04Z","2020-10-07T16:27:17Z"
"","9125","KAFKA-10361: Windows batch files that use /bin/windows/kafka-run-class.bat fail with a class path error on fresh installation","This contribution is based on public information from https://medium.com/@praveenkumarsingh/confluent-kafka-on-windows-how-to-fix-classpath-is-empty-cf7c31d9c787   I license my version of the work to the project under the project's open source license.","open","","BackTrak","2020-08-04T21:59:11Z","2020-08-04T21:59:11Z"
"","9394","Fully automate dev setup with Gitpod","This commit implements a fully-automated development setup using Gitpod.io, an online IDE for GitLab, GitHub, and Bitbucket that enables Dev-Environments-As-Code. This makes it easy for anyone to get a ready-to-code workspace for any branch, issue or pull request almost instantly with a single click.   *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","acmck","2020-10-08T14:48:48Z","2020-10-08T14:51:55Z"
"","8809","MINOR: Fix javadoc warnings","This commit fixes javadoc warnings caused by missing imports.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","cadonna","2020-06-05T14:34:32Z","2020-06-08T10:03:17Z"
"","9232","KAFKA-9924: Add remaining property-based RocksDB metrics as described in KIP-607","This commit adds the remaining property-based RocksDB metrics as described in KIP-607, except for num-entries-active-mem-table, which was added in PR #9177.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","cadonna","2020-08-31T11:14:47Z","2020-09-03T07:47:59Z"
"","9177","KAFKA-9924: Add RocksDB metric num-entries-active-mem-table","This commit adds the first RocksDB metric that exposes RocksDB property num-entries-active-mem-table. More specifically it introduces  - code in StreamsMetricsImpl that is shared by all such metrics, - unit tests for the shared code - code that adds the metric - unit tests and intergration tests for the metric  This commit only contains one metric to keep the PR at a reasonable size. All other RocksDB metrics described in KIP-607 will be added in other PRs.","closed","","cadonna","2020-08-13T20:33:59Z","2020-08-31T11:51:30Z"
"","9395","KAFKA-9726: Add LegacyReplicationPolicy for MM2","This commit adds a new replication policy for MirrorMaker 2, `LegacyReplicationPolicy`. This policy imitates MirrorMaker 1 behavior of not renaming replicated topics. The exception is made for `heartbeats` topic, that is replicated according to `DefaultReplicationPolicy`.  Avoiding renaming topics brings a number of limitations, among which the most important one is the impossibility of detecting replication cycles. This makes cross-replication using `LegacyReplicationPolicy` effectively impossible. See `LegacyReplicationPolicy` Javadoc for details.  A new method `canTrackSource` is added to `ReplicationPolicy`. Its result indicates if the replication policy can track back to the source topic of a topic. It is needed to allow detecting target topics work when `LegacyReplicationPolicy` is used.  On the testing side, the tests have the same strategy as for `DefaultReplicationPolicy` with nicessary adjustments (e.g. no active/active replication is tested).  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ivanyu","2020-10-08T17:02:23Z","2021-05-07T09:21:19Z"
"","8633","KAFKA-9965: Incrementing counter cause uneven distribution with RoundRobinPartitioner","This code change provides fix for the JIRA ticket KAFKA-9965.   Added synchronized block to safely decrement the counter on the map when a new batch is created.","closed","","ashishroy077","2020-05-08T16:01:23Z","2020-07-17T08:59:17Z"
"","9231","KAFKA-10447: Migrate tools module to JUnit 5 and mockito","This change sets the groundwork for migrating other modules incrementally.  Main changes: - Replace `junit` 4.13 with `junit-jupiter` and `junit-vintage` 5.7.0-RC1. - All modules except for `tools` depend on `junit-vintage`. - `tools` depends on `junit-jupiter`. - Convert `tools` tests to JUnit 5. - Update `PushHttpMetricsReporterTest` to use `mockito` instead of `powermock` and `easymock` (powermock doesn't seem to work well with JUnit 5 and we don't need it since mockito can mock static methods). - Update `mockito` to 3.5.7. - Update `TestUtils` to use JUnit 5 assertions since `tools` depends on it.  Unrelated clean-ups: - Remove `unit` from package names in a few `core` tests. - Replace `try/catch/fail` with `assertThrows` in a number of places. - Tag `CoordinatorTest` as integration test. - Remove unnecessary type parameters when invoking methods and constructors.  Tested with IntelliJ and gradle. Verified that the following commands work as expected: * ./gradlew tools:unitTest * ./gradlew tools:integrationTest * ./gradlew tools:test * ./gradlew core:unitTest * ./gradlew core:integrationTest * ./gradlew clients:test  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-08-30T23:03:18Z","2020-09-10T23:14:43Z"
"","9008","KAFKA-9629 Use generated protocol for Fetch API","This change makes use of the generated protocols for FetchRequest and FetchResponse. The main challenge here was how to allow the transferrable bytes of the record set to be directly sent to the outgoing response without copying into a buffer.   The proposed solution is similar to the existing multi-send object used in [FetchResponse](https://github.com/apache/kafka/pull/9008/files#diff-703009e7d02b102b24c03145c2e0e170). However, a new writer class [RecordsWriter](https://github.com/apache/kafka/pull/9008/files#diff-779905aabf500cf13753614066c9d316) was introduced to allow interleaving of ByteBufferSend (for headers and other non-record fields) along with RecordsSend-s which implement the efficient byte transfer.  Another change introduced here is that FetchRequest and FetchResponse do not maintain their own copies of the fields from the message. Instead, they hold a reference to the generated message class (FetchRequestData and FetchResponseData). Read-only copies of different forms of the message data are created once open construction to allow for efficient access using the existing class methods.  For example, in FetchRequest we hold the FetchRequestData, but also compute and hold:  ```java     private final FetchRequestData fetchRequestData;      // These are immutable read-only structures derived from FetchRequestData     private final Map fetchData;     private final List toForget;     private final FetchMetadata metadata; ```   And in FetchResponse, we similarly hold:  ```java     private final FetchResponseData fetchResponseData;     private final LinkedHashMap> responseDataMap; ```  If we want, we could deprecate all the accessors on FetchRequest/FetchResponse and force callers to use the `#data()` method. This would eliminate the need for these additional data structures.  Finally, most of the other changes are fixing up tests that were actually using invalid default values for protocol messages (which are now enforced, thanks to the generated classes) as well as rectifying the JSON schema to match what the actual defined `Schema`s were (e.g., FETCH_RESPONSE_V11)","closed","","mumrah","2020-07-10T17:50:50Z","2020-07-30T17:29:40Z"
"","9429","KAFKA-10572 mirror-maker config changes for KIP-629","This change implements the KIP-629 changes for mirror maker configuration with backwards compatibility. cc @rhauch","closed","connect,","xvrl","2020-10-13T22:53:56Z","2020-10-20T14:15:15Z"
"","9265","Fix typo in name of output topic","This change fixes inconsistent naming for the output topic in the documentation.","closed","","mmerdes","2020-09-08T14:51:06Z","2020-10-18T15:19:50Z"
"","8614","KAFKA-7472: add the HeaderFrom and HeaderTo SMTs","This change brings the `HeaderFrom` and `HeaderTo` SMTs to complete [KIP-145](https://cwiki.apache.org/confluence/display/KAFKA/KIP-145+-+Expose+Record+Headers+in+Kafka+Connect) (as requested in [KAFKA-7472](https://issues.apache.org/jira/browse/KAFKA-7472))  The tests cover for the creation of key/value fields, of headers and their suppression. They also specify the behaviour of the SMTs in case of miss-configuration.    ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","connect,","DivLoic","2020-05-04T19:57:55Z","2020-05-04T20:33:05Z"
"","9427","backport KAFKA-10571","This change backports KAFKA-10571 (#9366) and #9398 to 2.7 for KIP-629  cc @gwenshap","closed","","xvrl","2020-10-13T19:46:23Z","2020-10-14T23:46:46Z"
"","9374","MINOR: Fix NPE in KafkaAdminClient.describeUserScramCredentials","This bug was detected as part of #9370. @rondagostino and I decided that this should be fixed right away and not until the other PR eventually gets merged (or not). I am not only properly handling `null` everywhere but also rewrote the function to be more readable (and more efficient, but I think this is not important here). I extended the existing test to go through all possible permutations of the users argument to make sure that we never get an NPE.","closed","","Fleshgrinder","2020-10-05T15:29:54Z","2020-10-26T16:22:05Z"
"","8644","KAFKA-9313: Set `use_all_dns_ips` as the new default for `client.dns.lookup` (KIP-602)","This applies to the producer, consumer, admin client, connect worker and inter broker communication.  `ClientDnsLookup.DEFAULT` has been deprecated and a warning will be logged if it's explicitly set in a client config.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","badaiaqrandista","2020-05-10T22:50:51Z","2020-06-04T13:26:03Z"
"","8923","KAFKA-6435: KIP-623 Add internal topics option to streamResetter","This allows users to specify which internal-topics the tool will attempt to delete instead of inferring it. ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","JoelWee","2020-06-24T20:04:27Z","2021-04-28T16:55:09Z"
"","9369","KAFKA-4715: Ignore case of CompressionType and OffsetResetStrategy","This allows the configuration values for CompressionType in the ProducerConfig and the OffsetResetStrategy in the ConsumerConfig to be specified regardless of their case.","closed","","Fleshgrinder","2020-10-03T16:25:42Z","2021-06-17T06:16:42Z"
"","9213","MINOR: add epoch lineage checks to system tests","This adds assertions to check that leader epoch lineages match between replicas. These have been added to system tests that involve broker restarts and that wait for replicas to rejoin the ISR by the end of the test.  I also moved wait_until_rejoin_isr from downgrade_test and upgrade_test  as the implementation was the same in each.","open","","lbradstreet","2020-08-24T16:49:51Z","2020-08-25T23:45:43Z"
"","9453","MINOR: Update jdk and maven names in Jenkinsfile","They were renamed in Apache Jenkins.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-10-19T14:14:06Z","2020-10-19T21:11:33Z"
"","8564","KAFKA-9921: disable caching on stores configured to retain duplicates","These two options are essentially incompatible, as caching will do nothing to reduce downstream traffic and writes when it has to allow non-unique keys (skipping records where the value is also the same is a separate issue, see [KIP-557](https://cwiki.apache.org/confluence/display/KAFKA/KIP-557%3A+Add+emit+on+change+support+for+Kafka+Streams)). But enabling caching on a store that's configured to retain duplicates is actually more than just ineffective, and currently causes incorrect results.  We should just log a warning and disable caching whenever a store is retaining duplicates to avoid introducing a regression. Maybe when 3.0 comes around we should consider throwing an exception instead to alert the user more aggressively.","closed","streams,","ableegoldman","2020-04-27T20:52:33Z","2020-05-01T00:27:56Z"
"","9305","MINOR: Backport fixes to ClientUtils.resolve tests to 2.5","These tests were fragile, so we made a temporary fix https://github.com/apache/kafka/pull/9294.  These changes need to be back-ported to previous versions.  The tests in question passed locally.","closed","","jolshan","2020-09-18T18:10:47Z","2020-10-20T14:00:22Z"
"","9307","MINOR: Backported changes to ClientUtils.resolve tests to 2.4","These tests were fragile, so we made a temporary fix https://github.com/apache/kafka/pull/9294  These changes need to be back-ported to previous versions.  The tests in question passed locally.","closed","","jolshan","2020-09-18T18:29:38Z","2020-10-08T12:37:48Z"
"","9088","sync docs for list of emitted metrics by MirrorMetrics","these metrics `record-rate` and `byte-count` are not listed here according to the MirrorMetrics source file:  https://github.com/apache/kafka/blob/3df5464fca06d36b806e50c9d6db047d9d612651/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorMetrics.java#L47-L95","closed","","d1egoaz","2020-07-27T18:42:13Z","2020-11-30T20:45:37Z"
"","8903","POC: dump tool for suppress buffer changelog","There's currently no good way to look into the changelog for a suppression buffer, since the format is a binary schema.  This POC tool would allow scanning over the changelog and parsing the records.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","streams,","vvcephei","2020-06-19T18:03:50Z","2020-06-19T19:25:31Z"
"","8791","AK to CCS merge for 03 june 2019","There was a version bump in AK to 2.7.0-SNAPSHOT. The merge needed to be applied manually.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","agg111","2020-06-03T06:32:24Z","2020-06-03T06:58:23Z"
"","8585","KAFKA-9938; Debug consumer should be able to fetch from followers","There was a minor regression in the fetch protocol introduced in 2.4 as part of the KIP-392 work. We should allow the ""debug consumer"" to read from follower regardless of the protocol version.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-04-29T19:47:46Z","2021-08-20T18:32:07Z"
"","8664","KAFKA-9716: Clarify meaning of compression rate metrics","There is some confusion over the compression rate metrics, as the meaning of the value isn't clearly stated in the metric description. In this case, it was assumed that a higher compression rate value meant better compression. This PR clarifies the meaning of the value, to prevent misunderstandings.  Alternative approaches that were considered were to either change the name of the metric or its implementation, but this would have a negative impact on those who are already making use of this metric.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rgroothuijsen","2020-05-13T23:57:02Z","2020-06-09T19:09:33Z"
"","9169","MINOR: the scheduler used to perform rebalance should have thread prefix","There is already a scheduler (see https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/server/KafkaServer.scala#L264) using default thread prefix so the others should define different thread name. Otherwise, it is hard to distinguish them by JVM profiler.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-08-12T14:10:57Z","2020-12-17T11:10:40Z"
"","9332","KAFKA-10511; Ensure monotonic start epoch/offset updates in `MockLog`","There is a minor difference in behavior between the epoch caching logic in `MockLog` from the behavior in `LeaderEpochFileCache`. The latter ensures that every new epoch/start offset entry added to the cache increases monotonically over the previous entries. This patch brings the behavior of `MockLog` in line.   It also simplifies the `assignEpochStartOffset` api in `ReplicatedLog`. We always intend to use the log end offset, so this patch removes the start offset parameter.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-09-24T00:10:39Z","2020-09-29T00:16:56Z"
"","9476","MINOR: Refactor RaftClientTest to be used by other tests","There is a lot of functionality in KafkaRaftClientTest that is useful for writing other tests. Refactor that functionality into another class that can be reused in other tests.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jsancio","2020-10-21T21:56:37Z","2020-10-23T16:19:17Z"
"","9351","KAFKA-10047: Unnecessary widening of (int to long) scope in FloatSerializer","There is a JIRA ticket requesting this small change (https://issues.apache.org/jira/browse/KAFKA-10047)  ### Committer Checklist (excluded from commit message) - [x] Verify design and implementation  - [x] Verify test coverage and CI build status - [x] Verify documentation (including upgrade notes)","open","","leosilvadev","2020-09-29T17:59:34Z","2020-09-29T19:53:39Z"
"","9435","KAFKA-10606: Disable auto topic creation for fetch-all-topic-metadata request","There is a bug that causes fetch-all-topic-metadata requests triggering auto topic creation. Details are described in KAFKA-10606. This is the simplest way to fix this bug on the broker side.","closed","","Lincong","2020-10-14T18:18:31Z","2020-12-09T15:31:55Z"
"","8944","KAFKA-10209: Fix connect_rest_test.py after the introduction of new connector configs","There are two new configs introduced by 371f14c3c12d2e341ac96bd52393b43a10acfa84 and 1c4eb1a5757df611735cfac9b709e0d80d0da4b3 so we have to update the expected configs in connect_rest_test.py  issue: https://issues.apache.org/jira/browse/KAFKA-10209  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","chia7712","2020-06-29T05:49:23Z","2020-10-16T05:39:14Z"
"","8907","MINOR: code cleanup for `VOut` inconsistent naming","There are two kind of naming of VOut in Streams module: VOut / Vout. This PR rename the naming of Vout to VOut.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vitojeng","2020-06-20T09:12:32Z","2020-07-26T02:38:36Z"
"","8871","MINOR: code cleanup for inconsistent naming","There are two kind of naming of valueSerde in Streams module: valSerde / valueSerde. No function has been changed in PR, only renamed **valSerde** to **valueSerde**.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vitojeng","2020-06-15T00:38:03Z","2020-07-24T01:09:46Z"
"","8484","MINOR: eliminate unnecessary partition lookups in fetch path","There are two cases in the fetch pass where a partition is unnecessarily looked up from the partition Pool, when one is already accessible. This will be a fairly minor improvement on high partition count clusters, but could be worth 1% from some profiles I have seen.","closed","","lbradstreet","2020-04-14T15:06:55Z","2020-04-15T16:24:30Z"
"","8789","MINOR: Fix the javadoc broken links of streams","There are some broken links of streams javadoc, for example: * ReadOnlyKeyValueStore * ReadOnlyWindowStore  Only javadoc is update.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","docs,","vitojeng","2020-06-03T02:27:13Z","2020-06-16T12:23:41Z"
"","8755","KAFKA-10069: Correctly remove user-defined ""predicate"" and ""negate"" configs from transformation properties","There are official configDef for both ""predicate"" and ""negate"" so we should remove user-defined configDef. However, current behavior does incorrect comparison so the duplicate key will destroy the following embed configDef.  https://issues.apache.org/jira/browse/KAFKA-10069  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","chia7712","2020-05-29T15:15:47Z","2020-10-16T05:46:09Z"
"","8538","MINOR: Pass `-release 8` to scalac and upgrade to Gradle 6.4","The version of Zinc included with Gradle 6.4 includes a fix for the blocker that was preventing us from passing `-release 8` to scalac.  Release notes for Gradle 6.4:  https://docs.gradle.org/6.4/release-notes.html  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-04-23T14:29:27Z","2020-05-06T05:20:34Z"
"","9479","KAFKA-10631: Handle ProducerFencedException on offset commit","The transaction manager does currently not handle producer fenced errors returned from a offset commit request.  This PR adds the handling of the producer fenced errors.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","cadonna","2020-10-22T16:03:29Z","2020-10-23T17:04:50Z"
"","8835","MINOR: reduce sizeInBytes for percentiles metrics","The total amount of memory per Percentiles metric is actually the sizeInBytes * number of samples, where the default number of samples is 2. There are also at least 2 Percentiles metrics per task (and more when there are multiple sources or multiple terminal nodes). So the total memory we allocate for the current e2e latency metrics is `4 * sizeInBytes * numTasks`  The current sizeInBytes we chose was 1MB. This is still not particularly large, but may add up and cause unnecessary pressure for users running on lean machines.  I reduced the size to 100kB and still found it accurate enough* so we may as well reduce the size so we don't have to worry. (*1,000 runs of the randomized test all passed, meaning it was accurate to within 25% of the expected value)","closed","streams,","ableegoldman","2020-06-09T02:48:34Z","2020-06-12T00:38:15Z"
"","8578","KAFKA-9875: Make integration tests more resilient","The ticket is for a flaky test that failed to clean up topics _after_ the test, which isn't strictly necessary for test success.  * alter the ""clean up after test"" method to never throw an exception   (after verifying it's always the last invocation inside a finally block,   so it won't break any test semantics) * consolidated the naming of all integration tests' app ids, topics, etc., by introducing    a new test utility to generate safe, unique, descriptive names.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-04-28T22:46:53Z","2020-04-29T22:11:54Z"
"","9286","KAFKA-10292: Set min.insync.replicas to 1 of __consumer_offsets","The test StreamsBrokerBounceTest.test_all_brokers_bounce() fails on 2.5 because in the last stage of the test there is only one broker left and the offset commit cannot succeed because the min.insync.replicas of __consumer_offsets is set to 2 and acks is set to all. This causes a time out and extends the closing of the Kafka Streams client to beyond the duration passed to the close method of the client.  This affects especially the 2.5 branch since there Kafka Streams commits offsets for each task, i.e., close() needs to wait for the timeout for each task. In 2.6 and trunk the offset commit is done per thread, so close() does only need to wait for one time out per stream thread.  I opened this PR on trunk, since the test could also become flaky on trunk and we want to avoid diverging system tests across branches.  A more complete solution would be to improve the test by defining a better success criteria.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","cadonna","2020-09-14T20:11:07Z","2020-09-16T07:03:51Z"
"","9181","KAFKA-9516; Increase timeout in testNonBlockingProducer to make it more reliable","The test has been timing out occasionally and it is on the first send on a producer, so increasing timeout to 30s similar to some of the other timeouts in BaseProducerSendTest.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rajinisivaram","2020-08-14T15:06:10Z","2020-08-16T09:30:04Z"
"","8555","KAFKA-9920:Fix NetworkDegradeTest.test_rate test error","The test case of kafkatest.tests.core.network_degrade_test.NetworkDegradeTest.test_rate. rate_limit_kbit=1000000.device_name=eth0.task_name=rate-1000-latency-50.latency_ms=50 failed. And the error log was ""Expected most of the measured rates to be within an order of magnitude of target 1000000. This means `tc` did not limit the bandwidth as expected."" It was because that the rate_limt didn't take immediately after starting.  Change-Id: I2de1d3fc696e11b411986bb2e3ce43f074fbac4a Signed-off-by: Jiamei Xie   *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jiameixie","2020-04-26T01:29:02Z","2022-05-24T03:28:00Z"
"","8894","KAFKA-9509: Increase timeout when consuming records to fix flaky test in MM2","The test `MirrorConnectorsIntegrationTest.testReplication` failed too often recently. It failed at least 6 times (I didn't check all failed builds) in today's(6/17) trunk build, and also failed my PR testing! I think it should be fixed soon to save developer's time.   The test is to test MM2 replication. And recently, it failed all because the Records were not replicated to primary/backup cluster yet, so that the consumer cannot retrieve the records in time.  In this PR, I add retries to these consumer.poll, to have 3 retries to poll the records. It should make the tests more stable.  Moreover, the assertion error message didn't display successfully because the `consume()` will throw exception directly and got displayed. After my change, the assertion error message can be displayed, and will let us know exactly which assertion failed.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-06-18T08:54:51Z","2020-06-29T20:22:09Z"
"","8667","KAFKA-9994: Handle task migrated inside corruption path","The TaskMigratedException should always be non-fatal and caught within the run loop. Adding try-catch for corrupted path as well is necessary.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","abbccdda","2020-05-14T17:44:39Z","2020-05-15T00:31:50Z"
"","8995","Restore stream-table duality description","The stream-table duality section was dropped inadvertently sometime after version 0.11.0, so this PR restores it.","closed","docs,","JimGalasyn","2020-07-08T19:31:10Z","2020-07-09T20:59:20Z"
"","8670","KAFKA-10001: Should trigger store specific callback if it is also a listener","The store's registered callback could also be a restore listener, in which case it should be triggered along with the user specified global listener as well.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","guozhangwang","2020-05-15T00:43:47Z","2020-05-15T18:27:06Z"
"","9277","MINOR: Fix JSON generation of nested structs with non-matching type/name","The schema specification allows a struct type name to differ from the field name. This works with the generated `Message` classes, but not with the generated JSON converter. The problem seems to be that the type name gets replaced with the field name when the struct is registered.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-09-09T23:55:00Z","2020-09-10T20:27:21Z"
"","9059","KAFKA-10300 fix flaky core/group_mode_transactions_test.py","the root cause is same to #9026 so I copy the approach of #9026 to resolve ```core/group_mode_transactions_test.py```  issue: https://issues.apache.org/jira/browse/KAFKA-10300  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-07-23T03:48:18Z","2020-07-23T22:59:58Z"
"","8653","MINOR: Correct MirrorMaker2 integration test configs for Connect internal topics","The replication factor for the Connect workers’ internal topics were incorrectly named and not actually used.  This only affects & fixes tests, and should be backported all the way back to the `2.4` branch.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","rhauch","2020-05-12T14:06:03Z","2020-05-21T18:04:09Z"
"","9124","MINOR: add additional shutdown log info","The purpose of this PR is to both enhance the visibility of shutdown progress for Kafka, as well as for the debugging purpose of a delayed process in between socket server close and eventually kafka server close.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-08-04T19:01:23Z","2020-08-05T05:07:17Z"
"","8793","KAFKA-9514; The protocol generator generated useless condition when a field is made nullable and flexible version is used","The protocol generator generates useless conditions when a field of type string is made nullable after the request has been converted to using optional fields.  As an example, we have make the field `ProtocolName` nullable in the `JoinGroupResponse`. The `JoinGroupResponse` supports optional fields since version 6 and the field is nullable since version 7. Under these conditions, the generator generates the following code:  ``` if (protocolName == null) {  if (_version >= 7) {    if (_version >= 6) {      _writable.writeUnsignedVarint(0);    } else {      _writable.writeShort((short) -1);   }  } else {    throw new NullPointerException();  } } ```  spotbugs raises an `UC_USELESS_CONDITION` because `_version >= 6` is always true.  This PR fixes the bug by propagating the outer versions to the underlying `VersionConditional` so it can generate the code accordingly.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-06-03T13:44:34Z","2020-06-04T08:15:02Z"
"","8636","MINOR: remove duplicate properties encode in KafkaZkClient#setOrCreat…","the properties is encoded three times by ```KafkaZkClient#setOrCreateEntityConfigs``` :(  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-05-09T08:31:24Z","2020-05-30T15:58:35Z"
"","9311","KAFKA-9910: Implement new transaction timed out error","The producer recovers by internally sending InitProducerId with the current epoch when received TRANSACTION_TIMED_OUT error.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","zhaohaidao","2020-09-19T15:00:26Z","2021-06-05T06:59:10Z"
"","9185","MINOR: use the link of JDK 11 to replace the dynamic url when buildin…","The official supported JDKs are 8 and 11 so we should only expose static API link of either JDK 8 or JDK 11. For example, the exposed API link is JDK 11 even if the JDK version used to build kafka is 11+  This PR also fix current broken QA of JDK 15 (the API web-site of JDK 15 is not ready)   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-08-15T15:48:36Z","2020-09-02T16:45:16Z"
"","8939","MINOR: rename class `RecordTimeDefintion` to `RecordTimeDefinition`","The naming of internal class `RecordTimeDefintion` in streams module should be a typo. This PR fix it to `RecordTimeDefinition`.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vitojeng","2020-06-27T21:30:33Z","2020-07-24T01:08:06Z"
"","9465","MINOR: Remove unused TopicCommand.askToProceed() method","The method `TopicCommand.askToProceed()` is unused. So I've removed it in this PR. I'm relying on existing tests to report any regressions, but I code searched for the method in GitHub and it was not used at other places.","closed","","kowshik","2020-10-20T19:56:15Z","2020-10-21T04:04:28Z"
"","8782","KAFKA-10080; Fix race condition on txn completion which can cause duplicate appends","The method `maybeWriteTxnCompletion` is unsafe for concurrent calls. This can cause duplicate attempts to write the completion record to the log, which can ultimately lead to illegal state errors and possible to correctness violations if another transaction had been started before the duplicate was written. This patch fixes the problem by ensuring only one thread can successfully remove the pending completion from the map.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-06-02T16:54:28Z","2020-06-03T17:37:54Z"
"","9166","KAFKA-10388; Fix struct conversion logic for tagged structures","The message generator was missing conversion logic for tagged structures. This led to casting errors when either `fromStruct` or `toStruct` were invoked. In the process of fixing this, I also found that tagged byte arrays were missing null checks. I fixed this here so that the improved tests passed.   I noticed as well that zero-copy byte arrays were not handled, but that can be addressed separately (https://issues.apache.org/jira/browse/KAFKA-10389).  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-08-11T22:44:13Z","2020-08-12T15:30:00Z"
"","9418","KAFKA-10601; Add support for append linger to Raft implementation","The main purpose of this patch is to add `quorum.linger.ms` behavior to the raft implementation. This gives users a powerful knob to tune the impact of fsync.  When an append is accepted from the state machine, it is held in an accumulator (similar to the producer) until the configured linger time is exceeded. This allows the implementation to amortize fsync overhead at the expense of some write latency.  The patch also improves our methodology for testing performance. Up to now, we have relied on the producer performance test, but it is difficult to simulate expected controller loads because producer performance is limited by other factors such as the number of producer clients and head-of-line blocking. Instead, this patch adds a workload generator which runs on the leader after election.  Finally, this patch brings us nearer to the write semantics expected by the KIP-500 controller. It makes the following changes:  - Introduce `RecordSerde` interface which abstracts the underlying log implementation from `RaftClient`. The generic type is carried over to `RaftClient` and is exposed through the read/write APIs. - `RaftClient.append` is changed to `RaftClient.scheduleAppend` and returns the last offset of the expected log append. - `RaftClient.scheduleAppend` accepts a list of records and ensures that the full set are included in a single batch. - Introduce `RaftClient.Listener` with a single `handleCommit` API which will eventually replace `RaftClient.read` in order to surface committed data to the controller state machine. Currently `handleCommit` is only used for records appended by the leader.  (Note that this patch piggybacks on top of #9352. I will rebase as soon as this PR has been merged.)","closed","kip-500,","hachikuji","2020-10-12T23:06:10Z","2021-08-11T13:17:08Z"
"","9224","KAFKA-10304: refactor MM2 integration tests","The main proposals of this PR: (1) extract the common functions into a base class `MirrorConnectorsIntegrationBaseTest` (2) test in SSL-enabled cluster","closed","","ning2008wisc","2020-08-26T17:20:07Z","2021-01-14T16:33:24Z"
"","8657","KAFKA-8334 Make sure the thread which tries to complete delayed reque…","The main changes of this PR are shown below.  1. replace ```tryLock``` by ```lock``` for ```DelayedOperation#maybeTryComplete``` 1. complete the delayed requests without holding group lock   **BEFORE** ``` test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.num_producers=3.acks=1 status: PASS run time: 56.718 seconds {""records_per_sec"": 621619.67445, ""mb_per_sec"": 59.28} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_consumer_throughput.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.2.security_protocol=SSL.compression_type=none status: PASS run time: 1 minute 16.067 seconds {""records_per_sec"": 1565190.1706, ""mb_per_sec"": 149.2682} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_consumer_throughput.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.2.security_protocol=SSL.compression_type=snappy status: PASS run time: 1 minute 2.486 seconds {""records_per_sec"": 3165558.7211, ""mb_per_sec"": 301.8912} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_consumer_throughput.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.3.security_protocol=SSL.compression_type=none status: PASS run time: 1 minute 19.929 seconds {""records_per_sec"": 1350621.2858, ""mb_per_sec"": 128.8053} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_consumer_throughput.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.3.security_protocol=SSL.compression_type=snappy status: PASS run time: 1 minute 3.014 seconds {""records_per_sec"": 3653635.3672, ""mb_per_sec"": 348.4378} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_consumer_throughput.security_protocol=PLAINTEXT.compression_type=none status: PASS run time: 58.852 seconds {""records_per_sec"": 3252032.5203, ""mb_per_sec"": 310.138} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_consumer_throughput.security_protocol=PLAINTEXT.compression_type=snappy status: PASS run time: 59.315 seconds {""records_per_sec"": 3825554.7054, ""mb_per_sec"": 364.8333} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.security_protocol=SASL_PLAINTEXT.compression_type=none status: PASS run time: 41.012 seconds {""latency_99th_ms"": 6.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 16.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.security_protocol=SASL_PLAINTEXT.compression_type=snappy status: PASS run time: 44.975 seconds {""latency_99th_ms"": 5.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 19.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.security_protocol=SASL_SSL.compression_type=none status: PASS run time: 49.868 seconds {""latency_99th_ms"": 5.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 15.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.security_protocol=SASL_SSL.compression_type=snappy status: PASS run time: 48.454 seconds {""latency_99th_ms"": 5.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 19.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_and_consumer.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.2.security_protocol=SSL.compression_type=none status: PASS run time: 1 minute 9.145 seconds {""consumer"": {""records_per_sec"": 610426.0774, ""mb_per_sec"": 58.2148}, ""producer"": {""records_per_sec"": 620385.880017, ""mb_per_sec"": 59.16}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_and_consumer.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.2.security_protocol=SSL.compression_type=snappy status: PASS run time: 1 minute 2.140 seconds {""consumer"": {""records_per_sec"": 1465845.793, ""mb_per_sec"": 139.7939}, ""producer"": {""records_per_sec"": 1416831.963729, ""mb_per_sec"": 135.12}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_and_consumer.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.3.security_protocol=SSL.compression_type=none status: PASS run time: 1 minute 10.968 seconds {""consumer"": {""records_per_sec"": 599089.3841, ""mb_per_sec"": 57.1336}, ""producer"": {""records_per_sec"": 626370.184779, ""mb_per_sec"": 59.74}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_and_consumer.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.3.security_protocol=SSL.compression_type=snappy status: PASS run time: 58.237 seconds {""consumer"": {""records_per_sec"": 1298532.6581, ""mb_per_sec"": 123.8377}, ""producer"": {""records_per_sec"": 1315443.304394, ""mb_per_sec"": 125.45}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_and_consumer.security_protocol=PLAINTEXT.compression_type=none status: PASS run time: 1 minute 0.201 seconds {""consumer"": {""records_per_sec"": 997705.2779, ""mb_per_sec"": 95.1486}, ""producer"": {""records_per_sec"": 957212.596918, ""mb_per_sec"": 91.29}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_and_consumer.security_protocol=PLAINTEXT.compression_type=snappy status: PASS run time: 56.187 seconds {""consumer"": {""records_per_sec"": 1313025.2101, ""mb_per_sec"": 125.2198}, ""producer"": {""records_per_sec"": 1363512.407963, ""mb_per_sec"": 130.03}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.2.security_protocol=SSL.compression_type=none status: PASS run time: 57.195 seconds {""latency_99th_ms"": 3.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 11.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.2.security_protocol=SSL.compression_type=snappy status: PASS run time: 57.311 seconds {""latency_99th_ms"": 3.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 8.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.3.security_protocol=SSL.compression_type=none status: PASS run time: 57.756 seconds {""latency_99th_ms"": 3.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 11.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.3.security_protocol=SSL.compression_type=snappy status: PASS run time: 57.291 seconds {""latency_99th_ms"": 3.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 8.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.security_protocol=PLAINTEXT.compression_type=none status: PASS run time: 48.981 seconds {""latency_99th_ms"": 3.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 15.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.security_protocol=PLAINTEXT.compression_type=snappy status: PASS run time: 51.503 seconds {""latency_99th_ms"": 3.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 9.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_long_term_producer_throughput.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.2.security_protocol=SSL.compression_type=none status: PASS run time: 1 minute 8.161 seconds {""0"": {""records_per_sec"": 698421.567258, ""mb_per_sec"": 66.61}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_long_term_producer_throughput.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.2.security_protocol=SSL.compression_type=snappy status: PASS run time: 56.530 seconds {""0"": {""records_per_sec"": 1639881.928501, ""mb_per_sec"": 156.39}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_long_term_producer_throughput.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.3.security_protocol=SSL.compression_type=none status: PASS run time: 1 minute 4.389 seconds {""0"": {""records_per_sec"": 720097.933319, ""mb_per_sec"": 68.67}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_long_term_producer_throughput.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.3.security_protocol=SSL.compression_type=snappy status: PASS run time: 59.589 seconds {""0"": {""records_per_sec"": 1621271.076524, ""mb_per_sec"": 154.62}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_long_term_producer_throughput.security_protocol=PLAINTEXT.compression_type=none status: PASS run time: 56.165 seconds {""0"": {""records_per_sec"": 1152737.752161, ""mb_per_sec"": 109.93}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_long_term_producer_throughput.security_protocol=PLAINTEXT.compression_type=snappy status: PASS run time: 54.846 seconds {""0"": {""records_per_sec"": 1646903.820817, ""mb_per_sec"": 157.06}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=10.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 59.692 seconds {""records_per_sec"": 1794354.545455, ""mb_per_sec"": 17.11} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=10.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 58.774 seconds {""records_per_sec"": 1973499.779444, ""mb_per_sec"": 18.82} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=100.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 57.450 seconds {""records_per_sec"": 325613.051917, ""mb_per_sec"": 31.05} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=100.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 54.134 seconds {""records_per_sec"": 734232.49453, ""mb_per_sec"": 70.02} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=1000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 54.106 seconds {""records_per_sec"": 41259.452813, ""mb_per_sec"": 39.35} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=1000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 52.577 seconds {""records_per_sec"": 51681.555641, ""mb_per_sec"": 49.29} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=10000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 57.747 seconds {""records_per_sec"": 4320.991629, ""mb_per_sec"": 41.21} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=10000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 55.024 seconds {""records_per_sec"": 4223.096287, ""mb_per_sec"": 40.27} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=100000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 53.355 seconds {""records_per_sec"": 817.794028, ""mb_per_sec"": 77.99} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=100000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 53.097 seconds {""records_per_sec"": 797.859691, ""mb_per_sec"": 76.09} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=10.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 57.602 seconds {""records_per_sec"": 1779132.025451, ""mb_per_sec"": 16.97} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=10.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 59.207 seconds {""records_per_sec"": 1935367.267484, ""mb_per_sec"": 18.46} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=100.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 58.127 seconds {""records_per_sec"": 330911.489152, ""mb_per_sec"": 31.56} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=100.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 50.805 seconds {""records_per_sec"": 615677.522936, ""mb_per_sec"": 58.72} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=1000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 51.221 seconds {""records_per_sec"": 40378.158845, ""mb_per_sec"": 38.51} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=1000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 50.578 seconds {""records_per_sec"": 51901.392111, ""mb_per_sec"": 49.5} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=10000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 53.369 seconds {""records_per_sec"": 4363.13394, ""mb_per_sec"": 41.61} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=10000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 53.982 seconds {""records_per_sec"": 4323.775773, ""mb_per_sec"": 41.23} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=100000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 54.736 seconds {""records_per_sec"": 810.386473, ""mb_per_sec"": 77.28} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=100000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 54.867 seconds {""records_per_sec"": 795.023697, ""mb_per_sec"": 75.82} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-one.acks=1 status: PASS run time: 48.440 seconds {""records_per_sec"": 701608.468374, ""mb_per_sec"": 66.91} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.acks=-1 status: PASS run time: 55.268 seconds {""records_per_sec"": 268274.435339, ""mb_per_sec"": 25.58} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.acks=1 status: PASS run time: 50.207 seconds {""records_per_sec"": 467657.491289, ""mb_per_sec"": 44.6} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=none.acks=1.message_size=10 status: PASS run time: 55.395 seconds {""records_per_sec"": 2038543.742406, ""mb_per_sec"": 19.44} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=none.acks=1.message_size=100 status: PASS run time: 52.835 seconds {""records_per_sec"": 479520.185781, ""mb_per_sec"": 45.73} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=none.acks=1.message_size=1000 status: PASS run time: 47.566 seconds {""records_per_sec"": 50609.728507, ""mb_per_sec"": 48.27} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=none.acks=1.message_size=10000 status: PASS run time: 49.949 seconds {""records_per_sec"": 5941.124391, ""mb_per_sec"": 56.66} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=none.acks=1.message_size=100000 status: PASS run time: 48.718 seconds {""records_per_sec"": 1698.734177, ""mb_per_sec"": 162.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=snappy.acks=1.message_size=10 status: PASS run time: 55.253 seconds {""records_per_sec"": 1946594.923858, ""mb_per_sec"": 18.56} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=snappy.acks=1.message_size=100 status: PASS run time: 50.712 seconds {""records_per_sec"": 986894.852941, ""mb_per_sec"": 94.12} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=snappy.acks=1.message_size=1000 status: PASS run time: 58.378 seconds {""records_per_sec"": 112787.394958, ""mb_per_sec"": 107.56} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=snappy.acks=1.message_size=10000 status: PASS run time: 50.972 seconds {""records_per_sec"": 5747.751606, ""mb_per_sec"": 54.81} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=snappy.acks=1.message_size=100000 status: PASS run time: 47.419 seconds {""records_per_sec"": 1580.683157, ""mb_per_sec"": 150.75} -------------------------------------------------------------------------------- ```  **AFTER** ``` test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.num_producers=3.acks=1 status: PASS run time: 56.262 seconds {""records_per_sec"": 625731.99396, ""mb_per_sec"": 59.68} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_consumer_throughput.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.2.security_protocol=SSL.compression_type=none status: PASS run time: 1 minute 15.345 seconds {""records_per_sec"": 1458151.0645, ""mb_per_sec"": 139.0601} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_consumer_throughput.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.2.security_protocol=SSL.compression_type=snappy status: PASS run time: 1 minute 5.284 seconds {""records_per_sec"": 3173595.6839, ""mb_per_sec"": 302.6577} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_consumer_throughput.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.3.security_protocol=SSL.compression_type=none status: PASS run time: 1 minute 16.265 seconds {""records_per_sec"": 1477759.7163, ""mb_per_sec"": 140.9301} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_consumer_throughput.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.3.security_protocol=SSL.compression_type=snappy status: PASS run time: 1 minute 4.992 seconds {""records_per_sec"": 2992220.2274, ""mb_per_sec"": 285.3604} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_consumer_throughput.security_protocol=PLAINTEXT.compression_type=none status: PASS run time: 1 minute 2.562 seconds {""records_per_sec"": 3987240.8293, ""mb_per_sec"": 380.2529} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_consumer_throughput.security_protocol=PLAINTEXT.compression_type=snappy status: PASS run time: 1 minute 1.068 seconds {""records_per_sec"": 3531073.4463, ""mb_per_sec"": 336.7494} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.security_protocol=SASL_PLAINTEXT.compression_type=none status: PASS run time: 43.213 seconds {""latency_99th_ms"": 6.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 19.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.security_protocol=SASL_PLAINTEXT.compression_type=snappy status: PASS run time: 44.302 seconds {""latency_99th_ms"": 6.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 17.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.security_protocol=SASL_SSL.compression_type=none status: PASS run time: 52.117 seconds {""latency_99th_ms"": 6.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 17.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.security_protocol=SASL_SSL.compression_type=snappy status: PASS run time: 48.599 seconds {""latency_99th_ms"": 6.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 15.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_and_consumer.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.2.security_protocol=SSL.compression_type=none status: PASS run time: 1 minute 6.347 seconds {""consumer"": {""records_per_sec"": 610165.3548, ""mb_per_sec"": 58.1899}, ""producer"": {""records_per_sec"": 645161.290323, ""mb_per_sec"": 61.53}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_and_consumer.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.2.security_protocol=SSL.compression_type=snappy status: PASS run time: 58.196 seconds {""consumer"": {""records_per_sec"": 1365001.365, ""mb_per_sec"": 130.1767}, ""producer"": {""records_per_sec"": 1315270.288044, ""mb_per_sec"": 125.43}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_and_consumer.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.3.security_protocol=SSL.compression_type=none status: PASS run time: 1 minute 8.056 seconds {""consumer"": {""records_per_sec"": 635364.3815, ""mb_per_sec"": 60.5931}, ""producer"": {""records_per_sec"": 645369.474024, ""mb_per_sec"": 61.55}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_and_consumer.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.3.security_protocol=SSL.compression_type=snappy status: PASS run time: 55.585 seconds {""consumer"": {""records_per_sec"": 1396453.0094, ""mb_per_sec"": 133.1761}, ""producer"": {""records_per_sec"": 1345170.836696, ""mb_per_sec"": 128.29}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_and_consumer.security_protocol=PLAINTEXT.compression_type=none status: PASS run time: 57.844 seconds {""consumer"": {""records_per_sec"": 995024.8756, ""mb_per_sec"": 94.893}, ""producer"": {""records_per_sec"": 934928.9454, ""mb_per_sec"": 89.16}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_and_consumer.security_protocol=PLAINTEXT.compression_type=snappy status: PASS run time: 57.728 seconds {""consumer"": {""records_per_sec"": 1442793.2477, ""mb_per_sec"": 137.5955}, ""producer"": {""records_per_sec"": 1343002.954607, ""mb_per_sec"": 128.08}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.2.security_protocol=SSL.compression_type=none status: PASS run time: 59.918 seconds {""latency_99th_ms"": 4.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 10.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.2.security_protocol=SSL.compression_type=snappy status: PASS run time: 58.414 seconds {""latency_99th_ms"": 4.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 13.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.3.security_protocol=SSL.compression_type=none status: PASS run time: 58.689 seconds {""latency_99th_ms"": 4.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 10.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.3.security_protocol=SSL.compression_type=snappy status: PASS run time: 57.322 seconds {""latency_99th_ms"": 4.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 11.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.security_protocol=PLAINTEXT.compression_type=none status: PASS run time: 53.221 seconds {""latency_99th_ms"": 4.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 12.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_end_to_end_latency.security_protocol=PLAINTEXT.compression_type=snappy status: PASS run time: 53.012 seconds {""latency_99th_ms"": 4.0, ""latency_50th_ms"": 0.0, ""latency_999th_ms"": 13.0} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_long_term_producer_throughput.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.2.security_protocol=SSL.compression_type=none status: PASS run time: 1 minute 9.797 seconds {""0"": {""records_per_sec"": 712352.186921, ""mb_per_sec"": 67.94}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_long_term_producer_throughput.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.2.security_protocol=SSL.compression_type=snappy status: PASS run time: 58.567 seconds {""0"": {""records_per_sec"": 1586294.416244, ""mb_per_sec"": 151.28}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_long_term_producer_throughput.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.3.security_protocol=SSL.compression_type=none status: PASS run time: 1 minute 3.881 seconds {""0"": {""records_per_sec"": 730513.551026, ""mb_per_sec"": 69.67}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_long_term_producer_throughput.interbroker_security_protocol=PLAINTEXT.tls_version=TLSv1.3.security_protocol=SSL.compression_type=snappy status: PASS run time: 58.038 seconds {""0"": {""records_per_sec"": 1624959.376016, ""mb_per_sec"": 154.97}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_long_term_producer_throughput.security_protocol=PLAINTEXT.compression_type=none status: PASS run time: 54.064 seconds {""0"": {""records_per_sec"": 1184834.123223, ""mb_per_sec"": 112.99}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_long_term_producer_throughput.security_protocol=PLAINTEXT.compression_type=snappy status: PASS run time: 53.514 seconds {""0"": {""records_per_sec"": 1647175.094713, ""mb_per_sec"": 157.09}} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=10.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 1 minute 0.244 seconds {""records_per_sec"": 1814733.910222, ""mb_per_sec"": 17.31} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=10.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 59.460 seconds {""records_per_sec"": 2014373.705538, ""mb_per_sec"": 19.21} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=100.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 58.051 seconds {""records_per_sec"": 328240.890193, ""mb_per_sec"": 31.3} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=100.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 52.228 seconds {""records_per_sec"": 747730.91922, ""mb_per_sec"": 71.31} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=1000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 53.001 seconds {""records_per_sec"": 40475.572979, ""mb_per_sec"": 38.6} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=1000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 54.782 seconds {""records_per_sec"": 70752.24038, ""mb_per_sec"": 67.47} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=10000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 57.875 seconds {""records_per_sec"": 4461.768617, ""mb_per_sec"": 42.55} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=10000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 57.089 seconds {""records_per_sec"": 4282.386726, ""mb_per_sec"": 40.84} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=100000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 54.228 seconds {""records_per_sec"": 824.324324, ""mb_per_sec"": 78.61} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.2.message_size=100000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 51.462 seconds {""records_per_sec"": 809.897405, ""mb_per_sec"": 77.24} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=10.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 59.836 seconds {""records_per_sec"": 1812773.095624, ""mb_per_sec"": 17.29} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=10.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 56.087 seconds {""records_per_sec"": 2029604.113111, ""mb_per_sec"": 19.36} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=100.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 55.743 seconds {""records_per_sec"": 348707.976098, ""mb_per_sec"": 33.26} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=100.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 52.794 seconds {""records_per_sec"": 974003.628447, ""mb_per_sec"": 92.89} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=1000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 55.364 seconds {""records_per_sec"": 41284.835435, ""mb_per_sec"": 39.37} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=1000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 51.486 seconds {""records_per_sec"": 57827.229642, ""mb_per_sec"": 55.15} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=10000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 55.384 seconds {""records_per_sec"": 4502.180476, ""mb_per_sec"": 42.94} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=10000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 54.028 seconds {""records_per_sec"": 4217.787555, ""mb_per_sec"": 40.22} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=100000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=none status: PASS run time: 56.079 seconds {""records_per_sec"": 839.79975, ""mb_per_sec"": 80.09} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.tls_version=TLSv1.3.message_size=100000.topic=topic-replication-factor-three.security_protocol=SSL.acks=1.compression_type=snappy status: PASS run time: 54.970 seconds {""records_per_sec"": 826.35468, ""mb_per_sec"": 78.81} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-one.acks=1 status: PASS run time: 46.430 seconds {""records_per_sec"": 746068.371317, ""mb_per_sec"": 71.15} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.acks=-1 status: PASS run time: 53.541 seconds {""records_per_sec"": 318277.685558, ""mb_per_sec"": 30.35} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.acks=1 status: PASS run time: 49.139 seconds {""records_per_sec"": 487355.482934, ""mb_per_sec"": 46.48} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=none.acks=1.message_size=10 status: PASS run time: 53.150 seconds {""records_per_sec"": 2153686.136072, ""mb_per_sec"": 20.54} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=none.acks=1.message_size=100 status: PASS run time: 51.156 seconds {""records_per_sec"": 455438.411944, ""mb_per_sec"": 43.43} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=none.acks=1.message_size=1000 status: PASS run time: 51.568 seconds {""records_per_sec"": 52820.543093, ""mb_per_sec"": 50.37} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=none.acks=1.message_size=10000 status: PASS run time: 46.992 seconds {""records_per_sec"": 6253.960857, ""mb_per_sec"": 59.64} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=none.acks=1.message_size=100000 status: PASS run time: 46.280 seconds {""records_per_sec"": 1669.154229, ""mb_per_sec"": 159.18} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=snappy.acks=1.message_size=10 status: PASS run time: 54.138 seconds {""records_per_sec"": 1951122.546882, ""mb_per_sec"": 18.61} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=snappy.acks=1.message_size=100 status: PASS run time: 47.680 seconds {""records_per_sec"": 1021443.683409, ""mb_per_sec"": 97.41} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=snappy.acks=1.message_size=1000 status: PASS run time: 47.886 seconds {""records_per_sec"": 116104.67128, ""mb_per_sec"": 110.73} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=snappy.acks=1.message_size=10000 status: PASS run time: 54.126 seconds {""records_per_sec"": 5550.454921, ""mb_per_sec"": 52.93} -------------------------------------------------------------------------------- test_id: kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput.topic=topic-replication-factor-three.security_protocol=PLAINTEXT.compression_type=snappy.acks=1.message_size=100000 status: PASS run time: 46.799 seconds {""records_per_sec"": 1582.54717, ""mb_per_sec"": 150.92} --------------------------------------------------------------------------------   ```  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-05-12T17:23:47Z","2020-09-10T01:46:16Z"
"","9438","KAFKA-10613: Only set leader epoch when list-offset version >= 4","The leader epoch field is added in version 4, and the auto-generated protocol code would throw unsupported version exception if the field is set to any non-default values for version < 4. This would cause older versioned clients to never receive list-offset results.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-10-14T21:43:23Z","2020-10-15T17:03:08Z"
"","9219","KAFKA-10432: LeaderEpochCache is incorrectly recovered for leader epoch 0","The leader epoch cache is incorrectly recovered for epoch 0 as the assignment is skipped when epoch == 0. This check was likely intended to prevent negative epochs from being applied or there was an assumption that epochs started at 1.  A test has been added to LogSegmentTest to show the LogSegment recovery path works for the epoch cache. This was a test gap as none of the  recover calls supply a leader epoch cache to recover.","closed","","lbradstreet","2020-08-25T17:46:52Z","2020-09-08T19:43:37Z"
"","8843","KAFKA-9991: Fix flaky unit tests","The latest commit #8254 on this test deleted all topics after each test, but the topic was actually shared among tests before. And after that we are relying on the less-reliable auto-topic generation to get the topic which makes the test flaky.  I'm now using different topics for different tests, also setting the app.id for tests differently.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","guozhangwang","2020-06-10T02:50:53Z","2020-06-10T21:11:20Z"
"","9132","[KAFKA-10422] [WIP] Introduce `timesForOffsets` in `KafkaConsumer`","The kafka consumer already provides an operation to quickly lookup the offsets by timestamp by using the `offsetsForTimes` operation.  However there are use cases where the inverse operation would be useful: having a set of offsets, I would like to lookup the ingestion timestamps for all these messages. Currently it would require fetching all these message by random access to retrieve the timestamps.  This add the `timesForOffsets` operation to the kafka consumer. The operation signature is equivalent to `offsetsForTimes`: given a mapping from partition to the offset to look up, it returns a mapping from partition to the timestamp and offset of the message at the requested offset. null is returned for the partition if there is no message at this offset.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","guillaumebort","2020-08-06T14:49:42Z","2021-02-19T15:11:52Z"
"","9322","KAFKA-10512: Prevent JmxTool Crashing on Unmarshall Error","The JMXTool will query for all metrics when not supplied an ""--object-name"" arg. However, some MBean objects can contain attributes that cannot be serialized, thus crashing the JMXTool before reporting any metrics. This PR catches those exceptions, printing an error message but allowing the tool to continue to reporting all metrics w/ the errored ones filtered out","open","","mattwong949","2020-09-23T00:10:43Z","2020-09-23T00:10:43Z"
"","8934","KAFKA-10134: Use long poll if we do not have fetchable partitions","The intention of using poll(0) is to not block on rebalance but still return some data; however, if there's no fetchable partitions then there's no point of polling with 0ms. What's worse, with poll(0) we may fall into a busy loop since we may advance the system test with too small pace.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","consumer,","guozhangwang","2020-06-27T00:40:15Z","2020-07-08T16:53:16Z"
"","8748","HOTFIX: relax constraint on randomized percentiles test","The intent of this test isn't to validate that it's accurate to 10% exactly, just to make sure it isn't orders of magnitude off, we should just relax the constraint to be within 20%  Should go to 2.6","closed","","ableegoldman","2020-05-28T20:53:17Z","2020-06-26T22:37:10Z"
"","8501","KAFKA-9881: Convert integration test to verify measurements from RocksDB to unit test","The integration test RocksDBMetricsIntegrationTest takes pretty long to complete. Most of the runtime is spent in the two tests that verify whether the RocksDB metrics get actual measurements from RocksDB. Those tests need to wait for the thread that collects the measurements of the RocksDB metrics to trigger the first recordings of the metrics.  This PR adds a unit test that verifies whether the Kafka Streams metrics get the measurements from RocksDB and removes the two integration tests that verified it before. The verification of the creation and scheduling of the RocksDB metrics recording trigger thread is already contained in KafkaStreamsTest and consequently it is not part of this PR.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","cadonna","2020-04-16T13:52:33Z","2020-06-08T10:03:23Z"
"","9297","KAFKA-10495:Fix spelling mistake","The iff is wrong word.I fixed it to if.","closed","","ouyangnengda","2020-09-17T13:15:10Z","2020-09-18T03:27:33Z"
"","9287","extract common functions from SourceConnector and SourceTask","The idea is to centralize the common functions of current `MirrorSourceConnector` and `MirrorSourceTask` to prepare for reusing them in new Sink Connector and Sink Task in future (KIP-656 https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=158870065)  Two new files are proposed: - `MirrorConnectorCommon`: contains the reusable functions extracted from `MirrorSourceConnector` - `MirrorTaskCommon`: contains the reusable functions extracted from `MirrorSourceTask`  no functional changes to current behaviors","open","","ning2008wisc","2020-09-15T06:13:44Z","2021-06-10T15:48:57Z"
"","9355","MINOR: tweak the callback of committing offsets","The following changes are included.  1. don't create unnecessary ```OffsetCommitCompletion``` if users don't define callback 1. log the error of finding coordinator if user don't define callback 1. add unit test of failing to commit offsets when using callback  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-09-30T09:30:23Z","2020-10-16T03:28:50Z"
"","9301","KAFKA-10482: Fix flaky testDynamicListenerConnectionCreationRateQuota","The flaky test is because we have race condition in `testDynamicListenerConnectionCreationRateQuota`. We set the `initialConnectionCount` with the global shared `connectionCount` in the `verifyConnectionRate` method, but we have multi-thread test cases, which might get the wrong `initialConnectionCount`. And later the waiting close will never complete since the expected initialConnectionCount is wrong.  Ex: ![image](https://user-images.githubusercontent.com/43372967/93566080-0bc8cc00-f9bf-11ea-9aa7-9bc651f5ede2.png)  The error message is: ``` kafka.network.DynamicConnectionQuotaTest > testDynamicListenerConnectionCreationRateQuota FAILED java.util.concurrent.ExecutionException: org.scalatest.exceptions.TestFailedException: Connections not closed (initial = 2 current = 1) at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122) at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:205) at kafka.network.DynamicConnectionQuotaTest.testDynamicListenerConnectionCreationRateQuota(DynamicConnectionQuotaTest.scala:219) ```  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-09-18T02:18:31Z","2020-09-23T11:34:47Z"
"","9282","MINOR: Update junit to 5.7.0","The final release is now out: https://junit.org/junit5/docs/5.7.0/release-notes/index.html  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-09-13T16:06:32Z","2020-09-14T14:47:35Z"
"","9391","MINOR: fix potential NPE in PartitionData.equals","the field ```metadata``` is nullable (see https://github.com/apache/kafka/blob/trunk/clients/src/main/resources/common/message/OffsetFetchResponse.json#L50)  the method ```equals``` is not used in production and ```PartitionData``` is not exposed to client so this issue is minor :)  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-10-08T06:16:22Z","2020-10-18T13:29:14Z"
"","8778","KAFKA-10083: fix failed testReassignmentWithRandomSubscriptionsAndChanges tests","The failed test is because we changed the class member `partitionMovements` initialization to when the class instance created, from initialized when used within `assign` method. This won't have any issue when 1st used the `AbstractStickyAssignor` instance. But if it is used later, the `partitionMovements` will store the old info, and cause this failed tests. Fix it by moving the `partitionMovements` initialization back to `assign` method.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-06-02T12:32:04Z","2020-06-03T02:24:39Z"
"","8932","MINOR: rename ""NOT_INITALIZED"" to ""NOT_INITIALIZED""","The enum ```State``` is private so it is fine to fix typo without breaking compatibility.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-06-26T10:15:52Z","2020-06-26T17:38:40Z"
"","9205","MINOR: Fix typo in example","The ducker-ak test example includes a file path that does not exist. I fixed to be the correct path.","closed","","jolshan","2020-08-21T18:18:24Z","2020-10-28T19:00:33Z"
"","8518","MINOR: add support for kafka 2.4 and 2.5 to downgrade test","The downgrade test does not currently support 2.4 and 2.5. When you enable them, it fails as a result of consumer group static membership. This PR makes the downgrade test work with all of our released versions again.","closed","","lbradstreet","2020-04-19T20:18:01Z","2020-04-29T01:01:33Z"
"","8975","MINOR: Document that max.block.ms affects some transaction methods","The documentation for max.block.ms said it affected only send() and partitionsFor(), but it actually also affects initTransactions(), abortTransaction() and commitTransaction(). So rework the documentation to cover these methods too.","closed","","tombentley","2020-07-02T16:36:42Z","2020-07-04T17:54:12Z"
"","8489","KAFKA-9857:Failed to build image ducker-ak-openjdk-8 on arm","The default OpenJDK base image is openjdk:8. When building image on arm, no matching manifest for linux/arm64/v8 in the manifest list entries error will occur. For arm, the default OpenJDK should be set to arm64v8/openjdk:8  Change-Id: Ib450a36b3977a167743c24476ec1810f4830b66b Signed-off-by: Jiamei Xie   *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jiameixie","2020-04-15T02:47:05Z","2021-12-23T09:36:37Z"
"","8627","MINOR - Increase Trogdor Histogram buckets for latency to 10000ms","The current latency histograms for ProduceBenchWorker and ConsumeBenchWorker are limited to 5000ms, causing the histograms to truncate and report 5000ms on requests that take longer.  This increases the maximum latency the histogram accepts to 10000ms.","closed","","scott-hendricks","2020-05-06T20:23:18Z","2020-05-07T14:24:34Z"
"","9142","MINOR: Fix delete_topic for system tests","The current implementation of `delete_topic` in `kafka.py` doesn't take into account security credentials and thus fails when running tests with security enabled and trying to delete a topic. This PR is to fix this issue.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","skaundinya15","2020-08-07T19:24:59Z","2020-08-19T16:43:54Z"
"","8963","KAFKA-10017: fix flaky EosBetaUpgradeIntegrationTest","The current failures we're seeing with this test are due to faulty assumptions that it makes and not any real bug in eos-beta (at least, from what I've seen so far).  The test relies on tightly controlling the commits, which it does by setting the commit interval to MAX_VALUE and manually requesting commits on the context. In two phases, the test assumes that any pending data will be committed after a rebalance. But we actually take care to avoid unnecessary commits -- with eos-alpha, we only commit tasks that are revoked while in eos-beta we must commit all tasks if any are revoked, but only if the revoked tasks themselves need a commit.  The failure we see occurs when we try to verify the committed data after a second client is started and the group rebalances. The already-running client has to give up two tasks to the newly started client, but those tasks may not need to be committed in which case none of the tasks would be. So we still have an open transaction on the partitions where we try to read committed data.  We can use a punctuator to force a commit on the running client","closed","","ableegoldman","2020-07-01T03:00:45Z","2020-07-06T21:22:17Z"
"","8802","MINOR: Fix fetch session epoch comment in `FetchRequest.json`","The current ""about"" string incorrectly describes the session epoch as the partition epoch. Rename to `SessionEpoch` to make usage clearer. Also rename `MaxWait` to `MaxWaitTimeMs` and `FetchableTopic` to `FetchTopic` for consistency with `FetchPartition`.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-06-04T23:32:20Z","2020-06-08T23:51:49Z"
"","9111","KAFKA-10337: await async commits in commitSync even if no offsets given","The contract for `commitSync()` guarantees that the callbacks for all prior async commits will be invoked before it (successfully?) returns. Prior to this change the contract could be violated if an empty offsets map were passed in to `commitSync()`.  Also added a unit test in `ConsumerCoordinatorTest` exercising this particular path.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","thomaslee","2020-08-02T02:37:41Z","2021-08-28T21:49:20Z"
"","8836","KAFKA-10124:Wrong rebalance.time.ms","The consumer rebalance protocol is changed. Method onPartitionsRevoked is called after onPartitionsAssigned, so wrong joinTime is got.  Change-Id: I561a48a13a870bd3cb03008825b69b804c6a94b4 Signed-off-by: Jiamei Xie   *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jiameixie","2020-06-09T06:14:35Z","2021-04-04T02:29:57Z"
"","8529","KAFKA-9901:Fix streams_broker_bounce_test error","The constructor of StreamsSmokeTestJobRunnerService has been changed. But it's not updated in streams_broker_bounce_test.py, which makes num_threads = 3 to be processing_guarantee's value and causes that StreamsTest can't startup  Change-Id: I07ebc3e007e0ddd0b5182d5cf9467cdfac993eae Signed-off-by: Jiamei Xie   *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jiameixie","2020-04-22T06:03:01Z","2020-04-26T01:33:19Z"
"","9077","MINOR: remove NewTopic#NO_PARTITIONS and NewTopic#NO_REPLICATION_FACT…","The constants used to represent no_partition and no_replica are important factor in creating topic. Hence, we should have consistent reference to code base.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-07-25T11:18:56Z","2020-07-27T16:57:29Z"
"","9161","KAFKA-10385 - Remove no print stat when on detailed stat mode on Consumer Perf","The condition to see a detailed stats is conditionned by the time.      if (currentTimeMillis - lastReportTime >= config.reportingInterval)        if (config.showDetailedStats)  But when you finish the loop, you haven t the last stats of the performance tests. Just the previous status exists.     I propose just to remove the condition to show the final statistic result.","open","","sebadiaz","2020-08-11T13:07:37Z","2020-08-21T19:26:57Z"
"","9085","MINOR: Support java.util.Optional in the auto-generated protocol","The AK protocol often relies on sentinel value (e.g. null or -1) to indicate that a field was not provided. Usually, these sentinels are turned into `java.util.Optional` that is empty when the field is equal to the sentinel. Until now, we were doing this transformation while mapping the Struct to internal Request or Response classes. With the generated protocol, we would like to get rid of these internal classes and also avoid spending time to construct them.  This PR is an attempt to support `java.util.Optional` in the auto-generated classes. A field can be marked as `optional` that indicates to the generator that its type must be wrapped in an `Optional`.  When an optional is written, its internal value is used or its default if the optional is undefined. When an option is read, the value read is used or it defaults to an empty optional if the default value is read.  I did a deep integration by changing all the places where values are written or read to do the above conversions. I just wrote it as a proof of concept to discuss this further. The code may be simplified.  An alternative to this would be to only provide getters and setters which convert the internal value to an Optional and vice versa. That would limit the scope of the change. The downside would be that every time the getters or the setters are called, it requires to do the conversion.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-07-27T13:54:57Z","2022-02-04T20:29:08Z"
"","9216","KAFKA-10428: Fix schema for header conversion in MirrorSourceTask.","The addBytes method adds the header using Schema.BYTES, which results in base64 encoding when the record is stored.  SimpleHeaderConverter#toConnectHeader implements schema inference which we can use here, as the ConsumerRecord does not have header schema information.  Testing: I added schema verification to the existing MirrorSourceTaskTest#testSerde, with a string and int example.","closed","","jthompson6","2020-08-24T23:46:55Z","2020-09-03T19:57:35Z"
"","9320","KAFKA-10439: Connect's Values to parse BigInteger as Decimal with zero scale.","The `org.apache.kafka.connect.data.Values#parse` method parses integers, which are larger than `Long.MAX_VALUE` as `double` with `Schema.FLOAT64_SCHEMA`.  That means we are losing precision for these larger integers.  For example: ``` SchemaAndValue schemaAndValue = Values.parseString(""9223372036854775808""); ``` returns: ``` SchemaAndValue{schema=Schema{FLOAT64}, value=9.223372036854776E18} ``` Also, this method parses values, that can be parsed as `FLOAT32` to `FLOAT64`.  This PR changes parsing logic, to use `FLOAT32`/`FLOAT64` for numbers that don't have and fraction part(`decimal.scale()!=0`) only, and use an arbitrary-precision `org.apache.kafka.connect.data.Decimal` otherwise. Also, it updates the method to parse numbers, that can be represented as `float` to `FLOAT64`.  Added unit tests, that cover parsing `BigInteger`, `Byte`, `Short`, `Integer`, `Long`, `Float`, `Double` types.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","avocader","2020-09-22T18:51:47Z","2020-10-06T00:24:44Z"
"","9227","KAFKA-10439: Connect's Values to parse BigInteger as Decimal with zero scale.","The `org.apache.kafka.connect.data.Values#parse` method parses integers, which are larger than `Long.MAX_VALUE` as `double` with `Schema.FLOAT64_SCHEMA`.  That means we are losing precision for these larger integers.  For example: ``` SchemaAndValue schemaAndValue = Values.parseString(""9223372036854775808""); ``` returns: ``` SchemaAndValue{schema=Schema{FLOAT64}, value=9.223372036854776E18} ``` Also, this method parses values, that can be parsed as `FLOAT32` to `FLOAT64`.  This PR changes parsing logic, to use `FLOAT32`/`FLOAT64` for numbers that don't have and fraction part(`decimal.scale()!=0`) only, and use an arbitrary-precision `org.apache.kafka.connect.data.Decimal` otherwise. Also, it updates the method to parse numbers, that can be represented as `float` to `FLOAT64`.  Added unit tests, that cover parsing `BigInteger`, `Byte`, `Short`, `Integer`, `Long`, `Float`, `Double` types.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","avocader","2020-08-27T19:22:00Z","2020-09-22T18:50:24Z"
"","8587","MINOR: Fix broken JMX link by adding missing starting double quote","The `href` attribute missed the starting double quote, so the hyperlink is interpreted as `https://docs.oracle.com/.../agent.html""`, with a redundant tailing double quote. Add the missing starting double quote back to fix this issue.  ![image](https://user-images.githubusercontent.com/43372967/80663698-5193ff00-8ac7-11ea-817e-885b5b322da8.png)   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-04-30T01:49:05Z","2020-04-30T04:02:03Z"
"","8498","MINOR: make serialize function naming more explicit","The `AbstractRequest.serialize(header)` reads ambiguous meaning as whether the underlying request data is being serialized or not. Making it `serializeWithHeader` sounds more clear that this is a combined buffer.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-04-16T05:40:26Z","2020-06-21T02:56:23Z"
"","8746","Bump trunk to 2.7.0-SNAPSHOT","The `2.6` branch has been created, so we need to bump trunk to the next snapshot version, 2.7.0-SNAPSHOT  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rhauch","2020-05-28T18:02:11Z","2020-06-02T02:23:10Z"
"","8563","MINOR: Fix broken JMX URL in docs","The ""Monitoring and Management Using JMX Technology"" link on the operations page is broken because of a missing double quote in the html a tag.  1. Open http://kafka.apache.org/documentation/#operations and search for ""JMX Technology"" 2. Click the ""Monitoring and Management Using JMX Technology"" link, you will get ""Page not found "" error  3. notice the URL in the browser address bar, there is a extra double quote at end of the URL https://docs.oracle.com/javase/8/docs/technotes/guides/management/agent.html""","closed","","wj1918","2020-04-27T18:47:00Z","2020-04-30T03:03:27Z"
"","9183","KAFKA-10404; Use higher poll timeout to avoid rebalance in testCoordinatorFailover","Tests use 6s poll timeout, which isn't sufficient to ensure that clients don't leave the group due to poll timeout. The PR increases poll timeout to 15s. Session timeout of 5s is also low, but leaving it as-is for now with lower heartbeat timeout to make sure we catch unexpected rebalances during the failover.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rajinisivaram","2020-08-14T17:28:17Z","2020-08-16T13:43:22Z"
"","8854","KAFKA-10146, KAFKA-9066: Retain metrics for failed tasks (backport to 2.5)","Targets the `2.5` branch, which is currently blocked by the 2.5.1 release effort. See #9106 for the equivalent PR targeting the `2.4` branch.  This should be merged only after AK 2.5.1 has been released, which is currently ongoing.  This backports the KAFKA-9066 / #8502 changes to retain metrics for failed tasks that was already merged to `trunk` and backported to the `2.6` branch.   This PR has one change relative to the original PR: it removes an integration test added in the `2.6` branch for KIP-158 and modified as part of KAFKA-9066 / #8502.  Ping @C0urante (original author)  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","rhauch","2020-06-11T15:31:31Z","2020-08-12T22:42:13Z"
"","9106","KAFKA-10146, KAFKA-9066: Retain metrics for failed tasks (backport to 2.4)","Targets the `2.4` branch. See #8854 for the similar PR for the `2.5` branch, which is currently blocked by the 2.5.1 release effort.  This backports the KAFKA-9066 / #8502 changes to retain metrics for failed tasks that was already merged to trunk and backported to the 2.6 branch.  Like #8854, this PR has one change relative to the original PR: it removes an integration test added in the 2.6 branch for KIP-158 and modified as part of KAFKA-9066 / #8502.  Author: Chris Egerton  Reviewers: Nigel Liang , Randall Hauch   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","rhauch","2020-07-30T19:06:46Z","2020-07-30T22:44:26Z"
"","9347","KAFKA-10531: Check for negative values to Thread.sleep call","System.currentTimeMillis() is not monotonic, so using that to calculate time to sleep can result in negative values. That will throw IllegalArgumentException.  This change checks for that and sleeps for a second (to avoid tight loop) if the value returned is negative.  This change need to be backported to older branches that have Connect.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","soondenana","2020-09-28T21:13:49Z","2020-10-16T06:15:46Z"
"","8517","MINOR: use monotonic clock for replica fetcher DelayedItem","Switches the replica fetcher to use a monotonic clock to calculate delays.  In doing so an unnecessary time conversion was removed the replica fetcher hot path. This is a small but significant (2.2%) cost when testing clusters with high replica counts when throttling has engaged (see attached profile).","open","","lbradstreet","2020-04-19T19:56:31Z","2020-07-06T19:56:29Z"
"","8828","KAFKA-9216: Enforce that Connect’s internal topics use `compact` cleanup policy","Supplements #8270   This change adds a check to the KafkaConfigBackingStore, KafkaOffsetBackingStore, and KafkaStatusBackingStore to use the admin client to verify that the internal topics are compacted and do not use the `delete` cleanup policy.  Connect already will create the internal topics with `cleanup.policy=compact` if the topics do not yet exist when the Connect workers are started; the new topics are created always as compacted, overwriting any user-specified `cleanup.policy`. However, if the topics already exist the worker did not previously verify the internal topics were compacted, such as when a user manually creates the internal topics before starting Connect or manually changes the topic settings after the fact.  The current change helps guard against users running Connect with topics that have delete cleanup policy enabled, which will remove all connector configurations, source offsets, and connector & task statuses that are older than the retention time. This means that, for example, the configuation for a long-running connector could be deleted by the broker, and this will cause restart issues upon a subsequent rebalance or restarting of Connect worker(s).  Connect behavior requires that its internal topics are compacted and not deleted after some retention time. Therefore, this additional check is simply enforcing the existing expectations, and therefore does not need a KIP.  Added unit tests for the new logic, and added an integration test that verifies that the worker will fail to start if each of the three internal topics does not use only `cleanup.policy=compact`.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","rhauch","2020-06-07T22:02:48Z","2020-06-11T03:39:53Z"
"","8788","MINOR: Remove unused isSticky assert out from tests only do constrainedAssign","Suggested by @ableegoldman in https://github.com/apache/kafka/pull/8778#discussion_r434008302, remove the unused isSticky assert out from tests only do `constrainedAssign`. I printed out the test name and which assign method used during tests. Below is the output. So, we can remove the `isSticky()` assertion from the tests using `constrainedAssign` method.  In summary, total 9 tests were doing `assertTrue(assignor.isSticky())` but using `constrainedAssign`. Thanks.   > StickyAssignorTest - testAssignmentWithConflictingPreviousGenerations > 2020-06-03T09:44:03.362+0800 [DEBUG] [TestEventLogger]     constrainedAssign  > StickyAssignorTest - testSchemaBackwardCompatibility > 2020-06-03T09:44:03.376+0800 [DEBUG] [TestEventLogger]     constrainedAssign  > StickyAssignorTest - testAssignmentWithMultipleGenerations1 > 2020-06-03T09:44:03.378+0800 [DEBUG] [TestEventLogger]     constrainedAssign  > StickyAssignorTest - testAssignmentWithMultipleGenerations2 > 2020-06-03T09:44:03.380+0800 [DEBUG] [TestEventLogger]     constrainedAssign  > AbstractStickyAssignorTest - testStickiness > 2020-06-03T09:44:03.383+0800 [DEBUG] [TestEventLogger]     constrainedAssign  > AbstractStickyAssignorTest - testAddRemoveConsumerOneTopic > 2020-06-03T09:44:03.386+0800 [DEBUG] [TestEventLogger]     constrainedAssign  > AbstractStickyAssignorTest - testReassignmentWithRandomSubscriptionsAndChanges > 2020-06-03T09:44:03.393+0800 [DEBUG] [TestEventLogger]     generalAssign  > AbstractStickyAssignorTest - testNewSubscription > 2020-06-03T09:44:06.238+0800 [DEBUG] [TestEventLogger]     generalAssign  > AbstractStickyAssignorTest - testAddRemoveTopicTwoConsumers > 2020-06-03T09:44:06.239+0800 [DEBUG] [TestEventLogger]     constrainedAssign  > AbstractStickyAssignorTest - testReassignmentAfterOneConsumerLeaves > 2020-06-03T09:44:06.243+0800 [DEBUG] [TestEventLogger]     generalAssign  > AbstractStickyAssignorTest - testLargeAssignmentWithMultipleConsumersLeavingAndRandomSubscription > 2020-06-03T09:44:06.268+0800 [DEBUG] [TestEventLogger]     generalAssign  > AbstractStickyAssignorTest - testSameSubscriptions > 2020-06-03T09:44:08.400+0800 [DEBUG] [TestEventLogger]     constrainedAssign  > AbstractStickyAssignorTest - testReassignmentAfterOneConsumerAdded > 2020-06-03T09:44:08.403+0800 [DEBUG] [TestEventLogger]     constrainedAssign   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-06-03T02:22:29Z","2020-06-08T21:25:21Z"
"","8706","KAFKA-10030 allow fetching a key from a single partition","StreamThreadStateStoreProvider#stores throws exception whenever taskId is not found, which is not correct behaviour in multi-threaded env where state store partitions are distributed among several StreamTasks.   final Task task = tasks.get(keyTaskId); if (task == null) {  throw new InvalidStateStoreException(  String.format(""The specified partition %d for store %s does not exist."",  storeQueryParams.partition(),  storeName)); } Reproducible with KStream number of threads more then 1   StoreQueryIntegrationTest#streamsConfiguration  config.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2);     Suggested solution is to not throw exception if at least one state store is found, which is always true when using StoreQueryParameters.withPartition  https://issues.apache.org/jira/browse/KAFKA-10030?jql=project%20%3D%20KAFKA%20AND%20component%20%3D%20streams  @mjsax @guozhangwang","closed","streams,","dima5rr","2020-05-21T11:06:57Z","2020-06-02T01:36:32Z"
"","8704","KAFKA-10030 allow fetching a key from a single partition","StreamThreadStateStoreProvider#stores throws exception whenever taskId is not found, which is not correct behaviour in multi-threaded env where state store partitions are distributed among several StreamTasks.   final Task task = tasks.get(keyTaskId); if (task == null) {  throw new InvalidStateStoreException(  String.format(""The specified partition %d for store %s does not exist."",  storeQueryParams.partition(),  storeName)); } Reproducible with KStream number of threads more then 1   StoreQueryIntegrationTest#streamsConfiguration  config.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2);     Suggested solution is to not throw exception if at least one state store is found, which is always true when using StoreQueryParameters.withPartition","closed","","dima5rr","2020-05-21T10:50:16Z","2020-05-21T10:51:43Z"
"","9020","KAFKA-10271 Performance regression while fetching a key from a single partition","StreamThreadStateStoreProvider excessive loop over calling internalTopologyBuilder.topicGroups(), which is synchronized, thus causing significant performance degradation to the caller, especially when store has many partitions.  https://issues.apache.org/jira/browse/KAFKA-10271","closed","","dima5rr","2020-07-14T15:05:22Z","2020-10-08T17:43:02Z"
"","8733","MINOR: Remove retries entry from Streams config table","Streams doesn't override the `retries` config now.","closed","docs,","JimGalasyn","2020-05-27T19:11:26Z","2020-05-27T19:25:38Z"
"","9206","MINOR: rewrite zipWithIndex by normal foreach to refrain unnecessary …","steal some memory back from hot method :) - improvement: +17% - garbage allocation: -12 %  **Parameters** 1. bufferSupplierStr = NO_CACHING 1. bytes = RANDOM 1. compressionType = NONE 1. maxBatchSize = 500 1. messageSize = 100000 1. messageVersion = 2  **BEFORE**  ``` Benchmark                                                                                                  (bufferSupplierStr)  (bytes)  (maxBatchSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score       Error   Units UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed                                        NO_CACHING   RANDOM             500         100000                 2  thrpt   15  2315566.901 ± 35760.064   ops/s UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.alloc.rate                         NO_CACHING   RANDOM             500         100000                 2  thrpt   15     4004.046 ±    61.825  MB/sec UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.alloc.rate.norm                    NO_CACHING   RANDOM             500         100000                 2  thrpt   15     1904.000 ±     0.001    B/op UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Eden_Space                NO_CACHING   RANDOM             500         100000                 2  thrpt   15     4007.442 ±    80.422  MB/sec UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Eden_Space.norm           NO_CACHING   RANDOM             500         100000                 2  thrpt   15     1905.678 ±    29.493    B/op UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Old_Gen                   NO_CACHING   RANDOM             500         100000                 2  thrpt   15        0.007 ±     0.001  MB/sec UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Old_Gen.norm              NO_CACHING   RANDOM             500         100000                 2  thrpt   15        0.003 ±     0.001    B/op UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.count                              NO_CACHING   RANDOM             500         100000                 2  thrpt   15      516.000              counts UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.time                               NO_CACHING   RANDOM             500         100000                 2  thrpt   15      491.000                  ms ```  **AFTER**  ``` Benchmark                                                                                                  (bufferSupplierStr)  (bytes)  (maxBatchSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score      Error   Units UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed                                        NO_CACHING   RANDOM             500         100000                 2  thrpt   15  2715876.329 ± 4288.625   ops/s UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.alloc.rate                         NO_CACHING   RANDOM             500         100000                 2  thrpt   15     4163.501 ±    6.553  MB/sec UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.alloc.rate.norm                    NO_CACHING   RANDOM             500         100000                 2  thrpt   15     1688.000 ±    0.001    B/op UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Eden_Space                NO_CACHING   RANDOM             500         100000                 2  thrpt   15     4164.497 ±   56.694  MB/sec UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Eden_Space.norm           NO_CACHING   RANDOM             500         100000                 2  thrpt   15     1688.397 ±   22.173    B/op UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Old_Gen                   NO_CACHING   RANDOM             500         100000                 2  thrpt   15        0.008 ±    0.002  MB/sec UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Old_Gen.norm              NO_CACHING   RANDOM             500         100000                 2  thrpt   15        0.003 ±    0.001    B/op UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.count                              NO_CACHING   RANDOM             500         100000                 2  thrpt   15      536.000             counts UncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.time                               NO_CACHING   RANDOM             500         100000                 2  thrpt   15      518.000                 ms ```    ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-08-22T08:43:26Z","2020-09-24T09:46:22Z"
"","8725","KAFKA-9608: Transaction Event Simulation Test","Start the basic template for transaction event simulation.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","abbccdda","2020-05-25T17:55:33Z","2020-09-18T21:20:02Z"
"","8681","KAFKA-10010: Should make state store registration idempotent","Standby task could also at risk of getting into illegal state when not being closed during `HandleLostAll`  1. The standby task was initializing as `CREATED` state, and task corrupted exception was thrown from registerStateStores  2. The task corrupted exception was caught, and do a non-affected task commit  3. The task commit failed due to task migrated exception  4. The handleLostAll didn't close the standby task, leaving it as CREATED state  5. Next rebalance complete, the same task was assigned back as standby task.  6. Illegal Argument exception caught as state store already registered  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-05-17T18:20:21Z","2020-05-19T22:02:56Z"
"","9346","KAFKA-10535: Split ProcessorContext into Processor/StateStore/RecordContext","Split up the ProcessorContext into separate containers more appropriate for usage in `Processor#init` (`api.ProcessorContext`),  `StateStore#init` (`StateStoreContext`), and `Processor#process` (the new `Record` and `RecordMetadata` classes).  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-09-28T20:55:19Z","2020-10-02T18:00:38Z"
"","8787","KAFKA-10085: correctly compute lag for optimized source changelogs","Split out the optimized source changelogs and fetch the committed offsets rather than the end offset for task lag computation  Must be cherrypicked to 2.6","closed","","ableegoldman","2020-06-03T00:00:18Z","2020-06-26T22:39:57Z"
"","8701","MINOR: Add reason to log message when incrementing the log start offset","Sometimes logging leaves us guessing at the cause of an increment to the log start offset. Since this results in deletion of user data, I think the logging should be clear about the reason.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-05-20T23:11:54Z","2020-05-26T20:52:20Z"
"","9362","KAFKA-migration-scripts","Something i found that that was missing in the /bin sources when using kafka, is a script to help migrating between 2 clusters, without messing out the offsets.  so i have made this suite of scripts to simulate a cluster migration, and after the dry-run, finaly migrate !","open","","tcarecolin","2020-10-01T20:02:09Z","2020-10-01T20:14:32Z"
"","9084","MINOR: Preserve Kafka exception from RebalanceListener","Some of the rebalance listener may be implemented by Kafka as well, e.g. Connect and Streams, and if the exception thrown is actually a KafkaException, then we should not wrap it but directly throw the exception from the listener.  Unit tests to be added; cc @abbccdda to review.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","guozhangwang","2020-07-27T05:49:41Z","2020-10-15T16:40:03Z"
"","9295","MINOR: standardize rebalance related logging for easy discovery & debugging","Some minor logging adjustments to standardize the grammar of rebalance related messages and make it easy to query the logs for quick debugging results","closed","","ableegoldman","2020-09-16T23:57:59Z","2020-09-26T03:29:18Z"
"","9308","MINOR: streams docs fixes","Some minor fixes that were found in the kafka-site PR review after the AK PR had already been merged  Should be cherrypicked to 2.6, only after https://github.com/apache/kafka/pull/9027","closed","","ableegoldman","2020-09-18T23:16:01Z","2020-09-28T20:20:53Z"
"","9171","MINOR: add ableegoldman and cadonna to whitelist","So we don't have to bug the committers to kick off tests 😄","closed","","ableegoldman","2020-08-12T17:29:26Z","2020-08-12T18:10:37Z"
"","8915","MINOR; Iterate over the partitions only once when building LeaderAndIsrRequest","Small optimization in building LeaderAndIsrRequest to avoid iterating twice on the partitions.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-06-23T12:54:11Z","2020-06-29T07:23:59Z"
"","8576","format with correct syntax","small change fix string formatting  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","fantayeneh","2020-04-28T21:11:05Z","2020-04-30T06:02:12Z"
"","8590","KAFKA-6145: Remove check to reuse previous assignment","Since we cannot guarantee to reassign the correct number of stand-by tasks when reusing the previous assignment and the reassignment is rather a micro-optimization, it is removed to keep the algorithm correct and simple.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","cadonna","2020-04-30T12:17:10Z","2020-05-20T08:07:04Z"
"","8482","KAFKA-9863: update the deprecated --zookeeper option in the documentation into --bootstrap-server","Since V2.2.0, the -zookeeper option turned into deprecated because Kafka can directly connect to brokers with --bootstrap-server (KIP-377). But in the official documentation, there are many example commands use --zookeeper instead of --bootstrap-server. Follow the command in the documentation, you'll get this warning, which is not good.  ``` Warning: --zookeeper is deprecated and will be removed in a future version of Kafka. Use --bootstrap-server instead to specify a broker to connect to. ```  Update configuration.html, ops.html, security.html files  Mainly update 2 commands: 1. before: `bin/kafka-configs.sh --zookeeper localhost:2181 ...`     after: `bin/kafka-configs.sh --bootstrap-server localhost:9092 ...` 2. before: `bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 ...`     after: `bin/kafka-reassign-partitions.sh --bootstrap-server localhost:9092 ...`  JIRA: https://issues.apache.org/jira/browse/KAFKA-9863  ### Committer Checklist (excluded from commit message) - [x] Verify design and implementation  - [x] Verify test coverage and CI build status - [x] Verify documentation (including upgrade notes)","closed","","showuon","2020-04-14T11:28:19Z","2020-06-30T17:29:51Z"
"","8947","KAFKA-10212: Describing a topic with the TopicCommand fails if unauthorised to use ListPartitionReassignments API","Since https://issues.apache.org/jira/browse/KAFKA-8834, describing topics with the TopicCommand requires privileges to use ListPartitionReassignments or fails to describe the topics with the following error:  > Error while executing topic command : Cluster authorization failed.   This is a quite hard restriction has most of the secure clusters do not authorize non admin members to access ListPartitionReassignments.  This patch catches the `ClusterAuthorizationException` exception and gracefully fails back. We already do this when the API is not available so it remains consistent.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-06-29T13:14:41Z","2020-10-06T20:08:45Z"
"","8876","KAFKA-10167: use the admin client to read end-offset","Since admin client allows use to use flexible offset-spec, we can always set to use read-uncommitted regardless of the eos config.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","guozhangwang","2020-06-16T00:44:55Z","2020-06-18T19:24:46Z"
"","9043","KAFKA-10295: Wait for connector recovery in test_bounce","Signed-off-by: Greg Harris   This additional waiting is for: * The scheduled.rebalance.max.time.ms to expire and for tasks to be reassigned * The source connector to start and commit offsets at least once beyond it's last commit * The sink connector to have adequate time to read any of the messages written by the source  Prevents flakey test failures with messages like ""Found sink sequence number greater than any generated sink sequence number for task %d: %d > %d"" when test_bounce is running with hard bounces and Incremental Cooperative Rebalancing enabled.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","gharris1727","2020-07-20T06:52:52Z","2020-07-21T18:48:24Z"
"","9040","KAFKA-10286: Connect system tests should wait for workers to join group","Signed-off-by: Greg Harris   Currently, the system tests `connect_distributed_test` and `connect_rest_test` only wait for the REST api to come up. The startup of the worker includes an asynchronous process for joining the worker group and syncing with other workers. There are some situations in which this sync takes an unusually long time, and the test continues without all workers up. This leads to flakey test failures, as worker joins are not given sufficient time to timeout and retry without waiting explicitly.  This changes the ConnectDistributedTest to wait for the `Joined group` message to be printed to the logs before continuing with tests. I've activated this behavior by default, as it's a superset of the checks that were performed by default before.  This log message is present in every version of DistributedHerder that I could find, in slightly different forms, but always with `Joined group` at the beginning of the log message. This change should be safe to backport to any branch.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","gharris1727","2020-07-18T08:18:46Z","2020-07-22T18:10:35Z"
"","8649","MINOR: Replace null with an actual value for timestamp field in InsertField SMT unit tests","Signed-off-by: Arjun Satish   PR adds a unit test to check the behavior of the InsertField SMT when trying to insert a field that takes its value from the Kafka record timestamp. All other tests currently pass a null value for the record timestamp.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","wicknicks","2020-05-12T02:28:38Z","2020-05-13T01:03:31Z"
"","9015","MINOR: Remove call to Exit.exit() to prevent infinite recursion","Signed-off-by: Arjun Satish   If we call org.apache.kafka.common.utils.Exit#exit(int code) with code=0, the current implementation will go into an infinite recursion and kill the VM with a stack overflow error.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","wicknicks","2020-07-14T00:54:13Z","2020-07-14T20:42:04Z"
"","8535","KAFKA-9903","ShutdownComplete will countdown in the finally block when thread shutdown due to an error, and in this case thread is not running. So isRunning logic should check isShutdownInitiated and isShutdownComplete.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","lushilin","2020-04-22T19:27:18Z","2020-04-25T08:55:20Z"
"","9022","KAFKA-10158: Fix flaky testDescribeUnderReplicatedPartitionsWhenReassignmentIsInProgress","Set `replica.fetch.max.bytes` to `1` and produce multiple record batches to allow for throttling to take place. This helps avoid a race condition where the reassignment would complete more quickly than expected causing an assertion to fail some times.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","bdbyrne","2020-07-14T19:00:54Z","2020-08-15T15:40:11Z"
"","8661","KAFKA-9603: Do not turn on bulk loading for segmented stores on stand-by tasks","Segmented state stores turn on bulk loading of the underlying RocksDB when restoring. This is correct for segmented state stores that are in restore mode on active tasks and the onRestoreStart() and onRestoreEnd() in RocksDBSegmentsBatchingRestoreCallback take care of toggling bulk loading mode on and off. However, restoreAll() in RocksDBSegmentsBatchingRestoreCallback might also turn on bulk loading mode. When this happens on a stand-by task bulk loading mode is never turned off. That leads to steadily increasing open file descriptors in RocksDB because in bulk loading mode RocksDB creates continuously new files but never compacts them (which is the intended behaviour).  This PR checks whether the task is an active task before turning on bulk  loading mode in restoreAll() for segmented state stores.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","cadonna","2020-05-12T19:57:30Z","2020-05-22T12:08:40Z"
"","9136","KAFKA-10211: Add DirectoryConfigProvider","See KIP-632.","closed","","tombentley","2020-08-07T09:57:56Z","2020-08-22T15:10:49Z"
"","8909","KAFKA-6733: Support of printing additional ConsumerRecord fields in DefaultMessageFormatter (rebased)","See KIP-431: https://cwiki.apache.org/confluence/display/KAFKA/KIP-431%3A+Support+of+printing+additional+ConsumerRecord+fields+in+DefaultMessageFormatter  Rebased to the latest trunk from https://github.com/apache/kafka/pull/4807  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","badaiaqrandista","2020-06-21T13:42:19Z","2020-07-22T08:22:32Z"
"","9253","KAFKA-10366 & KAFKA-9649: Implement KIP-659 to allow TimeWindowedDeserializer and TimeWindowedSerde to handle window size","See KIP details and discussions here: https://cwiki.apache.org/confluence/display/KAFKA/KIP-659%3A+Improve+TimeWindowedDeserializer+and+TimeWindowedSerde+to+handle+window+size  Deprecates methods that allow users to skip setting a window size when one is needed. Adds a window size streams config to allow the `timeWindowedDeserializer` to calculate window end time.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","lct45","2020-09-04T18:44:38Z","2021-02-02T00:21:00Z"
"","9460","MINOR: Fix JDK8 compatibility issue in Snappy","See https://github.com/xerial/snappy-java/releases/tag/1.1.7.7 for more details.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-10-20T14:35:42Z","2020-10-21T03:44:40Z"
"","8951","KAFKA-10212: Describing a topic with the TopicCommand fails if unauthorised to use ListPartitionReassignments API (targeting 2.5 branch)","See https://github.com/apache/kafka/pull/8947  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-06-29T15:36:04Z","2020-10-06T20:08:41Z"
"","9162","MINOR: refactor Log to get rid of ""return"" in nested anonymous function","scala throws and then catches ```NonLocalReturnException``` to implement the control flow of returning from a nested anonymous function. That is anti-pattern and we should avoid using it in the hot methods.  I run the producer benchmark and the following screen snapshot show the improvement by this patch. The ```NonLocalReturnException``` is gone.  **BEFORE**    **AFTER**      ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-08-11T15:43:36Z","2020-10-27T09:45:12Z"
"","8537","KAFKA-9907: Switch default build to Scala 2.13","Scala 2.13.2 introduces support for suppressing warnings, which makes it possible to enable fatal warnings. This is useful enough from a development perspective to justify this change.  In addition, Scala 2.13.2 also has a Vector implementation with significant performance improvements and encoding of String matches to switches.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-04-23T06:14:10Z","2020-04-23T14:03:18Z"
"","9285","Minor: fix streams quickstart in Jenkinsfile","Running commands like ""cd"" or setting variables inside `sh` steps do not survive to following steps in Jenkinsfile. Instead we're supposed to use things like `dir(""somedir"") { ... }` and injecting variables with `env` directive or directly into the command string (like I've done here).","closed","","mumrah","2020-09-14T14:33:16Z","2020-10-15T07:47:34Z"
"","8807","KAFKA-10106: log time taken to handle LeaderAndIsr request","ReplicaManager!becomeLeaderOrFollower handles the LeaderAndIsr request, StateChangeLogger logs when this request is handled, however it can be useful to log when this calls ends and record the time taken, can help operationally.   Proposal is to ReplicaManager!becomeLeaderOrFollower start measuring the time before the `replicaStateChangeLock` is acquired and log before the response is returned.   Note lines that changed here are 1373-1377 and 1233, with the response being captured in 1246.","closed","","rite2nikhil","2020-06-05T07:49:07Z","2020-06-08T18:58:41Z"
"","8938","KAFKA-10173: Use SmokeTest for upgrade system tests","Replaces the previous upgrade test's trivial Streams app with the commonly used SmokeTest, exercising many more features. Also adjust the test matrix to test upgrading from each released version since 2.2 to the current branch.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","vvcephei","2020-06-27T18:08:15Z","2020-07-03T19:03:45Z"
"","8993","KAFKA-10173: Use SmokeTest for upgrade system tests (#8938)","Replaces the previous upgrade test's trivial Streams app with the commonly used SmokeTest, exercising many more features. Also adjust the test matrix to test upgrading from each released version since 2.0 to the current branch.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-07-08T15:25:10Z","2020-07-31T16:30:05Z"
"","9400","MINOR rename kafka.utils.Whitelist to IncludeList","rename internal classes, methods, and related constants for KIP-629","closed","","xvrl","2020-10-09T05:50:08Z","2020-10-13T19:37:03Z"
"","8865","KAFKA-10168: fix StreamsConfig parameter name variable","Rename `TOPOLOGY_OPTIMIZATION` to `TOPOLOGY_OPTIMIZATION_CONFIG`.  All variables in `StreamConfig` end with `_CONFIG`. We should align the variable name accordingly. This is technically a public API change. Happy to do a quick KIP for it, if we think we need one.  Cf. https://cwiki.apache.org/confluence/display/KAFKA/KIP-626%3A+Rename+StreamsConfig+config+variable+name  \cc @guozhangwang @vvcephei","closed","kip,","mjsax","2020-06-13T00:56:17Z","2020-06-20T00:41:11Z"
"","8597","KAFKA-6145: KIP 441 remove balance factor","Removes this config and its usage from the balanced assignor (effectively setting it to 1)","closed","","ableegoldman","2020-05-01T02:04:46Z","2020-05-01T18:41:14Z"
"","8921","KAFKA-10160: Kafka MM2 consumer configuration","Removed hardcoded auto.offset.reset in MM2 consumer configuration, retained default as earliest unless specified.  ### Committer Checklist (excluded from commit message) - [*] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","satishbellapu","2020-06-24T00:24:57Z","2021-03-19T12:17:23Z"
"","9457","MINOR: Trivial Cleanups","Remove unused variables, methods, parameters, unthrown exceptions, and fixing typos.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dongjinleekr","2020-10-20T08:11:26Z","2021-03-10T05:21:31Z"
"","9281","KAFKA-10478: Allow duplicated ports in advertised.listeners","Remove the requirement for unique port numbers for the advertised.listener parameters. This restriction makes for the listeners parameter but there's not reason to apply the same logic for advertised.listeners.  Being able to do this opens possibilities for some practical applications when using Kerberos authentication. For example, when configuring Kafka using Kerberos authentication and a Load Balancer we need to have two SASL_SSL listeners: (A) one running with the kafka/hostname principal and (B) another using kafka/lb_name, which is necessary for proper authentication when using the LB FQDN. After bootstrap, though, the client receives the brokers' addresses with the actual host FQDNs advertised by the brokers. To connect to the brokerd using the hostnames the client must connect to the listener A to be able to authenticate successfully with Kerberos.  All unit/integration tests have passed.  ### Committer Checklist (excluded from commit message) - [X] Verify design and implementation  - [X] Verify test coverage and CI build status - [X] Verify documentation (including upgrade notes)","closed","","asdaraujo","2020-09-12T15:16:17Z","2020-10-07T19:53:14Z"
"","8686","MINOR: Remove redundant TOC and introduction in Running Streams Applications","Remove redundant TOC and introduction in Running Streams Applications https://kafka.apache.org/25/documentation/streams/developer-guide/running-app  before: ![image](https://user-images.githubusercontent.com/43372967/82212247-d181ec00-9944-11ea-8aac-3612fc17893d.png)  after: ![image](https://user-images.githubusercontent.com/43372967/82212560-510fbb00-9945-11ea-8b0d-7911a2ac13e2.png)   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-05-18T12:22:44Z","2020-05-19T00:02:52Z"
"","9179","KAFKA-10390: Remove ignore case option when grep process info to be more specific","Remove ignore case option when grep process info to be more specific since our entry point is definitely `kafka.Kafka`.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-08-14T03:07:25Z","2020-10-01T01:25:36Z"
"","8513","MINOR: jackson 2.10.3","release notes: https://github.com/FasterXML/jackson/wiki/Jackson-Release-2.10.3  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","sullis","2020-04-18T23:05:56Z","2020-08-05T17:33:42Z"
"","8659","KAFKA-9617 Replica Fetcher can mark partition as failed when max.mess…","related to https://issues.apache.org/jira/browse/KAFKA-9617  Skip to check the size of record if the record is already accepted by leader.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-05-12T18:34:18Z","2020-05-16T17:05:27Z"
"","9251","KAFKA-10459: Document IQ APIs where order does not hold between stores","Referring to https://github.com/apache/kafka/pull/9138#discussion_r480469688 , documented on the `ReadOnlyWindowStore` class. Thanks.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","showuon","2020-09-04T03:56:49Z","2020-09-22T01:41:24Z"
"","8981","KAFKA-10235 Fix flaky transactions_test.py","Reducing timeout of transaction can quickly cleanup the unstable offsets. IN hard_bounce mode, transaction is broke ungracefully. Hence, it produces unstable offsets which obstructs TransactionalMessageCopier from receiving position of group.  issue: https://issues.apache.org/jira/browse/KAFKA-10235  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-07-05T17:47:51Z","2020-07-09T16:33:08Z"
"","8884","MINOR: Fix flaky HighAvailabilityTaskAssignorIntegrationTest","Reduce test data set from 1000 records to 500. Some recent test failures indicate that the Jenkins runners aren't able to process all 1000 records in two minutes.   Also add sanity check that all the test data are readable from the input topic.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-06-16T20:59:16Z","2020-06-17T15:17:02Z"
"","9234","MINOR: Record all poll invocations","Record the `pollSensor` after every invocation to poll, rather than just when we get records back so that we can accurately gauge how often we're invoking Consumer#poll.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-08-31T21:00:39Z","2020-09-03T19:23:24Z"
"","9096","MINOR: Add comments to constrainedAssign and generalAssign method","Recently, I tried to read the codes to understand what the `constrainedAssign` and `generalAssign` method is doing, but it is so difficult and suffering due to the complexity of the algorithm. And then I traced back to the JIRA ticket and KIP to get much more information about them. So, I think we should put at least the algorithm goal and main steps in the code comments, to let other developers better understand them and better do trouble shooting if any.   **reference for `constrainedAssign` algorithm:** https://issues.apache.org/jira/browse/KAFKA-9987?focusedCommentId=17106832&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17106832  **reference for `generalAssign` algorithm:** https://cwiki.apache.org/confluence/display/KAFKA/KIP-54+-+Sticky+Partition+Assignment+Strategy   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","consumer,","showuon","2020-07-29T06:53:30Z","2020-08-03T18:51:21Z"
"","8893","MINOR: Upgrade jetty to 9.4.30.v20200611","Recently commit 492306a updated both jetty to version 9.4.27.v20200227 and jersey to version 2.31  However in the latest versions of jetty, the renaming of the method `Response#closeOutput` to `Response#completeOutput` has been reverted, with the latest version using again `Response#closeOutput`.   Jersey has not released a recent version in which `Response#closeOutput` is called directly. In its latest version 2.31 `Response#closeOutput` will be called if `Response#completeOutput` throws a `NoSuchMethodError` exception, which keeps things functional but inefficient.   Therefore we can choose to merge this PR early, while waiting for a new version of jersey, or we could wait and update both dependencies together again.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","kkonstantine","2020-06-18T02:15:55Z","2020-06-29T17:36:17Z"
"","8741","KAFKA-9332 change how to get joinGroupTimeoutMs","rebalanceTimeoutMs + 5000 is always greater than rebalanceTimeoutMs","closed","","sasukerui","2020-05-28T14:38:53Z","2020-06-07T21:21:27Z"
"","8803","KAFKA-10102: update ProcessorTopology instead of rebuilding it","Rather than recreate the entire topology when we find new regex matched input partitions, we can just update the relevant pieces.  Only the SourceNodes and ProcessorTopology seem to care about the input topics, and we can actually extract this information out of the SourceNode altogether by pulling it into the ProcessorTopology.  Should go to 2.6","closed","streams,","ableegoldman","2020-06-05T04:02:58Z","2020-06-26T22:39:52Z"
"","8922","MINOR: Fixed some resource leaks.","Ran [infer tool](https://fbinfer.com/). Fixed some resource leak.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","leonardge","2020-06-24T08:09:08Z","2020-07-19T15:06:13Z"
"","8847","KAFKA-7833: Add missing test","Quick follow up to #8825   Call for review @guozhangwang @vvcephei","closed","tests,","mjsax","2020-06-11T00:42:45Z","2020-06-11T03:17:11Z"
"","9357","MINOR: Fix KStreamKTableJoinTest and StreamTaskTest","Quick fixes for checkstyle issues in StreamTaskTest and updated syntax for tests in KSTreamKTableJoinTest based on changes from https://github.com/apache/kafka/pull/9186  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","lct45","2020-09-30T21:16:40Z","2020-10-01T04:59:59Z"
"","8991","Sync AK trunk -> Confluent Kafka master 2020/07/07","Pull changes from AK trunk into confluentinc/kafka. All changes applied cleanly.  Expecting Schema Registry failure due to known blocking changes.   *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","steverod","2020-07-08T00:30:41Z","2020-07-08T03:04:09Z"
"","8573","Add posibility to append parameters for tool execution","Provides the possibility to append connection infos to all executed commands: ``` $ export KAFKA_OPTS=""--bootstrap-server 10.1.1.1:9092,10.1.1.1:9092,10.1.1.1:9092"" kafka-topics.sh --create --topic eventlog-global-dev-003 -replication-factor 3 --partitions 1 $ kafka-topics.sh --create --topic eventlog-global-dev-005 -replication-factor 3 --partitions 1 Adding specified KAFKA_OPTS_APPEND : '--bootstrap-server 10.1.1.1:9092,10.1.1.1:9092,10.1.1.1:9092' ```  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","scoopex","2020-04-28T13:35:36Z","2020-06-05T21:03:43Z"
"","9222","KAFKA-10437: Implement test-utils and StateStore changes for KIP-478","Propose a new init method for StateStore so that it works with the new ProcessorContext. Convert the test-utils MockProcessorContext to the new API.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","vvcephei","2020-08-26T02:13:05Z","2021-01-08T02:04:34Z"
"","8647","KAFKA-9669; Loosen validation of inner offsets for older message formats","Prior to KAFKA-8106, we allowed the v0 and v1 message formats to contain non-consecutive inner offsets. Inside `LogValidator`, we would detect this case and rewrite the batch. After KAFKA-8106, we changed the logic to raise an error in the case of the v1 message format (v0 was still expected to be rewritten). This caused an incompatibility for older clients which were depending on the looser validation. This patch reverts the old logic of rewriting the batch to fix the invalid inner offsets.  Note that the v2 message format has always had stricter validation. This patch also adds a test case for this.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-05-12T00:49:57Z","2020-05-12T19:06:09Z"
"","9408","KAFKA-10598: Improve IQ name and type checks","Previously, we would throw a confusing error, ""the store has migrated,"" when users ask for a store that is not in the topology at all, or when the type of the store doesn't match the QueryableStoreType parameter.  Adds an up-front check that the requested store is registered and also a better error message when the QueryableStoreType parameter doesn't match the store's type.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-10-10T00:11:02Z","2020-10-12T15:58:18Z"
"","9002","MINOR: Add ApiMessageTypeGenerator","Previously, we had some code hard-coded to generate message type classes for RPCs.  We might want to generate message type classes for other things as well, so make it more generic.","closed","","cmccabe","2020-07-09T15:04:45Z","2020-07-15T16:03:51Z"
"","8651","kafkatest: Deploy VerifiableClient in constructor to avoid test timeouts","Previous to this fix a plugged-in verifiable client, such as confluent-kafka-python, would be deployed on the node in the background worker thread as the client was started. Since this could be time consuming (e.g., 10+ seconds) and since the main test thread would continue to operate, it was common for the current test to time out waiting for e.g. the verifiable producer to produce messages while it was in fact still deploying.  The fix here is to deploy the verifiable client on the node when the verifiable client is instantiated, which is thus a blocking operation on the main test thread, avoiding any test-based timeouts.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","edenhill","2020-05-12T07:45:00Z","2020-05-21T16:59:33Z"
"","9266","KAFKA-10469: Resolve logger levels hierarchically","Previous to root logger level was used, ignoring intervening loggers with different levels.","closed","","tombentley","2020-09-08T16:18:28Z","2020-11-10T14:40:28Z"
"","8591","KAFKA-6342: Move workaround for JSON parsing of non-escaped strings","PR #4303 introduced parsing for some invalid JSONs, such as escaped SSL names. This PR moves the parsing directly under AclEntry to localize this logic.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","viktorsomogyi","2020-04-30T13:33:18Z","2020-05-07T13:22:37Z"
"","8890","KAFKA-9891: add integration tests for EOS and StandbyTask","Ports the test from #8886 to `trunk` -- this should be merged to `2.6` branch.  One open question. In `2.6` and `trunk` we rely on the active tasks to wipe out the store if it crashes. However, assume there is a hard JVM crash and we don't call `closeDirty()` the store would not be wiped out. Thus, I am wondering, if we would need to fix this (for both active and standby tasks) and do a check on _startup_ if a local store must be wiped out?  The current test passes, as we do a proper cleanup after the exception is thrown.  Call for review @guozhangwang @abbccdda","closed","tests,","mjsax","2020-06-17T22:06:36Z","2020-06-19T22:16:04Z"
"","8904","KAFKA-10185: Restoration info logging (#8896)","Ports #8896 to 2.5  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-06-19T19:54:08Z","2020-06-21T20:27:19Z"
"","8773","MINOR: ChangelogReader should poll for duration 0 for standby restore","polling for standby replicas should not block, so use a duration of 0. Still working on a test.","closed","","rodesai","2020-06-01T22:45:02Z","2020-06-02T05:34:08Z"
"","9019","Add connect-mirror-maker.bat for Windows platform","Please, add this file to make it possible to run MirrorMaker 2.0 on Windows platform","open","","ruslanbay","2020-07-14T14:57:23Z","2020-07-14T15:34:26Z"
"","8592","KAFKA-3184: Add Checkpoint for In-memory State Store","Persistent mode for InMemoryKeyValueStore. If persistent mode is enabled then:    * checkpoint thread started on `KeyValueStore#init`   * every `InMemoryKeyValueStore#COUNT_FLUSH_TO_STORE` flush execution copy of the `InMemoryKeyValueStore#map` passed to checkpoint thread.   * checkpoint thread persists data every time it sees new instance of `InMemoryKeyValueStore#map`.   * persisted data are loaded on `KeyValueStore#init`. ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","nizhikov","2020-04-30T16:12:40Z","2020-05-13T08:23:39Z"
"","9419","KAFKA-10343: Add IBP based ApiVersion tests","Per requirement from KIP-590, we need to add IBP as part of the ApiVersionResponse consideration. All redirected RPCs need to take IBP into consideration when getting a future bump. This PR ensures to remind the developer by doing a hard-coded ApiVersion test to check for any recent RPC version bump.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-10-13T06:52:32Z","2020-10-14T23:06:42Z"
"","8940","KAFKA-10181: AlterConfig/IncrementalAlterConfig should route to the controller for non validation calls","Per KIP-590 requirement, we need to route the AlterConfig protocols toward the controller, instead of letting individual brokers handle them.   In this change, if the call is for validation only, we could still follow what we currently have by: 1. Send topic resource changes to a random node 2. Send broker resource changes to the specified node  Otherwise, if this is not a validation only call (we are actually changing the config), all resources should be bundled and sent to the controller.  Bumped AlterConfig/IncrementalAlterConfig RPC to v2. When the 3 conditions are met: 1. Request >= v2 2. Not a validation request 3. The target broker is not the controller  we would fail individual resource change request with `NOT_CONTROLLER` error.  Although AlterConfig is deprecated, we still need to maintain the backward compatibility instead of leaving a possible RPC which could still be routing to non controller for actual config changes.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-06-28T05:31:54Z","2020-07-30T04:14:37Z"
"","9215","KAFKA-10133: MM2 readme update on config","Per https://issues.apache.org/jira/browse/KAFKA-10133, MM2 users sometimes confuse on specifying or overriding the default configurations at different levels: connector, MM2, producer/consumers. It may be great if we clarify how to correctly set those configs in README.md, in addition to the example config file.","closed","","ning2008wisc","2020-08-24T21:34:14Z","2020-09-04T19:05:12Z"
"","9309","KAFKA-10503: MockProducer doesn't throw ClassCastException when no","partition for topic  Though MockProducer admits serializers in its constructors, it doesn't check during send method that those serializers are the proper ones to serialize key/value included into the ProducerRecord.  This check is only done if there is a partition assigned for that topic.  It would be an enhancement if these serialize methods were also invoked in simple scenarios, where no partition is assigned to a topic.  Added a unit test to check expected behaviour  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","gmunozfe","2020-09-19T14:04:05Z","2020-10-01T05:31:22Z"
"","9333","KAFKA-9274: Revert deprecation of `retries` for producer and admin clients","Partially reverts #8864   Call for review @vvcephei @hachikuji @cmccabe @ijuma @rhauch","closed","admin,","mjsax","2020-09-24T00:46:51Z","2020-09-30T19:13:39Z"
"","9385","KAFKA-9274: fix incorrect default value for `task.timeout.ms` config","Part of KIP-572.  Also add handler method to trigger/reset the timeout on a task.  Call for review @vvcephei","closed","kip,","mjsax","2020-10-06T20:30:28Z","2021-01-08T02:04:11Z"
"","9397","KAFKA-10583: Add documentation on the thread-safety of KafkaAdminClient.","Other than a Stack Overflow comment (see https://stackoverflow.com/a/61738065) by Colin Patrick McCabe (@cmccabe ) and a proposed design note on KIP-117 wiki, there is no source that verifies the thread-safety of `KafkaAdminClient`.  This patch updates JavaDoc of `KafkaAdminClient` to clarify its thread-safety.","closed","","efeg","2020-10-08T19:05:33Z","2020-10-19T16:11:02Z"
"","8943","KAFKA-10196: Add missing '--version' option to producer-performance","Option '--version' is missing in producer-performance. This patch is to add this option to display kafka version.  Change-Id: Icfbdecfe56fb51439ec83d7ef7dc48ace3116ca2 Signed-off-by: Jiamei Xie   *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jiameixie","2020-06-29T01:35:30Z","2022-05-24T03:27:02Z"
"","8950","Optimize the judgment condition of TopicMetadata parameters","Optimize the judgment condition of TopicMetadata parameters. Judgment has been made in the method handleTopicMetadataRequest. like authorizedTopics.isEmpty   if (authorizedTopics.isEmpty)         Seq.empty[MetadataResponse.TopicMetadata]       else         getTopicMetadata(metadataRequest.allowAutoTopicCreation, authorizedTopics, request.context.listenerName,           errorUnavailableEndpoints, errorUnavailableListeners)  I think there is no need to do another judgment in the getTopicMetadata method. I think  topics.isEmpty can be deleted  if (topicResponses.size == topics.size) {       topicResponses     }","open","","sasukerui","2020-06-29T14:57:33Z","2020-10-19T05:24:20Z"
"","8652","KAFKA-9980: Reserved word """" may not be santinized to ""%3Cdefault%3E""","One-line change. Please refer to the Jira ticket. Straight forward.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ctan888","2020-05-12T07:48:25Z","2020-06-30T17:32:51Z"
"","8510","MINOR: cleanup RocksDBStore tests","One of the new rocksdb unit tests creates a non-temporary `rocksdb` directory wherever the test is run from, with some rocksdb files left behind after the test(s) are done. We should use the `tempDirectory` dir for this testing","closed","","ableegoldman","2020-04-18T03:56:40Z","2020-04-20T22:25:40Z"
"","9348","KAFKA-10527; Voters should not reinitialize as leader in same epoch","One of the invariants that the raft replication protocol ensures is that each record is uniquely identified by leader epoch and offset. This can be violated if a leader remains elected with the same epoch between restarts since unflushed data could be lost.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip-500,","hachikuji","2020-09-29T04:25:46Z","2021-08-11T13:17:08Z"
"","9260","MINOR: Update scala default version in readme","Now, default should be 2.13.x, not 2.12.x. Update it.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-09-08T06:26:04Z","2020-09-09T00:17:08Z"
"","8960","KAFKA-9144; Track timestamp from txn markers to prevent early producer expiration","Note this is a backport of (#7687) for 2.3.  Existing producer state expiration uses timestamps from data records only and not from transaction markers. This can cause premature producer expiration when the coordinator times out a transaction because we drop the state from existing batches. This in turn can allow the coordinator epoch to revert to a previous value, which can lead to validation failures during log recovery. This patch fixes the problem by also leveraging the timestamp from transaction markers.  We also change the validation logic so that coordinator epoch is verified only for new marker appends. When replicating from the leader and when recovering the log, we only log a warning if we notice that the coordinator epoch has gone backwards. This allows recovery from previous occurrences of this bug.  Finally, this patch fixes one minor issue when loading producer state from the snapshot file. When the only record for a given producer is a control record, the ""last offset"" field will be set to -1 in the snapshot. We should check for this case when loading to be sure we recover the state consistently.  Reviewers: Ismael Juma , Guozhang Wang   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-06-30T20:49:47Z","2020-07-08T02:22:46Z"
"","8815","HOTFIX: fix validity check in sticky assignor tests","Not sure what happened here, but there's a commented out line and incorrect indentation that checkstyle didn't catch. Not to mention the code itself is just generally questionable  Should be cherrypicked to 2.6, 2.5, and 2.4","closed","","ableegoldman","2020-06-05T16:58:44Z","2020-06-09T03:01:04Z"
"","8852","MINOR: code cleanup for Kafka Streams task classes","Not functional change. Pure code cleanup  Call for review @vvcephei","open","streams,","mjsax","2020-06-11T04:15:35Z","2020-12-31T02:22:50Z"
"","8851","MINOR: code cleanup for Kafka Streams task classes","Not functional change. Pure code cleanup  Call for review @vvcephei","closed","streams,","mjsax","2020-06-11T04:04:17Z","2020-06-11T04:19:56Z"
"","8572","MINOR: Fix partition numbering from 0 to P-1 instead of P in docs","nit. Protocol docs describe partition numbers as follows:  > Topic partitions themselves are just ordered ""commit logs"" numbered 0, 1, ..., P.  I assume this is a typo, as partition numbers start from 0 up to P-1.","closed","","jeqo","2020-04-28T12:49:43Z","2020-04-28T20:38:12Z"
"","8584","MINOR: fix docs typo baseTimestamp to firstTimestamp","nit. `baseTimestamp` is used when `firstTimestamp` is defined on the on-disk format and implementation.","closed","","jeqo","2020-04-29T13:06:28Z","2020-08-08T09:21:06Z"
"","8794","KAFKA-10092: Remove unused code branches in NioEchoServer","NioEchoServer the enum has its constructor declared as private, which is redundant. There is also an unused exception throws and unused method.  Reviewers: Jakob Homan   This is a newbie ticket to get used to the contribution flow.","closed","","afalko","2020-06-03T21:46:01Z","2020-10-26T05:06:57Z"
"","8879","MINOR: Upgrade ducktape to 0.7.8","Newer version of ducktape that updates some dependencies and adds some features. You can see that diff here:  https://github.com/confluentinc/ducktape/compare/v0.7.7...v0.7.8  I would like this back ported as far back as 1.0","closed","","andrewegel","2020-06-16T16:29:17Z","2020-06-18T05:08:14Z"
"","9195","KAFKA-10092 Remove unnecessary enum modifier in NioEchoServer","Newbie:   In NioEchoServer the enum has its constructor declared as private, which is redundant. We can remove this.  public class NioEchoServer extends Thread {     public enum MetricType {         TOTAL, RATE, AVG, MAX;         private final String metricNameSuffix;          private MetricType() {             metricNameSuffix = ""-"" + name().toLowerCase(Locale.ROOT);         }}}   Removed the MetricType constructor for the MetricType Enum","closed","","Sasilekha","2020-08-18T08:56:33Z","2020-10-26T05:07:31Z"
"","8842","MINOR: Moving helper methods in one test file to companion object","Moving helper methods in test file ReassignPartitionsIntegrationTest into a companion object and removing private keyword from the methods so that they may be used elsewhere.","open","","dielhennr","2020-06-10T01:41:40Z","2020-06-10T01:44:27Z"
"","8844","KAFKA-9887 fix failed task or connector count on startup failure","Moved the responsibility for recording task and connector startup and failure metrics from the Worker class  into the status listener that gets passed into the WorkerTask. The status listener is decorated to record the metrics when onStartup or onFailure occur (if failure happens before startup). This gets around the previous issues where these metrics were not being recorded because  the WorkerTasks/WorkerConnectors were either not propagating exceptions upwards, or were unable to do so easily because they were running on completely different threads. Also split out WorkerMetricsGroup from being an inner class into being a standard class. This was to make sure the Data Abstraction Coupling checkStyle rule for the Worker class was not violated.  Testing involved adding some unit tests for the decorated listeners to ensure they recorded metrics correctly. Some manual testing was done with Connectors and Tasks that deliberately threw exceptions in the startup phase to ensure JMX metrics were reported correctly. Some of the unit tests for the Worker class had some assertions around startup statistics removed, as setting these statistics is no longer the direct responsibility of the Worker class,  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","michael-carter-instaclustr","2020-06-10T05:39:20Z","2021-07-20T23:50:57Z"
"","8697","KAFKA-9983: KIP-613, add INFO level e2e latency metrics","Moved all metrics to processor-node-level, but the INOF level metrics are recorded only at the source and ""sink"" nodes (in quotations as this may be a non-sink terminal node)","closed","kip,","ableegoldman","2020-05-20T04:15:32Z","2020-06-12T23:08:46Z"
"","8668","KAFKA-9987: optimize sticky assignment algorithm for same-subscription case","Motivation and pseudo code algorithm in the ticket.  Added a scale test with large number of topic partitions and consumers and 30s timeout. With these changes, assignment with 2,000 consumers and 200 topics with 2,000 each completes within a few seconds.  Porting the same test to trunk, it took 2 minutes even with a 100x reduction in the number of topics (ie, 2 minutes for 2,000 consumers and 2 topics with 2,000 partitions)  Should be cherry-picked to 2.6, 2.5, and 2.4","closed","","ableegoldman","2020-05-14T18:46:15Z","2020-06-26T22:37:18Z"
"","8971","MINOR: prune the metadata upgrade test matrix","Most of the values in the metadata upgrade test matrix are just testing the upgrade/downgrade path between two previous releases. This is unnecessary. We run the tests for all supported branches, so what we should test is the up-/down-gradability of released versions with respect to the current branch.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","vvcephei","2020-07-01T19:55:58Z","2020-07-10T15:25:20Z"
"","8600","KAFKA-9928: Fix flaky GlobalKTableEOSIntegrationTest","Most changes thus improve the error message output in case a test fails.  Potential fix: remove producer config `retries=1`  Call for review @guozhangwang @abbccdda","closed","tests,","mjsax","2020-05-01T21:04:28Z","2020-05-08T06:01:16Z"
"","8899","MINOR: Reduce build time by gating test coverage plugins behind a flag","Most builds don't require test coverage output, so it's wasteful to spend cycles tracking coverage information for each method invoked.  I ran a quick test in a fast desktop machine, the absolute difference will be larger in a slower machine. The tests were executed after `./gradlew clean` and with a gradle daemon that was started just before the test (and mildly warmed up by running `./gradlew clean` again).  `./gradlew unitTest --continue --profile`: * With coverage enabled: 6m32s * With coverage disabled: 5m47s  I ran the same test twice and the results were within 2s of each other, so reasonably consistent.  16% reduction in the time taken to run the unit tests is a reasonable gain with little downside, so I think this is a good change.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-06-18T23:02:26Z","2020-06-19T14:32:58Z"
"","8552","MINOR: Fix some java docs of ReplicaStateMachine","Modify the java docs of ReplicaStateMachine, the java docs is not in consistent with `OfflineReplica.validPreviousStates` and `OnlineReplica.validPreviousStates`  Move the  repeated `if(traceEnabled)` before `logSuccessfulTransition` method to the method  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dengziming","2020-04-25T13:24:03Z","2020-12-10T03:15:04Z"
"","9350","KAFKA-10534: change params type to avoid redundant judgments.","Modify the AbstractConfig class, convert params `originals` type from Map to Map to avoid redundant judgments in the code.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","kobebryantlin0","2020-09-29T17:37:06Z","2020-09-29T17:38:33Z"
"","9410","KAFKA-9679: Make MockConsumer.poll() consistent with KafkaConsumer","MockConsumer should filter records from unassigned partitions instead of throwing.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","arafsheikh","2020-10-11T19:21:00Z","2020-10-11T22:02:47Z"
"","9466","KAFKA-10564: fix flaky test","Minor update to fix flaky state directory test, per feedback from @chia7712   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","mikebin","2020-10-20T21:35:53Z","2020-10-21T02:19:13Z"
"","9446","MINOR: distinguish between missing source topics and internal assignment errors","Minor followup to KAFKA-10559  I noticed that we were converting any and all TaskAssignmentException to the INCOMPLETE_SOURCE_TOPIC_METADATA error code to shut down all the clients. Since these errors are typically fatal, it does seem appropriate to propagate the shutdown command. But we should do so with a new AssignorError instead of piggy-backing on the INCOMPLETE_SOURCE_TOPIC_METADATA, which would be pretty confusing for users who do in fact have all their source topics.  Changes in this PR: - Add new AssignorError.ASSIGNMENT_ERROR for generic assignment errors - Missing source topics --> throw/catch MissingSourceTopicException --> INCOMPLETE_SOURCE_TOPIC_METADATA  - Internal assignment errors --> throw/catch TaskAssignmentException --> ASSIGNMENT_ERROR  Should be cherry-picked to 2.7","closed","streams,","ableegoldman","2020-10-15T22:27:26Z","2020-10-21T16:45:39Z"
"","8786","KAFKA-10083: fix failed testReassignmentWithRandomSubscriptionsAndChanges tests","Minimum fix needed to stop this test failing and unblock others","closed","","ableegoldman","2020-06-02T22:50:47Z","2020-06-26T22:37:26Z"
"","9361","KAFKA-10535: Split ProcessorContext into Processor/StateStore/Record Contexts","Migrate different components of the old ProcessorContext interface into separate interfaces that are more appropriate for their usages. See KIP-478 for the details.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-10-01T17:08:40Z","2020-10-02T23:49:22Z"
"","8710","MINOR: Improve security documentation for Kafka Streams","Migrate content from https://github.com/confluentinc/docs/pull/4655.  Also restore content from https://github.com/apache/kafka/pull/4532, which seems to have been lost along the way. cc @mjsax","closed","docs,","JimGalasyn","2020-05-21T22:48:15Z","2020-05-22T18:40:44Z"
"","9112","KAFKA-10312 Fix error code returned by getPartitionMetadata","MetadataCache#getPartitionMetadata returns an error when the topic's leader Id is present at MetadataCache but listener endpoint is not present for this leader. For older version, LEADER_NOT_AVAILABLE is returned while LISTENER_NOT_FOUND is returned for new metadata version.  getPartitionMetadata was looking up MetadataCache's host brokerId rather than the topic's leader id while determining what error to return. This could result in the call returning LISTENER_NOT_FOUND when it should have returned LEADER_NOT_AVAILABLE. This commit corrects this behavior.  Unit tests were already present to test out the error codes returned under different situations but they were giving out a false positive. The test was using same broker id for both the MetadataCache's host as well as for the topic's leader. Error manifests when the MetadataCache's host id is changed. Improved the test.  This commit also consolidated couple of related tests to reduce code duplication.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","RamanVerma","2020-08-02T18:50:18Z","2020-11-03T22:45:44Z"
"","9420","KAFKA-10604: The StreamsConfig.STATE_DIR_CONFIG's default value does not reflect the JVM parameter or OS-specific settings","Make the default state store directory location to follow OS-specific temporary directory settings or `java.io.tmpdir` JVM parameter, with `Utils#getTempDir`.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dongjinleekr","2020-10-13T08:09:41Z","2021-01-29T15:45:31Z"
"","9449","MINOR: simplify implementation of ConsumerGroupOperationContext.hasCo…","make it more readable :)  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-10-16T05:06:24Z","2020-10-22T09:02:14Z"
"","9027","KAFKA-9161: add docs for KIP-441 and KIP-613 and other configs that need fixing","Mainly adds docs for KIP-441 and KIP-613, also ended up fixing some miscellaneous unrelated issues in the docs:  1. Adds some missing configs to the Streams config docs: `max.task.idle.ms`,`topology.optimization`, `default.windowed.key.serde.inner.class`, and `default.windowed.value.serde.inner.class`  2. Defines the previously-undefined default windowed serde class configs, including choosing a default (null) and giving them a doc string, so the yshould nwo show up in the auto-generated general Kafka config docs 3. Adds a note to warn users about the [rocksDB bug](https://github.com/facebook/rocksdb/issues/6247) that prevents setting a strict capacity limit and counting write buffer memory against the block cache  Should eventually be cherry-picked back to the 2.6 branch","closed","","ableegoldman","2020-07-15T02:46:08Z","2020-09-28T20:20:59Z"
"","8988","KAFKA-10199: Separate restore threads","Main Ideas:  1) Add a separate StateRestoreThread which is responsible for restore active / update standby tasks. Having N restore threads with N stream threads, with a 1-1 mapping just because it makes the synchronization simpler and we can keep the number of restore consumer the same.  2) Extract the StoreChangelogReader from all other classes (TaskManager, StreamThread) to be solely owned by this thread only, and hence the reader can still be non thread-safe. The communication between the two threads are just two concurrent queues: a) for sending new / closed tasks that should be registered / deregistered at the restore thread, and b) for letting the restore thread to communicate task corruption exception to the main thread to handle it.  3) There are a bunch of tricky things that I'd have to nudge around, which I've also highlighted in the comments below.  4) Updated unit tests, making some refactoring as well.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-07-06T20:53:32Z","2022-06-15T00:02:37Z"
"","9025","MINOR: update required MacOS version","MacOS 10.14 should actually work, too. At least our tests passed while they fail on 10.13.  This PR should be cherry-picked to `2.6` branch.  Call for review @vvcephei","closed","docs,","mjsax","2020-07-14T23:03:50Z","2020-07-15T17:10:28Z"
"","8877","KAFKA-9194: Missing documentation for replicaMaxWaitTimeMs config value","Looks it is a typo, the actual key supposed to be this #replicaFetchWaitMaxTimeMs(replica.fetch.wait.max.ms) instead of that the docs have this #replicaMaxWaitTimeMs  ### Committer Checklist (excluded from commit message) - [*] Verify design and implementation  - [*] Verify test coverage and CI build status - [*] Verify documentation (including upgrade notes)","closed","core,","satishbellapu","2020-06-16T02:50:39Z","2020-06-21T10:15:15Z"
"","9364","KAFKA-10471 Mark broker crash during log loading as unclean shutdown","LogManager writes a clean shutdown file when the broker shuts down. The presence of this file indicates that the broker had a clean shutdown and log recovery is not needed upon the next boot up.  Earlier, LogManager would check for this file at the start of log loading workflow, and delete it after the log has been loaded. If the broker were to crash while loading logs, the file would not be deleted and mislead LogManager when it tries to load logs upon next boot up. Hence, a crash during log loading will not be considered a hard reset of broker.  As part of this fix, we delete the clean shutdown file as soon as we look it up, at the start of log loading workflow. Thereafter, we maintain a boolean flag to indicate if broker underwent clean shutdown or not. So, if the broker were to crash while logs are being loaded, LogManager will be able to detect this as a hard reset.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","RamanVerma","2020-10-02T09:05:28Z","2020-11-02T21:07:15Z"
"","8911","inLock is redundant in ControllerEventManager","LinkedBlockingQueue is threadsafe for put, outter inLock is unnecessary.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rushsky518","2020-06-22T03:13:32Z","2020-06-28T16:20:39Z"
"","9451","MirrorMaker2 Exactly-once Semantics","KIP: https://cwiki.apache.org/confluence/display/KAFKA/KIP-656%3A+MirrorMaker2+Exactly-once+Semantics  config to enable exactly-once (aka. transaction producer) ``` primary->backup.transaction.producer.enabled: true primary->backup.topics: foo,bar,heartbeats topics: foo,bar,heartbeats primary.consumer.isolation.level: read_committed ``` validation tool on k8s: https://github.com/ning2008wisc/kafka-producer-consumer-test  TODO: (1) add unit test, (2) switch between `MirrorSinkConnector` and `MirrorSourceConnector` by config","open","","ning2008wisc","2020-10-18T00:46:53Z","2020-10-18T00:46:53Z"
"","9344","MINOR; Preserve ThrottlingQuotaExceededException when request timeouts after being retried due to a quota violation (KIP-599)","KIP-599 had proposed to keep returning the `ThrottlingQuotaExceededException` to the called even when the request times out due to reaching `default.api.timeout.ms`. The current implementation does not cover this yet.  From KIP-599: > Once `default.api.timeout.ms` has been reached, the topics which were throttled will return the `ThrottlingQuotaExceededException` to the caller.  This PR adds the logic to preserve the `ThrottlingQuotaExceededException` when topics are retried. The `throttleTimeMs` is also adjusted accordingly as the request could remain pending or in-flight for quite a long time.  I have run various tests on clusters with enabled quotas and I, indeed, find it better to preserve the exception. Otherwise, the caller does not really understand what is going on. This allows the caller to take the appropriate measure and also to take the `throttleTimeMs` into consideration.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-09-28T11:27:24Z","2020-09-29T14:31:38Z"
"","8976","KIP-617: Allow Kafka Streams State Stores to be iterated backwards","KIP reference implementation.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","jeqo","2020-07-02T16:47:14Z","2020-08-11T13:50:23Z"
"","8824","Kafka 5514: KafkaConsumer ignores default values in Properties object because of incorrect use of Properties object.","KafkaConsumer (and some other classes like KafkaProducer) does not respect defaults in Properties objects.  This is because a process translates the Properties to a Map in the Utils class which uses the underlying Hastable methods rather than the Propoerty methods.  This pull request corrects that to use the appropriate Properties methods a well as being backwards compatible for code that has been using the underlying Hashtable methods to contruct properties (there are differences due to the fact that Properties key and values must be Strings.  Performed full suite of unit test and integration tests.  Added unit tests for fix.  No documntation changes required as the behavior is the same.  The only slight difference is in the message for the ConfigException.  This contribution is my original work and I license this work to the project under the project's open source license.","open","","wlaforest","2020-06-07T01:28:53Z","2020-06-07T03:02:44Z"
"","8731","KAFKA-10050: kafka_log4j_appender.py fixed for JDK11","kafka_log4j_appender.py broken on JDK11 by #befd80b38d3ccb1aa0c6d99a899129fd5cf27774 This fix just setup node version for log4j appender.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","nizhikov","2020-05-27T09:45:27Z","2020-05-28T03:49:58Z"
"","9271","MINOR: correct package of LinuxIoMetricsCollector","kafka.server.LinuxIoMetricsCollector -> kafka.metrics.LinuxIoMetricsCollector  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-09-09T09:51:56Z","2020-10-08T14:58:51Z"
"","8987","KAFKA-10221: Backport fix for KAFKA-9603 to 2.5","KAFKA-9603 reports that the number of open files keeps increasing in RocksDB. The reason is that bulk loading is turned on but never turned off in segmented state stores for standby tasks.  This bug was fixed in 2.6 through PR #8661 by using code that is not present in 2.5. So cherry-picking was not possible.  This PR backports the fix to 2.5.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","cadonna","2020-07-06T19:49:21Z","2020-07-29T08:03:12Z"
"","9310","KAFKA-10504: It will not work to skip to InitProducerId as lastError is always null","Kafka-8805 introduced an optimization for txn abort process: If the last error is an INVALID_PRODUCER_ID_MAPPING error, skip directly to InitProduceId.  However this optimization will not work as the var lastError is always null. Because the txn state will transit to ABORTING_TRANSACTION from ABORTABLE_ERROR when beginAbort is called, and the lastError will updated to null.  We can use abortableError to skip directly to InitProduceId. abortableError is used for recording the last abortable error.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","zhaohaidao","2020-09-19T14:55:29Z","2021-05-16T13:48:23Z"
"","9017","KAFKA-8582 [WIP] Add ability to handle late messages in streams-aggregation","KAFKA-8582 Indicates that there is a need to handle *late* messages, which arrive when respective aggregation window (including grace period) is already closed. There is also related [SO question](https://stackoverflow.com/questions/62370180/kafka-stream-time-and-window-expire-kstreamsessionwindowaggregate-skipping-rec), where @mjsax mentions following options for handling late messages: - start new app to reset stream time - fall back to the Processor API and basically re-implement aggregation logic manually.  This PR tries to add an ability to forward such *late* messages to a configurable deadLetterTopic.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","kip,","piddubnyi","2020-07-14T13:22:18Z","2020-07-23T17:04:34Z"
"","8965","KAFKA-8147: Add changelog topic configuration to KTable suppress","KAFKA-8147: Add changelog topic configuration to KTable suppress  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","highluck","2020-07-01T07:58:36Z","2020-12-04T20:01:40Z"
"","9026","KAFKA-10274; Consistent timeouts in transactions_test","KAFKA-10235 fixed a consistency issue with the transaction timeout and the progress timeout. Since the test case relies on transaction timeouts, we need to wait at last as long as the timeout in order to ensure progress. However, having a low transaction timeout makes the test prone to the issue identified in KAFKA-9802, in which the coordinator timed out the transaction while the producer was awaiting a `Produce` response.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-07-15T00:02:55Z","2020-07-22T19:06:48Z"
"","9280","KAFKA-10186: Abort transaction with pending data with TransactionAbortedException","KAFKA-10186: Abort transaction with pending data with TransactionAbortedException  If a transaction is aborted with no underlying exception, throw a new kind of exception - `TransactionAbortedException` to distinguish this from other fatal exceptions.  This is part of KIP-654 and resolves KAFKA-10186  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","nym3r0s","2020-09-11T10:21:38Z","2020-10-07T16:34:40Z"
"","9064","KAFKA-10205: Documentation and handling of non deterministic Topologies","Kafka Streams topologies must be defined in a deterministic order, otherwise users can run into confusing NPE. This patch adds a more descriptive exception and documentation clarifying the deterministic requirement.  https://issues.apache.org/jira/browse/KAFKA-10205   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","soarez","2020-07-23T13:59:15Z","2020-10-02T09:02:07Z"
"","8722","KAFKA-5295: Allow source connectors to specify topic-specific settings for new topics (KIP-158)","Kafka Connect workers have been able to create Connect's internal topics using the new admin client for some time now (see KAFKA-4667). However, tasks of source connectors are still relying upon the broker to auto-create topics with default config settings if they don't exist, or expect these topics to exist before the connector is deployed, if their configuration needs to be specialized.   With the implementation of KIP-158 here, if `topic.creation.enable=true`, Kafka Connect will supply the source tasks of connectors that are configured to create topics with an admin client that will allow them to create new topics on-the-fly before writing the first source records to a new topic. Additionally, each source connector has the opportunity to customize the topic-specific settings of these new topics by defining groups of topic configurations.   This feature is tested here via unit tests (old tests that have been adjusted and new ones) as well as integration tests.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","kkonstantine","2020-05-24T02:09:50Z","2020-05-27T05:07:35Z"
"","9442","MINOR: optimize unrecordedVoters method","Just as `grantingVoters()` and `rejectingVoters()`, `unrecordedVoters()` method be optimezed by using `votersInState(State)`","closed","","dengziming","2020-10-15T12:16:09Z","2020-10-22T08:36:55Z"
"","9293","POC: Allow bypassing the cache layer in IQ","Just a quick POC of how we can optionally bypass the caching layer in IQ. Some queries that are common in IQ but rare in the PAPI perform really poorly with the caching layer involved. We should have a comprehensive solution to this in the future, but for now it seems worth considering just giving a way to bypass it.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","vvcephei","2020-09-16T18:16:56Z","2021-10-13T23:45:42Z"
"","9031","KAFKA-10298: replace abstract Windows with a proper interface","Just a POC for illustrative purposes. No need to review.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","vvcephei","2020-07-16T16:36:49Z","2020-08-17T15:17:28Z"
"","8497","KAFKA-6145: KIP-441 Build state constrained assignment from balanced one","John's awesome `TaskAssignorConvergenceTest` revealed some issues with the current assignor, which he nailed down as being due to the state constrained and balanced assignments not converging.  One way to get an assignment that is as close to the balanced assignment as possible while still being state constrained is of course to start with the balanced assignment, and move tasks around as necessary to satisfy the state constraint. With this basic approach, the converge test is passing.  This PR also includes some semi-orthogonal refactoring, most significantly the removal of the  assignment maps; we now just immediately assign tasks to the `ClientState` rather than first sticking them in an intermediate map.   Also moves `ValidClientsByTaskLoadQueue` to its own file.  Apologies for the length of this PR due to the above, but it didn't seem reasonable to do things the wrong way in the parts I changed, just so they could be undone in a followup PR along with the other parts.","closed","","ableegoldman","2020-04-16T05:10:35Z","2020-06-26T22:39:50Z"
"","9050","KAFKA-10193: Add preemption for controller events that have callbacks","JIRA: https://issues.apache.org/jira/browse/KAFKA-10193 * add `preempt(): Unit` method for all `ControllerEvent` so that all events (and future events) must implement it * for events that have callbacks, move the preemption from individual methods to `preempt()` * add preemption for `ApiPartitionReassignment` and `ListPartitionReassignments` * add integration tests: 1. test whether `preempt()` is called when controller shuts down 2. test whether the events with callbacks have the correct error response (`NOT_CONTROLLER`) * explicit typing for `ControllerEvent` methods  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jeffkbkim","2020-07-22T02:41:56Z","2020-08-07T17:19:39Z"
"","9089","KAFKA-10224: Update jersey license from CDDL to EPLv2","Jersey has changed its license from CDDL to EPLv2 starting from version 2.28. This PR updates the included license information to reflect this.  This should be cherry-picked as far back as the `2.3` branch, which is the first branch that started using Jersey 2.28.","closed","","rgroothuijsen","2020-07-27T20:47:04Z","2020-07-28T18:08:05Z"
"","9080","MINOR: Recommend Java 11","Java 11 has been recommended for a while, but the ops section had not been updated. Also added `-XX:+ExplicitGCInvokesConcurrent` which has been in `kafka-run-class` for a while. Finally, tweaked the text slightly to read better.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-07-25T23:20:59Z","2020-07-26T19:25:35Z"
"","9058","MINOR: Update jackson to latest 2.10.5","Jackson 2.10.5 is now available. This pull request is for updating the patch from 2.10.**2** to 2.10.**5**.   ~~This should also be cherry picked to older branches as well (at least 2.5 and above but probably 2.2 and above).~~  - 2.6, 2.5 are on 2.10.2. - 2.4, 2.3, 2.2 are on 2.10.0. - 2.1 is on 2.9.8, which is a bit more significant change.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [x] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","niteshmor","2020-07-22T18:45:48Z","2020-08-04T19:45:04Z"
"","8927","KAFKA-10200: Fix testability of PAPI with windowed stores","It's currently not possible to unit-test custom processors that use windowed stores, because the provided windowed store implementations cast the context to InternalProcessorContext.  This change adds a public API example using windowed stores, and fixes the casts internally that would make that example fail previously.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-06-25T16:34:26Z","2020-06-30T16:59:48Z"
"","8906","KAFKA-10190: To set replication throttling configs at broker entity-default","It looks to be a bug that Kafka broker's dynamic configs for replication, like follower.replication.throttled.rate, leader.replication.throttled.rate and replica.alter.log.dirs.io.max.bytes.per.second can only be set at specific broker id,  it doesn't take effect when they are set under entity-default via kafka-config command.","open","","jianjianjiao","2020-06-20T04:16:29Z","2021-08-04T13:34:18Z"
"","8506","Minor: avoid duplicate unwrapping when end of stream has been reached","It is impossible to complete handshake successfully when end of stream has been reached. We should catch the EOFException and then throw exception directly to save a bit cost of unwrapping.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-04-17T09:05:38Z","2020-04-20T13:09:05Z"
"","8766","MINOR: Update zstd to 1.4.5","It improves decompression speed:  >For x64 cpus, expect a speed bump of at least +5%, and up to +10% in favorable cases. >ARM cpus receive more benefit, with speed improvements ranging from +15% vicinity, >and up to +50% for certain SoCs and scenarios (ARM‘s situation is more complex due >to larger differences in SoC designs).  See https://github.com/facebook/zstd/releases/tag/v1.4.5 for more details.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-05-31T16:07:56Z","2020-05-31T21:58:34Z"
"","8674","KAFKA-9996: Upgrade zookeeper to 3.5.8","It fixes 30 issues, including third party CVE fixes, several leader-election related fixes and a compatibility issue with applications built against earlier 3.5 client libraries (by restoring a few non public APIs).  See ZooKeeper 3.5.8 Release Notes for details: https://zookeeper.apache.org/doc/r3.5.8/releasenotes.html  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-05-15T13:26:25Z","2020-05-15T16:01:45Z"
"","9401","KAFKA-9628 Replace Produce request/response with automated protocol","issue: https://issues.apache.org/jira/browse/KAFKA-9628   ### Benchmark  1. loop **30** times 1. calculate average  #### kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput  > @cluster(num_nodes=5) > @parametrize(acks=-1, topic=TOPIC_REP_THREE)  - +0.3144915325 % - 28.08766667 ->  28.1715625 (mb_per_sec)  > @cluster(num_nodes=5) > @matrix(acks=[1], topic=[TOPIC_REP_THREE], message_size=[100000],compression_type=[""none""], security_protocol=['PLAINTEXT'])  - +4.220730323 % - 157.145 -> 163.7776667 (mb_per_sec)  > @cluster(num_nodes=7) > @parametrize(acks=1, topic=TOPIC_REP_THREE, num_producers=3)  - +5.996241145% - 57.64166667 -> 61.098 (mb_per_sec)  > @cluster(num_nodes=5) > @parametrize(acks=1, topic=TOPIC_REP_THREE)  - +0.3979572536% - 44.05833333 -> 44.23366667 (mb_per_sec)  > @cluster(num_nodes=5) > @parametrize(acks=1, topic= TOPIC_REP_ONE)  - +2.228235226% - 69.23266667 -> 70.77533333 (mb_per_sec)  ### JMH results  In short, most ops performance are regression since we have to convert data to protocol data. The cost is inevitable (like other request/response) before we use protocol data directly.  ### JMH for ProduceRequest  1. construction regression:     - 281.474 -> 454.935 ns/op     - 296.000 -> 1888.000 B/op 1. toErrorResponse regression:     - 41.942 -> 107.528 ns/op     - 1216.000 -> 1616.000 B/op 1. toStruct improvement:     - 255.185 -> 90.728 ns/op     - 864.000 -> 304.000 B/op  **BEFORE** ``` Benchmark                                                                        Mode  Cnt     Score    Error   Units ProducerRequestBenchmark.constructorErrorResponse                                avgt   15    41.942 ±  0.036   ns/op ProducerRequestBenchmark.constructorErrorResponse:·gc.alloc.rate                 avgt   15  6409.263 ±  5.478  MB/sec ProducerRequestBenchmark.constructorErrorResponse:·gc.alloc.rate.norm            avgt   15   296.000 ±  0.001    B/op ProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Eden_Space        avgt   15  6416.420 ± 76.071  MB/sec ProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Eden_Space.norm   avgt   15   296.331 ±  3.539    B/op ProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Old_Gen           avgt   15     0.002 ±  0.002  MB/sec ProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Old_Gen.norm      avgt   15    ≈ 10⁻⁴             B/op ProducerRequestBenchmark.constructorErrorResponse:·gc.count                      avgt   15   698.000           counts ProducerRequestBenchmark.constructorErrorResponse:·gc.time                       avgt   15   378.000               ms ProducerRequestBenchmark.constructorProduceRequest                               avgt   15   281.474 ±  3.286   ns/op ProducerRequestBenchmark.constructorProduceRequest:·gc.alloc.rate                avgt   15  3923.868 ± 46.303  MB/sec ProducerRequestBenchmark.constructorProduceRequest:·gc.alloc.rate.norm           avgt   15  1216.000 ±  0.001    B/op ProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Eden_Space       avgt   15  3923.375 ± 59.568  MB/sec ProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Eden_Space.norm  avgt   15  1215.844 ± 11.184    B/op ProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Old_Gen          avgt   15     0.004 ±  0.001  MB/sec ProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Old_Gen.norm     avgt   15     0.001 ±  0.001    B/op ProducerRequestBenchmark.constructorProduceRequest:·gc.count                     avgt   15   515.000           counts ProducerRequestBenchmark.constructorProduceRequest:·gc.time                      avgt   15   279.000               ms ProducerRequestBenchmark.constructorStruct                                       avgt   15   255.185 ±  0.069   ns/op ProducerRequestBenchmark.constructorStruct:·gc.alloc.rate                        avgt   15  3074.889 ±  0.823  MB/sec ProducerRequestBenchmark.constructorStruct:·gc.alloc.rate.norm                   avgt   15   864.000 ±  0.001    B/op ProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Eden_Space               avgt   15  3077.737 ± 31.537  MB/sec ProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Eden_Space.norm          avgt   15   864.800 ±  8.823    B/op ProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Old_Gen                  avgt   15     0.003 ±  0.001  MB/sec ProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Old_Gen.norm             avgt   15     0.001 ±  0.001    B/op ProducerRequestBenchmark.constructorStruct:·gc.count                             avgt   15   404.000           counts ProducerRequestBenchmark.constructorStruct:·gc.time                              avgt   15   214.000               ms ```  **AFTER** ``` Benchmark                                                                        Mode  Cnt     Score    Error   Units ProducerRequestBenchmark.constructorErrorResponse                                avgt   15   107.528 ±  0.270   ns/op ProducerRequestBenchmark.constructorErrorResponse:·gc.alloc.rate                 avgt   15  4864.899 ± 12.132  MB/sec ProducerRequestBenchmark.constructorErrorResponse:·gc.alloc.rate.norm            avgt   15   576.000 ±  0.001    B/op ProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Eden_Space        avgt   15  4868.023 ± 61.943  MB/sec ProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Eden_Space.norm   avgt   15   576.371 ±  7.331    B/op ProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Old_Gen           avgt   15     0.005 ±  0.001  MB/sec ProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Old_Gen.norm      avgt   15     0.001 ±  0.001    B/op ProducerRequestBenchmark.constructorErrorResponse:·gc.count                      avgt   15   639.000           counts ProducerRequestBenchmark.constructorErrorResponse:·gc.time                       avgt   15   339.000               ms ProducerRequestBenchmark.constructorProduceRequest                               avgt   15   454.935 ±  0.332   ns/op ProducerRequestBenchmark.constructorProduceRequest:·gc.alloc.rate                avgt   15  3769.014 ±  2.767  MB/sec ProducerRequestBenchmark.constructorProduceRequest:·gc.alloc.rate.norm           avgt   15  1888.000 ±  0.001    B/op ProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Eden_Space       avgt   15  3763.407 ± 31.530  MB/sec ProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Eden_Space.norm  avgt   15  1885.190 ± 15.594    B/op ProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Old_Gen          avgt   15     0.004 ±  0.001  MB/sec ProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Old_Gen.norm     avgt   15     0.002 ±  0.001    B/op ProducerRequestBenchmark.constructorProduceRequest:·gc.count                     avgt   15   494.000           counts ProducerRequestBenchmark.constructorProduceRequest:·gc.time                      avgt   15   264.000               ms ProducerRequestBenchmark.constructorStruct                                       avgt   15    90.728 ±  0.695   ns/op ProducerRequestBenchmark.constructorStruct:·gc.alloc.rate                        avgt   15  3043.140 ± 23.246  MB/sec ProducerRequestBenchmark.constructorStruct:·gc.alloc.rate.norm                   avgt   15   304.000 ±  0.001    B/op ProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Eden_Space               avgt   15  3047.251 ± 59.638  MB/sec ProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Eden_Space.norm          avgt   15   304.404 ±  5.034    B/op ProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Old_Gen                  avgt   15     0.003 ±  0.001  MB/sec ProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Old_Gen.norm             avgt   15    ≈ 10⁻⁴             B/op ProducerRequestBenchmark.constructorStruct:·gc.count                             avgt   15   400.000           counts ProducerRequestBenchmark.constructorStruct:·gc.time                              avgt   15   205.000               ms ``` ### JMH for ProduceResponse  1. construction regression:     - 3.293 -> 303.226 ns/op     - 24.000 -> 1848.000 B/op 1. toStruct improvement:     - 825.889 -> 311.725 ns/op     - 2208.000 -> 896.000 B/op  **BEFORE**  ``` Benchmark                                                                          Mode  Cnt     Score    Error   Units ProducerResponseBenchmark.constructorProduceResponse                               avgt   15     3.293 ±  0.004   ns/op ProducerResponseBenchmark.constructorProduceResponse:·gc.alloc.rate                avgt   15  6619.731 ±  9.075  MB/sec ProducerResponseBenchmark.constructorProduceResponse:·gc.alloc.rate.norm           avgt   15    24.000 ±  0.001    B/op ProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Eden_Space       avgt   15  6618.648 ±  0.153  MB/sec ProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Eden_Space.norm  avgt   15    23.996 ±  0.033    B/op ProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Old_Gen          avgt   15     0.003 ±  0.002  MB/sec ProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Old_Gen.norm     avgt   15    ≈ 10⁻⁵             B/op ProducerResponseBenchmark.constructorProduceResponse:·gc.count                     avgt   15   720.000           counts ProducerResponseBenchmark.constructorProduceResponse:·gc.time                      avgt   15   383.000               ms ProducerResponseBenchmark.constructorStruct                                        avgt   15   825.889 ±  0.638   ns/op ProducerResponseBenchmark.constructorStruct:·gc.alloc.rate                         avgt   15  2428.000 ±  1.899  MB/sec ProducerResponseBenchmark.constructorStruct:·gc.alloc.rate.norm                    avgt   15  2208.000 ±  0.001    B/op ProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Eden_Space                avgt   15  2430.196 ± 55.894  MB/sec ProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Eden_Space.norm           avgt   15  2210.001 ± 51.009    B/op ProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Old_Gen                   avgt   15     0.003 ±  0.001  MB/sec ProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Old_Gen.norm              avgt   15     0.002 ±  0.001    B/op ProducerResponseBenchmark.constructorStruct:·gc.count                              avgt   15   319.000           counts ProducerResponseBenchmark.constructorStruct:·gc.time                               avgt   15   166.000               ms ```  **AFTER**  ``` Benchmark                                                                          Mode  Cnt     Score    Error   Units ProducerResponseBenchmark.constructorProduceResponse                               avgt   15   303.226 ±  0.517   ns/op ProducerResponseBenchmark.constructorProduceResponse:·gc.alloc.rate                avgt   15  5534.940 ±  9.439  MB/sec ProducerResponseBenchmark.constructorProduceResponse:·gc.alloc.rate.norm           avgt   15  1848.000 ±  0.001    B/op ProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Eden_Space       avgt   15  5534.046 ± 51.849  MB/sec ProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Eden_Space.norm  avgt   15  1847.710 ± 18.105    B/op ProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Old_Gen          avgt   15     0.007 ±  0.001  MB/sec ProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Old_Gen.norm     avgt   15     0.002 ±  0.001    B/op ProducerResponseBenchmark.constructorProduceResponse:·gc.count                     avgt   15   602.000           counts ProducerResponseBenchmark.constructorProduceResponse:·gc.time                      avgt   15   318.000               ms ProducerResponseBenchmark.constructorStruct                                        avgt   15   311.725 ±  3.132   ns/op ProducerResponseBenchmark.constructorStruct:·gc.alloc.rate                         avgt   15  2610.602 ± 25.964  MB/sec ProducerResponseBenchmark.constructorStruct:·gc.alloc.rate.norm                    avgt   15   896.000 ±  0.001    B/op ProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Eden_Space                avgt   15  2613.021 ± 42.965  MB/sec ProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Eden_Space.norm           avgt   15   896.824 ± 11.331    B/op ProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Old_Gen                   avgt   15     0.003 ±  0.001  MB/sec ProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Old_Gen.norm              avgt   15     0.001 ±  0.001    B/op ProducerResponseBenchmark.constructorStruct:·gc.count                              avgt   15   343.000           counts ProducerResponseBenchmark.constructorStruct:·gc.time                               avgt   15   194.000               ms ```  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-10-09T05:58:00Z","2020-11-18T21:44:23Z"
"","9423","KAFKA-9263 The new hw is added to incorrect log when ReplicaAlterLogD…","issue: https://issues.apache.org/jira/browse/KAFKA-9263  The following actions results in this issue.  1. handle_1 gets the current log 2. ReplicaAlterLogDirsThread replaces current log by future log 3. handle_1 adds the new hw to “current” log but the log is actually invalid  The solution is that the action 1 and 3 must be executed within same read lock of leaderIsrUpdateLock to avoid adding new hw to invalid log (which is replaced by ReplicaAlterLogDirsThread)   **Test Plan**  Relying on ```PlaintextAdminIntegrationTest.testAlterReplicaLogDirs```. I have looped the test with this patch 100 times. all pass  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-10-13T15:21:06Z","2020-12-02T03:21:28Z"
"","9128","KAFKA-7540 reduce session timeout to evict dead member in time and so…","issue: https://issues.apache.org/jira/browse/KAFKA-7540  In short, the LEAVE_GROUP is sent to a shutdown broker so the dead member which is left in the group obstructs broker from completing rebalance.  The test case creates two consumers (with different group) and then shutdown their coordinator (broker). After first coordinator is shutdown, the heartbeat thread of first consumer gets timeout so it sends LEAVE_GROUP request to “next” coordinator. Unfortunately, the LEAVE_GROUP request can’t be processed successfully if the ”next” coordinator is the coordinator of second consumer (yep, it is shutdown also).   The simple approach is that we can reduce the session timeout so coordinator can evict dead member in time.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-08-05T07:04:11Z","2021-03-02T16:29:25Z"
"","9318","KAFKA-10497 Convert group coordinator metadata schemas to use generat…","issue: https://issues.apache.org/jira/browse/KAFKA-10497  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-09-22T10:54:05Z","2020-11-18T06:49:05Z"
"","9257","KAFKA-10463 the necessary utilities in Dockerfile should include git","issue: https://issues.apache.org/jira/browse/KAFKA-10463  the default image of Dockerfile is ```openjdk:8``` and it pre-installed git so it is fine that necessary utilities does not include git. However, the later version of openjdk image does not include git by default and error message ""git: command not found"" ensues.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-09-07T10:04:25Z","2020-09-14T22:22:01Z"
"","9230","KAFKA-10446 add lz4 and zstd to compression type of benchmark_test.py","issue: https://issues.apache.org/jira/browse/KAFKA-10446  Both ""lz4"" and ""zstd"" are popular and important compressions supported by kafka. They are worth being benchmark.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-08-30T15:48:59Z","2020-09-26T07:53:57Z"
"","9223","KAFKA-10438 Lazy initialization of record header to reduce memory usa…","issue: https://issues.apache.org/jira/browse/KAFKA-10438  There is no checks for header key so instantiating key (bytes to string) is unnecessary. The risk of this PR is the exception of converting byte[] to string can't be discovered quickly (the conversion error is rare so it should be fine).  **JMH RESULT**  1. ops: +12% 1. The optimization of memory usage is very small as the cost of creating extra ```ByteBuffer``` is almost same to byte array copy (used to construct ```String```). Using large key results in better improvement but I don't think large key is common case.   **BEFORE** ``` Benchmark                                                                     (bufferSupplierStr)  (bytes)  (compressionType)  (headerKeySize)  (maxBatchSize)  (maxHeaderSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score      Error   Units RecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM               NONE               10             200                5           1000                 2  thrpt   15  2035938.174 ± 1653.566   ops/s RecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM               NONE               10             200                5           1000                 2  thrpt   15     2040.000 ±    0.001    B/op ```  ``` Benchmark                                                                     (bufferSupplierStr)  (bytes)  (compressionType)  (headerKeySize)  (maxBatchSize)  (maxHeaderSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score      Error   Units RecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM               NONE               30             200                5           1000                 2  thrpt   15  1979193.376 ± 1239.286   ops/s RecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM               NONE               30             200                5           1000                 2  thrpt   15     2120.000 ±    0.001    B/op ```   **AFTER**  ``` Benchmark                                                                     (bufferSupplierStr)  (bytes)  (compressionType)  (headerKeySize)  (maxBatchSize)  (maxHeaderSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score      Error   Units RecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM               NONE               10             200                5           1000                 2  thrpt   15  2289115.973 ± 2661.856   ops/s RecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM               NONE               10             200                5           1000                 2  thrpt   15     2032.000 ±    0.001    B/op ```  ``` Benchmark                                                                     (bufferSupplierStr)  (bytes)  (compressionType)  (headerKeySize)  (maxBatchSize)  (maxHeaderSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score     Error   Units RecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM               NONE               30             200                5           1000                 2  thrpt   15  2222625.706 ± 908.358   ops/s RecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM               NONE               30             200                5           1000                 2  thrpt   15     2040.000 ±   0.001    B/op  ```  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-08-26T10:09:35Z","2020-09-21T15:03:50Z"
"","9220","KAFKA-10433 Reuse the ByteBuffer in validating compressed records","issue: https://issues.apache.org/jira/browse/KAFKA-10433  It is hot method so reusing the ByteBuffer can reduce a bunch of memory usage if the compression type supports BufferSupplier.  **experiment** - duration: 1 minute - compression: LZ4 - workload: 10 producers -> 1 broker  - memory usage of byte array allocation: 4.52 GB -> 0.68 GB  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-08-25T17:49:02Z","2020-08-30T09:55:56Z"
"","9182","KAFKA-10403 Replace scala collection by java collection in generating…","issue: https://issues.apache.org/jira/browse/KAFKA-10403  It seems to me the metrics is a ""kind"" of public interface so users should be able to access metrics of kafka server without scala library.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-08-14T16:10:01Z","2020-09-09T14:44:04Z"
"","9291","KAFKA-10264 Flaky Test TransactionsTest.testBumpTransactionalEpoch","issue: https://issues.apache.org/jira/browse/KAFKA-10264  The test case sends two records before killing broker. The failure is caused by that the both records are NOT in a single batch. The failure of first record can abort second batch and then produces KafkaException rather than TimeoutException.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-09-16T06:39:28Z","2020-12-08T17:13:32Z"
"","9013","KAFKA-10044 Deprecate ConsumerConfig#addDeserializerToConfig and Prod…","issue: https://issues.apache.org/jira/browse/KAFKA-10044   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-07-13T09:52:27Z","2020-07-13T23:23:19Z"
"","8930","Mirror Maker 2: offset-syncs variable","Introduce `offset-syncs.topic.override` to MirrorConnectorConfig for overriding the default topic `mm2-offset-syncs.ALIAS.internal`. This can help with shared kafka clusters that require every topic to have a prefix, such as some of heroku's.    ### Committer Checklist (excluded from commit message) - [ ] Propose a KIP (or ask an apache member) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","cgetzen","2020-06-25T21:12:28Z","2022-02-10T16:36:09Z"
"","9278","MINOR: remove DelayedOperations.checkAndCompleteFetch","inspired by https://github.com/apache/kafka/pull/8657#discussion_r484092945  ``` With this change, DelayedOperations.checkAndCompleteFetch() is only used in tests. I am wondering if it can be removed. It's fine if we want to do this in a followup PR. ```  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-09-10T02:34:07Z","2020-09-10T15:50:29Z"
"","8634","Reverse iterator for WindowStore","Initial draft for https://issues.apache.org/jira/browse/KAFKA-9929  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","jeqo","2020-05-08T22:36:54Z","2020-07-02T16:48:03Z"
"","9288","KAFKA-10482: increase the connection close waiting time","Increase the connection close waiting time to make the test more reliable. It waits for 15 secs for now, which causes the test failed frequently. Increase the waiting time to 25 secs.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-09-15T06:58:12Z","2020-09-15T08:05:42Z"
"","9201","MINOR: Increase the amount of time available to the `test_verifiable_producer` test","Increase the amount of time available to the `test_verifiable_producer` test to login and get the process name for the verifiable producer from 5 seconds to 10 seconds.  We were seeing some test failures due to the assertion failing because the verifiable producer would complete before we could login, list the processes, and parse out the producer version. Previously, we were giving this operation 5 seconds to run, this PR bumps it up to 10 seconds.   I verified locally that this does not flake, but even at 5 seconds I wasn't seeing any flakes. Ultimately we should find a better strategy than racing to query the producer process (as outlined in the existing comments).","closed","","gardnervickers","2020-08-19T18:04:39Z","2020-11-12T21:19:43Z"
"","8533","KAFKA-9589: Fixed bug in V2 log validator tests","In this PR, we fixed a test that is written but not ran. JIRA here: https://issues.apache.org/jira/browse/KAFKA-9589  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","leonardge","2020-04-22T16:45:35Z","2022-03-10T22:44:12Z"
"","9393","KAFKA-10028: Minor fixes to describeFeatures and updateFeatures apis","In this PR, I have addressed the review comments from @chia7712 in https://github.com/apache/kafka/pull/9001 which were provided after https://github.com/apache/kafka/pull/9001 was merged. The changes are made mainly to `KafkaAdminClient`: 1. Improve error message in `updateFeatures` api when feature name is empty. 2. Propagate top-level error message in `updateFeatures` api. 3. Add an empty-parameter variety for `describeFeatures` api. 4. Minor documentation updates to `@param` and `@return` to make these resemble other apis.  **Test plan:** Relying on existing unit and integration tests.","closed","","kowshik","2020-10-08T08:34:44Z","2020-10-08T17:05:30Z"
"","8524","KAFKA-9866: Avoid election for topics where preferred leader is not in ISR","In this commit we made sure that the auto leader election only happens after the newly starter broker is in the `isr`.  No accompany tests are added due to the fact that: 1. this is a change to the `private` method and no public facing change is made 2. it is hard to create tests for this change without considerable effort  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","leonardge","2020-04-21T08:48:53Z","2020-04-27T22:16:01Z"
"","9095","KAFKA-10321: fix infinite blocking for global stream thread startup","In the unit test `shouldDieOnInvalidOffsetExceptionDuringStartup` for JDK 11, we spotted a case where a global stream thread startup would stall if it fails immediately upon the first poll. The reason is that `start()` function only checks whether the thread is *not running*, as it needs to block until it finishes the initialization. However, if the thread transits to `DEAD` immediately, the `start()` call would block forever.  Use the failed unit test to verify it works.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-07-29T06:53:22Z","2020-07-30T04:04:21Z"
"","9062","KAFKA-8098: fix the flaky test by disabling the auto commit to avoid member rejoining","In the test, we first test removing 1 member from group, and then test removing the other 2 members from group, and it failed sometimes at the 2nd member number assert. After investigation, I found it's because we enabled auto commit for the consumers(default setting), and the removed consumer offset commit will get the `UNKNOWN_MEMBER_ID` error, which will then make the member rejoin. (check ConsumerCoordinator#OffsetCommitResponseHandler) So, that's why after the 2nd members removing, the members will sometimes be not empty.   I set the consumer config to disable the auto commit to fix this issue. Thanks.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-07-23T09:46:53Z","2020-09-19T10:58:47Z"
"","9029","KAFKA-10255: Fix flaky testOneWayReplicationWithAutoOffsetSync test","In the original test, we will sleep for static 5 seconds to ensure the automated group offset sync is complete. It sometimes synced fast (less than 1 sec), and sometimes slow (~ 20 seconds). I rewrite the sleep to wait for specific condition:   1. `consumer.endOffsets` to make sure the topic partition metadata is synced 2. `backupClient.listConsumerGroupOffsets` to make sure the consumerGroupOffset is also synced  I've tested in my local environment a lot of times. It can make the test more stable.  Thanks.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-07-16T10:01:13Z","2020-07-30T21:01:21Z"
"","8942","modify the judgment condition in KafkaApis getTopicMetadata","in the method handleTopicMetadataRequest it has been determined whether authorizedTopics is empty，no need to judge again in the getTopicMetadata method，the method getTopicMetadata should be removed  topics.isEmpty. Maybe in the future getTopicMetadata method will use the single judgment condition.","closed","","sasukerui","2020-06-28T15:31:51Z","2020-10-19T05:19:59Z"
"","8805","KAFKA-9848: Avoid triggering scheduled rebalance delay when task assignment fails but Connect workers remain in the group","In the first version of the incremental cooperative protocol, in the presence of a failed sync request by the leader, the assignor was designed to treat the unapplied assignments as lost and trigger a rebalance delay.   This commit applies optimizations in these cases to avoid the unnecessary activation of the rebalancing delay. First, if the worker that loses the sync group request or response is the leader, then it detects this failure by checking the what is the expected generation when it performs task assignments. If it's not the expected one, it resets its view of the previous assignment because it wasn't successfully applied and it doesn't represent a correct state. Furthermore, if the worker that has missed the assignment sync is an ordinary worker, then the leader is able to detect that there are lost assignments and instead of triggering a rebalance delay among the same members of the group, it treats the lost tasks as new tasks and reassigns them immediately. If the lost assignment included revocations that were not applied, the leader reapplies these revocations again.   Existing unit tests and integration tests are adapted to test the proposed optimizations.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","kkonstantine","2020-06-05T06:58:28Z","2020-06-09T16:41:17Z"
"","8607","KAFKA-9731: Disable immediate fetch response for hw propagation if replica selector is not defined","In the case described in the JIRA, there was a 50%+ increase in the total fetch request rate in 2.4.0 due to this change.  I included a few additional clean-ups: * Simplify `findPreferredReadReplica` and avoid unnecessary collection copies. * Use `LongSupplier` instead of `Supplier` in `SubscriptionState` to avoid unnecessary boxing.  Added a unit test to ReplicaManagerTest and cleaned up the test class a bit including consistent usage of Time in MockTimer and other components.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-05-03T23:34:58Z","2020-07-22T21:02:56Z"
"","8936","KAFKA-10207: Fixed padded timeindex causing premature data deletion","In some cases when a new log segment is rolled, the previous segment's timeindex and offset index do not have the excess 0 bytes trimmed. This results in a situation where the next load from disk triggers retention window breaches and the data is deleted. This happens because the mmap pointing to the index data seeks to the end and because there are 0 bytes padding the end in some cases, the loaded timestamp is 0.  The sanity checks were previously removed explicitly by KIP-263.  A unittest was added to confirm the sanity check on timeindex will in fact catch this scenario. There doesn't seem to be existing testing for LogSegment.sanityCheck() so I opted to test the specific functionality and rely on the same logic that TransactionIndex currently relies on.   ### Committer Checklist (excluded from commit message) - [x] Verify design and implementation  - [ ] Verify test coverage and CI build status - [x] Verify documentation (including upgrade notes)","open","","Johnny-Malizia","2020-06-27T03:39:39Z","2020-12-31T23:46:45Z"
"","9066","KAFKA-10287: Skip unknown offsets when computing sum of changelog offsets","In PR #8962 we introduced a sentinel UNKNOWN_OFFSET to mark unknown offsets in checkpoint files. The sentinel was set to -2 which is the same value used for the sentinel LATEST_OFFSET that is used in subscriptions to signal that state stores have been used by an active task. Unfortunately, we missed to skip UNKNOWN_OFFSET when we compute the sum of the changelog offsets.   If a task had only one state store and it did not restore anything before the next rebalance, the stream thread wrote -2 (i.e., UNKNOWN_OFFSET) into the subscription as sum of the changelog offsets. During assignment, the leader interpreted the -2 as if the stream run the task as active although it might have run it as standby. This misinterpretation of the sentinel value resulted in unexpected task assigments.    ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","cadonna","2020-07-23T19:41:37Z","2020-07-29T08:02:52Z"
"","9097","KAFKA-10319: Skip unknown offsets when computing sum of changelog offsets","In PR #8962 we introduced a sentinel UNKNOWN_OFFSET to mark unknown offsets in checkpoint files. The sentinel was set to -2 which is the same value used for the sentinel LATEST_OFFSET that is used in subscriptions to signal that state stores have been used by an active task. Unfortunately, we missed to skip UNKNOWN_OFFSET when we compute the sum of the changelog offsets.  If a task had only one state store and it did not restore anything before the next rebalance, the stream thread wrote -2 (i.e., UNKNOWN_OFFSET) into the subscription as sum of the changelog offsets. During assignment, the leader interpreted the -2 as if the stream run the task as active although it might have run it as standby. This misinterpretation of the sentinel value resulted in unexpected task assigments.  This is a port of PR #9066 to trunk.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","cadonna","2020-07-29T07:59:41Z","2020-09-23T11:49:35Z"
"","9454","KAFKA-10618: Add UUID class, use in protocols","In order to support topic IDs, we need to create a public UUID class. This class will be used in protocols. This PR creates the class, modifies code to use the class in the message protocol and changes the code surrounding the existing messages/json that used the old UUID class.  SimpleExampleMessage was used only for testing, so all usages of UUID have been switched to the new class.  SubscriptionInfoData uses UUID for processId extensively. It also utilizes java.util.UUID implementation of Comparable so that UUIDs can be ordered. I felt that this functionality was not necessary for the UUIDs used for topic IDs so I decided to convert to java.util.UUID on the boundary of SubscriptionInfoData. I was only able to find the sorting necessary for testing, though, so this still may be changed.  I also added tests for the methods of the new UUID class. The existing SimpleExampleMessage tests should be sufficient for testing the new UUID class in message protocols.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jolshan","2020-10-19T18:00:24Z","2020-10-21T09:17:13Z"
"","9170","KAFKA-10391: Overwrite checkpoint in task corruption to remove corrupted partitions","In order to do this, I also removed the optimization such that once enforced checkpoint is set to true, we always checkpoint unless the state stores are not initialized at all (i.e. the snapshot is null).  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-08-12T16:53:55Z","2020-08-13T04:20:58Z"
"","9090","toString pattern change like ProducerRecord.java","In most of 'toString()' methods,'=' is used instead of ' = ', so I followed the convention. Actually, if you print 'ProducerRecord' and 'ConsumerRecord', the pattern looks different and looks strange. --------------------------------- producerRecord: ProducerRecord(topic=xxxx, partition=null, headers= ...) consumerRecord: ConsumerRecord(topic = xxxx, partition = 0, ..., headers = ...)","open","","codelabor","2020-07-28T07:09:39Z","2020-07-28T20:09:00Z"
"","9218","MINOR: Fix shouldNotResetEpochHistoryHeadIfUndefinedPassed","In LeaderEpochFileCacheTest.scala, code is identical for `shouldNotResetEpochHistoryHeadIfUndefinedPassed` and `shouldNotResetEpochHistoryTailIfUndefinedPassed`. Seems `truncateFromStart` should be invoked in `shouldNotResetEpochHistoryHeadIfUndefinedPassed` instead of `truncateFromEnd`.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","huxihx","2020-08-25T02:47:52Z","2020-10-13T02:07:01Z"
"","8891","KAFKA-10143: Improve test coverage for throttle changes during reassignment","In KIP-455, we changed the behavior of the reassignment tool so that the `--additional` flag is required in order to use the command to alter the throttle. This patch improves the documentation to make this clearer and adds some integration tests to validate the behavior.  This patch also contains a few minor code quality improvements:  - Factor out a helper `calculateCurrentMoveMap` from `calculateMoveMap` to compute the current move map, which makes the logic easier to follow - Rename `calculateMoveMap` to `calculateProposedMoveMap` to make intention clearer - Split `modifyBrokerThrottles` into two methods `modifyLogDirThrottle` and `modifyInterBrokerThrottle` - Move logic to compute leader and follower throttles into a new method `modifyReassignmentThrottle`, which takes it out of the execution path when log dir throttles are changed - Minor stylistic improvements such as replacing `.map.flatten` with `.flatMap`  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-06-18T00:46:56Z","2020-10-12T19:36:47Z"
"","8795","KAFKA-10095: Simplify calls in LogCleanerManagerTest","In kafka.log.LogCleanerManagerTest we have two calls to .get(something).nonEmpty, which is equivalent to .contains(something). Making changes to simplify these calls.  Reviewers: Jakob Homan jghoman@gmail.com  This is a newbie ticket to get used to the contribution flow.","open","","sarahgonsalves223","2020-06-03T21:52:38Z","2020-07-07T03:53:14Z"
"","8964","KAFKA-9450: Decouple flushing state from commiting","In Kafka Streams the source-of-truth of a state store is in its changelog, therefore when committing a state store we only need to make sure its changelog records are all flushed and committed, but we do not actually need to make sure that the materialized state have to be flushed and persisted since they can always be restored from changelog when necessary.  On the other hand, flushing a state store too frequently may have side effects, e.g. rocksDB flushing would gets the memtable into an L0 sstable, leaving many small L0 files to be compacted later, which introduces larger overhead.  Therefore this PR decouples flushing from committing, such that we do not always flush the state store upon committing, but only when sufficient data has been written since last time flushed. The checkpoint file would then also be overwritten only along with flushing the state store indicating its current known snapshot. This is okay since: a) if EOS is not enabled, then it is fine if the local persisted state is actually ahead of the checkpoint, b) if EOS is enabled, then we would never write a checkpoint file until close.  Here's a more detailed change list of this PR:  1. Do not always flush state stores when calling pre-commit; move `stateMgr.flush` into post-commit to couple together with checkpointing.   2. In post-commit, we checkpoint when: a) The state store's snapshot has progressed much further compared to the previous checkpoint, b) When the task is being closed (but as a minor optimization, we would avoid checkpointing on closing if it is exactly the same as the previous one).  3. There are some tricky obstacles that I'd have to work around in a bit hacky way: for cache / suppression buffer, we still need to flush them in pre-commit to make sure all records sent via producers, while the underlying state store should not be flushed. I've decided to introduce a new API in CachingStateStore to be triggered in pre-commit.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","guozhangwang","2020-07-01T03:20:48Z","2020-08-12T03:21:42Z"
"","8626","KAFKA-9921: explicit handling of null values with retainDuplicates","In general the behavior of window stores with `retainDuplicates` is not well documented or enforced, so we should attempt to clarify things better in the javadocs and in the code itself. This explicitly skips the put/delete when the value is null and duplicates are allowed, and specifies this behavior in the docs.  Also adds in a test I left out in the earlier PR https://github.com/apache/kafka/pull/8564","closed","","ableegoldman","2020-05-06T19:52:03Z","2020-05-12T22:59:14Z"
"","8512","KAFKA-6024: Consider moving validation in KafkaConsumer ahead of call to acquireAndEnsureOpen()","In commitSync method in KafkaConsumer , acquireAndEnsureOpen() is called before parameter validation , which is not really required . ```    @Override     public void commitSync(Duration timeout) {         acquireAndEnsureOpen();         try {                maybeThrowInvalidGroupIdException();      ```          Since the value of parameter would not change per invocation, it seems performing validation ahead of acquireAndEnsureOpen() call would be better.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","harshitshah4","2020-04-18T17:56:56Z","2020-07-23T18:33:13Z"
"","9014","KAFKA-10156 [WIP] Fix flaky testCloseOldestConnection","In `testCloseOldestConnection` flaky behavior can be caused by the code path when in `selector.poll(0)` the connection is not closed immediately. This can be due to `Selector#maybeReadFromClosingChannel` returning `true`. To avoid this, also check `selector.closingChannel(id)` in addition to `selector.disconnected().containsKey(id)`.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","serjchebotarev","2020-07-13T13:24:30Z","2020-07-14T11:54:15Z"
"","9341","MINOR: Fix MirrorConnectorsIntegrationTest","In `setup()`, `primary` was checked to be running twice, instead of `backup`.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ivanyu","2020-09-26T16:45:58Z","2020-10-02T16:50:22Z"
"","9028","KAFKA-10035: Safer conversion of consumer timeout parameters","In `org.apache.kafka.streams.integration.AbstractResetIntegrationTest`:  - Corrected types of consumer timeout params: `STREAMS_CONSUMER_TIMEOUT ` and `CLEANUP_CONSUMER_TIMEOUT ` from `long` to `int` - Type-safe conversion from `int` to `String`  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","serjchebotarev","2020-07-15T16:09:43Z","2020-08-21T19:36:01Z"
"","9145","KAFKA-10370: consumer.seek() with SinkTaskContext's offsets when initialize","In [WorkerSinkTask.java](https://github.com/apache/kafka/blob/trunk/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java), when we want the consumer to consume from certain offsets, rather than from the last committed offset, [WorkerSinkTaskContext](https://github.com/apache/kafka/blob/trunk/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTaskContext.java#L63-L66) provided a way to supply the offsets from external (e.g. an implementation of SinkTask) to rewind the consumer.  In the [poll() method](https://github.com/apache/kafka/blob/trunk/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java#L312), it first calls **rewind()** to read the offsets from WorkerSinkTaskContext, if the offsets are not empty, then in the [rewind() method](https://github.com/apache/kafka/blob/trunk/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java#L615-L633), run **consumer.seek(tp, offset)** to rewind the consumer.  As a part of [WorkerSinkTask initialization](https://github.com/apache/kafka/blob/trunk/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java#L290-L307), when the [SinkTask starts](https://github.com/apache/kafka/blob/trunk/connect/api/src/main/java/org/apache/kafka/connect/sink/SinkTask.java#L83-L88), we can supply the specific offsets by **context.offset(supplied_offsets);** in start() method, so that when the consumer does the first poll in WorkerSinkTask, it should rewind to the specific offsets in rewind() method. However in practice, we saw the following IllegalStateException when running consumer.seek(tp, offsets);  ` [2020-08-07 23:53:55,752] INFO WorkerSinkTask{id=MirrorSinkConnector-0} Rewind test-1 to offset 3 (org.apache.kafka.connect.runtime.WorkerSinkTask:648) [2020-08-07 23:53:55,752] INFO [Consumer clientId=connector-consumer-MirrorSinkConnector-0, groupId=connect-MirrorSinkConnector] Seeking to offset 3 for partition test-1 (org.apache.kafka.clients.consumer.KafkaConsumer:1592) [2020-08-07 23:53:55,752] ERROR WorkerSinkTask{id=MirrorSinkConnector-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:187) java.lang.IllegalStateException: No current assignment for partition test-1         at org.apache.kafka.clients.consumer.internals.SubscriptionState.assignedState(SubscriptionState.java:368)         at org.apache.kafka.clients.consumer.internals.SubscriptionState.seekUnvalidated(SubscriptionState.java:385)         at org.apache.kafka.clients.consumer.KafkaConsumer.seek(KafkaConsumer.java:1597)         at org.apache.kafka.connect.runtime.WorkerSinkTask.rewind(WorkerSinkTask.java:649)         at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:334)         at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:229)         at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:198)         at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)         at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:235)         at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)         at java.util.concurrent.FutureTask.run(FutureTask.java:266)         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)         at java.lang.Thread.run(Thread.java:748) [2020-08-07 23:53:55,752] ERROR WorkerSinkTask{id=MirrorSinkConnector-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:188) `  As suggested in https://stackoverflow.com/questions/41008610/kafkaconsumer-0-10-java-api-error-message-no-current-assignment-for-partition/41010594, the resolution (that has been initially verified) proposed in this PR is to use consumer.assign() with consumer.seek(), instead of consumer.subscribe, to handle the initial position of the consumer, when specific offsets are provided by external through WorkerSinkTaskContext","closed","","ning2008wisc","2020-08-08T02:49:57Z","2020-09-04T19:03:42Z"
"","9178","KAFKA-8362: fix the old checkpoint won't be removed after alter log dir","In [KIP-113](https://cwiki.apache.org/confluence/display/KAFKA/KIP-113%3A+Support+replicas+movement+between+log+directories), we support replicas movement between log directories. But while the directory change, we forgot to remove the topicPartition offset data in old directory, which will cause there are more than 1 checkpoint copy stayed in the logs for the altered topicPartition. And it'll let the LogCleaner get stuck due to it's possible to always get the old topicPartition offset data from the old checkpoint file.   I added one more parameter `topicPartitionToBeRemoved` in `updateCheckpoints()` method. So, if the `update` parameter is `None` (as before), we'll do the remove action to remove the `topicPartitionToBeRemoved` data in dir, otherwise, update the data as before.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-08-14T01:46:11Z","2020-09-14T15:50:46Z"
"","9175","KAFKA-8362: Fix the old checkpoint data won't be removed after alter log dir","In [KIP-113](https://cwiki.apache.org/confluence/display/KAFKA/KIP-113%3A+Support+replicas+movement+between+log+directories), we support replicas movement between log directories. But while the directory change, we forgot to remove the topicPartition offset data in old directory, which will cause there are more than 1 checkpoint copy stayed in the logs for the altered topicPartition. And it'll let the LogCleaner get stuck due to it's possible to always get the old topicPartition offset data from the old checkpoint file.   I added one more parameter `topicPartitionToBeRemoved` in `updateCheckpoints()` method. So, if the `update` parameter is `None` (as before), we'll do the remove action to remove the `topicPartitionToBeRemoved` data in dir, otherwise, update the data as before.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-08-13T11:29:29Z","2020-08-14T03:17:40Z"
"","9434","MINOR: Handle lastFetchedEpoch/divergingEpoch in FetchSession and DelayedFetch","In 2.7, we added lastFetchedEpoch to fetch requests and divergingEpoch to fetch responses. We are not using these for truncation yet, but in order to use these for truncation with IBP 2.7 onwards in the next release, we should make sure that we handle these in all the supporting classes even in 2.7.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rajinisivaram","2020-10-14T16:11:23Z","2020-10-16T08:58:02Z"
"","9037","MINOR: Improved code quality for various files.","Improved code quality for various files.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","leonardge","2020-07-17T16:34:37Z","2020-07-18T09:18:32Z"
"","9149","KAFKA-10340: Improve the trace logging under connector based topic creation","Improve the logging in `maybeCreateTopic` to let user know if  `!topicCreation.isTopicCreationRequired(topic)`, we won't create this topic because the topic creation setting is disabled or the topic name is already created. Also, we should let user know that if the topic doesn't exist, we'll rely on the `auto.create.topics.enable` setting in broker side to see if the topic can be auto created or not. Otherwise, if the `auto.create.topics.enable` is disabled, the producer.send will get only `TimeoutException` and no other valuable clue for users.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","showuon","2020-08-10T06:45:09Z","2020-10-16T01:15:46Z"
"","8771","MINOR: Add explanation for disabling forwarding from value transformers","Improve code to be self documenting, in cases where forwarding of messages is disabled due to the type of processor being used,","closed","streams,","astubbs","2020-06-01T14:07:23Z","2020-06-08T10:14:01Z"
"","9445","KAFKA-10615 Detail plain authentication failure log","Improve broker logs when a client authenticates using Plain mechanism and wrong password.  This helps identifying wihich client is misconfigured.","open","","gquintana","2020-10-15T18:11:28Z","2020-10-15T18:11:28Z"
"","9441","KAFKA-10614: Ensure group state (un)load is executed in the submitted order","Implements the single thread with FIFO approach suggested in https://issues.apache.org/jira/browse/KAFKA-10614","closed","","tombentley","2020-10-15T11:33:16Z","2021-07-13T21:04:36Z"
"","8957","KAFKA-5235: GetOffsetShell: support for multiple topics and consumer configuration override","Implements KIP-635  Changes: - Added kafka-get-offsets.sh script - Removed deprecated max-wait-ms and offsets arguments - Updated tool to query all topic-partitions by default - Updated topic argument to support patterns - Added topic-partitions argument to support a list of topic-partition patterns - Added exclude-internal-topics to support filtering internal topics  Testing done: added new ducktape tests for the tool.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","urbandan","2020-06-30T13:22:39Z","2020-10-14T06:54:18Z"
"","9430","KAFKA-5235: GetOffsetShell: support for multiple topics and consumer configuration override","Implements KIP-635  Changes:  - Added kafka-get-offsets.sh script - Removed deprecated max-wait-ms and offsets arguments - Updated tool to query all topic-partitions by default - Updated topic argument to support patterns - Added topic-partitions argument to support a list of topic-partition patterns - Added exclude-internal-topics to support filtering internal topics  Testing done: added new ducktape tests for the tool.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","urbandan","2020-10-14T06:52:59Z","2021-02-11T11:06:21Z"
"","9396","KAFKA-10437: Implement new PAPI support for test-utils","Implements KIP-478 for the test-utils module: * adds mocks of the new ProcessorContext and StateStoreContext * adds tests that all stores and store builders are usable with the new mock * adds tests that the new Processor api is usable with the new mock * updates the demonstration Processor to the new api  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","vvcephei","2020-10-08T17:29:10Z","2021-01-08T02:03:59Z"
"","9137","KAFKA-9929: Support reverse iterator on KeyValueStore","Implements [KIP-617](https://cwiki.apache.org/confluence/display/KAFKA/KIP-617%3A+Allow+Kafka+Streams+State+Stores+to+be+iterated+backwards) on KeyValueStore.  Testing strategy: extend existing tests to validate reverse operations are supported.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jeqo","2020-08-07T16:20:51Z","2020-08-22T01:29:41Z"
"","8723","KIP-569-KAFKA-9494: DescribeConfigsResponse - include additional metadata information","Implements [KIP-569](https://cwiki.apache.org/confluence/display/KAFKA/KIP-569%3A+DescribeConfigsResponse+-+Update+the+schema+to+include+additional+metadata+information+of+the+field)  Adds `documentation` and `type` of `ConfigEntry` in version 3 of `DescribeConfigsResponse`  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","srpanwar-confluent","2020-05-25T08:33:08Z","2020-05-29T22:18:50Z"
"","9099","KAFKA-6733: Printing additional ConsumerRecord fields in DefaultMessageFormatter","Implementation of KIP-431 - Support of printing additional ConsumerRecord fields in DefaultMessageFormatter  https://cwiki.apache.org/confluence/display/KAFKA/KIP-431%3A+Support+of+printing+additional+ConsumerRecord+fields+in+DefaultMessageFormatter  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","badaiaqrandista","2020-07-29T12:56:06Z","2020-10-07T12:24:04Z"
"","8955","KAFKA-10020: Create a new version of a scala Serdes without name clash (KIP-616)","Implementation of a solution for KIP-616.  Wildcard import of the old `org.apache.kafka.streams.scala.Serdes` leads to a name clash because some of implicits has the same names as types from the scala's std lib. New `org.apache.kafka.streams.scala.serialization.Serdes` is the same as old `Serdes`, but without name clashes. The old one was marked as deprecated.  Also, missing serdes for `UUID`, `ByteBuffer` and `Short` types are present in the new `Serdes`.","closed","kip,","LMnet","2020-06-30T09:49:53Z","2021-01-08T02:05:27Z"
"","8720","KAFKA-9971: Error Reporting in Sink Connectors (KIP-610)","Implementation for KIP-610: https://cwiki.apache.org/confluence/display/KAFKA/KIP-610%3A+Error+Reporting+in+Sink+Connectors  This PR adds the `ErrantRecordReporter` interface as well as its implementation - `WorkerErrantRecordReporter`. The `WorkerErrantRecordReporter` is created in `Worker` and brought up through `WorkerSinkTask` to `WorkerSinkTaskContext`. An integration test and unit test has been added.","closed","connect,","aakashnshah","2020-05-23T01:00:41Z","2020-06-07T22:51:20Z"
"","8691","KAFKA-9960: implement KIP-606 to add metadata context to MetricsReporter","Implement KIP-606, add metadata context to MetricsReporter: * Added a new api to MetricsReporter to allow client to expose additional metadata fields to reporter plugin. Added an interface MetricsContext to encapsulate metadata. * Deprecated JmexReporter(String prefix) constructor. The prefix will be passed to the reporter via MetricsContext. * Replaced existing usage of JmxReporter with the default ImxReporter and pass JMX prefix to MetricsContext using _namespace as key. * From Kafka broker, populate MetricsContext with: kafka.cluster.id and kafka.nroker.id * From Connect, populate MetricsContext with: connect.kafka.cluster.id, connect.group.id  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","xiaodongdu","2020-05-18T23:42:39Z","2020-06-12T23:09:10Z"
"","9390","MINOR: Implement ApiError#equals and hashCode","Implement ApiError#equals and hashCode.  They are sometimes useful in tests.","closed","","cmccabe","2020-10-07T23:56:53Z","2020-10-09T17:25:55Z"
"","8900","KAFKA-10169: swallow non-fatal KafkaException and don't abort transaction during clean close","If there's any pending data and we haven't flushed the producer when we abort a transaction, a KafkaException is returned for the previous `send`. This is a bit misleading, since the situation is not an unrecoverable error and so the Kafka Exception is really non-fatal. For now, we should just catch and swallow this in the RecordCollector (see also: [KAFKA-10169](https://issues.apache.org/jira/browse/KAFKA-10186))  The reason we ended up aborting an un-flushed transaction was due to the combination of a. always aborting the ongoing transaction when any task is closed/revoked b. only committing (and flushing) if at least one of the revoked tasks needs to be committed (regardless of whether any non-revoked tasks have data/transaction in flight)  Given the above, we can end up with an ongoing transaction that isn't committed since none of the revoked tasks have any data in the transaction. We then abort the transaction anyway, when those tasks are closed. So in addition to the above (swallowing this exception), we should avoid unnecessarily aborting data for tasks that haven't been revoked.  We can handle this by splitting the RecordCollector's `close` into a dirty and clean flavor: if dirty, we need to abort the transaction since it may be dirty due to the commit attempt failing. But if clean, we can skip aborting the transaction since we know that either we just committed and thus there is no ongoing transaction to abort, or else the transaction in flight contains no data from the tasks being closed  Note that this means we still abort the transaction any time a task is closed dirty, so we _must_ close/reinitialize _any_ active task with pending data (that was aborted).   In sum: 1. only abort the transaction during a dirty close 2. refactor shutdown to make sure we don't `closeClean` a task whose data was actually aborted","closed","streams,","ableegoldman","2020-06-18T23:41:12Z","2020-06-26T22:28:20Z"
"","8702","MINOR: Fix join group request timeout lower bound","If the request timeout is larger than the rebalance timeout, we should use the former as the JoinGroup request timeout.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-05-21T00:56:02Z","2020-05-22T18:53:00Z"
"","8582","KAFKA-9932: Don't load configs from ZK when the log has already been loaded","If a broker contains 8k replicas, we would previously issue 8k ZK calls to retrieve topic configs when processing the first LeaderAndIsr request. That should translate to 0 after these changes.  Credit to @junrao for identifying the problem.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-04-29T04:58:10Z","2020-04-29T21:33:16Z"
"","8637","KAFKA-9976: Reuse repartition node in all cases for KGroupedStream and KGroupedTable aggregates","If a `KGroupedStream` or `KGroupedTable` requires a repartition, reusing the same instance results in creating a new repartition topic.   Unless the user provides a name via `Grouped`.  However, we should have consistent behavior regardless if the user provides a name or Kafka Streams generates it.  This PR changes the behavior to create one repartition topic (if required) per instance.  I've updated the test cases. ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","bbejeck","2020-05-09T20:47:28Z","2020-05-21T17:48:12Z"
"","9335","Update quickstart.html","i've followed quickstart instructions here https://kafka.apache.org/documentation/#quickstart_send and when i run: `bin/kafka-console-producer.sh --topic quickstart-events --bootstrap-server localhost:9092` i get: `bootstrap-server is not a recognized option` the solution was to use: `bin/kafka-console-producer.sh --topic quickstart-events --broker-list localhost:9092`","closed","","fredsh2k","2020-09-24T09:28:53Z","2020-09-25T11:11:17Z"
"","8974","KAFKA-10225 Increase default zk session timeout for system tests","I'm digging in the flaky system tests and then I noticed there are many flaky caused by following check. ```python         with node.account.monitor_log(KafkaService.STDOUT_STDERR_CAPTURE) as monitor:             node.account.ssh(cmd)             # Kafka 1.0.0 and higher don't have a space between ""Kafka"" and ""Server""             monitor.wait_until(""Kafka\s*Server.*started"", timeout_sec=timeout_sec, backoff_sec=.25,                                err_msg=""Kafka server didn't finish startup in %d seconds"" % timeout_sec) ```  And the error message in broker log is shown below. ``` kafka.zookeeper.ZooKeeperClientTimeoutException: Timed out waiting for connection while in state: CONNECTING 	at kafka.zookeeper.ZooKeeperClient.waitUntilConnected(ZooKeeperClient.scala:262) 	at kafka.zookeeper.ZooKeeperClient.(ZooKeeperClient.scala:119) 	at kafka.zk.KafkaZkClient$.apply(KafkaZkClient.scala:1880) 	at kafka.server.KafkaServer.createZkClient$1(KafkaServer.scala:430) 	at kafka.server.KafkaServer.initZkClient(KafkaServer.scala:455) 	at kafka.server.KafkaServer.startup(KafkaServer.scala:227) 	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44) 	at kafka.Kafka$.main(Kafka.scala:82) 	at kafka.Kafka.main(Kafka.scala) ```  I'm surprised the default timeout of zk connection in system test is only 2 seconds as the default timeout in production is increased to 18s (see https://github.com/apache/kafka/commit/4bde9bb3ccaf5571be76cb96ea051dadaeeaf5c7) ``` config_property.ZOOKEEPER_CONNECTION_TIMEOUT_MS: 2000 ```     issue: https://issues.apache.org/jira/browse/KAFKA-10225  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","chia7712","2020-07-02T06:06:22Z","2020-07-08T20:19:41Z"
"","9135","MINOR Refactor Producer class in examples","I'm a newbie to the Kafka project and going through the examples. Along the way I did a very small refactoring to the Producer class: * Convert the Callback class into a method  The aim was to simplify the whole class and introduce lambda-style / functional style programming now available  in current java versions.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","tom1299","2020-08-07T08:21:53Z","2020-10-19T17:16:11Z"
"","9174","KAFKA-10395: relax output topic check in TTD to work with dynamic routing","I went through all 5 stages of grief in thinking about what to do here and decided the best thing was to just relax the check after all. Hopefully users who find their output topic unexpectedly empty due to a typo in the topic name will be able to figure it out quickly from the warning we now log instead.  Not sure how rampant the problem of output-topic-typos is to begin with...","closed","","ableegoldman","2020-08-13T01:11:47Z","2020-08-26T21:39:27Z"
"","9032","KAFKA-10259: KIP-554 Broker-side SCRAM Config API","I still need to add a test file `core/src/test/scala/unit/kafka/admin/UserScramCredentialsCommandTest.scala`, but aside from that I think it's close to done.","closed","","rondagostino","2020-07-16T22:50:19Z","2020-09-04T20:05:03Z"
"","8508","MINOR: Improve usage of LogCaptureAppender","I started a ""small"" cleanup, and it ended up to become a ""big"" cleanup...   - limit the usage of `LogCaptureAppender` to the class under test (if possible)  - ensure that the registered appended is unregistered (via try-with-resource)  - limit the ""scope"" of creating/unregistering the appended to a minimum   - cleanup all warning of all classes touched  - some code reformatting  - some class renaming  Call for review @vvcephei","closed","","mjsax","2020-04-18T00:29:02Z","2020-04-21T16:25:54Z"
"","9082","MINOR: Update dependencies for Kafka 2.7 (part 1)","I left out updates that could be risky. Preliminary testing indicates we can build (including spotBugs) and run tests with Java 15 with these changes. I will do more thorough testing once Java 15 reaches release candidate stage in a few weeks.  Minor updates with mostly bug fixes: - Scala: 2.12.11 -> 2.12.12 (compiler and collection performance improvements) - Bouncy castle: 1.64 -> 1.66 (several bug fixes) - HttpClient: 4.5.11 -> 4.5.12 (small number of bug fixes) - Mockito: 3.3.3 -> 3.4.4 (several bug fixes and Java 15 support) - Netty: 4.5.10 -> 4.5.11 (several bug fixes) - Snappy: 1.1.7.3 -> 1.1.7.6 (small number of bug fixes) - Zstd: 1.4.5-2 -> 1.4.5-6 (small number of bug fixes)  Gradle plugin and library upgrades: - Gradle version plugins: 0.28.0 -> 0.29.0 (small number of bug fixes) - Git: 4.0.1 -> 4.0.2 (small number of bug fixes) - Scoverage plugin: 4.0.1 -> 4.0.2 (small number of bug fixes) - Shadow plugin: 5.2.0 -> 6.0.0 (Java 15 support and require Gradle 6.0) - Test Retry plugin: 1.1.5 -> 1.1.6 (small number of bug fixes) - Spotless plugin: 4.4.4 -> 5.1.0 (several internal changes that should not matter to us) - Spotbugs: 4.0.3 -> 4.0.6 (small number of bug fixes) - Spotbugs plugin: 4.2.4 -> 4.4.4 (small number of bug fixes)  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-07-26T16:19:28Z","2020-07-27T10:47:20Z"
"","8742","KAFKA-10057 optimize class ConfigCommand method alterConfig parameters","I know this parameter will be used in the future, but it is not used here","open","","sasukerui","2020-05-28T14:51:41Z","2020-12-09T09:32:30Z"
"","9359","kafka-10273 Connect Converters should produce actionable error messages","I have written actionable error messages for the JSON-converter   @rhauch Hi, please review if this is acceptable, if anything needs to be changed and if I need to do the same for the rest of the converters.","open","connect,","shadikajevand","2020-10-01T08:11:35Z","2020-10-29T12:30:54Z"
"","9091","MINOR; Make KafkaAdminClientTest.testDescribeLogDirsPartialFailure and KafkaAdminClientTest.testAlterReplicaLogDirsPartialFailure test more reliable","I have seem them failing locally from times to times. It seems that the changes made in https://github.com/apache/kafka/pull/8864 have made them more fragile. I have updated them to be more reliable.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-07-28T07:23:41Z","2020-09-11T05:03:12Z"
"","8985","MINOR; KafkaAdminClient#alterReplicaLogDirs should not fail all the futures when only one call fails","I have noticed that `alterReplicaLogDirs` fails all the unrealised futures when one of the call sent out fails (e.g. timeout). So if two calls A and B are sent out, if A fails before B comes back, all the futures are failed even if B is successful. I think that each call should realised their related futures only.  This PR adds a unit test to reproduce the issue and fix it.  It seems that other calls may suffer from the same issue. I will review them and open other PRs.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-07-06T08:57:22Z","2020-10-06T20:08:20Z"
"","9470","Add recursive support to Connect Cast and ReplaceField transforms, and support for casting complex types to either a native or JSON string.","I have added support for the `Cast` and `ReplaceField` transformations to recursively traverse the structure of messages (both with and without a schema) and perform the Cast or Replace operations on matching child primitive fields if they are found at any level nested within the structure.  Nested parents of all currently-supported Connect complex types should be supported (Map, Array, or Struct) but most of the primitive field handling is still similar to before (the lowest level within the nesting would normally be a Struct when using Schema or Map when schemaless).  This behavior can be controlled by a new configuration parameter called `recursive` for both transformations.  The default setting is **false** so any existing connectors would not be impacted -- you must set the parameter to **true** in order for the child complex types to be traversed.  Otherwise, the default behavior should be the same as before.  I have also cleaned up the Config names a bit to match some of the other transformations (namely, using a class interface called `ConfigName` which can be accessed statically), it is a bit nicer to work with and brings a little more consistency across the different built-in transforms.  Since this is more than just a trivial change, I have created a few new unit tests, some of them quite complex, to try and make sure that everything is working ok compared to before.  I have also been running both of these as custom SMTs against data in our production kafka cluster and used some learnings there to iron out a few issues.  I have had tens of millions of events actually using this updated code so I think/hope the changes are pretty well-tested but welcome if there is some kind of feedback or concern with them!  Here is a full list of everything that I have changed:  ### Cast  #### Added new Config Parameters: - `recursive` optional boolean, default = `false` - `complex.string.as.json` optional boolean, default = `false`  #### Changes:  - Created new public static interface `ConfigName` and marked the old public static string `SPEC_CONFIG` as deprecated (so it can still be used for a while until it is removed later). - Added new `ConfigName` for `SPEC`, `RECURSIVE`, and `COMPLEX_STRING_AS_JSON` - Created new interface `ConfigDefault` to provide an easy way to set and consume default values for these two new optional configuration parameters. - And then of course defined and set up the config parameters for usage within the rest of the class. - Added ARRAY, MAP, and STRUCT as valid types to convert FROM (but the only thing they can convert TO is STRING, otherwise if your `SPEC` tries to convert them to something else it will throw a `DataException`).  Before you would receive a `DataException` if you tried to include a complex type in the `SPEC` but now at least you are given the option to Cast them to a string! - Refactored the `apply...` methods so that they will call a child method that recursively builds the structure of the schema or value depending if the user sets the `recursive` config parameter to true (otherwise it should basically work the same as before -- look at everything that is at the top level of the structure and then return).  There are new methods for recursively handling different type of structures but in the end the same basic flow happens at each child level as what was happening before (`for each field in fields...`).     - However, one change in the design is that when building the new Value, instead of looping through each field from the new schema and performing an `oldstruct.get(oldfield)`, it instead will loop again through each field in the old schema.  This is so that nested primitive conversions happen correctly and what happens in the Value should be exactly the same thing that happened in the Schema. - When a child schema is created as part of the recursion, it is also added to the `schemaUpdateCache`, and the recursive methods call `getOrBuildUpdatedSchema` so they should fetch it from the cast in case it has already been converted.  This is the same when child values are converted -- they should fetch their new child schemas from the cache instead of building them again. - Added usage of an instance of `JsonConverter` and `JsonDeserializer` if you wish to have the complex types toString come out in a JSON text format instead of the Java object's toString() implementation.  This is helpful for scenarios for example like using a JdbcSinkConnector where you have an array of structs as one field in your source, you can put these values into a database table as a blob of JSON text, then parse these values as JSON (for example PostgreSQL has loads of really good JSON parsing).  This behavior is controlled by the new configuration parameter `complex.string.as.json` but again by default it is set to false (so you have to set to true in order to use this). - I also changed `castValueToType` from `private static` to `private`.  This was so that we can allow a check in this method on the instance value of our new `complex.string.as.json` configuration parameter and decide to call `castToJsonString` instead of the old `castToString` method.   - I realize this one can maybe be a bit controversial, and there were several options I considered.  First, however, I tried to examine any public static method or property of any kind and see if anything ever makes use of `castValueToType` and could not see any (please mention if you see something I missed).  So a change from private static to private in this case seems very minor and should not impact any functionality -- nothing else can see or use it anyway outside of this class itself.   - Another option is possibly a bit more like the `TimestampConverter` transform, where they have created a private instance of a `Config` subclass and then pass the entire instance to some of the static methods.  But I think that change would have to ""touch""  a lot more places, and given the point above (I did not see where it was actually used anywhere from anything public static ) this seemed like a bit too much of a rebuild.   - Also usage of this `castToJsonString` with using the `JsonConverter` and `JsonDeserializer` could be done a few other ways... but this was the one that I felt tried to use existing functionalities within Connect and was the ""cleanest"" looking that I could initially come up with from a code perspective.  And the reason to use a single private instance of the classes was to try and save a bit on resources -- it is possible that you will have multiple Json string conversions even within one record so I thought it was better to only have one instance we can re-use over and over. - Changed the log level for the Cast log message from Trace to Debug (this seems like something you definitely want to see in Debug and not just Trace!). - Added new test cases for casting Arrays and Maps to string, to JSON Strings, as well as for working with different types of recursive records (both with and without schema).  In these tests, I found that a lot of the weird issues only happen once you go a few levels deep so I have made the tests a little more complicated to ensure that everything was working properly even with multiple nested levels.  #### Example Usage  ``` curl -X PUT -H ""Content-Type: application/json"" --data '{   ""connector.class"": ""FileStreamSink"",   ""topics"": ""test"",   ""file"": ""/tmp/cast.txt"",   ""transforms"": ""cast"",   ""transforms.cast.type"": ""org.apache.kafka.connect.transforms.Cast$Value"",   ""transforms.cast.spec"": ""child_int:string,child_array_of_structs:string"",   ""transforms.cast.recursive"": ""true"",   ""transforms.cast.complex.string.as.json"": ""true"" }' http://localhost:8083/connectors/filestreamsink_cast_test/config ```   ### ReplaceField  #### Added new Config Parameters: - `recursive` optional boolean, default = `false`  #### Changes:  - A lot of the changes here are very similar to what was done in `Cast`.  In fact, even before my changes, the flow of these two transforms was actually almost identical, so it worked quite well to do them both like this at the same time and they are easily used together in transform chains within Connect. - Namely, there is a new `recursive` configuration parameter and the `apply...` methods have been updated to recursively call methods to build the new target schema and values.  A lot of the code is exactly the same so you should even find direct copy-paste from `Cast` to here and using a lot of the same private object names, methods, etc.    - Note also that the pattern follows the same as with `Cast` -- looping through the old schema and converted child values based on the old structure instead of first creating a new schema and then getting the old field.  This new flow also means that the `reverseRenamed` method and its `reverseRenames` map are no longer needed either (but I left them in for now). - Added a logger instance and added Debug-level logging for a few different events, such as when a field is excluded or included, or when it is renamed.  So some of the methods were refactored a bit in order to provide this logging (for example the `filter` and `renamed` methods). - I also added support when using `renames` for a ""contains exactly one of"" kind of scenario.  What I mean by this is that in your schema, you have several fields which you know by design that only one of them will have a value, and when that one has a value, all of the rest within that group will be null.  The change to this transform now allows you to specify a target name more than one time, but when the value transform is occurring, if more than one of them have a value then it will throw a `DataException`.  Before, the transform would throw a `DataException` when building the new schema based on the `renames` config (trying to add a duplicate field to the schema) but instead now this check happens when building the updated value instead. - Also added a few unit tests to handle new scenarios and recursive operation (both with and without schemas).  #### Example Usage  ``` curl -X PUT -H ""Content-Type: application/json"" --data '{   ""connector.class"": ""FileStreamSink"",   ""topics"": ""test"",   ""file"": ""/tmp/replace.txt"",   ""transforms"": ""replace"",   ""transforms.replace.type"": ""org.apache.kafka.connect.transforms.ReplaceField$Value"",   ""transforms.replace.renames"": ""child_value_one:child_value,child_value_two:child_value"",   ""transforms.replace.recursive"": ""true"", }' http://localhost:8083/connectors/filestreamsink_replace_test/config ```  I hope this covers everything but if you have any questions or concerns then please feel free to ask!    ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","joshuagrisham","2020-10-21T15:11:29Z","2020-10-24T17:46:11Z"
"","8931","MINOR: Update Scala to 2.13.3","I had to fix several compiler errors due to deprecation of auto application of `()`. A related Xlint config (`-Xlint:nullary-override`) is no longer valid in 2.13, so we now only enable it for 2.12. The compiler flagged two new inliner warnings that required suppression and the semantics of `&` in `@nowarn` annotations changed, requiring a small change in one of the warning suppressions.  I also removed the deprecation of a number of methods in `KafkaZkClient` as they should not have been deprecated in the first place since `KafkaZkClient` is an internal class and we still use these methods in the Controller and so on. This became visible because the Scala compiler now respects Java's `@Deprecated` annotation.  Finally, I included a few minor clean-ups (eg using `toBuffer` instead `toList`) when fixing the compilation warnings.  Noteworthy bug fixes in Scala 2.13.3:  * Fix 2.13-only bug in Java collection converters that caused some operations to perform an extra pass * Fix 2.13.2 performance regression in Vector: restore special cases for small operands in appendedAll and prependedAll * Increase laziness of #:: for LazyList * Fixes related to annotation parsing of @Deprecated from Java sources in mixed compilation  Full release notes: https://github.com/scala/scala/releases/tag/v2.13.3  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-06-25T22:58:25Z","2020-06-26T17:19:33Z"
"","9045","MINOR: Adjust 'release.py' script to use shell when using gradlewAll and PGP signing","I had to add these one-by-one in order to build the AK 2.6.0 RCs.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rhauch","2020-07-20T12:40:08Z","2020-07-27T14:22:24Z"
"","8925","KAFKA-9974: Integration test shouldApplyUpdatesToStandbyStore; Make produce-sync flush","I cannot actually re-produce the failure locally, but by looking at the code I think there's an issue in `produceKeyValuesSynchronously`: when Eos is not enabled, we then need to call `flush` to make sure all records are indeed sent ""synchronously"". If Eos is enabled the `commitTxn` would flush the records already.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-06-25T01:18:54Z","2020-06-30T03:27:53Z"
"","8830","KAFKA-10116: GraalVM native-image prototype","I can generate a native image with the added task (`./gradlew core:nativeImage`), but it exits soon after start-up. Needs debugging.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","ijuma","2020-06-07T23:17:23Z","2021-03-01T02:03:24Z"
"","9331","MINOR: Use JUnit 5 in raft module","I also removed a test class with no tests currently.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-09-24T00:04:42Z","2020-09-24T09:37:22Z"
"","8495","MINOR: downgrade test should wait for ISR rejoin between rolls","I added a change to the upgrade test a while back that would make it wait for ISR rejoin before rolls. This prevents incompatible brokers charging through a bad roll and disguising a downgrade problem.  We now also check for protocol errors in the broker logs.","closed","","lbradstreet","2020-04-16T00:50:04Z","2020-04-23T07:15:44Z"
"","9250","KAFKA-10461 The config of closing heartbeat is invalid.","https://issues.apache.org/jira/projects/KAFKA/issues/KAFKA-10461?filter=allissues","closed","","jiweiautohome","2020-09-04T03:38:30Z","2020-09-14T02:50:58Z"
"","8551","KAFKA-9918 SslEngineFactory is NOT closed when channel is closing","https://issues.apache.org/jira/browse/KAFKA-9918  the default implementation (**DefaultSslEngineFactory**) does not have any releasable object so we didn't notice this issue. However, it would be better to fix this issue for the custom engine factory.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-04-25T10:58:02Z","2020-05-04T17:25:50Z"
"","8575","KAFKA-8713 KIP-581 Add accept.optional.null to solve optional null","https://issues.apache.org/jira/browse/KAFKA-8713  https://cwiki.apache.org/confluence/display/KAFKA/KIP-581:+Value+of+optional+null+field+which+has+default+value  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","kip,","pan3793","2020-04-28T17:21:18Z","2022-06-06T19:31:24Z"
"","8895","KAFKA-8398 Avoiding NPE in ByteBufferUnmapper#unmap()","https://issues.apache.org/jira/browse/KAFKA-8398  Regularly seeing this NPE when shutting down the broker in our tests. I *think* simply returning early in this case should suffice.  Hey @ijuma, could you take a a look at this one perhaps? Thanks!","closed","","gunnarmorling","2020-06-18T10:36:14Z","2020-07-06T08:21:54Z"
"","9399","KAFKA-10584:IndexSearchType should use sealed trait instead of Enumeration","https://issues.apache.org/jira/browse/KAFKA-10584  In Scala, we prefer sealed traits over Enumeration since the former gives you exhaustiveness checking. With Scala Enumeration, you don't get a warning if you add a new value that is not handled in a given pattern match.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","core,","huxihx","2020-10-09T03:18:06Z","2020-10-10T03:34:57Z"
"","9240","KAFKA-10456: Wrong description in kafka-console-producer.sh help","https://issues.apache.org/jira/browse/KAFKA-10456  Fix typo in description of ConsoleProducer.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tools,","huxihx","2020-09-02T01:06:30Z","2020-09-02T09:59:03Z"
"","9225","KAFKA-10431: Sequential selection of payload in ProducerPerformance","https://issues.apache.org/jira/browse/KAFKA-10431  Currently, ProducerPerformance randomly selects a payload from the payload file when sending message. This might cause the some payloads being selected more times than others. It's better to do sequential selection of payloads.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","huxihx","2020-08-27T08:19:42Z","2020-10-12T09:01:09Z"
"","9189","KAFKA-10407: Have KafkaLog4jAppender support `linger.ms` and `batch.size`","https://issues.apache.org/jira/browse/KAFKA-10407  Currently, KafkaLog4jAppender does not support `linger.ms` or `batch.size`. In some situations, those two parameters are good to tune the performance.   *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","huxihx","2020-08-17T02:25:01Z","2020-08-20T13:51:51Z"
"","9154","MINOR KAFKA-10382 - MockProducer is not ThreadSafe, ideally it should be as the implementation it mocks is","https://issues.apache.org/jira/browse/KAFKA-10382  Copied from the jira:  In testing my project, I discovered that the MockProducer is not thread safe as I thought. It doesn't use thread safe libraries for it's underlying stores, and only some of it’s methods are synchronised.   As performance isn’t an issue for this, I would propose simply synchronising all public methods in the class, as some already are.   In my project, send is synchronised and commit transactions isn’t. This was causing weird collection manipulation and messages going missing. My lolcat only solution was simply to synchronise on the MockProducer instance before calling commit.   See my workaround: https://github.com/astubbs/async-consumer/pull/13/files#diff-8e93aa2a2003be7436f94956cf809b2eR558","open","","astubbs","2020-08-10T13:21:35Z","2020-08-10T17:54:08Z"
"","9102","KAFKA-10326 Both serializer and deserializer should be able to see th…","https://issues.apache.org/jira/browse/KAFKA-10326  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","chia7712","2020-07-30T04:24:35Z","2020-10-01T03:23:31Z"
"","9071","KAFKA-10305: Print usage when parsing fails for ConsumerPerformance","https://issues.apache.org/jira/browse/KAFKA-10305  When `kafka-consumer-perf-test.sh` is executed without required options or no options at all, only the error message is displayed. It's better off showing the usage as well like what we did for kafka-console-producer.sh.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","huxihx","2020-07-24T05:53:53Z","2020-07-25T11:04:17Z"
"","9051","KAFKA-10268: dynamic config like ""--delete-config log.retention.ms"" doesn't work","https://issues.apache.org/jira/browse/KAFKA-10268  Currently, ConfigCommand's `--delete-config` API does not restore the config to default value, no matter at broker-level or broker-default level. Besides, Admin.incrementalAlterConfigs API also runs into this problem. This patch fixes it by removing the corresponding config from the `newConfig` properties when reconfiguring dynamic broker config.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","huxihx","2020-07-22T02:42:26Z","2020-07-28T15:56:03Z"
"","8984","KAFKA-10227: Enforce cleanup policy to only contain compact or delete once","https://issues.apache.org/jira/browse/KAFKA-10227  This patch fixes both TopicCommand and ConfigCommand. When duplicate items are specified in `cleanup.policy`, they will be removed automatically and then applied.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","tools,","huxihx","2020-07-06T07:46:11Z","2021-10-04T15:45:40Z"
"","8980","KAFKA-10222:Incorrect methods show up in 0.10 Kafka Streams docs","https://issues.apache.org/jira/browse/KAFKA-10222  Non-existent methods show up in the doc: builder.from(""my-input-topic"").mapValue(value -> value.length().toString()).to(""my-output-topic"");  There is no method named from or mapValues. They should be stream and mapValues respectively.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","docs,","huxihx","2020-07-05T02:18:07Z","2020-07-07T17:46:03Z"
"","8806","KAFKA-10108 The cached configs of SslFactory should be updated only i…","https://issues.apache.org/jira/browse/KAFKA-10108  The following cases should NOT change the cached configs of SslFactory.  1. validate reconfiguration 1. throw exception when checking the new ssl engine factory  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-06-05T07:30:14Z","2020-10-27T12:35:43Z"
"","8796","KAFKA-10096: Remove unnecessary String.format call.","https://issues.apache.org/jira/browse/KAFKA-10096  Since format is not provided in VersionConditionalTest::assertEquals, we can just pass the string into StringBuilder::append.  This is a newbie ticket to get used to the contribution flow.  Reviewers: @jghoman","closed","","cancecen","2020-06-03T22:00:54Z","2020-06-03T22:14:47Z"
"","8826","KAFKA-10090 Misleading warnings: The configuration was supplied but i…","https://issues.apache.org/jira/browse/KAFKA-10090  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-06-07T14:02:27Z","2020-12-03T02:34:28Z"
"","8792","KAFKA-10089 The stale ssl engine factory is not closed after reconfigure","https://issues.apache.org/jira/browse/KAFKA-10089  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-06-03T08:52:34Z","2020-06-03T18:04:22Z"
"","8783","KAFKA-10063 UnsupportedOperation when querying cleaner metrics after …","https://issues.apache.org/jira/browse/KAFKA-10063  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-06-02T16:57:36Z","2020-06-08T23:47:23Z"
"","8698","KAFKA-10022:console-producer supports the setting of client.id","https://issues.apache.org/jira/browse/KAFKA-10022  ""console-producer"" supports the setting of ""client.id"", which is a reasonable requirement, and the way ""console consumer"" and ""console producer"" handle ""client.id"" can be unified. ""client.id"" defaults to ""console-producer""   *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","xinzhuxiansheng","2020-05-20T16:14:17Z","2020-05-25T17:51:17Z"
"","8694","KAFKA-10022: console-producer supports the setting of client.id","https://issues.apache.org/jira/browse/KAFKA-10022  ""console-producer"" supports the setting of ""client.id"", which is a reasonable requirement, and the way ""console consumer"" and ""console producer"" handle ""client.id"" can be unified. ""client.id"" defaults to ""console-producer""   *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","xinzhuxiansheng","2020-05-19T13:03:17Z","2020-05-20T16:42:13Z"
"","8685","KAFKA-10014 Always try to close all channels in Selector#close","https://issues.apache.org/jira/browse/KAFKA-10014  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-05-18T08:37:26Z","2020-06-10T19:24:32Z"
"","9048","WIP: Replace org.reflections with classgraph for class scanning in Connect","https://github.com/classgraph/classgraph is a more recent and more actively developed classpath scanning library.   I'll be doing some testing and performance benchmarking before I open this PR for general review. Opening as draft atm.    ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","connect,","kkonstantine","2020-07-21T18:37:03Z","2020-07-21T18:47:33Z"
"","9140","KAFKA-10371; Partition reassignments can result in crashed ReplicaFetcherThreads","https://github.com/apache/kafka/pull/8672 introduced a bug leading to crashing the replica fetcher threads. The issue is that https://github.com/apache/kafka/pull/8672 deletes the Partitions prior to stopping the replica fetchers. As the replica fetchers relies access the Partition in the ReplicaManager, they crash with a NotLeaderOrFollowerException that is not handled.  This PR reverts the code to the original ordering to avoid this issue.  The regression has been caught by our system test: `kafkatest.tests.core.reassign_partitions_test`.  I have not managed to reproduce the issue in a unit test without reimplementing the entire system test in Java. I am not sure that makes sense as we already have it in Python.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-08-07T16:29:40Z","2020-08-08T07:37:55Z"
"","9458","MINOR: fix system tests sending ACLs through ZooKeeper","http://confluent-kafka-branch-builder-system-test-results.s3-us-west-2.amazonaws.com/2020-10-20--001.1603165159--rondagostino--minor_another_acl_system_test_fix--e4506f309/report.html   Tests | Passes | Failures | Ignored | Time -- | -- | -- | -- | -- 4 | 4 | 0 | 0 | 7 minutes 17.330 seconds","closed","","rondagostino","2020-10-20T11:57:57Z","2020-10-20T12:13:51Z"
"","8898","KAFKA-10138: Prefer --bootstrap-server for reassign_partitions command in ducktape tests","http://confluent-kafka-branch-builder-system-test-results.s3-us-west-2.amazonaws.com/2020-06-17--001.1592453352--vinothchandar--KC342-ducktape--e64cc463b/report.html  Both ThrottlingTest and ReassignPartitionsTest, which invokes these methods pass locally and twice in CI.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vinothchandar","2020-06-18T21:46:35Z","2020-06-19T19:35:51Z"
"","8919","HOTFIX: use .equals to compare HostInfo in StreamsMetadataState","Hotfix for patching this in older branches","closed","streams,","ableegoldman","2020-06-23T22:10:48Z","2020-06-24T18:28:00Z"
"","9157","KAFKA-5636: Update for KIP-450 to handle early records","Handles records that fall between 0 and the timeDifference that would normally create negative windows. This puts a new record that falls into this range in a window from [0, timeDifference] and creates the record's right windows as later records fall into it.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","lct45","2020-08-10T18:26:27Z","2021-01-08T02:05:36Z"
"","9063","MINOR: Fixed deprecated Gradle build Properties.","Gradle properties: `baseName`, `classifier` and `version` has been deprecated. So I have change these to `archiveBaseName`, `archiveClassifier` and `archiveVersion`. More infomration [here](https://docs.gradle.org/6.5/dsl/org.gradle.api.tasks.bundling.Zip.html#org.gradle.api.tasks.bundling.Zip:zip64).  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","leonardge","2020-07-23T10:03:00Z","2020-07-25T22:39:33Z"
"","8751","MINOR: Update to Gradle 6.5 and tweak build jvm config","Gradle 6.5 includes a fix for https://github.com/gradle/gradle/pull/12866, which affects the performance of Scala compilation.  I profiled the scalac build with async profiler and 54% of the time was on GC even after the Gradle upgrade (it was more than 60% before), so I switched to the throughput GC (GC latency is less important for batch builds) and it was reduced to 38%.  I also centralized the jvm configuration in `build.gradle` and simplified it a bit by removing the minHeapSize configuration from the test tasks.  On my desktop, the time to execute clean builds with no cached Gradle daemon was reduced from 127 seconds to 97 seconds. With a cached daemon, it was reduced from 120 seconds to 88 seconds. The performance regression when we upgraded to Gradle 6.x was 27 seconds with a cached daemon  (https://github.com/apache/kafka/pull/7677#issuecomment-616271179), so it should be fixed now.  Gradle 6.4 with no cached daemon:  ``` BUILD SUCCESSFUL in 2m 7s 115 actionable tasks: 112 executed, 3 up-to-date ./gradlew clean compileScala compileJava compileTestScala compileTestJava  1.15s user 0.12s system 0% cpu 2:08.06 total ```  Gradle 6.4 with cached daemon:  ``` BUILD SUCCESSFUL in 2m 0s 115 actionable tasks: 111 executed, 4 up-to-date ./gradlew clean compileScala compileJava compileTestScala compileTestJava  0.95s user 0.10s system 0% cpu 2:01.42 total ```  Gradle 6.5 with no cached daemon:  ``` BUILD SUCCESSFUL in 1m 46s 115 actionable tasks: 111 executed, 4 up-to-date ./gradlew clean compileScala compileJava compileTestScala compileTestJava  1.27s user 0.12s system 1% cpu 1:47.71 total ```  Gradle 6.5 with cached daemon:  ``` BUILD SUCCESSFUL in 1m 37s 115 actionable tasks: 111 executed, 4 up-to-date ./gradlew clean compileScala compileJava compileTestScala compileTestJava  1.02s user 0.10s system 1% cpu 1:38.31 total ```  This PR with no cached Gradle daemon:  ``` BUILD SUCCESSFUL in 1m 37s 115 actionable tasks: 81 executed, 34 up-to-date ./gradlew clean compileScala compileJava compileTestScala compileTestJava  1.27s user 0.10s system 1% cpu 1:38.70 total ```  This PR with cached Gradle daemon:  ``` BUILD SUCCESSFUL in 1m 28s 115 actionable tasks: 111 executed, 4 up-to-date ./gradlew clean compileScala compileJava compileTestScala compileTestJava  1.02s user 0.10s system 1% cpu 1:29.35 total ```  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-05-29T02:26:23Z","2020-06-03T20:19:11Z"
"","9035","set dev version to 2.5.1","Getting ready for the 2.5.1 RC.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-07-17T15:42:50Z","2020-07-17T16:33:29Z"
"","9148","KAFKA-10379: Implement the KIP-478 StreamBuilder#addGlobalStore()","From KIP-478, implement the new StreamBuilder#addGlobalStore() overload that takes a stateUpdateSupplier fully typed Processor.  Where necessary, use the adapters to make the old APIs defer to the new ones, as well as limiting the scope of this change set.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","vvcephei","2020-08-10T03:19:03Z","2021-01-08T02:05:01Z"
"","8889","MINOR: reuse toConfigObject(Map) to generate Config","from https://github.com/apache/kafka/pull/8853#discussion_r441609880  ``` nit: I think that we can use toConfigObject(topicMetadata.configs) here. ```  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-06-17T15:14:56Z","2020-06-17T20:46:06Z"
"","9006","KAFKA-3370 nearest offset reset","from discussion in [KAFKA-3370](https://issues.apache.org/jira/browse/KAFKA-3370) - Introduce nearest.offset.reset option on the Consumer, which will only be used on OffsetOutOfRangeException.  On enable, the offset will be reset to the earliest if out-of-range offset is not higher than the earliest offset, otherwise it will be reset to the latest offset.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","ttapjinda","2020-07-10T06:39:56Z","2020-07-15T07:28:57Z"
"","8840","KAFKA-10129 Fail QA if there are javadoc warnings","from @hachikuji  (https://github.com/apache/kafka/pull/8660#pullrequestreview-425856179)  > One other question I had is whether we should consider making doc failures also fail the build?  issue: https://issues.apache.org/jira/browse/KAFKA-10129  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-06-09T15:48:07Z","2020-09-02T16:44:46Z"
"","9342","MINOR: Update doc for raft state metrics","Found this while reviewing related code. cc @hachikuji to review and merge.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-09-28T02:57:06Z","2020-10-05T21:52:38Z"
"","9194","KAFKA-10384: Separate converters from generated messages","For the generated message code, put the JSON conversion functionality in a separate JsonConverter class.  Make MessageDataGenerator simply another generator class, alongside the new JsonConverterGenerator class.  Move some of the utility functions from MessageDataGenerator into FieldSpec and other places, so that they can be used by other generator classes.  Use argparse4j to support a better command-line for the generator.","closed","","cmccabe","2020-08-18T00:31:07Z","2020-08-26T22:10:16Z"
"","9249","KAFKA-10458: Add update quota for TokenBucket registered with Sensor","For Rate() metric with quota config, we update quota by updating config of KafkaMetric. However, it is not enough for TokenBucket, because it uses quota config on record() to properly calculate the number of tokens. Sensor passes config stored in the corresponding StatAndConfig, which currently never changes. This means that after updating quota via KafkaMetric.config, which is our current and only method, Sensor would record the value using old quota but then measure the value to check for quota violation using the new quota value. This PR adds update method to Sensor that properly updates quota for TokenBucket.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","apovzner","2020-09-03T06:06:48Z","2020-09-09T17:40:54Z"
"","9196","KAFKA-10402: Upgrade system tests to python3","For now, Kafka system tests use python2 which is outdated and not supported. This PR upgrades python to the third version.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","nizhikov","2020-08-18T10:17:40Z","2020-10-07T16:41:45Z"
"","8709","KAFKA-9952; Remove immediate fetch completion logic on high watermark updates","For KIP-392, we added logic to make sure that high watermark changes are propagated to followers without delay in order to improve end to end latency when fetching from followers. The downside of this change is that it increases the rate of fetch requests from followers which can have a noticeable impact on performance (see KAFKA-9731).   To fix that problem, we have already modified the code so that we only propagate high watermark changes immediately when a replica selector is used (which is not the default). However, leaving this logic around means that it is risky to enable follower fetching since it changes the follower request rate, which can have a big impact on overall broker performance.   This patch disables immediate propagation of the high watermark more generally. Instead, users can use the max wait time in order to control the worst-case latency. Note that this is typically only a problem anyway for low-throughput clusters since otherwise we will always have a steady rate of high watermark updates.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-05-21T21:31:00Z","2020-05-27T21:41:50Z"
"","9382","KAFKA-10554; Perform follower truncation based on diverging epochs in Fetch response","For IBP 2.7 onwards, fetch responses include diverging epoch and offset in fetch responses if `lastFetchedEpoch` is provided in the fetch request. This PR uses that information for truncation and avoids the additional OffsetForLeaderEpoch requests in followers when `lastFetchEpoch` is known.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rajinisivaram","2020-10-06T13:53:04Z","2020-12-03T10:12:07Z"
"","8816","MINOR: Print all removed dynamic members during join complete","For better visibility on the group rebalance, we are trying to print out the evicted members inside the group coordinator during rebalance complete.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-06-05T17:01:40Z","2020-06-10T00:33:44Z"
"","8772","MINOR: clarify exception throwing in allStorePartitionLags javadocs","Followup to https://github.com/apache/kafka/pull/8738, backporting the javadocs to 2.5","closed","","ableegoldman","2020-06-01T17:47:59Z","2020-06-02T23:03:21Z"
"","9000","KAFKA-10036 Improve handling and documentation of Suppliers","Following up on #8752 which seems to have gone stale.  @mjsax can you continue the review?","closed","streams,","soarez","2020-07-09T09:59:17Z","2020-11-04T10:07:15Z"
"","8521","MINOR: Use .asf.yaml to direct github notifications to JIRA and mailing lists","Following the instructions from: https://cwiki.apache.org/confluence/display/INFRA/.asf.yaml+features+for+git+repositories#id-.asf.yamlfeaturesforgitrepositories-ImplementedFeatures  This PR redirects all github `commit` notifications to `commits@kafka.apache.org` and `issues`, `pullrequests` notifications to `github@kafka.apache.org` mailing list.   Also enable `link` `label` JIRA notification options.","closed","","omkreddy","2020-04-20T13:35:57Z","2020-04-20T14:52:38Z"
"","8635","KAFKA-9949: Fix Flaky  GlobalKTableIntegrationTest","Following similar idea as in #8600 , check for all key-value pairs in the global store before proceeding to check for join results.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","guozhangwang","2020-05-09T05:17:47Z","2020-05-12T00:04:33Z"
"","8998","MINOR; KafkaAdminClient#describeLogDirs should not fail all the futures when only one call fails","Following https://github.com/apache/kafka/pull/8985, I have found another case which incorrectly realised all futures when a failure occurs.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-07-09T07:39:54Z","2020-10-06T20:08:03Z"
"","9069","KAFKA-5876: Apply UnknownStateStoreException for Interactive Queries","follow-up #8200   KAFKA-5876's PR break into multiple parts, this PR is part 2: apply UnknownStateStoreException   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vitojeng","2020-07-24T00:03:23Z","2021-05-11T05:49:01Z"
"","9198","HOTFIX: use Exit.exit instead of System.exit","Follow up to #9067 -- seems I made an error resolving the unclean cherry-pick from `trunk` to `2.6`.  Call for review @vvcephei @ijuma","closed","","mjsax","2020-08-18T21:28:28Z","2020-08-19T00:56:03Z"
"","8631","MINOR: improve tests for TopologyTestDriver","Follow up to #8483 (in particular https://github.com/apache/kafka/pull/8483#discussion_r418808840)  Call for review @big-andy-coates @vvcephei","closed","tests,","mjsax","2020-05-08T04:57:14Z","2020-05-12T22:10:27Z"
"","8779","[MINOR] Fixing spotbug fail - removing unused variable.","Fixing nit in c6633a157eec1712116d294eb3785a96cba4e331. This commit break spotbug check with the ""Dead store to isFreshAssignment in org.apache.kafka.clients.consumer.internals.AbstractStickyAssignor.generalAssign(Map, Map)""  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","nizhikov","2020-06-02T14:12:46Z","2020-06-02T16:48:39Z"
"","8483","KAFKA-9865: Expose output topic names from TopologyTestDriver","fixes: https://issues.apache.org/jira/browse/KAFKA-9865 kip: https://cwiki.apache.org/confluence/display/KAFKA/KIP-594%3A+Expose+output+topic+names+from+TopologyTestDriver   This commit exposes the names of the topics the topology produced output to during its run.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","big-andy-coates","2020-04-14T14:48:57Z","2020-06-12T23:10:18Z"
"","9415","KAFKA-10494: eager handling of sending old values","fixes: https://issues.apache.org/jira/browse/KAFKA-10494  Nodes that are materialized should not forward requests to `enableSendingOldValues` to parent nodes, as they themselves can handle fulfilling this request. However, some instances of `KTableProcessorSupplier` were still forwarding requests to parent nodes, which was causing unnecessary materialization of table sources.  The following instances of `KTableProcessorSupplier` have been updated to not forward `enableSendingOldValues` to parent nodes if they themselves are materialized and can handle sending old values downstream:   * `KTableMapValues`  * `KTableTransformValues`  Other instances of `KTableProcessorSupplier` have not be modified for reasons given below:  * `KTableSuppressProcessorSupplier`: though it has a `storeName` field, it didn't seem right for this to handle sending old values itself. It's only job is to suppress output.  * `KTableKTableAbstractJoin`: doesn't have a store name, i.e. it is never materialized, so can't handle the call itself.  * `KTableKTableJoinMerger`: table-table joins already have materialized sources, which are sending old values. It would be an unnecessary performance hit to have this class do a lookup to retrieve the old value from its store.  * `KTableReduce`: is always materialized and already handling the call without forwarding  * `KTableAggregate`: is always materialized and already handling the call without forwarding  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","big-andy-coates","2020-10-12T19:01:11Z","2020-10-14T08:17:17Z"
"","9156","KAFKA-10077: Filter downstream of state-store results in spurious tombstones","fixes: [KAFKA-10077](https://issues.apache.org/jira/browse/KAFKA-10077).  Enable sending old values on `KTable.filter` call to avoid the filter forwarding tombstones for rows that do not exist in the output.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","big-andy-coates","2020-08-10T17:48:47Z","2020-09-28T10:24:38Z"
"","9067","MINOR: Streams integration tests should not call exit","Fixes this issue: ``` Execution failed for task ':streams:unitTest'. > Process 'Gradle Test Executor 69' finished with non-zero exit value 134 ```  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","vvcephei","2020-07-23T20:43:31Z","2020-08-18T21:37:10Z"
"","9070","MINOR: speed up release script","Fixes slow release due to establishing a  separate SSH connection per file to copy.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-07-24T02:17:17Z","2020-08-02T00:45:59Z"
"","8715","KAFKA-10033: AdminClient should throw UnknownTopicOrPartitionException instead of UnknownServerException if altering configs of non-existing topic","Fixes KAFKA-10033.  Replace AdminOperationException with UnknownTopicOrPartitionException if topic does not exist when validating topic configs in AdminZkClient.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","gnkoshelev","2020-05-22T14:29:58Z","2020-06-04T18:33:04Z"
"","8628","KAFKA-9942: Fixes ConfigCommand client quotas w/ default users.","Fixes ConfigCommand client quotas w/ default users when using --bootstrap-servers.  Test is expanded to handle all valid (user, client-id) enumerations.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","bdbyrne","2020-05-06T21:35:11Z","2020-05-10T12:54:09Z"
"","8658","KAFKA-9980: Fix bug where alterClientQuotas could not set default client quotas","Fixes an issue where the default entity name `""""` was erroneously being sanitized, which prevented proper inheritance of default configs.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","bdbyrne","2020-05-12T17:44:31Z","2022-05-11T22:10:08Z"
"","8580","KAFKA-9832: fix attempt to commit non-running tasks","Fixes an attempt to commit potentially non-running tasks while recovering from task corruption.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-04-29T02:40:49Z","2020-04-29T14:24:34Z"
"","8969","MINOR: Update introduction.html","fixed grammar  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [x] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","Wavez","2020-07-01T19:09:12Z","2020-07-01T23:51:30Z"
"","9478","Fixed unit test mocks and incorrect required context serdes.","Fixed an incorrect requireNonNull on the context Serdes introduced with #9338   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","thake","2020-10-22T12:43:22Z","2020-10-28T14:31:28Z"
"","9365","KAFKA-10566: Fix erroneous config usage warnings","Fix warn log messages caused by making HashMap copies of configs prior to using. This is not an ideal solution, but because the `Map`s are passed through `Configurable.configure(Map)` it's not possible to use another type (such as the `RecordingMap` type) directly.","closed","","tombentley","2020-10-02T16:00:23Z","2020-12-03T10:30:21Z"
"","9480","KAFKA-10592: Fix vagrant for a system tests with python3","Fix vagrant for a system tests with a python3.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","nizhikov","2020-10-22T16:28:55Z","2020-10-24T19:41:02Z"
"","8770","Update quickstart.html","Fix v2.4.x~v2.5.x console producer script doesn't supports  `--bootstrap-server` option. We should use `--broker-list` instead.  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [x] Verify design and implementation  - [x] Verify test coverage and CI build status - [x] Verify documentation (including upgrade notes)","closed","","tonytony2020","2020-06-01T07:45:30Z","2020-06-22T04:01:32Z"
"","8561","MINOR: Fix typos in test mm2 config","Fix typo in mirrormaker 2 configs: `stoage` --> `storage`","closed","","jeffwidman","2020-04-27T17:06:29Z","2020-04-30T05:04:01Z"
"","8777","KAFKA-10082: Fix the failed testMultiConsumerStickyAssignment","Fix the failed `testMultiConsumerStickyAssignment` by modifying the logic error in `allSubscriptionsEqual` method.   We will create the `consumerToOwnedPartitions` to keep the set of previously owned partitions encoded in the Subscription. It's our basis to do the reassignment. In the `allSubscriptionsEqual`, we'll get the member generation of the subscription, and remove all previously owned partitions as invalid if the current generation is higher. However, the logic before my fix, will remove the current highest member out of the `consumerToOwnedPartitions`, which should be kept because it's the current higher generation member. Fix this logic error.  BTW, it's a nice improvement in KAFKA-9987!  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-06-02T07:18:41Z","2020-06-02T16:51:19Z"
"","9202","KAFKA-10401: Fix the currentStateTimeStamp doesn't get set correctly","Fix the `currentStateTimeStamp` doesn't get set in `GROUP_METADATA_VALUE_SCHEMA_V3`, and did a small refactor to use the `GROUP_VALUE_SCHEMAS.size - 1` replace the default hard-coded max version number. Also add test for it.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-08-20T04:28:02Z","2020-09-21T20:35:17Z"
"","9075","KAFKA-10306: GlobalThread should fail on InvalidOffsetException","Fix for `2.6` blocker bug.  Call for review @guozhangwang @vvcephei (\cc @rhauch)","closed","streams,","mjsax","2020-07-24T21:37:01Z","2020-07-26T19:41:49Z"
"","8908","MINOR: fix warning of javadoc task","Fix following task warning: ``` > Task :streams:javadoc /Users/vitojeng/kafka/streams/src/main/java/org/apache/kafka/streams/kstream/CogroupedKStream.java:187: warning - invalid usage of tag < /Users/vitojeng/kafka/streams/src/main/java/org/apache/kafka/streams/kstream/CogroupedKStream.java:187: warning - invalid usage of tag > /Users/vitojeng/kafka/streams/src/main/java/org/apache/kafka/streams/kstream/CogroupedKStream.java:187: warning - invalid usage of tag < /Users/vitojeng/kafka/streams/src/main/java/org/apache/kafka/streams/kstream/CogroupedKStream.java:187: warning - invalid usage of tag > /Users/vitojeng/kafka/streams/src/main/java/org/apache/kafka/streams/kstream/CogroupedKStream.java:239: warning - invalid usage of tag < /Users/vitojeng/kafka/streams/src/main/java/org/apache/kafka/streams/kstream/CogroupedKStream.java:239: warning - invalid usage of tag > /Users/vitojeng/kafka/streams/src/main/java/org/apache/kafka/streams/kstream/CogroupedKStream.java:239: warning - invalid usage of tag < /Users/vitojeng/kafka/streams/src/main/java/org/apache/kafka/streams/kstream/CogroupedKStream.java:239: warning - invalid usage of tag > /Users/vitojeng/kafka/streams/src/main/java/org/apache/kafka/streams/LagInfo.java:43: warning - invalid usage of tag & 9 warnings ```  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vitojeng","2020-06-20T10:37:45Z","2020-07-24T01:09:19Z"
"","9426","MINOR: Fix flaky shouldRejectNonExistentStoreName","Fix flaky test by making sure Streams is running before making assertions about IQ.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-10-13T18:21:53Z","2020-10-29T17:24:03Z"
"","8929","KAFKA-4996: Fix findbugs multithreaded correctness warnings for streams","Fix findbugs multithreaded correctness warnings for streams, updated variables to be threadsafe  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","lct45","2020-06-25T18:30:20Z","2020-06-30T20:13:18Z"
"","8571","KAFKA-7613: Enable -Xlint:rawtypes for connect, fixing warnings","Fix all existing javac warnings about use of raw types in Kafka Connect add -Xlint:rawtypes to the connect the javac options in build.gradle. This addresses part of KAFKA-7613, but further work will be needed for the other warnings.","closed","connect,","tombentley","2020-04-28T09:39:19Z","2021-07-07T16:25:37Z"
"","9428","MINOR: fix a bug in removing elements from an ImplicitLinkedHashColle…","Fix a bug that was introduced by change 86013dc9f8cf02813418f41c3c49c745f9ee6ea5 that resulted in incorrect behavior when deleting through an iterator.  The bug is that the hash table relies on a denseness invariant... if you remove something, you might have to move some other things.  Calling removeElementAtSlot will do this.  Calling removeFromList is not enough.","closed","","cmccabe","2020-10-13T21:48:15Z","2020-10-14T21:54:46Z"
"","9237","KAFKA-10454 / Update copartitionSourceGroups when optimization algorithm is triggered","Fix [KAFKA-10454](https://issues.apache.org/jira/browse/KAFKA-10454) bug  Main issue was that when optimization algorithm was removing repartition nodes, corresponding `copartitionSourceGroups` was never updated. As a result, copartition enforcer wasn't able to do the checks and set proper number of partitions.  Test ensures that whenever optimization is set, changelog topic for the table is not created. And whenever optimization is turned off, appropriate changelog topic for the table is created.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","lkokhreidze","2020-09-01T09:37:59Z","2020-10-21T06:53:24Z"
"","9092","KAFKA-10163; Define `controller_mutation_rate` as a Double instead of a Long","First tests have shown that `controller_mutation_rate` can be quite low (e.g. around 1) in clusters with multiple tenants. At the moment, the rate is defined as a Long which limits the possible low values. Using a Double seems more appropriate.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-07-28T11:31:09Z","2020-08-03T10:16:05Z"
"","8864","KAFKA-9274: Mark `retries` config as deprecated and add new `task.timeout.ms` config","First PR for KIP-572 for public changes only. Producer/Admin client won't have any functional change as they still will respect `retries`. For KS, we will get rid or the usage or `retries` in follow up PRs.  Call for review: @cmccabe @hachikuji @abbccdda @vvcephei","closed","kip,","mjsax","2020-06-13T00:06:43Z","2020-09-24T00:48:05Z"
"","8765","KAFKA-10073: endTxn wait until markers compelete","First change of KAFKA-9878: endTxn wait until markers compelete  change details can be found in: https://issues.apache.org/jira/browse/KAFKA-9878","open","","zhaohaidao","2020-05-31T15:07:08Z","2020-05-31T16:33:03Z"
"","9256","Fix some Gradle deprecation warnings","Find the guide for upgrading here: https://docs.gradle.org/6.6/userguide/upgrading_version_5.html#changes_6.0  Changes made in this PR: - Use `java-library` instead of `java` plugin (to have access to the `api` configuration) - Use `api` instead of `compile` - Use `testImplementation` instead of `testCompile` - Use `testRuntimeOnly` instead of `testRuntime`  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","jonhkr","2020-09-05T20:56:17Z","2020-09-09T19:05:30Z"
"","8800","MINOR: Fix incorrect GC log size with JDK9+","file size was incorrectly set to 100KB instead of 100MB","closed","","xvrl","2020-06-04T18:38:38Z","2020-06-09T09:23:41Z"
"","8586","KAFKA-9939; Fix overcounting delayed fetches in request rate metrics","Fetches which hit purgatory are currently counted twice in fetch request rate metrics. This patch moves the metric update into `fetchMessages` so that they are only counted once.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-04-29T20:15:00Z","2020-05-01T22:29:50Z"
"","9340","Improving Fetch Session Caching for KAFKA-10558","Fetch session cache performance is currently a blocker for increasing cache size.  [Edit 9/28] With commit f528df6, now following the original cache eviction logic. The following benchmark data for sessions_lastUsed has been updated to reflect this change.   ## Summary of changes  #### @lbradstreet - JMH benchmark to log performance improvements - making `EvictableKey`'s `compareTo` method faster - restructuring of `tryEvict` [Edit 9/28 - partially reverted]  - ~~restructuring of `touch`~~ [Edit 9/28 - reverted]     - ~~`evictableBy` treemaps changed to store unprivileged and privileged sessions respectively~~  #### ahuang98  - `sessions` turned into LinkedHashMap (from mutable.HashMap) to absorb function of `lastUsed`     - entries in `sessions` are now ordered by the time the session was last touched  -  ~~`evictableBy` treemaps renamed to `unprivilegedSessions` and `privilegedSesions`~~ [Edit 9/28 - reverted]  - [Edit 9/28] `evictableByAll` updated to store only unprivileged sessions that have been touched > `evictionMs` after their creation     - previously stored privileged sessions that had been touched > `evictionMs` after their creation as well, which was unnecessary as `evictEntry` was only ever called on `evictableByAll` if the new session was unprivileged (and unprivileged can never evict unstale privileged sessions)  ## Testing  - Unit test     - ~~assertion in `testSessionCache` currently commented out due to misunderstanding of cache eviction behavior~~ [Edit 9/28 - reverted]     - [Edit 9/28] new test added called `testSessionCacheEvictionRules`, which continues where `testSessionCache` left off, testing more combinations of [privileged, unprivileged], [smaller, larger], [stale, unstale] sessions trying to evict each other  - JMH benchmark     - [Edit 9/28] after reverting back to original cache eviction logic (and updating benchmark to include the case when fetch session size stays the same and when fetch session size increases), the benchmark was rerun on an aws ec2 instance with 5 warmup and 5 measurement iterations. It shows that the performance of the optimized code with cache size 5000 is better than performance of trunk with cache size 1000. The table below highlights a portion of the results (cache size 2000 removed for brevity).   | benchPrivileged | cacheSize | cacheUtilization | fetchSessionAddedPartitions | newSession | numEvictableEntries | percentPrivileged | Mode | Cnt | sessions_lastUsed Score | sessions_lastUsed Error | trunk Score | trunk Error | Units | |---|---|---|---|---|---|---|---|---|---|---|---|---|---| | FALSE | 1000 | 99 | FALSE | FALSE | 0 | 10 | avgt | 5 | 2684.031 | 310.096 | 4436.728 | 91.48 | ns/op | | FALSE | 1000 | 99 | FALSE | FALSE | 1 | 10 | avgt | 5 | 2611.156 | 261.744 | 4364.698 | 459.283 | ns/op | | FALSE | 1000 | 99 | FALSE | FALSE | 10 | 10 | avgt | 5 | 2592.409 | 226.455 | 4342.929 | 11.88 | ns/op | | FALSE | 1000 | 99 | FALSE | TRUE | 0 | 10 | avgt | 5 | 1135.636 | 226.186 | 2338.599 | 51.281 | ns/op | | FALSE | 1000 | 99 | FALSE | TRUE | 1 | 10 | avgt | 5 | 1090.842 | 187.019 | 2244.938 | 16.262 | ns/op | | FALSE | 1000 | 99 | FALSE | TRUE | 10 | 10 | avgt | 5 | 1205.874 | 163.137 | 2366.496 | 49.18 | ns/op | | FALSE | 1000 | 99 | TRUE | FALSE | 0 | 10 | avgt | 5 | 2914.277 | 291.322 | 4636.73 | 85.494 | ns/op | | FALSE | 1000 | 99 | TRUE | FALSE | 1 | 10 | avgt | 5 | 2795.851 | 320.944 | 4739.525 | 60.319 | ns/op | | FALSE | 1000 | 99 | TRUE | FALSE | 10 | 10 | avgt | 5 | 2758.375 | 395.131 | 4565.73 | 123.265 | ns/op | | FALSE | 1000 | 99 | TRUE | TRUE | 0 | 10 | avgt | 5 | 1138.057 | 215.631 | 2481.799 | 42.688 | ns/op | | FALSE | 1000 | 99 | TRUE | TRUE | 1 | 10 | avgt | 5 | 1153.209 | 160.686 | 2361.695 | 223.737 | ns/op | | FALSE | 1000 | 99 | TRUE | TRUE | 10 | 10 | avgt | 5 | 1167.731 | 156.937 | 2462.849 | 311.975 | ns/op | | FALSE | 1000 | 100 | FALSE | FALSE | 0 | 10 | avgt | 5 | 2536.62 | 253.821 | 4429.647 | 129.688 | ns/op | | FALSE | 1000 | 100 | FALSE | FALSE | 1 | 10 | avgt | 5 | 2552.363 | 290.637 | 4403.863 | 94.2 | ns/op | | FALSE | 1000 | 100 | FALSE | FALSE | 10 | 10 | avgt | 5 | 2719.227 | 226.613 | 4490.728 | 451.676 | ns/op | | FALSE | 1000 | 100 | FALSE | TRUE | 0 | 10 | avgt | 5 | 2020.613 | 237.905 | 4063.931 | 2124.466 | ns/op | | FALSE | 1000 | 100 | FALSE | TRUE | 1 | 10 | avgt | 5 | 1887.49 | 277.308 | 3644.97 | 39.779 | ns/op | | FALSE | 1000 | 100 | FALSE | TRUE | 10 | 10 | avgt | 5 | 1924.926 | 162.053 | 3794.089 | 65.17 | ns/op | | FALSE | 1000 | 100 | TRUE | FALSE | 0 | 10 | avgt | 5 | 2854.754 | 254.033 | 4715.486 | 351.3 | ns/op | | FALSE | 1000 | 100 | TRUE | FALSE | 1 | 10 | avgt | 5 | 2836.238 | 87.322 | 4562.898 | 366.507 | ns/op | | FALSE | 1000 | 100 | TRUE | FALSE | 10 | 10 | avgt | 5 | 2896.398 | 179.845 | 4636.409 | 74.467 | ns/op | | FALSE | 1000 | 100 | TRUE | TRUE | 0 | 10 | avgt | 5 | 1965.438 | 174.204 | 3683.458 | 54.7 | ns/op | | FALSE | 1000 | 100 | TRUE | TRUE | 1 | 10 | avgt | 5 | 2006.538 | 138.899 | 3575.06 | 292.394 | ns/op | | FALSE | 1000 | 100 | TRUE | TRUE | 10 | 10 | avgt | 5 | 1973.776 | 150.744 | 3680.105 | 311.529 | ns/op | | FALSE | 5000 | 99 | FALSE | FALSE | 0 | 10 | avgt | 5 | 3814.783 | 308.839 | 7263.359 | 3569.287 | ns/op | | FALSE | 5000 | 99 | FALSE | FALSE | 1 | 10 | avgt | 5 | 4032 | 327.804 | 6755.35 | 4460.69 | ns/op | | FALSE | 5000 | 99 | FALSE | FALSE | 10 | 10 | avgt | 5 | 3943.826 | 303.445 | 6834.419 | 4304.774 | ns/op | | FALSE | 5000 | 99 | FALSE | TRUE | 0 | 10 | avgt | 5 | 1741.143 | 25.107 | 3277.982 | 370.198 | ns/op | | FALSE | 5000 | 99 | FALSE | TRUE | 1 | 10 | avgt | 5 | 1811.051 | 19.183 | 3075.932 | 355.452 | ns/op | | FALSE | 5000 | 99 | FALSE | TRUE | 10 | 10 | avgt | 5 | 1755.726 | 62.321 | 3202.241 | 447.799 | ns/op | | FALSE | 5000 | 99 | TRUE | FALSE | 0 | 10 | avgt | 5 | 4277.164 | 400.039 | 7695.309 | 4712.432 | ns/op | | FALSE | 5000 | 99 | TRUE | FALSE | 1 | 10 | avgt | 5 | 4495.467 | 149.012 | 7157.815 | 5084.501 | ns/op | | FALSE | 5000 | 99 | TRUE | FALSE | 10 | 10 | avgt | 5 | 4328.287 | 258.009 | 7284.502 | 4784.208 | ns/op | | FALSE | 5000 | 99 | TRUE | TRUE | 0 | 10 | avgt | 5 | 1827.201 | 33.735 | 3252.389 | 331.854 | ns/op | | FALSE | 5000 | 99 | TRUE | TRUE | 1 | 10 | avgt | 5 | 1812.893 | 96.06 | 3285.954 | 528.586 | ns/op | | FALSE | 5000 | 99 | TRUE | TRUE | 10 | 10 | avgt | 5 | 1846.243 | 36.486 | 3205.397 | 699.758 | ns/op | | FALSE | 5000 | 100 | FALSE | FALSE | 0 | 10 | avgt | 5 | 4030.801 | 302.56 | 7420.729 | 4290.428 | ns/op | | FALSE | 5000 | 100 | FALSE | FALSE | 1 | 10 | avgt | 5 | 4012.937 | 532.884 | 6674.48 | 4269.636 | ns/op | | FALSE | 5000 | 100 | FALSE | FALSE | 10 | 10 | avgt | 5 | 3950.678 | 361.499 | 6705.533 | 4174.262 | ns/op | | FALSE | 5000 | 100 | FALSE | TRUE | 0 | 10 | avgt | 5 | 2963.612 | 356.913 | 5272.88 | 2960.224 | ns/op | | FALSE | 5000 | 100 | FALSE | TRUE | 1 | 10 | avgt | 5 | 2950.102 | 365.079 | 5305.482 | 3082.805 | ns/op | | FALSE | 5000 | 100 | FALSE | TRUE | 10 | 10 | avgt | 5 | 2988.179 | 482.812 | 5298.415 | 2916.132 | ns/op | | FALSE | 5000 | 100 | TRUE | FALSE | 0 | 10 | avgt | 5 | 4449.98 | 288.919 | 7265.341 | 4296.304 | ns/op | | FALSE | 5000 | 100 | TRUE | FALSE | 1 | 10 | avgt | 5 | 4310.16 | 280.63 | 7131.075 | 4212.237 | ns/op | | FALSE | 5000 | 100 | TRUE | FALSE | 10 | 10 | avgt | 5 | 4493.523 | 335.859 | 6915.28 | 3832.782 | ns/op | | FALSE | 5000 | 100 | TRUE | TRUE | 0 | 10 | avgt | 5 | 3111.5 | 324.112 | 6333.948 | 4655.366 | ns/op | | FALSE | 5000 | 100 | TRUE | TRUE | 1 | 10 | avgt | 5 | 2851.528 | 387.506 | 5346.191 | 2603.39 | ns/op | | FALSE | 5000 | 100 | TRUE | TRUE | 10 | 10 | avgt | 5 | 2919.653 | 576.149 | 5214.732 | 3531.086 | ns/op | | TRUE | 1000 | 99 | FALSE | FALSE | 0 | 10 | avgt | 5 | 2312.858 | 308.792 | 4346.396 | 128.141 | ns/op | | TRUE | 1000 | 99 | FALSE | FALSE | 1 | 10 | avgt | 5 | 2328.731 | 235.691 | 4336.846 | 111.44 | ns/op | | TRUE | 1000 | 99 | FALSE | FALSE | 10 | 10 | avgt | 5 | 2193.93 | 223.112 | 4281.69 | 70.832 | ns/op | | TRUE | 1000 | 99 | FALSE | TRUE | 0 | 10 | avgt | 5 | 985.672 | 202.489 | 2069.452 | 21.386 | ns/op | | TRUE | 1000 | 99 | FALSE | TRUE | 1 | 10 | avgt | 5 | 951.886 | 229.803 | 1897.69 | 25.66 | ns/op | | TRUE | 1000 | 99 | FALSE | TRUE | 10 | 10 | avgt | 5 | 1004.162 | 180.472 | 2041.772 | 988.194 | ns/op | | TRUE | 1000 | 99 | TRUE | FALSE | 0 | 10 | avgt | 5 | 2454.62 | 312.529 | 4638.253 | 1152.913 | ns/op | | TRUE | 1000 | 99 | TRUE | FALSE | 1 | 10 | avgt | 5 | 2418.724 | 283.855 | 4497.284 | 120.397 | ns/op | | TRUE | 1000 | 99 | TRUE | FALSE | 10 | 10 | avgt | 5 | 2488.191 | 255.307 | 4613.689 | 87.091 | ns/op | | TRUE | 1000 | 99 | TRUE | TRUE | 0 | 10 | avgt | 5 | 1007.288 | 216.32 | 1953.663 | 29.537 | ns/op | | TRUE | 1000 | 99 | TRUE | TRUE | 1 | 10 | avgt | 5 | 1048.985 | 103.433 | 2046.502 | 27.578 | ns/op | | TRUE | 1000 | 99 | TRUE | TRUE | 10 | 10 | avgt | 5 | 1015.368 | 222.078 | 2069.779 | 73.225 | ns/op | | TRUE | 1000 | 100 | FALSE | FALSE | 0 | 10 | avgt | 5 | 2446.628 | 465.894 | 4290.631 | 106.343 | ns/op | | TRUE | 1000 | 100 | FALSE | FALSE | 1 | 10 | avgt | 5 | 2368.934 | 191.767 | 4408.351 | 400.138 | ns/op | | TRUE | 1000 | 100 | FALSE | FALSE | 10 | 10 | avgt | 5 | 2187.27 | 266.959 | 4337.202 | 1056.462 | ns/op | | TRUE | 1000 | 100 | FALSE | TRUE | 0 | 10 | avgt | 5 | 1808.21 | 185.681 | 3314.848 | 46.05 | ns/op | | TRUE | 1000 | 100 | FALSE | TRUE | 1 | 10 | avgt | 5 | 1760.174 | 328.793 | 3567.172 | 324.826 | ns/op | | TRUE | 1000 | 100 | FALSE | TRUE | 10 | 10 | avgt | 5 | 1813.038 | 179.371 | 3693.324 | 1729.497 | ns/op | | TRUE | 1000 | 100 | TRUE | FALSE | 0 | 10 | avgt | 5 | 2589.964 | 302.064 | 4481.754 | 116.27 | ns/op | | TRUE | 1000 | 100 | TRUE | FALSE | 1 | 10 | avgt | 5 | 2494.971 | 132.901 | 4646.743 | 360.485 | ns/op | | TRUE | 1000 | 100 | TRUE | FALSE | 10 | 10 | avgt | 5 | 2436.427 | 213.211 | 4619.616 | 60.566 | ns/op | | TRUE | 1000 | 100 | TRUE | TRUE | 0 | 10 | avgt | 5 | 1805.541 | 304.33 | 3410.814 | 46.948 | ns/op | | TRUE | 1000 | 100 | TRUE | TRUE | 1 | 10 | avgt | 5 | 1789.231 | 189.852 | 3719.754 | 1531.788 | ns/op | | TRUE | 1000 | 100 | TRUE | TRUE | 10 | 10 | avgt | 5 | 1820.644 | 374.211 | 3678.374 | 2205.007 | ns/op | | TRUE | 5000 | 99 | FALSE | FALSE | 0 | 10 | avgt | 5 | 3632.39 | 71.731 | 7780.043 | 4472.378 | ns/op | | TRUE | 5000 | 99 | FALSE | FALSE | 1 | 10 | avgt | 5 | 3453.896 | 83.615 | 8024.723 | 3659.888 | ns/op | | TRUE | 5000 | 99 | FALSE | FALSE | 10 | 10 | avgt | 5 | 3599.063 | 121.679 | 8023.747 | 7665.474 | ns/op | | TRUE | 5000 | 99 | FALSE | TRUE | 0 | 10 | avgt | 5 | 1452.063 | 12.308 | 2834.844 | 313.411 | ns/op | | TRUE | 5000 | 99 | FALSE | TRUE | 1 | 10 | avgt | 5 | 1414.658 | 53.679 | 2704.824 | 867.343 | ns/op | | TRUE | 5000 | 99 | FALSE | TRUE | 10 | 10 | avgt | 5 | 1398.966 | 35.347 | 2415.716 | 319.988 | ns/op | | TRUE | 5000 | 99 | TRUE | FALSE | 0 | 10 | avgt | 5 | 3764.004 | 111.786 | 7171.521 | 4100.908 | ns/op | | TRUE | 5000 | 99 | TRUE | FALSE | 1 | 10 | avgt | 5 | 4008.96 | 1740.722 | 7149.942 | 3353.829 | ns/op | | TRUE | 5000 | 99 | TRUE | FALSE | 10 | 10 | avgt | 5 | 4154.255 | 62.851 | 7300.532 | 4600.59 | ns/op | | TRUE | 5000 | 99 | TRUE | TRUE | 0 | 10 | avgt | 5 | 1473.955 | 61.37 | 2647.384 | 332.358 | ns/op | | TRUE | 5000 | 99 | TRUE | TRUE | 1 | 10 | avgt | 5 | 1553.625 | 53.221 | 2499.667 | 300.683 | ns/op | | TRUE | 5000 | 99 | TRUE | TRUE | 10 | 10 | avgt | 5 | 1543.222 | 76.352 | 2460.593 | 235.534 | ns/op | | TRUE | 5000 | 100 | FALSE | FALSE | 0 | 10 | avgt | 5 | 3754.874 | 119.507 | 6970.279 | 4022.109 | ns/op | | TRUE | 5000 | 100 | FALSE | FALSE | 1 | 10 | avgt | 5 | 3647.742 | 304.06 | 6940.627 | 3860.939 | ns/op | | TRUE | 5000 | 100 | FALSE | FALSE | 10 | 10 | avgt | 5 | 3439.3 | 129.355 | 6828.86 | 4131.018 | ns/op | | TRUE | 5000 | 100 | FALSE | TRUE | 0 | 10 | avgt | 5 | 2696.908 | 430.534 | 4997.008 | 3003.618 | ns/op | | TRUE | 5000 | 100 | FALSE | TRUE | 1 | 10 | avgt | 5 | 2771.329 | 473.938 | 5318.634 | 4470.219 | ns/op | | TRUE | 5000 | 100 | FALSE | TRUE | 10 | 10 | avgt | 5 | 2705.752 | 470.954 | 5613.541 | 4797.361 | ns/op | | TRUE | 5000 | 100 | TRUE | FALSE | 0 | 10 | avgt | 5 | 3822.819 | 193.345 | 7438.494 | 3789.759 | ns/op | | TRUE | 5000 | 100 | TRUE | FALSE | 1 | 10 | avgt | 5 | 3746.639 | 49.862 | 7971.087 | 5128.819 | ns/op | | TRUE | 5000 | 100 | TRUE | FALSE | 10 | 10 | avgt | 5 | 3748.738 | 71.739 | 7821.017 | 4253.262 | ns/op | | TRUE | 5000 | 100 | TRUE | TRUE | 0 | 10 | avgt | 5 | 2788.768 | 406.061 | 4998.906 | 3045.562 | ns/op | | TRUE | 5000 | 100 | TRUE | TRUE | 1 | 10 | avgt | 5 | 2588.279 | 419.307 | 4868.152 | 2795.423 | ns/op | | TRUE | 5000 | 100 | TRUE | TRUE | 10 | 10 | avgt | 5 | 2548.178 | 305.607 | 5582.232 | 6591.964 | ns/op |  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ahuang98","2020-09-26T01:37:21Z","2022-04-01T09:28:54Z"
"","9422","KAFKA-10602: Make RetryWithToleranceOperator thread safe","ErrantRecordReporter uses a RetryWithToleranceOperator instance, which is necessarily stateful, having a ProcessingContext of which there's supposed to be one per task. That ProcessingContext is used by both RetryWithToleranceOperator.executeFailed() and execute(), so it's not enough to just synchronize executeFailed().  So make all public methods of RetryWithToleranceOperator synchronized so that RetryWithToleranceOperator is now threadsafe.","closed","connect,","tombentley","2020-10-13T09:27:29Z","2020-10-15T18:54:46Z"
"","8799","KAFKA-8011: Fix flaky RegexSourceIntegrationTest","Ensure that tests cleanup after themselves and use different app.id per test run.  Call for review @guozhangwang @ableegoldman","closed","","mjsax","2020-06-04T01:33:07Z","2020-06-05T21:38:13Z"
"","8673","KAFKA-9992: EmbeddedKafkaCluster.deleteTopicAndWait not working with kafka_2.13","Eliminating JavaConverters in EmbeddedKafkaCluster  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","akatona84","2020-05-15T11:56:01Z","2020-05-20T06:35:22Z"
"","9274","KAFKA-10131: Remove use_zk_connection flag","Eliminate ""use_zk_connection"" and similarly-named flags in public system test methods.  System tests should always use admin client when the broker supports it.  We do need to bootstrap ACLs prior to Kafka starting or prior to enabling the authorizer, so the ability to force the use of a direct ZooKeeper connection rather than the admin client still exists for this case.  This PR also converts a few methods in kafka.py that were connecting directly to ZooKeeper for leader and replica/ISR lists to use the admin client when the broker version supports it.  It also adds support for using the admin client when performing ""kafka-topics.sh ... -if-not-exists"" which was added via KIP-604 in v2.6.","closed","","rondagostino","2020-09-09T20:40:21Z","2020-09-14T22:56:22Z"
"","8914","MINOR: Do not swallow exception when collecting PIDs","During Streams' system tests the PIDs of the Streams clients are collected. The method the collects the PIDs swallows any exception that might be thrown by the `ssh_capture()` function. Swallowing any exceptions might make the investigation of failures harder, because no information about what happened are recorded.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","cadonna","2020-06-23T11:08:11Z","2020-07-29T08:03:14Z"
"","8601","Remove unit","duplicate of https://github.com/apache/kafka/pull/8527 to get jenkins run","closed","","cmccabe","2020-05-01T23:33:04Z","2020-05-01T23:33:32Z"
"","9192","MINOR: Use new version of ducktape","ducktape diff: https://github.com/confluentinc/ducktape/compare/v0.7.8...v0.7.9  - bcrypt (a dependency of ducktape) dropped Python2.7 support. ducktape-0.7.9 now pins bcrypt to a Python2.7-supported version.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","andrewegel","2020-08-17T19:37:33Z","2020-08-18T02:06:32Z"
"","9402","KAFKA-10588 update console consumer arguments for KIP-629","draft PR, more changes needed in order to ensure backwards compatibility","closed","","xvrl","2020-10-09T06:13:13Z","2022-02-04T20:25:26Z"
"","9360","KAFKA-10557: Missing docs when describing topic configs including","documentation  Added unit test  Co-authored-by: Edoardo Comar  Co-authored-by: Mickael Maison   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","edoardocomar","2020-10-01T11:26:25Z","2020-10-02T09:11:27Z"
"","9444","KAFKA-8305: Doc Fix default.replication.factor","Doc fix for KAFKA-8305; mention its alternate use.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","garyrussell","2020-10-15T17:52:03Z","2020-10-15T17:52:03Z"
"","8719","[WIP] MINOR: Improve failure message in Kafka cluster used in Connect integration tests (pre Gradle memory change)","DO NOT MERGE  Debugging build failures  See #8718","closed","","rhauch","2020-05-22T18:31:08Z","2020-05-23T14:03:01Z"
"","8718","[WIP] MINOR: Improve failure message in Kafka cluster used in Connect integration tests","DO NOT MERGE  Debugging build failures","closed","","rhauch","2020-05-22T18:28:25Z","2020-05-23T14:02:55Z"
"","9431","KAFKA-10426: Deadlock on session key update.","DistributedHerder goes to updateConfigsWithIncrementalCooperative() synchronized method and called configBackingStore.snapshot() which take a lock on internal object in KafkaConfigBackingStore class.  Meanwhile KafkaConfigBackingStore in ConsumeCallback inside synchronized block on internal object gets SESSION_KEY record and calls updateListener.onSessionKeyUpdate() which take a lock on DistributedHerder.  So, we have a Deadlock.  To avoid this, updateListener with new session key should be called outside synchronized block as it's done, for example, for updateListener.onTaskConfigUpdate(updatedTasks).  This PR is a copy of: https://github.com/apache/kafka/pull/9211  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","xakassi","2020-10-14T07:56:23Z","2020-10-22T05:56:54Z"
"","9211","KAFKA-10426: Deadlock on session key update.","DistributedHerder goes to updateConfigsWithIncrementalCooperative() synchronized method and called configBackingStore.snapshot() which take a lock on internal object in KafkaConfigBackingStore class.  Meanwhile KafkaConfigBackingStore in ConsumeCallback inside synchronized block on internal object gets SESSION_KEY record and calls updateListener.onSessionKeyUpdate() which take a lock on DistributedHerder.  So, we have a Deadlock.  To avoid this, updateListener with new session key should be called outside synchronized block as it's done, for example, for updateListener.onTaskConfigUpdate(updatedTasks).   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","xakassi","2020-08-24T13:59:46Z","2020-10-14T07:59:53Z"
"","9023","KAFKA-10272: Add IBM i support to ""stop"" scripts","Details are documented in jira issue [KAFKA-10272](https://issues.apache.org/jira/projects/KAFKA/issues/KAFKA-10272).  Turns out a similar issue was fixed for IBM z/OS earlier this year, as part of PR #7913.  ### Committer Checklist (excluded from commit message) - [x] Verify design and implementation  - [x] ~~Verify test coverage and CI build status~~  N/A - [x] ~~Verify documentation (including upgrade notes)~~ N/A","closed","","ThePrez","2020-07-14T21:10:04Z","2020-09-02T15:46:25Z"
"","9139","KAFKA-9929: Support backward iterator on SessionStore","Depends on https://github.com/apache/kafka/pull/9138  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jeqo","2020-08-07T16:24:09Z","2021-10-19T14:21:21Z"
"","9138","KAFKA-9929: Support backward iterator on WindowStore","Depends on https://github.com/apache/kafka/pull/9137  Implements [KIP-617](https://cwiki.apache.org/confluence/display/KAFKA/KIP-617%3A+Allow+Kafka+Streams+State+Stores+to+be+iterated+backwards) on `WindowStore`.  Testing strategy: extend existing tests to validate reverse operations are supported.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jeqo","2020-08-07T16:22:27Z","2020-09-03T08:43:30Z"
"","9404","KAFKA-10589 replica verification tool changes for KIP-629","depends on #9400, ignore first commit still needs backwards compatibility changes","closed","","xvrl","2020-10-09T06:41:17Z","2021-07-08T23:38:45Z"
"","9403","KAFKA-10573 Update connect transforms configs for KIP-629","depends on #9367 (KAFKA-10570) - ignore the first commit until the other PR is merged  cc @rhauch for review","closed","connect,","xvrl","2020-10-09T06:28:47Z","2020-10-16T06:15:47Z"
"","8821","[DO NOT MERGE] Reenable flaky EosBetaUpgradeIntegrationTest","Debugging for KAFKA-10017","closed","","ableegoldman","2020-06-06T01:59:28Z","2020-06-26T22:39:55Z"
"","9054","KAFKA-10282: Remove Log metrics immediately when deleting log","Currently, we remove the Log metrics when asynchronous deletion of the log is triggered. However, we attempt to register the metrics immediately upon log creation. If a Log object is re-created for a partition that is pending deletion (because a topic was quickly re-created or because a partition was moved off and back onto a broker), the registration of the new metrics can happen before the asyncrhonous deletion. In this case, the metrics are removed after the second registration, leading to missing Log metrics.  To fix this, this patch changes the log deletion behavior to remove the metrics when the log is first marked for deletion, rather than when the files are deleted. This removes the window in which metrics registration can occur before metrics removal. This is justifiable because the log should be logically deleted when a delete request or partition movement finishes, rather than when the files are actually removed. Tested with unit tests.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","bob-barrett","2020-07-22T16:47:19Z","2020-07-31T02:40:26Z"
"","9384","MINOR: remove explicit passing of AdminClient into StreamsPartitionAssignor","Currently, we pass multiple object reference (`AdminClient`,`TaskManager`, and `Time`) into `StreamsPartitionAssignor`. Furthermore, we (miss)use `TaskManager#mainConsumer()` to get access to the main consumer (we need to do this, to avoid a cyclic dependency).  This PR unifies how object references are passed into a single `ReferenceContainer` class to  - not ""miss use"" the TaskManager as reference container  - unify how object references are passes  Note: we need to use a reference container to avoid cyclic dependencies, instead of using a config for each passed reference individually.","closed","streams,","mjsax","2020-10-06T20:23:11Z","2020-10-15T23:10:33Z"
"","9214","[DO NOT MERGE] POC: unify all jvm cache pools","Currently, users of Suppress in strict mode must either not configure a memory bound or consider a per-operator, per-partition bound. The former would result in the application crashing ungracefully if it needs too much memory, which is sub-optimal for some deployment strategies. The latter is nice for determinism, but is difficult to configure in practice.  In addition to suppress buffers, Streams has a record cache configuration. Currently, we make the assumption that all threads would probably use a uniform amount of cache space, but this assumption is clearly wrong in some cases.  Finally, there are some applications that want to run multiple Streams instances in the same JVM, probably for running different Streams topologies.  In aggregate, there are quite a few ""pools"" of heap space that users need to configure if they want to avoid an OOME, and the more threads, applications, and Suppress operators there are, the more granular these pools become. Of course, the more granular the pools are, the lower utilization of the available memory we will see. Plus, especially for Suppression, very granular pool configuration means a higher likelihood that the operator will run out of space and shut the app down.  This POC demonstrates the feasibility of unifying all these pools with one logical bound on total memory usage for all caches and suppression buffers, across all operators/tasks and all threads, and even across all Streams instances in the JVM.  Most of the tests pass right now, but not all of them. I also need to clean up a few more things before really starting a discussion.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","streams,","vvcephei","2020-08-24T19:41:29Z","2020-08-24T19:41:38Z"
"","8505","MINOR: Switch order of sections on tumbling and hopping windows in streams doc","Currently, tumbling windows are defined as ""a special case of hopping time windows"" in the streams docs, but hopping windows are only explained in a subsequent section. I think it would make sense to switch the order of these paragraphs around. To me this also makes more sense semantically.  Testing Built the site and checked that everything looks ok and html is valid (or at least didn't contain any new warnings that were caused by this change).  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","docs,","soenkeliebau","2020-04-17T09:02:29Z","2020-04-17T17:57:57Z"
"","9261","MINOR: Update source link in interactive query page","Currently, the source reference are all pointing to the 1.0 version codes, which is obviously wrong. Update to the current `dotVersion`. (ref: https://github.com/apache/kafka/blob/trunk/docs/streams/developer-guide/datatypes.html#L173)  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","showuon","2020-09-08T06:35:31Z","2020-09-14T15:11:04Z"
"","8829","KAFKA-10115: Incorporate errors.tolerance with the Errant Record Reporter","Currently, the errant record reporter doesn't take into account the value of `errors.tolerance.` Added a check if the reporter is within the tolerance limits; if not, then a `ConnectException` is thrown. This is essentially what is done across other parts of the `RetryAndToleranceOperator`.","closed","connect,","aakashnshah","2020-06-07T22:57:58Z","2020-06-11T05:38:00Z"
"","9078","KAFKA-10132: Return correct value types for MBean attributes","Currently, JMX outputs all metrics as having type `double`, even if they are strings or other types of numbers. This PR gets the type from the metric's value if possible, using `double` as a fallback if the type can't be determined.","open","","rgroothuijsen","2020-07-25T13:17:37Z","2021-02-07T17:05:48Z"
"","9262","MINOR: Fix log message when tasks directory is cleaned manually","Currently when a task directory is cleaned manually the message for the state dir cleaner is logged instead of the message for the manual cleanup. This is because the code checks the elapsed time since the last update before it checks whether the cleanup is a manual call. This commit changes the order of the checks.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","cadonna","2020-09-08T10:10:50Z","2020-10-05T20:23:13Z"
"","8625","MINOR: Only add 'Data' suffix for generated request/response/header types","Currently we add ""Data"" to all generated classnames in order to avoid naming collisions with existing Request/Response objects. Generated classes for other persistent schema definitions (such as those used in `GroupCoordinator` and `TransactionCoordinator`) will not necessarily have the same problem, so it would be nice if the generated types could use the name defined in the schema directly.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-05-06T19:09:24Z","2020-05-06T22:30:14Z"
"","9143","MINOR: Fix the way total consumed is calculated for verifiable consumer","Currently the way we calculate the number of total consumed messages for the verifiable consumer overcounts the number of actually consumed messages. This PR is to fix that to ensure we count the number of consumed messages correctly.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","skaundinya15","2020-08-07T19:30:44Z","2020-08-17T05:26:39Z"
"","9313","[mm2] Fix consumer/producer properties override","Currently the producer/consumer properties override for the MirrorSourceTask and OffsetSyncStore do not work. This is due the props stored into MirrorConnectorConfig have a `target.cluster` or `source.cluster` prefix. For example: ``` source.cluster.producer.bootstrap.servers -> localhost:9092 target.cluster.consumer.max.poll.interval.ms -> 120000 target.cluster.consumer.auto.offset.reset -> latest source.cluster.admin.bootstrap.servers -> localhost:9092 ```  The [sourceConsumerConfig](https://github.com/apache/kafka/blob/aa0cd667bcd5c4025e84097192030b59165ac9d0/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorConnectorConfig.java#L240) will strip this prefix and store all props as:  ``` producer.bootstrap.servers -> localhost:9092 consumer.auto.offset.reset -> latest consumer.max.poll.interval.ms -> 120000 alias -> A bootstrap.servers -> localhost:9092 admin.bootstrap.servers -> localhost:9092 consumer.bootstrap.servers -> localhost:9092 ```  The next line `props.keySet().retainAll(MirrorClientConfig.CLIENT_CONFIG_DEF.names());` will strip all the props not defined in this common CLIENT_CONFIG_DEF definition. Not relevant but can be confusing if you think the next line will filter on the current values in props.  Finally, the `props.putAll(originalsWithPrefix(CONSUMER_CLIENT_PREFIX));` is based on the on the `originals` variable that have the `target.cluster` or `source.cluster` prefix. There's no single property with the ""consumer."" prefix. This patterns repeats with the producer config.  This PR also allows to override the hardcoded `auto.offset.reset` value.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","scanterog","2020-09-21T14:59:34Z","2020-10-16T16:17:04Z"
"","8878","MINOR: Generator config-specific HTML ids","Currently the docs have HTML ids for each config key. That doesn't work correctly for config keys like bootstrap.servers which occur across producer, consumer, admin configs: We generate duplicate ids. So arrange for each config to prefix the ids it generates with the HTML id of its section heading.","closed","","tombentley","2020-06-16T13:38:14Z","2020-09-19T11:35:14Z"
"","9079","KAFKA-10308 fix flaky core/round_trip_fault_test.py","Creating a topic may fail (due to timeout) in running system tests. However, ```RoundTripWorker``` does not ignore ```TopicExistsException``` which makes ```round_trip_fault_test.py``` be a flaky one.  More specifically, a network exception can cause the CreateTopics request to reach Kafka but Trogdor retry it and hit a TopicAlreadyExists exception on the retry, failing the test.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-07-25T16:01:09Z","2020-08-06T15:16:45Z"
"","9180","MINOR: corrected unit tests in AbstractConfigTest.java- fixed invalid assertions","Corrected unit tests.","closed","","sanketfajage","2020-08-14T10:18:26Z","2020-11-03T06:48:37Z"
"","8616","KAFKA-9127: don't create StreamThreads for global-only topology (2.4)","Copy of [pull/8540](https://github.com/apache/kafka/pull/8540) targeted at 2.4","closed","","ableegoldman","2020-05-05T01:32:57Z","2020-05-08T19:31:15Z"
"","9221","KAFKA-10436: Implement KIP-478 Topology changes","Converts `Topology#addProcessor` and `#addGlobalStore` Also, convert some of the internals in support of `addProcessor`  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","vvcephei","2020-08-26T01:25:52Z","2021-01-08T02:04:39Z"
"","8845","KAFKA-10126:Add a warning message for ConsumerPerformance","ConsumerPerformance has not implemented options numThreadsOpt and numFetchersOpt as so far. This patch adds a warning message when used these options according to comments from https://issues.apache.org/jira/browse/KAFKA-10126 . Once these two options are implemented, this warning message should be removed.  Change-Id: Iae34b11210a361373eda42274ebfc153b636a989 Signed-off-by: Jiamei Xie   *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jiameixie","2020-06-10T09:57:30Z","2020-06-24T01:23:02Z"
"","8814","KAFKA-10111: Make SinkTaskContext.errantRecordReporter() a default method","Connector projects may have their own mock or testing implementations of the `SinkTaskContext`, and this newly-added method should be a default method to prevent breaking those projects. Changing this to a default method that returns null also makes sense w/r/t the method semantics, since the method is already defined to return null if the reporter has not been configured.  This should be backported to `2.6`, since that's when [KIP-610](https://cwiki.apache.org/confluence/display/KAFKA/KIP-610%3A+Error+Reporting+in+Sink+Connectors) was introduced.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","rhauch","2020-06-05T16:44:40Z","2020-06-05T20:20:26Z"
"","8565","KAFKA-9798: Send one round synchronously before starting the async producer","Comparing all other test cases, the `shouldAllowConcurrentAccesses` starts an async producer sending records throughout the test other than just synchronously sent and acked a few records before we start the streams application. Right after the streams app is started, we check that at least one record is sent to the output topic (i.e. completed processing). However since only this test starts the producer async and did not wait for it to complete, it is possible that the async producer gets too longer to produce some records and causing it to fail.  To follow what other tests did, I let this test to first send one round of records synchronously before starting the async producing.  Also encountered some new scala warnings that I fixed along with this PR.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","guozhangwang","2020-04-27T21:22:31Z","2020-05-04T01:39:49Z"
"","8520","Add explicit grace period to tumbling window example","Comments also discuss current default grace period value, and the fact that it may change with the next major release.  ### Committer Checklist (excluded from commit message) - [n/a] Verify design and implementation  - [n/a] Verify test coverage and CI build status - [X] Verify documentation (including upgrade notes)","closed","docs,","LiamClarkeNZ","2020-04-20T04:56:38Z","2020-05-02T01:48:05Z"
"","9012","KAFKA-10270: A broker to controller channel manager","Co-authored-by: Viktor Somogyi viktorsomogyi@gmail.com Co-authored-by: Boyang Chen boyang@confluent.io  Add a broker to controller channel manager for use cases from KIP-590 and KIP-497. Kudos to Viktor, the code template is from https://github.com/apache/kafka/pull/7716/  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-07-13T05:53:20Z","2020-07-29T18:40:15Z"
"","9294","MINOR: Fix now that kafka.apache.org resolves to 3 IP addresses","ClusterConnectStatesTest and ClientUtilsTest were failing because they expected kafka.apache.org to resolve to 2 IP addresses. This updates the tests so they reflect that DNS resolves to 3 addresses.","closed","","jolshan","2020-09-16T21:14:36Z","2020-09-30T22:38:04Z"
"","8655","failed","close request","closed","","qq619618919","2020-05-12T15:36:57Z","2020-05-12T16:33:21Z"
"","9105","MINOR: closable object Memory leak prevention","closable object Memory leak prevention  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","highluck","2020-07-30T17:19:31Z","2020-11-21T14:32:56Z"
"","8559","KAFKA-9922:Update examples README","Class kafka.examples.SimpleConsumerDemo was removed. But the java-simple-consumer-demo.sh was not removed and README was not updated.  Change-Id: Iff057ce91454b493859ace6c6959e674048e9678 Signed-off-by: Jiamei Xie   *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jiameixie","2020-04-27T08:58:37Z","2020-04-30T03:18:21Z"
"","9316","MINOR: clarify variables for skipping idempotent source updates","Clarify some confusing variable and method names.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-09-21T20:29:40Z","2020-09-24T14:25:40Z"
"","9468","KAFKA-10454 / (2.6) Update copartitionSourceGroups when optimization algorithm is triggered","cherry-picking https://github.com/apache/kafka/pull/9237 on 2.6 branch  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","lkokhreidze","2020-10-21T06:52:13Z","2020-11-02T17:15:40Z"
"","8785","KAFKA-10084: Fix EosTestDriver end offset","Check the uncommitted end offset after the committed end offset, so we can be sure never to miss a pending end-transaction marker.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-06-02T19:12:40Z","2020-06-03T16:36:35Z"
"","9199","KAFKA-10418: alter topic configs via kafka-topics error text","Changing a topic config with the `kafka-topics` command while connecting to Kafka via `--bootstrap-server` (rather than connecting to ZooKeeper via `--zookeeper`) is not supported. The desired functionality is available elsewhere, though: it is possible to change a topic config while connecting to Kafka rather than ZooKeeper via the `kafka-configs` command instead. However, neither the `kafka-topics` error message received nor the `kafka-topics` help information itself indicates this other possibility. For example:  ``` $ kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic test --config flush.messages=12345 Option combination ""[bootstrap-server],[config]"" can't be used with option ""[alter]"" ```  ``` $ kafka-topics.sh ... --config  A topic configuration override for the topic being created or altered...It is supported only in combination with – create if --bootstrap-server option is used. ```  Rather than simply saying that what you want to do isn't available, it would be better to say also that you can do it with the `kafka-configs` command.","closed","","rondagostino","2020-08-18T21:30:37Z","2020-08-21T06:28:23Z"
"","8730","KAFKA-10048: Possible data gap for a consumer after a failover when u…","Changed the MM2 checkpoint mirror task to ensure it replicates consumer offsets even when they are equal to zero to avoid issues with consumers after failovers.  Modified the test case to cover the possible scenario of consumer gap, as described on KAFKA-10048.   ### Committer Checklist (excluded from commit message) - [x] Verify design and implementation  - [x] Verify test coverage and CI build status - [x] Verify documentation (including upgrade notes)","closed","","asdaraujo","2020-05-27T06:58:08Z","2020-10-02T16:39:00Z"
"","9159","KAFKA-10378: change jacksonDatabind as compile dependency for clients project","change `jacksonDatabind` as `compile` dependency for clients project  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-08-11T06:09:21Z","2020-09-28T02:41:16Z"
"","8813","MINOR: fix backwards incompatibility in JmxReporter introduced by KIP-606","cc @omkreddy this should also get backported to 2.6.x","closed","","xvrl","2020-06-05T16:38:00Z","2020-06-05T20:02:06Z"
"","9405","MINOR internal KIP-629 changes to methods and variables","cc @gwenshap","closed","","xvrl","2020-10-09T06:51:35Z","2020-10-14T23:48:05Z"
"","8507","KAFKA-9818: Fix flaky test in RecordCollectorTest","Call for review @vvcephei. Follow up of #8488 (own ticket number)","closed","tests,","mjsax","2020-04-17T16:17:59Z","2020-04-18T00:25:22Z"
"","9217","MINOR: fix JavaDoc","Call for review @vvcephei","closed","streams,","mjsax","2020-08-25T01:07:31Z","2020-08-26T17:31:21Z"
"","9061","MINOR: removed incorrect deprecation annotations","Call for review @vvcephei","closed","streams,","mjsax","2020-07-23T04:07:24Z","2020-07-24T23:22:15Z"
"","8759","KAFKA-10066: TestOutputTopic should pass record headers into deserializers","Call for review @vvcephei","closed","streams,","mjsax","2020-05-29T23:18:26Z","2020-06-04T23:30:29Z"
"","8819","MINOR: improve code encapsulation between StreamThread and TaskManager","Call for review @guozhangwang @vvcephei","closed","streams,","mjsax","2020-06-05T22:48:10Z","2020-06-06T03:42:43Z"
"","9126","MINOR: Code cleanup in StreamsResetter","Call for review @guozhangwang @abbccdda","closed","tools,","mjsax","2020-08-04T22:17:35Z","2020-08-05T20:38:39Z"
"","8823","MINOR: fix HTML markup","Call for review @bbejeck","closed","docs,","mjsax","2020-06-06T21:14:42Z","2020-06-08T23:12:15Z"
"","8619","MINOR: Improve TopologyTestDriver JavaDocs","Call for review @bbejeck","closed","streams,","mjsax","2020-05-05T19:19:24Z","2020-05-05T22:56:27Z"
"","8488","KAFKA-9819: Fix flaky test in StoreChangelogReaderTest","Call for review @ableegoldman @vvcephei   The test failed with some log message from `AdminClient` however, we don't use any admin client in this test. Thus, we should not get the JVM shared root logger, but only the logger for the test class.","closed","tests,","mjsax","2020-04-15T01:57:02Z","2020-04-17T14:51:22Z"
"","9127","MINOR: fix HTML","Call for review @abbccdda @guozhangwang   This should go to 2.6 and I will also do a PR for kafka-site if necessary","closed","docs,","mjsax","2020-08-04T22:31:52Z","2020-08-06T18:24:15Z"
"","8621","KAFKA-9466: Update Kafka Streams docs for KIP-447","Call for review @abbccdda @guozhangwang","closed","docs,","mjsax","2020-05-06T02:01:05Z","2020-05-12T02:12:02Z"
"","8496","KAFKA-9748: Add Streams eos-beta integration test","Call for review @abbccdda @guozhangwang","closed","kip,","mjsax","2020-04-16T03:52:52Z","2020-06-12T23:10:41Z"
"","9425","KAFKA-10600: Connect should not add error to connector validation values for properties not in connector’s ConfigDef","By default the `Connector.validate(...)` will only include configuration values that are defined in the connector's `ConfigDef`, and validation is handled via `ConfigDef.Validator` objects. However, a connector can override the `Connector.validate(...)`, including in the output any configuration values whether or not they are not defined in the connector's `ConfigDef`.  Before this change, Connect always added an error to any configuration value that did not have a corresponding key defined in the connector's `ConfigDef`. Also, any errors on configuration values that did not have a corresponding key defined in the connector's `ConfigDef` was not counted in the total # of errors in the validation result.  This change removes the addition of those errors, so that only the errors returned by the connector's validation are included in the output, and all errors returned by the connector's validation output are counted in the total # of errors.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","rhauch","2020-10-13T17:53:26Z","2020-10-16T14:14:43Z"
"","8727","KAFKA-8120 Getting NegativeArraySizeException when using Kafka Connect","Bug fix only, [JIRA]( https://issues.apache.org/jira/browse/KAFKA-8120) 1. The Outer loop Issue, at Original line 134 of FileStreamSourceTask.java  	while (readerCopy.ready()) {  Since the buffer is used cross multiple poll. This condition missed a case that file has reached EOF, but buffer has un-parsed data.   To fix it, change the while loop to if statement, and move the file reading logic to extractLine         if (offset < buffer.length && reader.ready()) {  Test case: FileStreamSourceTaskTest.testSmallFile  2. The Expanding Buffer Issue, at Original line 140 of FileStreamSourceTask.java     if (offset == buffer.length) {         char[] newbuf = new char[buffer.length * 2];         System.arraycopy(buffer, 0, newbuf, 0, buffer.length);         buffer = newbuf;     }  For large file, this condition will be always true even expanding buffer is not needed, so every read will trigger expand buffer which will causes Java heap error or NegativeArraySizeException if buffer.length * 2 overflows.   To fix it, move the expanding buffer logic to the end of extractLine     if (offset == buffer.length &&  buffer.length  < maxBufferSize) {        needExtendBuffer = true;    }  Test case: FileStreamSourceTaskTest.testLargeFile  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","connect,","wj1918","2020-05-26T14:26:35Z","2020-05-27T05:15:26Z"
"","8764","KAFKA-10049: Fixed FKJ bug where wrapped serdes are set incorrectly when using default StreamsConfig serdes","Bug Details: Mistakenly setting the value serde to the key serde for an internal wrapped serde in the FKJ workflow.    Testing: Added integration test to use a non-primitive Serde, in this case the JSONSerde that the original bug finder reported using. Expanded integration test to ensure that the default Serdes work for the entire happy path of the FKJ.  Introduces a testing dependency on com.fasterxml.jackson, though this is already the case in other modules so I suspect it won't be a big issue.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","bellemare","2020-05-31T14:48:35Z","2020-06-12T16:55:27Z"
"","9116","KAFKA-10341: Add 2.6.0 to system tests and streams upgrade tests","BTW, `tests/kafkatest/version.py` was already modified to define the 2.6.0 version constants for the system tests, but these variables were never used. Thus, no need to modify that file.  Based upon #8378 (for 2.5)  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","rhauch","2020-08-03T22:53:17Z","2020-08-04T23:04:52Z"
"","8979","KAFKA-10223; Use NOT_LEADER_OR_FOLLOWER instead of non-retriable REPLICA_NOT_AVAILABLE for consumers","Brokers currently return NOT_LEADER_FOR_PARTITION to producers and REPLICA_NOT_AVAILABLE to consumers if a replica is not available on the broker during reassignments. Non-Java clients treat REPLICA_NOT_AVAILABLE as a non-retriable exception, Java consumers handle this error by explicitly matching the error code even though it is not an InvalidMetadataException. This PR renames `NOT_LEADER_FOR_PARTITION` to `NOT_LEADER_OR_FOLLOWER` and uses the same error for producers and consumers. This is compatible with both Java and non-Java clients since all clients handle this error code (6) as retriable exception. The PR also makes ReplicaNotAvailableException a subclass of InvalidMetadataException.  - ALTER_REPLICA_LOG_DIRS continues to return REPLICA_NOT_AVAILABLE. Retained this for compatibility since this request never returned NOT_LEADER_FOR_PARTITION earlier.  Did not  deprecate ReplicaNotAvailableException because of this. - MetadataRequest  version 0 also returns REPLICA_NOT_AVAILABLE for compatibility. Newer versions filter these out and  return Errors.NONE, so didn't change this. - Partition responses in MetadataRequest return REPLICA_NOT_AVAILABLE to indicate that one of the replicas is not available. Did not change this since NOT_LEADER_FOR_PARTITION is not suitable in this case.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rajinisivaram","2020-07-03T16:56:35Z","2021-07-23T11:34:03Z"
"","8714","MINOR: Improve broker registration and Log logging","Broker registration previously:  > INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArraySeq(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT),EndPoint(localhost,9093,ListenerName(SSL),SSL)), czxid (broker epoch): 4294967320 (kafka.zk.KafkaZkClient)  Now:  > INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:9092,SSL://localhost:9093, czxid (broker epoch): 4294967320 (kafka.zk.KafkaZkClient)  The second improvement is to avoid logging messages like:  > ""Deleting segments List()""  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-05-22T13:31:20Z","2020-05-24T16:35:29Z"
"","9283","KAFKA-9697 hide the metrics of control.plane.listener.name if it is u…","Both of ```ControlPlaneNetworkProcessorAvgIdlePercent``` and ```ControlPlaneExpiredConnectionsKilledCount```are exposed with meaningless value when ```control.plane.listener.name``` is unset. They should be hidden as other metrics when ```control.plane.listener.name``` is unset.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-09-14T11:57:54Z","2020-10-27T12:33:18Z"
"","9191","KAFKA-10355: Throw error when source topic was deleted","Before this commit, Kafka Streams would gracefully shut down the whole application when a source topic is deleted. The graceful shutdown does not give the user the possibility to react on the deletion of the source topic in the uncaught exception handler.  This commit changes this behavior and throws an error when a source topic is deleted.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","cadonna","2020-08-17T14:58:37Z","2020-09-07T09:42:21Z"
"","9353","KAFKA-10521; Skip partition watch registration when `AlterIsr` is expected","Before `AlterIsr` with KIP-497, the controller would register watches in Zookeeper for each reassigning partition so that it could be notified immediately when the ISR was expanded and the reassignment could be completed. This notification is not needed with the latest IBP when `AlterIsr` is enabled because the controller will execute all ISR changes itself.  There is one subtle detail. If we are in the middle of a roll in order to bump the IBP, then it is possible for the controller to be on the latest IBP while some of the brokers are still on the older one. In this case, the brokers on the older IBP will not send `AlterIsr`, but we can still rely on the delayed notification through the `isr_notifications` path to complete reassignments. This seems like a reasonable tradeoff since it should be a short window before the roll is completed.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-09-29T21:52:11Z","2020-10-14T00:53:48Z"
"","8892","KAFKA-10068: verify assignment performance with large cluster","Because we do some nontrivial things in the StreamsPartitionAssignor, and will likely want to verify the scalability of new assigns we may add in the future, I added this to StreamsPartitionAssignorTest (vs just testing the HATA).  With 10 topics at 1,000 partitions each and 100 consumers, the tests complete within seconds.  If you increase the number of partitions per topic by a factor of 10, the assignment takes about 1min (for all three task assignors). Of course, the test is actually doing two full assignments, so the total time per assignment is still reasonable","closed","streams,","ableegoldman","2020-06-18T02:15:22Z","2020-09-22T14:20:47Z"
"","9114","KAFKA-10162; Use Token Bucket algorithm for controller mutation quota (KIP-599, Part III)","Based on the discussion in https://github.com/apache/kafka/pull/9072, I have put together an alternative way. This one does the following: * Instead of changing the implementation of the Rate to behave like a Token Bucket, it actually use two different metrics: the regular Rate and a new Token Bucket. The latter is used to enforce the quota. * The Token Bucket algorithm uses the rate of the quota as the refill rate for the credits and compute the burst based on the number of samples and their length (# samples * sample length * quota). * The Token Bucket algorithm used can go under zero in order to handle unlimited burst (e.g. create topic with a number of partitions higher than the burst). Throttling kicks in when the number of credits is under zero. * The throttle time is computed as credits under zero / refill rate (or quota). * Only the controller mutation uses it for now. * The remaining number of credits in the bucket is exposed with the `tokens` metrics per user/clientId.  The code can be improved and refactored. I just wanted to get out quickly to get feedback about the approach.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-08-03T17:22:52Z","2020-08-06T16:47:12Z"
"","9373","KAFKA-10564: only process non-empty task directories when internally cleaning obsolete state stores","Avoid continuous repeated logging by not trying to clean empty task directories, which are longer fully deleted during internal cleanup as of https://issues.apache.org/jira/browse/KAFKA-6647.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","mikebin","2020-10-05T04:49:59Z","2020-10-20T21:34:06Z"
"","8606","KAFKA-9731: No need to propagate HWM to followers when using default …","Attempted fix to the unnecessary fetch request responses detected by @vahidhashemian in KAFKA-9731.   I did not add tests (under the assumption that the correctness of HWM propagation is already tested, and those tests will validate my change). I also didn't attempt to reproduce the issue that Vahid spotted, but rather implemented the solution he suggested.","closed","","gwenshap","2020-05-03T21:41:36Z","2020-05-04T00:05:08Z"
"","8916","MINOR; Provide lowest and highest supported versions alongside with the schema in the auto-generated protocol","At the moment, the only way available to get the supported versions of a Message is to look at the number of defined schemas, assuming that the lowest version is 0. This PR adds static constants with the versions alongside with the schemas.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tools,","dajac","2020-06-23T13:40:21Z","2020-10-06T20:08:54Z"
"","8547","MINOR: Remove unused foreign-key join class","As titled  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-04-24T23:39:38Z","2020-04-25T02:18:04Z"
"","9392","MINOR: the top-level error message of AlterPartitionReassignmentsResp…","as title  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-10-08T06:36:14Z","2020-10-20T02:54:15Z"
"","9315","KAFKA-10496: Removed relying on external DNS servers in tests","As ticket suggested I’ve tried to introduce an in-memory DNS server for testing purposes, but unfortunately capability to change default DNS provider has been removed in Java 9: https://bugs.openjdk.java.net/browse/JDK-8134577.  There is a request for restoring it: https://bugs.openjdk.java.net/browse/JDK-8192780, but so far has not been implemented.  Therefore this PR decouples DNS resolution from `InetAddress.getAllByName` implementation in order to mock its behavior in tests.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","piotrrzysko","2020-09-21T18:34:56Z","2021-07-20T14:47:59Z"
"","8682","KAFKA-10011: Remove task id from lockedTaskDirectories during handleLostAll","As stated, we couldn't wait for handleRebalanceComplete in the case of handleLostAll, as we already closed the active task as dirty, and could potentially require its offset in the next thread.runOnce call.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-05-17T19:12:17Z","2020-05-19T21:00:14Z"
"","8850","KAFKA-10141: Add more detail to log segment delete messages","As specified in https://issues.apache.org/jira/browse/KAFKA-10141, it would be helpful to include as much information as possible when deleting log segments. This patch introduces log messages that give more specific details as to why the log segment was deleted and the specific metadata regarding that log segment.   *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","skaundinya15","2020-06-11T03:37:38Z","2020-08-01T02:26:02Z"
"","8999","MINOR; Return timed out connections as a List instead of a Set","As pointed out by @ijuma in https://github.com/apache/kafka/pull/8990#discussion_r451059876, using a `Set` is not necessary as the caller only cares about having the list of timed out connections/nodes. It does nothing else but iterating over the list.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-07-09T07:57:01Z","2020-10-20T06:36:27Z"
"","9007","KAFKA-10120: Deprecate DescribeLogDirsResult.all() and .values()","As per KIP-621. Also added some tests in KafkaAdminClientTest","closed","","tombentley","2020-07-10T13:54:39Z","2020-08-01T06:46:43Z"
"","9115","Bump dev version to 2.6.1-SNAPSHOT","As part of the 2.6.0 release, we need to bump the dev version of the `2.6` branch to 2.6.1.","closed","","rhauch","2020-08-03T19:27:00Z","2020-08-04T23:07:34Z"
"","8491","Minor: Add 2.5 versions","As part of the 2.5.0 release, add the 2.5 versions to various places in the build","closed","","mumrah","2020-04-15T14:27:48Z","2020-04-15T20:13:19Z"
"","8677","KAFKA-9999: Make internal topic creation error non-fatal","As of today, the internal topic creation failure could shut down a stream thread. Instead of hard failure, we could take a more conservative approach by triggering another rebalance and retry with the topic creation to avoid a thread death due to unavailability of the broker.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-05-15T22:08:15Z","2020-11-03T00:31:18Z"
"","9024","MINOR: change Streams integration test log levels","And reduce the less relevant logs","closed","tests,","ableegoldman","2020-07-14T23:03:29Z","2020-08-04T18:41:31Z"
"","8656","KAFKA-9981; dedicated mm2 cluster lose the update operation.","Although the configBackingStore task not on the leader node,The configBackingStore directly notifies the mirrormaker task after sensing the configuration update.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","qq619618919","2020-05-12T16:13:34Z","2022-06-23T03:49:03Z"
"","8519","MINOR: Upgrade gradle plugins and test libraries for Java 14 support","Also: * Remove deprecated `=` in resolutionStrategy. * Replace `AES/GCM/PKCS5Padding` with `AES/GCM/NoPadding` in `PasswordEncoderTest`. The former is invalid and JDK 14 rejects it, see https://bugs.openjdk.java.net/browse/JDK-8229043.  With these changes, the build works with Java 14 and Scala 2.12. The same will apply to Scala 2.13 when Scala 2.13.2 is released (should happen within 1-2 weeks).  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-04-20T02:52:16Z","2020-04-20T20:55:25Z"
"","8490","MINOR: Fix compiler warnings and add @nowarn for the unfixed ones","Also upgrade to scala-collection-compat 2.1.6 as it introduces the @nowarn annotation.  Scala 2.13.2 (soon to be released) suppresses warnings with this annotation.  While at it, also update scala-java8-compat to 0.9.1.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-04-15T14:20:42Z","2020-04-20T13:50:35Z"
"","9129","MINOR: Update jmh to 1.27 for async profiler support","Also updated the jmh readme to make it easier for new people to know what's possible and best practices.  There were some changes in the generated benchmarking code that required adjusting `spotbugs-exclude.xml` and for a `javac` warning to be suppressed for the benchmarking module. I took the chance to make the spotbugs exclusion mode maintainable via a regex pattern.  Tested the commands on Linux and macOS with zsh.  JMH highlights:  * async-profiler integration. Can be used with -prof async, pass -prof async:help to look for the accepted options. * perf c2c [2] integration. Can be used with -prof perfc2c, if available. * JFR profiler integration. Can be used with -prof jfr, pass -prof jfr:help to look for the accepted options.  Full details: * 1.24: https://mail.openjdk.java.net/pipermail/jmh-dev/2020-August/002982.html * 1.25: https://mail.openjdk.java.net/pipermail/jmh-dev/2020-August/002987.html * 1.26: https://mail.openjdk.java.net/pipermail/jmh-dev/2020-October/003024.html * 1.27: https://mail.openjdk.java.net/pipermail/jmh-dev/2020-December/003096.html  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-08-05T13:57:55Z","2020-12-11T01:56:57Z"
"","9005","KAFKA-10263: Do not assign standby for revoking stateless tasks","Also piggy-back a small fix to use TreeMap other than HashMap to preserve iteration ordering.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-07-10T00:36:58Z","2020-07-10T23:51:01Z"
"","9338","KAFKA-10515: Properly initialize nullable Serdes with default values","Also introduced the notion of WrappingNullableSerdes (aligned to the concept of WrappingNullableSerializer and WrappingNullableDeserializer) and centralized initialization in WrappingNullables.  The added integeration test KTableKTableForeignKeyJoinDistributedTest tests wether all serdes are now correctly set on all stream clients.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","thake","2020-09-25T05:07:49Z","2020-10-21T14:51:54Z"
"","8716","KAFKA-6145: KIP-441: Fix assignor config passthough","Also fixes a system test by configuring the HATA to perform a one-shot balanced assignment  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","vvcephei","2020-05-22T16:47:44Z","2020-06-12T23:08:27Z"
"","9319","KAFKA-10413: Allow for even distribution of lost/new tasks when multiple Connect workers join at the same time","Allow even distribution of lost/new tasks when more than one worker joins the group at the same time  Issue description: Existing issue 1 description : When more than one worker joins the consumer group the incremental co operative assignor revokes and re assigns atmost average number of tasks per worker.  Issue: This results in the additional workers joining the group stay idle and would require more future rebalances to happen to have even distribution of tasks.  Fix: As part of task assignment calculation following a deployment, the reassignment of tasks are calculated by revoking all the tasks above ceil(average) number of tasks.  Existing issue 2 description: When more than one worker is lost and rejoins the group at most one worker will be re assigned with the lost tasks from all the workers that left the group.  Issue: In scenarios where more than one worker is lost and rejoins the group only one among them gets assigned all the partitions that were lost in the past. The additional workers that have joined would not get any task assigned to them until a rebalance that happens in future.  Fix: As part fo lost task re assignment all the new workers that have joined the group would be considered for task assignment and would be assigned in a round robin fashion with the new tasks.  Testing strategy : System testing in a Kube environment completed. UT : updated to UT","closed","connect,","ramesh-muthusamy","2020-09-22T11:20:50Z","2021-02-04T07:32:05Z"
"","9158","MINOR: Update the quickstart link in readme","After the new website launched, the quickstart link also changed. Update the quickstart link in readme.md.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-08-11T03:24:38Z","2020-08-12T02:52:55Z"
"","9104","KAFKA-10266: Update the connector config header.converter","After my update, the original wrong statement will be removed. > By default, the SimpleHeaderConverter is used to .....   And it'll be replaced with the following, with hyperlink to the worker config's header.converter section. >  By default, the value will be inherited from the Connect config.  Also, update the default value to **Inherited from Connect config**    ![圖片](https://user-images.githubusercontent.com/43372967/88891066-185d5d80-d275-11ea-8b89-3e0df1ed1904.png)    ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","connect,","showuon","2020-07-30T06:55:23Z","2020-12-14T03:17:23Z"
"","8567","KAFKA-9652: Fix throttle metric in RequestChannel and request log due to KIP-219","After KIP-219, responses are sent immediately and we rely on a combination of clients and muting of the channel to throttle. The result of this is that we need to track `apiThrottleTimeMs` as an explicit value instead of inferring it. On the other hand,  we no longer need `apiRemoteCompleteTimeNanos`.  Extend `BaseQuotaTest` to verify that throttle time in the request channel metrics are being set. Given the nature of the throttling numbers, the test is not particularly precise.  I included a few clean-ups: * Pass KafkaMetric to QuotaViolationException so that the caller doesn't have to retrieve it from the metrics registry. * Inline Supplier in SocketServer (use SAM). * Reduce redundant `time.milliseconds` and `time.nanoseconds`calls. * Use monotonic clock in ThrottledChannel and simplify `compareTo` method. * Simplify `TimerTaskList.compareTo`. * Consolidate the number of places where we update `apiLocalCompleteTimeNanos` and `responseCompleteTimeNanos`. * Added `toString` to ByteBufferSend` and `MultiRecordsSend`. * Restrict access to methods in `QuotaTestClients` to expose only what we need to.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-04-27T23:28:41Z","2020-04-30T03:09:21Z"
"","8917","KAFKA-10180: Fix security_config caching.","After 8b22b8159673bfe22d8ac5dcd4e4312d4f2c863c `security_config` properties are modified during `setup_node`: tls_version patched according to the node jdk version. But python `@property` decorator doesn't store property values and fresh instance of `SecurityConfig` created on each `kafka.security_config` call  This patch caches `SecurityConfig` instances so correct tls_version will be used during the test.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","nizhikov","2020-06-23T16:56:22Z","2020-06-28T15:50:06Z"
"","8949","KAFKA-10214: fix flaky zookeeper_tls_test.py","After 3661f981fff2653aaf1d5ee0b6dde3410b5498db security_config is cached. Hence, the later changes to security flag can't impact the security_config used by later tests.  issue: https://issues.apache.org/jira/browse/KAFKA-10214  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-06-29T14:15:33Z","2020-07-01T11:39:15Z"
"","9004","KAFKA-10261: Introduce the KIP-478 apis with adapters","Adds the new Processor and ProcessorContext interfaces as proposed in KIP-478. To integrate in a staged fashion with the code base, adapters are included to convert back and forth between the new and old APIs.  ProcessorNode is converted to the new APIs.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","vvcephei","2020-07-09T22:42:23Z","2021-01-08T02:05:17Z"
"","8747","MINOR: Log the reason for coordinator discovery failure","Adds the exception in the case of logging the ""Coordinator discovery failed"" message.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","consumer,","vvcephei","2020-05-28T18:24:33Z","2020-05-29T13:52:20Z"
"","9345","KAFKA-10338; Support PEM format for SSL key and trust stores (KIP-651)","Adds support for SSL key and trust stores to be specified in PEM format either as files or directly as configuration values.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rajinisivaram","2020-09-28T19:01:02Z","2022-03-14T17:40:51Z"
"","8863","KAFKA-8528: Expose Trogdor-specific JMX metrics for Tasks and Agents","Adds JMX metrics to Trogdor to keep track of Created, Running, and Done tasks and the number of Active Agents in a Trogdor cluster as seen in [KAFKA-8528](https://issues.apache.org/jira/browse/KAFKA-8528).  Adds a `TrogdorMetrics` class that contains a metric and sensors for tasks in the aforementioned states as well as for active agents. Utilizes the `Platform` interface shared by Tasks and Agents to create  a common `TrogdorMetrics` instance in a `MetricsContainer` class.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","spal1","2020-06-12T23:34:10Z","2020-07-07T14:46:54Z"
"","9094","KAFKA-10054: KIP-613, add TRACE-level e2e latency metrics","Adds avg, min, and max e2e latency metrics at the new TRACE level. Also adds the missing `avg` task-level metric at the INFO level.  I think where we left off with the KIP, the TRACE-level metrics were still defined to be ""stateful-processor-level"". I realized this doesn't really make sense and would be pretty much impossible to define given the DFS processing approach of Streams, and felt that store-level metrics made more sense to begin with. I haven't updated the KIP yet so I could get some initial feedback on this","closed","","ableegoldman","2020-07-29T01:59:58Z","2020-08-25T00:37:50Z"
"","8648","KAFKA-9966: add internal assignment listener to stabilize eos-beta upgrade test","Adds an internal assignment listener interface with a callback that exposes the assignment stability. A useful implementation that tracks the number of stable assignments is available in IntegrationTestUtils,  and leveraged to fix the flaky EOSBetaUpgradeTest, but any implementation can be plugged in to meet the specific needs of a test.","closed","tests,","ableegoldman","2020-05-12T02:07:06Z","2020-05-15T01:03:04Z"
"","8545","MINOR: smoke test for jmh benchmark functionality","Adds a smoke test to run a single jmh benchmark on each CI build. Without this change it is possible for the jmh benchmarks to break if we change our build setup.","open","","lbradstreet","2020-04-24T14:34:30Z","2020-04-24T14:46:29Z"
"","8961","MINOR: add retry to system test curl commands","Adds a retry to curl, using the built-in exponential backoff mechanism.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-06-30T22:30:12Z","2020-07-01T18:02:01Z"
"","9073","MINOR: add task ':streams:testAll'","Adds a new task to Streams to run all the tests for all sub-projects.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-07-24T16:58:27Z","2020-08-10T15:14:32Z"
"","8858","KAFKA-10153: Error Reporting in Connect Documentation","Adds a new section in Kafka Connect documentation for error reporting in Connect.","closed","connect,","aakashnshah","2020-06-12T07:00:05Z","2020-10-16T06:15:46Z"
"","8767","KAFKA-10060 GroupMetadataManager should not log if there are no offse…","address @ijuma [comment](https://issues.apache.org/jira/browse/KAFKA-10060?focusedCommentId=17118992&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17118992) > I think the expired offsets one can be removed if there are no offsets to expire.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-05-31T16:08:48Z","2020-05-31T21:59:41Z"
"","9437","KAFKA-10612: Log When SSL Authentication is in Unexpected State","Additional logging, no functional changes.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","belugabehr","2020-10-14T20:14:18Z","2020-10-14T20:14:18Z"
"","9172","KAFKA-10387: Fix inclusion of transformation configs when topic creation is enabled in Connect","Addition of configs for custom topic creation with KIP-158 created a regression when transformation configs are also included in the configuration of a source connector.   To experience the issue, just enabling topic creation at the worker is not sufficient. A user needs to supply a source connector configuration that contains both transformations and custom topic creation properties.   The issue is that the enrichment of configs in `SourceConnectorConfig` happens on top of an `AbstractConfig` rather than a `ConnectorConfig`. Inheriting from the latter allows enrichment to be composable for both topic creation and transformations.   Unit tests and integration tests are written to test these combinations.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","kkonstantine","2020-08-12T19:27:29Z","2020-10-16T05:46:10Z"
"","9204","KAFKA-6181 Examining log messages with {{--deep-iteration}} should show superset of fields","adding missing fields for --deep-iteration log messages.  Missing fields include : partitionLeaderEpoch, baseSequence, lastSequence, etc.,","closed","tools,","iprithv","2020-08-20T15:23:19Z","2020-11-21T07:56:09Z"
"","9273","KAFKA-9331: changes for Streams uncaught exception handler","Adding an option to shutdown an entire streams application for a Streams thread  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)  @cadonna","closed","","wcarlson5","2020-09-09T19:14:30Z","2020-12-11T17:09:24Z"
"","9239","Adding reverse iterator usage for sliding windows processing (extending KIP-450)","Adding a `backwardFetch` call to the window store for sliding windows processing. While the implementation works with the forward call to the window store, using `backwardFetch` allows for the iterator to be closed earlier, making implementation more efficient.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","lct45","2020-09-01T16:15:54Z","2020-09-11T21:38:17Z"
"","8620","KAFKA-9944: Added supporting customized HTTP response headers for Kafka Connect.","Added supporting customized  HTTP Response Headers for Kafka Connect REST server.  **[KIP-577](https://cwiki.apache.org/confluence/display/KAFKA/KIP+577%3A+Allow+HTTP+Response+Headers+to+be+Configured+for+Kafka+Connect) HAS BEEN ACCEPTED**","closed","connect,","jeffhuang26","2020-05-05T22:27:30Z","2020-05-24T13:56:28Z"
"","9243","Add ConsumerGroupCommand to delete static members","Added new option --remove-members to remove members from group in ConsumerGroupCommand. User can either remove member by providing member id (--member) or can delete all the members of group using (--all-members) option   https://issues.apache.org/jira/browse/KAFKA-9440 ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","kip,","sndp2693","2020-09-02T06:48:37Z","2022-03-12T00:04:07Z"
"","8558","KAFKA-8611 / KIP-221 documentation","Added KIP-221 documentation       ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","lkokhreidze","2020-04-27T08:04:29Z","2020-05-15T22:28:24Z"
"","8650","MINOR: Added unit tests for ConnectionQuotas","Added ConnectionQuotasTest, a unit test for ConnectionQuotas. We test connection limits functionality in SocketServerTest (max connections per IP), and DynamicConnectionQuotaTest (max broker-wide and per listener connection limits), which is an integration test. It is useful to have unit tests that directly test ConnectionQuotas.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","apovzner","2020-05-12T04:29:37Z","2020-05-21T16:21:05Z"
"","8811","KAFKA-10110: Corrected potential NPE when null label value added to KafkaMetricsContext","Added a new unit test to verify the functionality and expectations.  This should be backported to the `2.6` branch, since `KafkaMetricsContext` was added in 2.6 per #8691 / [KAFKA-9960](https://issues.apache.org/jira/browse/KAFKA-9960)  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","core,","rhauch","2020-06-05T16:09:23Z","2020-06-05T20:19:24Z"
"","8588","KAFKA-6145: KIP-441: Improve assignment balance","Add validation that task assignment is always balanced after convergence.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","vvcephei","2020-04-30T03:07:33Z","2020-06-12T23:09:51Z"
"","9144","KAFKA-9705: (part-1) add redirection fields in the request header","Add the redirection supporting fields, including:  1. initial principal name 2. initial client id 3. the flag to indicate whether a given request is coming from the control plane in a secured environment.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-08-07T22:43:31Z","2020-08-18T20:38:59Z"
"","9339","MINOR: add docs for 2.7 TRACE-level e2e latency metrics","Add the extended e2e latency metrics to the upgrade guide for 2.7.","closed","","ableegoldman","2020-09-25T23:53:45Z","2020-09-27T03:37:48Z"
"","8831","KAFKA-8657:Client-side automatic topic creation on Producer","Add support to configure allow.auto.create.topics.enable on producer client. This patch is based on https://github.com/apache/kafka/pull/7075, with rebase to current HEAD and add new test cases  Change-Id: I24444e152f7ca57e21fa6148cedc3428e2443732 Signed-off-by: Jiamei Xie   *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jiameixie","2020-06-08T01:46:00Z","2022-05-24T03:27:21Z"
"","8754","KAFKA-9927: Add support for varint32 and varint64 in protocol messages","Add support for the varint32 and varint64 types in the message generator.","open","kip,","tombentley","2020-05-29T15:02:41Z","2020-06-27T16:32:04Z"
"","9387","KAFKA-4759: Acl authorizer subnet support","Add subnet support to ACL authorizer. For IPv4 and IPv6, it supports:  - IP address range - Subnet CIDR notation  Test strategy has been simple: - Define ranges and set ACLs with IPs included in that range and other that it is not included inside the range.  BTW suggestions are welcome (I don't know Scala and I haven't been coding in a long time) :)  JIRA ticket: https://issues.apache.org/jira/browse/KAFKA-4759  ### Committer Checklist (excluded from commit message) - [x] Verify design and implementation  - [x] Verify test coverage and CI build status - [x] Verify documentation (including upgrade notes)","closed","","rgo","2020-10-06T21:01:19Z","2021-01-20T11:11:04Z"
"","9109","MINOR: Add notes for 2.6 on reassignment tool changes","Add some notable changes to the reassignment tool for the 2.6 release.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","hachikuji","2020-07-31T16:06:07Z","2020-07-31T17:20:35Z"
"","8966","KAFKA-10220: add null check for configurationKey","Add null check for configurationKey to avoid NPE, and add test for it.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-07-01T08:30:12Z","2020-07-09T09:28:16Z"
"","9264","KAFKA-5636: Add Sliding Windows documentation","Add necessary documentation for [KIP-450](https://cwiki.apache.org/confluence/display/KAFKA/KIP-450%3A+Sliding+Window+Aggregations+in+the+DSL), adding sliding window aggregations to KStreams  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","lct45","2020-09-08T14:24:35Z","2020-09-11T04:55:12Z"
"","8997","MINOR: Improve log4j for per-consumer assignment","Add log4j entry summarizing the assignment (prev owned and assigned) at the consumer level.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-07-09T01:27:29Z","2020-07-17T19:02:42Z"
"","8912","KIP-446: Add changelog topic configuration to KTable suppress","add KIP-446: Add changelog topic configuration to KTable suppress docs  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","highluck","2020-06-23T05:38:55Z","2020-07-01T07:57:56Z"
"","9327","Backport Jenkinsfile to 2.5","Add Jenkinsfile to 2.5 branch so we can use the PR builder job","closed","","mumrah","2020-09-23T15:16:21Z","2020-10-01T02:20:26Z"
"","9269","MINOR: add ImplicitLinkedHashCollection#moveToEnd","Add ImplicitLinkedHashCollection#moveToEnd.  Refactor ImplicitLinkedHashCollectionIterator to be a little bit more robust against concurrent modifications to the map.","closed","","cmccabe","2020-09-09T06:16:41Z","2020-09-10T00:29:12Z"
"","9349","MINOR: add proper checks to KafkaConsumer.groupMetadata","add following checks to ```KafkaConsumer.groupMetadata```  1. null check of coordinator (replace NPE by ```InvalidGroupIdException``` which is same to other methods) 1. concurrent check (```groupMetadata``` is not thread-safe so concurrent check is necessary)  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-09-29T05:05:45Z","2020-10-05T21:14:51Z"
"","8839","MINOR: Documentation for KIP-585","Add documentation for using transformation predicates. Add `PredicateDoc` for generating predicate config docs, following the style of `TransformationDoc`. Fix the header depth mismatch. Avoid generating HTML ids based purely on the config name since there are very likely to conflict (e.g. #name). Instead allow passing a function which can be used to generate an id from a config key.","closed","connect,","tombentley","2020-06-09T10:35:23Z","2020-10-16T05:46:10Z"
"","9276","KAFKA-10473: Add docs on partition size-on-disk, and other log-related metrics","Add docs on the following JMX metrics  kafka.log,type=Log,name=Size kafka.log,type=Log,name=NumLogSegments kafka.log,type=Log,name=LogStartOffset kafka.log,type=Log,name=LogEndOffset  To test this, I opened the docs in a web browser  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","wushujames","2020-09-09T22:20:40Z","2020-12-04T09:00:46Z"
"","9055","MINOR: Update SslEngineFactory javadoc","Add description for return tags, remove link to internal `SslFactory` class.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rajinisivaram","2020-07-22T17:41:27Z","2020-07-22T20:42:14Z"
"","9448","KAFKA-10605: KIP-478: Deprecate old PAPI registration methods","Add deprecation annotations to the methods replaced in KIP-478.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","vvcephei","2020-10-16T03:54:11Z","2021-01-08T02:03:19Z"
"","9267","MINOR: Add debug logs for StreamThread","Add debug logs to see when Streams calls poll, process, commit, etc.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-09-08T16:50:08Z","2020-09-10T20:47:20Z"
"","9383","KAFKA-10455: Ensure that probing rebalances always occur","Add data to subscriptionUserData to make sure that it's different each time a consumer rejoins ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","lct45","2020-10-06T16:00:29Z","2020-10-19T19:49:03Z"
"","9241","MINOR: Update the javadoc in GroupMetadataManager.scala","Add and update the Javadoc in `GroupMetadataManager.scala` 1. add missing parameters 2. rename the parameter name to be better understand and consistent ( change from `group` to `groupId`) 3. fix the wrong return description  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-09-02T03:02:48Z","2020-09-28T04:05:37Z"
"","8818","KAFKA-10086: Integration test for ensuring warmups are effective","Add an integration test for the task assignor. * ensure we see proper scale-out behavior with warmups * ensure in-memory stores are properly recycled and not restored through the scale-out process  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-06-05T22:31:18Z","2020-06-11T14:19:16Z"
"","9337","KAFKA-10519; Add missing unit test for `VotedState`","Add a simple unit test for `VotedState`. This was a leftover TODO from the initial Raft merge that was caught by #9331.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip-500,","hachikuji","2020-09-24T18:10:07Z","2021-08-11T13:17:08Z"
"","8549","KAFKA-9911: Add new PRODUCER_FENCED error code","Add a separate error code as PRODUCER_FENCED to differentiate INVALID_PRODUCER_EPOCH.  On broker side, we should replace INVALID_PRODUCER_EPOCH with PRODUCER_FENCED when the request version is the latest, while still returning INVALID_PRODUCER_EPOCH to older clients.  On client side, simply handling INVALID_PRODUCER_EPOCH the same as PRODUCER_FENCED if from txn coordinator APIs.   The TRANSACTION_TIMED_OUT code will be implemented in a subsequent PR.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-04-25T03:56:52Z","2020-08-12T15:54:02Z"
"","8920","DOCS-4446: document timestamped state stores","Add a section on the timestamped state store interfaces, per [KIP-258](https://cwiki.apache.org/confluence/display/KAFKA/KIP-258%3A+Allow+to+Store+Record+Timestamps+in+RocksDB).","closed","","JimGalasyn","2020-06-23T22:41:52Z","2020-07-07T01:10:40Z"
"","8743","MINOR: regression test for task assignor config","Add a regression test to ensure the task assignor config is always effective.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-05-28T16:21:47Z","2020-05-28T19:41:12Z"
"","9471","MINOR: Add Jenkinsfile to 2.6","Add a Jenkinsfile for the 2.6 branch so PRs can be built.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-10-21T16:59:25Z","2020-10-29T16:43:31Z"
"","9472","MINOR: Add Jenkinsfile to 2.3","Add a Jenkinsfile for the 2.3 branch so PRs can be built  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-10-21T17:10:22Z","2020-10-22T16:51:30Z"
"","9474","MINOR: Add Jenkinsfile to 2.2","Add a Jenkinsfile for the 2.2 branch so PRs can be built  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-10-21T17:57:43Z","2020-10-22T16:51:00Z"
"","9475","MINOR: Add Jenkinsfile to 2.1","Add a Jenkinsfile for the 2.1 branch so PRs can be built  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-10-21T18:02:23Z","2020-10-22T16:50:28Z"
"","9328","Minor: Add deleteDir for streams quickstart test","Add a `deleteDir` directive to the temporary dir we create during the streams/quickstart archetype test in the Jenkinsfile","open","","mumrah","2020-09-23T15:21:11Z","2020-10-16T08:26:16Z"
"","9121","KAFKA-10351: add tests for IOExceptions for GlobalStateManagerImpl/OffsetCheckpoint","add 2 tests for IOExceptions cases: 1 for `OffsetCheckpoint` and 1 for `GlobalStateManagerImpl`  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","showuon","2020-08-04T10:06:41Z","2020-10-01T01:26:53Z"
"","9034","KAFKA-10246 : AbstractProcessorContext topic() throws NPE","AbstractProcessorContext topic() throws NullPointerException when modifying a state store within the DSL from a punctuator","closed","","ashishroy077","2020-07-17T09:09:28Z","2020-07-25T15:51:52Z"
"","9086","FIX: Remove staticmethod tag to be able to use logger of instance","A system test failed with the following error  global name 'self' is not defined  The reason was that self was accessed in a static method to log a message.  This commit makes the method an instance method.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","cadonna","2020-07-27T13:55:33Z","2020-07-27T23:11:42Z"
"","8886","KAFKA-9891: fix corrupted StandbyTask state","A StandbyTask must wipe its local state if EOS is enabled and no local checkpoint file is found.  I left debug statement in on purpose to people can verify the test locally if they want.  - when the first instance starts up, the store should be empty  - if should process key 0 and put into the store  - after the second instance is running and has replicated the state, the first instance should process key 1 and crash  - after fail-over to instance 2, the store should only contain key 0  - instance 2 should reprocess key 1 (we skip it to avoid the crash for this case; note that the store content in not modified; we only need to do this to make sure instance 1 can be restarted and rebuild the standby store)  - instance 1 is restarted and rebuild the standby store  - we stop instance 2 an the store is migrated to instance 1: the store should only contain key 0 (if the fix in `StandbyTask` is remove, one can observe that the store content is 0 and 1)  - we re-enable error injection and re-inject the poison pill: instance 1 should fail again (without the fix, no error occurs because key 1 is detected as duplicated)  Call for review @abbccdda @guozhangwang","closed","streams,","mjsax","2020-06-17T04:23:41Z","2020-06-19T20:01:26Z"
"","8735","KAFKA-10052: Harden assertion of topic settings in Connect integration tests","A recently added assertion in Connect integration tests uses `consumer#partitionsFor` to verify that a topic was created with the expected number of partitions and replicas. However, probably because of metadata propagation delays, this call doesn't always return a valid `PartitionInfo` for the topic that has just been created and the test is terminated with a NPE.   This commit changes the assertion to perform retries in order to verify the topic settings and uses the admin client instead.  Tests have been adjusted to use the new assertion.    ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","kkonstantine","2020-05-27T22:02:09Z","2020-10-16T05:46:09Z"
"","9330","MINOR: Remove unneeded FIXME","A previous iteration of the Raft patch had a broken check for disconnects. We had fixed the problem, but forgotten to remove the FIXME.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip-500,","hachikuji","2020-09-23T16:00:48Z","2021-08-11T13:17:25Z"
"","9083","KAFKA-9450: Follow-up; Forbid process after closed","A few cleanup and tighten screws:  * When a processor is closed (due to topology-closure), we should not allow processing more records. * Let all built-in processors to extend from AbstractProcessor. * Remove duplicated override functions.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-07-27T05:42:37Z","2020-09-30T18:15:55Z"
"","9160","MINOR: Upgrade Gradle to 6.6","A couple of important bug fixes affecting Scala compilation are the main driver: * https://github.com/gradle/gradle/issues/13224 * https://github.com/gradle/gradle/issues/13392  Full release notes for the other improvements: * https://docs.gradle.org/6.6/release-notes.html  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-08-11T09:29:49Z","2020-08-11T16:22:24Z"
"","8509","KAFKA-9839: Broker should accept control requests with newer broker epoch","A broker throws IllegalStateException if the broker epoch in the LeaderAndIsr/UpdateMetadataRequest/StopReplicaRequest is larger than its current broker epoch. However, there is no guarantee that the broker would receive the latest broker epoch before the controller: When the broker registers with ZK, there are few more instructions to process before this broker ""knows"" about its epoch, while the controller may already get notified and send UPDATE_METADATA request (as an example) with the new epoch. This will result in clients getting stale metadata from this broker.   With this PR, a broker accepts LeaderAndIsr/UpdateMetadataRequest/StopReplicaRequest if the broker epoch is newer than the current epoch.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","apovzner","2020-04-18T02:23:17Z","2020-04-27T19:41:32Z"
"","9152","KAFKA-9839; Broker should accept control requests with newer broker epoch","A broker throws IllegalStateException if the broker epoch in the LeaderAndIsr/UpdateMetadataRequest/StopReplicaRequest is larger than its current broker epoch. However, there is no guarantee that the broker would receive the latest broker epoch before the controller: when the broker registers with ZK, there are few more instructions to process before this broker ""knows"" about its epoch, while the controller may already get notified and send UPDATE_METADATA request (as an example) with the new epoch. This will result in clients getting stale metadata from this broker.  With this PR, a broker accepts LeaderAndIsr/UpdateMetadataRequest/StopReplicaRequest if the broker epoch is newer than the current epoch.  Reviewers: David Jacot , Jason Gustafson   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","viktorsomogyi","2020-08-10T10:32:39Z","2022-01-10T13:25:11Z"
"","9151","KAFKA-9839; Broker should accept control requests with newer broker epoch","A broker throws IllegalStateException if the broker epoch in the LeaderAndIsr/UpdateMetadataRequest/StopReplicaRequest is larger than its current broker epoch. However, there is no guarantee that the broker would receive the latest broker epoch before the controller: when the broker registers with ZK, there are few more instructions to process before this broker ""knows"" about its epoch, while the controller may already get notified and send UPDATE_METADATA request (as an example) with the new epoch. This will result in clients getting stale metadata from this broker.  With this PR, a broker accepts LeaderAndIsr/UpdateMetadataRequest/StopReplicaRequest if the broker epoch is newer than the current epoch.  Reviewers: David Jacot , Jason Gustafson   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","viktorsomogyi","2020-08-10T10:32:02Z","2022-01-10T13:24:49Z"
"","9462","MINOR; Fix UpdateMetadataRequestTest.testVersionLogic's assertions","`UpdateMetadataRequestTest.testVersionLogic`'s assertions must verify the deserialized request.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-10-20T15:59:58Z","2020-10-20T19:24:59Z"
"","8684","KAFKA-10012 Reducing memory overhead associated with strings in Metri…","`SelectorMetrics` has a per-connection metrics, which means the number of `MetricName` objects and the strings associated with it (such as group name and description) grows with the number of connections in the client. This overhead of duplicate string objects is amplified when there are multiple instances of kafka clients within the same JVM.  This patch address some of the memory overhead by making `metricGrpName` a constant and introducing a new constant `perConnectionMetricGrpName`. Additionally, the strings for metric name and description in `createMeter` have been interned since there are about 8 types of meter metric for every single client.","closed","","navina","2020-05-18T04:13:08Z","2020-06-08T01:44:45Z"
"","8485","MINOR; KafkaApis#handleOffsetDeleteRequest does not group result correctly","`KafkaApis#handleOffsetDeleteRequest` does not build the response correctly because `topics.add` is not in the correct loop. Fortunately, due to how the response is processed by the admin client, it works but sends redundant information on the wire.  I wrote that piece of code. Shame on me.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-04-14T15:35:44Z","2020-04-16T05:47:41Z"
"","9299","MINOR: Use `Map.forKeyValue` to avoid tuple allocation in Scala 2.13","`foreachKv` invokes `foreachEntry` in Scala 2.13 and falls back to `foreach` in Scala 2.12.  This change requires a newer version of scala-collection-compat, so update it to the latest version (2.2.0).  Finally, included a minor clean-up in `GetOffsetShell` to use `toArray` before `sortBy` since it's more efficient.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-09-17T15:22:00Z","2020-09-21T23:04:32Z"
"","8860","Change the level of logging on not being unable to process the fetch.","`Change the level of logging on not being unable to process the fetch request to trace level.`  Make the unknown fetch session message trace level to not cause confusion. There exists a fixed number of fetch sessions every broker could have.  The default is 1000.  If the cache is full and none can be evicted, then the server falls back to the consumer sending the entire subscription each time it fetches messages.  The items in the cache can be evicted after x number of sec. If the existing session is evicted, the server will send unknown fetch session error. Then the client will make a full fetch request with the subscription, trying to set up a new session. Always having to bother client, warning about this makes users mistakenly think there is a problem when there is none.  `Signed-off-by: Andrew Choi `  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","andrewchoi5","2020-06-12T19:41:06Z","2020-06-24T21:30:00Z"
"","9379","MINOR: Annotate test BlockingConnectorTest as integration test","`BlockingConnectorTest` was incorrectly running as a unit test. Categorize this test correctly as integration test by adding the appropriate annotation  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","kkonstantine","2020-10-06T01:03:22Z","2020-10-06T14:41:16Z"
"","8838","KAFKA-10158 Fix flaky kafka.admin.TopicCommandWithAdminClientTest#testDescribeUnderReplicatedPartitionsWhenReassignmentIsInProgress","```TopicCommandWithAdminClientTest.testDescribeUnderReplicatedPartitionsWhenReassignmentIsInProgress``` frequently fails on my local.  Altering the assignments is a async request so it is possible that the reassignment is still in progress when we start to verify the ""under-replicated-partitions"". In order to make it stable, it needs a wait for the reassignment completion before verifying the topic command with ""under-replicated-partitions"".  issue: https://issues.apache.org/jira/browse/KAFKA-10158  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-06-09T09:57:20Z","2020-07-18T16:28:30Z"
"","9452","MINOR: Remove unnecessary code in the ConnectHeader class","```this.schemaAndValue``` is always not null. So ```assert this.schemaAndValue != null;``` is unnecessary code.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jackyoh","2020-10-19T04:10:00Z","2020-10-20T06:46:07Z"
"","9021","KAFKA-10257 system test kafkatest.tests.core.security_rolling_upgrade…","```security_rolling_upgrade_test``` may change the security listener and then restart Kafka servers. ```has_sasl``` and ```has_ssl``` get out-of-date due to cached ```_security_config```. This PR offers a simple fix that we always check the changes of port mapping and then update the sasl/ssl flag.  issue: https://issues.apache.org/jira/browse/KAFKA-10257    ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-07-14T16:48:41Z","2020-07-16T08:36:56Z"
"","9284","KAFKA-10479 Throw exception if users try to update configs of existen…","```scala def immutableListenerConfigs(kafkaConfig: KafkaConfig, prefix: String): Map[String, AnyRef] = {       newConfig.originals.asScala.filter { case (key, _) =>         key.startsWith(prefix) && !DynamicSecurityConfigs.contains(key)       }     } ```  We don't actually compare new configs to origin configs so the suitable exception is not thrown.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-09-14T14:10:10Z","2020-09-29T19:15:09Z"
"","9296","MINOR: remove unused scala files from core module","```NoEpochForPartitionException``` and ```ClientIdAndTopic``` are not used anymore.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-09-17T03:25:57Z","2020-10-08T14:10:09Z"
"","8853","KAFKA-10147 MockAdminClient#describeConfigs(Collection","```MockAdminClient#describeConfigs(Collection)``` has new implementation introduced by https://github.com/apache/kafka/commit/48b56e533b3ff22ae0e2cf7fcc649e7df19f2b06. It is unable to handle broker resource so ```ReassignPartitionsUnitTest#testModifyBrokerThrottles``` throws NPE.  https://issues.apache.org/jira/browse/KAFKA-10147  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-06-11T08:12:47Z","2020-06-17T15:15:09Z"
"","8901","MINOR: correct the doc of transaction.timeout.ms","```InvalidTxnTimeoutException``` is what produced by broker due to illegal txn timeout.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-06-19T08:12:18Z","2020-06-23T15:33:14Z"
"","8874","HOTFIX: checkstyle error in ProcessorStateManager","``` [ant:checkstyle] [ERROR] /home/chia7712/kafka/streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java:513:18: Variable 'oldType' should be declared final. [FinalLocalVariable] ```  related to a0da6785a27b13be173762965402b55860ac5635  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","chia7712","2020-06-15T18:20:54Z","2020-06-15T19:22:31Z"
"","9228","KAFKA-10445: Align IQ SessionStore API with Instant-based methods as ReadOnlyWindowStore","[KIP-666](https://cwiki.apache.org/confluence/display/KAFKA/KIP-666%3A+Add+Instant-based+methods+to+ReadOnlySessionStore) proposal  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jeqo","2020-08-29T16:25:05Z","2021-05-07T13:29:16Z"
"","9456","MINOR: Check for active controller in UpdateFeatures request processing logic","[KIP-584]: Cherry pick PR #9436 into AK 2.7 release branch. This PR improves the code a bit to take care of a minor case.","closed","","kowshik","2020-10-19T20:11:05Z","2020-10-20T16:00:58Z"
"","9455","KAFKA-10599: Implement basic CLI tool for feature versioning system","[KIP-584]: Cherry pick PR #9409 implementing a basic CLI tool for feature versioning system, into AK 2.7 release branch.","closed","","kowshik","2020-10-19T19:51:16Z","2020-10-20T16:02:09Z"
"","8928","KAFKA-10192: Wait for REST API to become available before testing blocked connectors in integration tests","[Jira](https://issues.apache.org/jira/projects/KAFKA/issues/KAFKA-10192)  The `testBlockInConnectorStop` test is failing semi-frequently on Jenkins. It's difficult to verify the cause without complete logs and I'm unable to reproduce locally, but I suspect the cause may be that the Connect worker hasn't completed startup yet by the time the test begins and so the initial REST request to create a connector times out with a 500 error. This isn't an issue for normal tests but we artificially reduce the REST request timeout for these tests as some requests are meant to exhaust that timeout.  The changes here use a small hack to verify that the worker has started and is ready to handle all types of REST requests before tests start.  If possible, we might want to run Jenkins tests on this PR 5-10 times to see if the changes have any effect.  cc @abbccdda   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","C0urante","2020-06-25T17:24:42Z","2020-07-14T16:27:49Z"
"","8608","KAFKA-9950: Construct new ConfigDef for MirrorTaskConfig before defining new properties","[Jira](https://issues.apache.org/jira/browse/KAFKA-9950)  MM2 is currently sharing the same `ConfigDef` object for all its connectors and tasks, which would be fine _if_ that object were used as-is. However, the `MirrorTaskConfig` class mutates the `ConfigDef` by defining additional properties, which leads to a potential `ConcurrentModificationException` during worker configuration validation and unintended inclusion of those new properties in the `ConfigDef` for the connectors which in turn is then visible via the REST API's `/connectors/{name}/config/validate` endpoint.  The fix here is a one-liner that just creates a copy of the `ConfigDef` before defining new properties.  A unit test is added that fails without this fix and passes with it.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","C0urante","2020-05-04T04:58:00Z","2022-02-27T03:54:47Z"
"","8511","KAFKA-9888: Copy connector configs before passing to REST extensions","[Jira](https://issues.apache.org/jira/browse/KAFKA-9888)  The changes made in [KIP-454](https://cwiki.apache.org/confluence/display/KAFKA/KIP-454%3A+Expansion+of+the+ConnectClusterState+interface) involved adding a `connectorConfig` method to the [ConnectClusterState](https://github.com/apache/kafka/blob/ecde596180975f8546c0e8e10f77f7eee5f1c4d8/connect/api/src/main/java/org/apache/kafka/connect/health/ConnectClusterState.java) interface that REST extensions could use to query the worker for the configuration of a given connector. The implementation for this method returns the Java `Map` that's stored in the worker's view of the config topic (when running in distributed mode). No copying is performed, which causes mutations of that `Map` object to persist across invocations of `connectorConfig` and, even worse, propagate to the worker when, e.g., starting a connector.  The changes here just cause the framework to copy that map before sending it to REST extensions, and alter a comment in `KafkaConfigBackingStore` that addresses the mutability of the snapshots that it provides to warn against changes that may lead to bugs like this one.  An existing unit test is modified to ensure that REST extensions receive a copy of the connector config, not the original.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","C0urante","2020-04-18T05:31:20Z","2021-06-13T22:22:34Z"
"","8502","KAFKA-9066: Retain metrics for failed tasks","[Jira](https://issues.apache.org/jira/browse/KAFKA-9066)  Right now, sink and source task JMX metrics are dropped as soon as the task fails. The changes here cause these metrics to be retained even if the task fails, and instead only be removed when the task has been shut down (in preparation for a rebalance, due to reconfiguration, or because of connector deletion) or abandoned during that shutdown process by the worker.  Existing unit tests are modified to account for this tweak in the worker logic.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","C0urante","2020-04-16T20:25:29Z","2021-11-19T14:20:33Z"
"","9375","KAFKA-10574: Fix infinite loop in Values::parseString","[Jira](https://issues.apache.org/jira/browse/KAFKA-10574)  The special byte sequence `0xEF, 0xBF, 0xBF`, when parsed as a UTF-8 string, causes the `StringCharacterIterator` to return `CharacterIterator.DONE` from its `next()`, `current()`, and other similar methods. This caused an infinite loop in the `Values` class whenever that byte sequence was encountered.  The fix is pretty simple. To see if we're at the end of a string, we compare `StandardCharacterIterator::getIndex` to `StandardCharacterIterator::getEndIndex`, instead of comparing the last-read character to `CharacterIterator.DONE` (since that character may occur in strings that we're parsing).  I've added a unit test that replicates this bug (when the fix in the `Values` class is not present). I gave it a timeout of five seconds in case someone accidentally re-creates the infinite loop in order to save some time and potential confusion.  All existing unit tests for the `Values` class pass with this change. ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","C0urante","2020-10-05T16:50:51Z","2022-05-18T03:02:40Z"
"","9003","KAFKA-10240: Stop throwing WakeupExceptions during sink task shutdown","[Jira](https://issues.apache.org/jira/browse/KAFKA-10240)  A benign `WakeupException` can be thrown by a sink task's consumer if the task is scheduled for shutdown by the worker. This is caught and handled gracefully if the exception is thrown when calling `poll` on the consumer, but not if calling `commitSync`, which is invoked by a task during shutdown and also when its partition assignment is updated.  If thrown during a partition assignment update, the `WakeupException` is caught and handled gracefully as part of the task's `iteration` loop. If thrown during shutdown, however, it is not caught and instead leads to the scary-looking log message ""Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted."".  These changes catch the `WakeupException` during shutdown and handle it gracefully with a `TRACE`-level log message.  A unit test is added to verify this behavior by simulating a thrown `WakeupException` during `Consumer::commitSync`, running through the `WorkerSinkTask::execute` method, and confirming that it does not throw a `WakeupException` itself.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","C0urante","2020-07-09T17:11:01Z","2020-11-09T15:35:53Z"
"","8973","KAFKA-10218: Stop reading config topic in every subsequent tick if catchup fails once","[Jira](https://issues.apache.org/jira/browse/KAFKA-10218)  We added a `canReadConfigs` field to the `DistributedHerder` a while back that gets set to `false` if the herder fails to catch up to the end of the config topic, but never gets set to `true` again if catchup succeeds at a later point.  This PR adds logic to reset it to `true` when it's safe to.  A single unit test is tweaked to ensure that the herder doesn't keep unnecessarily trying to catch up to the end of the config topic during every tick.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","C0urante","2020-07-01T21:23:39Z","2020-09-29T14:45:06Z"
"","8910","KAFKA-10188: Prevent SinkTask::preCommit from being called after SinkTask::stop","[Jira](https://issues.apache.org/jira/browse/KAFKA-10188)  The general lifecycle for a sink task is:  1. Instantiate the `SinkTask` object 2. Invoke `SinkTask::initialize` 3. Invoke `SinkTask::start` 4. While the task is still running: - Poll Kafka for records - Give those records to the task via `SinkTask::put` - Periodically commit offsets, which involves calling `SinkTask::preCommit` and committing the resulting map of `TopicPartition` to offset to Kafka 5. Commit offsets a penultimate time (including the call to `SinkTask::preCommit) 6. Invoke `SinkTask::stop` 7. Close the consumer for the task 8. Commit offsets a final time (also including the call to `SinkTask::preCommit`)  This final offset commit happens indirectly: closing the consumer for a sink task causes the rebalance listener for that consumer to be triggered, and the rebalance listener the framework uses for its consumers performs an offset commit for the task when partitions are revoked.  This is a bit of a problem because the framework calls `SinkTask::stop` before closing the consumer for the task. It's possible and even likely that tasks will have de-allocated resources necessary for their `preCommit` method and will fail unexpectedly at this point.  Since the framework already [ensures that offsets are committed](https://github.com/apache/kafka/blob/199f375b546c201289d2b15084e0a95598093fe0/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java#L194-L196) after the last call to `SinkTask::put`, it should be fine to remove this extra offset commit. There is still a chance that some data may be dropped in the case that a task performs completely asynchronous writes to Kafka and has written data between the pre-stop call to `SinkTask::preCommit` and the post-stop one, but there will be no loss of delivery guarantees provided by the framework, and this change will adhere to the publicly-stated API for sink tasks.  A unit test is added that covers the internal `WorkerSinkTask::close` method and ensures that `SinkTask::preCommit` is not called during that method.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","C0urante","2020-06-22T02:59:40Z","2020-10-06T18:25:16Z"
"","8554","KAFKA-9919: Add logging to KafkaBasedLog::readToLogEnd","[Jira ticket](https://issues.apache.org/jira/browse/KAFKA-9919)  Just some simple logging additions that should make life easier when the worker can't get caught up to the end of an internal topic.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","C0urante","2020-04-25T22:24:30Z","2021-04-09T04:22:10Z"
"","8866","HOTFIX: Fix compile error in TopicAdminTest","9a4f00f78bf37041006ae8b6432d194f603ac6cc changed the constructor of DescribeConfigsResponse.  ``` /home/chia7712/kafka/connect/runtime/src/test/java/org/apache/kafka/connect/util/TopicAdminTest.java:582: error: incompatible types: int cannot be converted to Struct         return new DescribeConfigsResponse(1000, configs);                                            ^ Note: Some messages have been simplified; recompile with -Xdiags:verbose to get full output 1 error ```  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","chia7712","2020-06-13T01:07:26Z","2020-10-16T05:39:01Z"
"","8762","MINOR: Remove no longer used ReflectionsUtil class","45f2261763eac5caaebf860daab32ef5337c9293 introduced another way to load plugins and so ReflectionsUtil is unused anymore.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","chia7712","2020-05-30T17:01:53Z","2020-06-02T00:17:48Z"
"","9200","MINOR: mirror integration tests should not call System.exit","406635bcc9f2a4c439d198ea0549170de331323c switched System.exit to using Exit.exit, however the integration tests did not choose to override the exit procedure.  This can cause invalid test runs with errors like this: ``` [2020-08-18T15:52:01.142Z] * What went wrong: [2020-08-18T15:52:01.142Z] Execution failed for task ':connect:mirror:integrationTest'. [2020-08-18T15:52:01.142Z] > Process 'Gradle Test Executor 192' finished with non-zero exit value 1 [2020-08-18T15:52:01.142Z]   This problem might be caused by incorrect test process configuration. [2020-08-18T15:52:01.142Z]   Please refer to the test execution section in the User Manual at https://docs.gradle.org/6.6/userguide/java_testing.html#sec:test_execution ```","closed","","lbradstreet","2020-08-19T00:06:06Z","2020-12-02T23:07:52Z"
"","9187","MINOR: bump mockito to 3.5.0","3.5.0 the inline mock maker no longer uses any reflection and 3.5.0 is backwards compatible.","closed","","lbradstreet","2020-08-16T16:59:07Z","2020-09-16T15:41:29Z"
"","8612","KAFKA-8120 Getting NegativeArraySizeException when using Kafka Connect","1. Trigger buffer expansion when buffer does not extract a line 2. Limit buffer size to Integer.MAX_VALUE   3. Using single loop inside FileStreamSourceTask.poll  4. Close the stream before throw ConnectException 5. Move stream and buffer related function to a separate class FileStreamBuffer Check the [JIRA](https://issues.apache.org/jira/browse/KAFKA-8120) comment for the steps to verify.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","wj1918","2020-05-04T13:34:23Z","2020-05-22T17:32:25Z"
"","8834","KAFKA-10134: Enable heartbeat during PrepareRebalance and Depend On State For Poll Timeout","1. Split the consumer coordinator's `REBALANCING` state into `PREPARING_REBALANCE ` and `COMPLETING_REBALANCE`. The first is when the join group request is sent, and the second is after the join group response is received. During the first state we should still not send hb since it shares the same socket with the join group request and the group coordinator has disabled timeout, however when we transit to the second state we should start sending hb in case leader's `assign` takes long time. This is also for fixing KAFKA-10122.  2. When deciding `coordinator#timeToNextPoll`, do not count in timeToNextHeartbeat if the state is in `UNJOINED` or `PREPARING_REBALANCE` since we would disable hb and hence its timer would not be updated.  3. On the broker side, allow hb received during `PREPARING_REBALANCE`, return NONE error code instead of REBALANCE_IN_PROGRESS. However on client side, we still need to ignore REBALANCE_IN_PROGRESS if state is COMPLETING_REBALANCE in case it is talking to an old versioned broker.  4. Piggy-backing a log4j improvement on the broker coordinator for triggering rebalance reason, as I found it a bit blurred during the investigation. Also subsumed https://github.com/apache/kafka/pull/9038 with log4j improvements.  The tricky part for allowing hb during `COMPLETING_REBALANCE` is in two parts: 1) before the sync-group response is received, a hb response may have reset the generation; also after the sync-group response but before the callback is triggered, a hb response can still reset the generation, we need to handle both cases by checking the generation / state. 2) with the hb thread enabled, the sync-group request may be sent by the hb thread even if the caller thread did not call `poll` yet.    ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-06-09T00:17:11Z","2020-09-11T01:02:57Z"
"","8712","KAFKA-10006: Don't create internal topics when LeaderNotAvailableException","1. Separate the exception handler for `LeaderNotAvailableException` and `UnknownTopicOrPartitionException` 2. For `UnknownTopicOrPartitionException`, keep as is (i.e. take the topic as not existed) 3. For `LeaderNotAvailableException`, log with correct message, and keep retries until the old leader or new leader become available, or running out of retries   3.1. add a set `leaderNotAvailableTopics`, to keep the topics that has `LeaderNotAvailableException`   3.2. Before trying to add to `topicsToCreate` set, check if the topicName is in the `leaderNotAvailableTopics`, if yes, then don't add (i.e. don't create this topic b/c its leader currently is not available)   3.3. When running out of retries, throw `StreamsException` with correct message 4. add tests  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","showuon","2020-05-22T10:16:05Z","2020-07-02T20:57:39Z"
"","8750","MINOR: Code cleanup and assertion message fixes in Connect integration tests","1. Remove redundant `connect.stop();` since we'll do it after each test case in `close()` function 2. Refine the error message to make it better explain the errors  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","showuon","2020-05-29T02:13:45Z","2020-10-16T05:46:09Z"
"","8856","KAFKA-10150: task state transitions/management and committing cleanup","1. KAFKA-10150:      - always transition to SUSPENDED during `suspend`, no matter the current state     - only call `prepareCommit` before closing if `task.commitNeeded` is true 2. Don't commit any consumed offsets during `handleAssignment` -- revoked active tasks (and any others that need committing) will be committed during `handleRevocation` so we only need to worry about cleaning them up in `handleAssignment` 3. KAFKA-10152: when recycling a task we should always commit consumed offsets (if any), but don't need to write the checkpoint (since changelog offsets are preserved across task transitions)  4. Make sure we close all tasks during shutdown, even if an exception is thrown during commit 5. In-flight records were skipped when we saved the `checkpointableOffsets` before flushing in `prepareCommit` (This was the root cause of [KAFKA-10151](https://issues.apache.org/jira/browse/KAFKA-10151) -- we now don't save the offsets at all during `prepareCommit` and just write the current offsets during `postCommit`  Must be cherry-picked to 2.6","closed","streams,","ableegoldman","2020-06-12T00:36:09Z","2020-06-26T22:40:51Z"
"","8514","MINOR: Further reduce runtime for metrics integration tests","1. In both RocksDBMetrics and Metrics integration tests, we do not need to wait for consumer to consume records from output topics since the sensors / metrics are registered upon task creation.  2. Merged the two test cases of RocksDB with one app that creates two state stores (non-segmented and segmented).  With these two changes, local runtime of these two tests reduced from 2min+ and 3min+ to under a minute.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","guozhangwang","2020-04-19T00:24:01Z","2020-04-20T18:01:12Z"
"","8581","MINOR: Fix typo and rephrase content in docs","1. fix typo: `atleast` -> `at least` 2. add missing `--` to be consistent 3. rephrase a sentence, to make it more clear:  before: `LinkedIn is currently running JDK 1.8 u5 (looking to upgrade to a newer version) with the G1 collector`  It will misguide the users to use JDK 1.8 u5, while the JDK 1.8 u251 is already released, which will include many important bug fixes. I did some rephrase as below:  after: `At the time when we write this, LinkedIn is running JDK 1.8 u5 (looking to upgrade to a newer version) with the G1 collector`  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-04-29T03:55:25Z","2020-04-30T06:27:30Z"
"","8622","MINOR: Update stream documentation","1. fix broken links 2. rephrase a sentence 3. update the version number  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","docs,","showuon","2020-05-06T03:27:09Z","2020-05-20T01:39:01Z"
"","8623","MINOR: Small fixes in the documentation","1. fix broken links 2. remove redundant sentences 3. fix content format issue  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","showuon","2020-05-06T04:00:36Z","2020-05-20T01:39:57Z"
"","8515","HOTFIX: fix checkstyle error of RocksDBStoreTest and flaky RocksDBTimestampedStoreTest.shouldOpenExistingStoreInRegularMode","1. fix broken build 1. fix flaky RocksDBTimestampedStoreTest.shouldOpenExistingStoreInRegularMode  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-04-19T08:15:29Z","2020-04-19T19:32:26Z"
"","9358","MINOR: Refactor unit tests around RocksDBConfigSetter","1. Extract the mock RocksDBConfigSetter into a separate class. 2. De-dup unit tests covering RocksDBConfigSetter.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-10-01T03:09:35Z","2020-10-06T16:10:06Z"
"","8695","KAFKA-9320: Enable TLSv1.3 by default (KIP-573)","1. Enables `TLSv1.3` by default with Java 11 or newer. 2. Add unit tests that cover the various TLSv1.2 and TLSv1.3 combinations. 3. Extend `benchmark_test.py` and `replication_test.py` to run with 'TLSv1.2' or 'TLSv1.3'.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","nizhikov","2020-05-19T19:12:57Z","2020-06-02T22:34:44Z"
"","8812","KAFKA-10101: Fix edge cases in Log.recoverLog and LogManager.loadLogs","1. Don't advance recovery point in `recoverLog` unless there was a clean shutdown. 2. Ensure the recovery point is not ahead of the log end offset. 3. Clean and flush leader epoch cache and truncate produce state manager if deleting segments due to log end offset being smaller than log start offset. 4. If we are unable to delete clean shutdown file that exists, mark the directory as offline (this was the intent, but the code was wrong).  Updated one test that was failing after this change to verify the new behavior.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-06-05T16:13:16Z","2021-02-27T17:59:07Z"
"","8593","MINOR: Improve Sensor recording efficiency","1. Added a `recordInternal` function to let all other public functions trigger, so that `shouldRecord` would only be checked once.  2. In Streams, pass along the current wall-clock time inside InternalProcessorContext when process / punctuate which can be passed in to the `record` function to reduce the calling frequency of `SystemTime.milliseconds()`.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-04-30T17:45:56Z","2020-05-02T00:11:30Z"
"","9421","MINOR: Change deprecated 'scala.collection.JavaConverters' to 'scala.jdk.CollectionConverters'","... with fixing typo, removing redundant method parameters, unused Throwables, and unused test methods.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dongjinleekr","2020-10-13T08:42:29Z","2021-02-11T12:58:45Z"
"","8676","KAFKA-10005: Decouple RestoreListener from RestoreCallback",".. and remove bulk loading mechanism inside RocksDB.  We need to validate in benchmarks that removing bulk loading would not incur large perf regression; if yes, we should consider adding other optimizations like separate thread polls and parallel writes before merging this PR.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-05-15T19:38:35Z","2020-06-08T21:18:40Z"
"","8870","MINOR: Fix timestampDelta type in doc","- Type of `timestampDelta` is written as `varint` in the doc, but actually it's `varlong`   * https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/record/DefaultRecord.java#L47  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ocadaruma","2020-06-14T09:49:49Z","2020-10-22T08:42:54Z"
"","8833","KAFKA-9441: remove prepareClose() to simplify task management","- Removes `prepareCloseClean()` and `prepareCloseDirty()`. - Removes state transition `RUNNING -> CLOSED` (tasks must be suspended before closing now) - replaces `suspend()` with `suspendDirty` and `suspendAndPrepareCommit()` - Decouples suspending/committing/closing (ie, no redundant code any longer, but enforces ""linear"" order of calls)  Call for review @guozhangwang @abbccdda @vvcephei @ableegoldman @cadonna","closed","kip,","mjsax","2020-06-08T17:12:21Z","2020-06-12T23:08:04Z"
"","8948","KAFKA-10174: Prefer --bootstrap-server for configs command in ducker tests","- Preferred when version >= 2.6.0  - Small renaming to make context clearer  - truncation_test.py and message_format_change_test.py pass locally as well as in CI  - Added prints to test to verify, it is indeed invoking --bootstrap-server  http://confluent-kafka-branch-builder-system-test-results.s3-us-west-2.amazonaws.com/2020-06-26--001.1593219250--vinothchandar--KAFKA-10174--1efed8fb5/report.html  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vinothchandar","2020-06-29T13:41:01Z","2020-07-16T16:39:19Z"
"","9060","KAFKA-9274: Remove `retries` from InternalTopicManager","- part of KIP-572  - replace `retries` in InternalTopicManager with infinite retires plus    a new timeout, based on consumer config MAX_POLL_INTERVAL_MS - if the new timeout hits, we don't throw `StreamsException` any longer (as we did when exceeding retries), but send `INCOMPLETE_SOURCE_TOPIC_METADATA` error code to let all instances shut down  Third PR for KIP-572 (cf #8864 and #9047)  Call for review @vvcephei","closed","kip,","mjsax","2020-07-23T04:06:04Z","2020-09-30T18:30:16Z"
"","9047","KAFKA-9274: Remove `retries` for global task","- part of KIP-572  - removed the usage of `retries` in `GlobalStateManger`  - instead of retries the new `task.timeout.ms` config is used  Second PR for KIP-572 (cf. #8864)  Call for review @vvcephei   Docs Screenshots:  Main upgrade guide:  ![Screen Shot 2020-08-04 at 10 26 48 AM](https://user-images.githubusercontent.com/8959638/89325274-6ab7c900-d63d-11ea-8a26-87da8e98337b.png)  Streams upgrade guide:  ![Screen Shot 2020-08-04 at 10 27 24 AM](https://user-images.githubusercontent.com/8959638/89325286-6ee3e680-d63d-11ea-97d9-6661c8c4ccea.png)  Snippet from StreamConfig:  ![Screen Shot 2020-08-04 at 10 28 37 AM](https://user-images.githubusercontent.com/8959638/89325306-73100400-d63d-11ea-8257-53b151fbd25a.png)","closed","kip,","mjsax","2020-07-21T07:21:50Z","2020-08-05T21:14:24Z"
"","9368","KAFKA-9274: Add timeout handling for state restore and StandbyTasks","- part of KIP-572  If a `TimeoutException` happens during restore of active tasks, or updating standby tasks, we need to trigger `task.timeout.ms` timeout.","closed","kip,","mjsax","2020-10-03T01:55:21Z","2021-01-08T02:04:26Z"
"","8679","KAFKA-10003: Mark KStream.through() as deprecated","- part of KIP-221","closed","kip,","mjsax","2020-05-17T02:49:10Z","2020-06-12T23:09:16Z"
"","8776","KAFKA-9441: Improve Kafka Streams task management","- make task manager agnostic to task state  - make tasks state transitions idempotent","closed","kip,","mjsax","2020-06-02T06:55:31Z","2020-06-12T23:08:10Z"
"","8820","KAFKA-10097: Internalize checkpoint data","- make checkpoint an internal data structure to avoid awkward passing around. - remove the possibility of getting a null checkpoint map   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","abbccdda","2020-06-06T00:27:07Z","2020-06-07T00:44:21Z"
"","8737","KAFKA-9945: TopicCommand should support --if-exists and --if-not-exists when --bootstrap-server is used","- Fixed command line arg checking  - Added unit test cases  - Local testing with a multi node Kafka cluster  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vinothchandar","2020-05-28T00:30:36Z","2020-06-02T23:17:15Z"
"","8503","Minor: Some html fixes in Streams DSL documentation","- duplicate id  - duplicate opening  element  - surplus closing  tag  Built website and checked working links for duplicate id.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","soenkeliebau","2020-04-16T21:56:32Z","2020-04-23T09:44:37Z"
"","8937","MINOR: Create ChannelBuilder for each connection in ConnectionStressWorker workload","- Currently we create single channel builder and reuse it in ConnectStressor workload.  This will fail when testing with secure connections, as we close channel builder after first connection.  This PR creates  ChannelBuilder for each test connection.  - Also increase to connect ready wait timeout to 500ms.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","omkreddy","2020-06-27T15:00:21Z","2020-07-09T19:22:05Z"
"","9242","MINOR: Fix misleading doc for replication quota","- Current docs for replication quota config are bit confusing because they contain a term ""(for each topic)"" though actually they work as upper bound for ""total"" replication traffic listed in `{leader/follower}.replication.throttled.replicas`.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","ocadaruma","2020-09-02T05:03:45Z","2020-09-02T05:03:45Z"
"","8728","MINOR: Slight MetadataCache tweaks to avoid unnecessary work","- Avoid tuple allocations by using `Map.update` instead of `+=` - Use `empty` instead of `apply` to avoid unnecessary array allocation  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-05-26T15:28:57Z","2020-05-28T04:03:41Z"
"","9046","KAFKA-9432:(follow-up) Set `configKeys` to null in `describeConfigs()` to make it backward compatible with older Kafka versions.","- After #8312, older brokers are returning empty configs,  with latest `adminClient.describeConfigs`.  Old brokers  are receiving empty configNames in `AdminManageer.describeConfigs()` method. Older brokers does not handle empty configKeys. Due to this old brokers are filtering all the configs. - Update ClientCompatibilityTest to verify describe configs - Add test case to test describe configs with empty configuration Keys  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","omkreddy","2020-07-20T20:53:12Z","2020-07-21T12:03:03Z"
"","8534","KAFKA-9512: Backport Flaky Test LagFetchIntegrationTest.shouldFetchLagsDuringRestoration","- Added additional synchronization and increased timeouts to handle flakiness - Added some pre-cautionary retries when trying to obtain lag map  *More detailed description of your change, Backport of PR #8076    ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vinothchandar","2020-04-22T17:41:20Z","2020-04-23T00:15:30Z"
"","9041","MINOR: Enable broker/client compatibility tests for 2.5.0 release","- Add missing broker/client compatibility tests for 2.5.0 release  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","omkreddy","2020-07-18T12:55:00Z","2020-07-20T12:51:31Z"
"","9461","MINOR: Clean-up streams javadoc warnings","*Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","bbejeck","2020-10-20T15:09:18Z","2020-10-20T23:41:12Z"
"","8825","KAFKA-7833: Add StateStore name conflict check in InternalTopologyBuilder","*Summary of testing strategy (including rationale) * Added two tests that calls `addGlobalStore` and `addStateStore` in two different orders * Added check for name conflict with a global store in the `addStateStore` path  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","chebbyChefNEQ","2020-06-07T06:37:36Z","2020-06-11T00:16:30Z"
"","8615","KAFKA-9954: Config command didn't validate the unsupported user config change","*More detailed description of your change, Throw an error when users are trying to alter user configs with AdminClient  *Summary of testing strategy `bin/kafka-configs.sh --bootstrap-server localhost:9092 --alter --add-config producer_byte_rate=44444 --entity-type users --entity-default`  will return  > Alternating user configs using AdminClient is not supported yet   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ctan888","2020-05-05T00:55:16Z","2020-05-26T22:03:49Z"
"","9363","KAFKA-10561: Timestamp Microseconds support","*More detailed description of your change, The purpose of this PR is to support microseconds precision when dealing with timestamps.  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","kip,","danielpetisme","2020-10-01T20:22:24Z","2021-06-29T22:26:56Z"
"","8610","KAKFA-9942: --entity-default flag is not working for alternating / describing configs in AdminClient","*More detailed description of your change, The client-side passes an empty string """" to the server controller indicating that the quota changes apply to the default entity. However, the server logic fails to convert the empty string to """", which will lead to the query for zk node ""/config/"" and cause an exception.  Will remove all the warning level log before merge.  *Summary of testing strategy (including rationale) Tested all the failed commands in the corresponding Jira ticket, except alter the default quota configs for entity type user, as the API hasn't been implemented.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ctan888","2020-05-04T09:35:38Z","2020-05-10T12:56:45Z"
"","9463","MINOR: Clean-up client javadoc warnings","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  To validate fix run `./gradlew javadoc`.  Note that this PR only addresses `client` javadoc warnings, there's #9461 for the streams warnings ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","bbejeck","2020-10-20T16:04:20Z","2020-10-20T19:56:30Z"
"","8683","KAFKA-9893: Configurable TCP connection timeout and improve the initial metadata fetch","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  1. Added a new common client configuration parameter socket.connection.setup.timeout.ms to the NetworkClient. Handle potential transportation layer timeout using the same approach as it handling potential request timeout. 2. When no connected channel exists, leastLoadedNode() will now provide a disconnected node that has the least recent connection attempts.  3. ClusterConnectionStates will keep the connecting node ids. Now it also has several new public methods to provide per connection relavant data.  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  1. A unit test for the basic functionality of the new configuration 2. A unit test for optimized leastLoadedNode() 3. Use docker scenarios for system tests. May add a duckertape test.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ctan888","2020-05-18T01:41:48Z","2020-08-17T16:15:44Z"
"","9167","KAFKA-9941;WorkerSinkTask：When a record triggers a RetriableException and the retry is processed successfully, its offset does not commit.","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [x] Verify design and implementation  - [x] Verify test coverage and CI build status - [x] Verify documentation (including upgrade notes)","open","connect,","aluode99","2020-08-12T03:45:10Z","2021-09-16T15:07:23Z"
"","8982","Adding metrics to measure the idempotent producers","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [x] Verify design and implementation  - [x] Verify test coverage and CI build status - [x] Verify documentation (including upgrade notes)","open","producer,","mingaliu","2020-07-05T20:53:26Z","2020-07-14T19:02:43Z"
"","8763","Ouweiqi","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [x] Verify design and implementation  - [x] Verify test coverage and CI build status - [x] Verify documentation (including upgrade notes)","closed","","nikepakou","2020-05-31T10:32:41Z","2020-05-31T10:33:23Z"
"","8761","Remove redundant code of KafkaProducer","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [x] Verify design and implementation  - [x] Verify test coverage and CI build status - [x] Verify documentation (including upgrade notes)","closed","","tswstarplanet","2020-05-30T13:00:52Z","2020-05-30T15:13:08Z"
"","9443","MINOR: fix error in quota_test.py system tests","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rondagostino","2020-10-15T16:03:02Z","2020-10-15T16:08:43Z"
"","9432","KAFKA-10559: Not letting TimeoutException shutdown the app during internal topic validation","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vamossagar12","2020-10-14T10:24:34Z","2020-10-20T17:33:35Z"
"","9424","2.7","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","lee9210","2020-10-13T16:25:37Z","2020-10-13T16:25:51Z"
"","9372","MINOR: Fix failing test due to KAFKA-10556 PR","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rondagostino","2020-10-04T20:01:47Z","2020-10-06T08:13:35Z"
"","9356","KAFKA-10556: NPE if sasl.mechanism is unrecognized","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rondagostino","2020-09-30T15:42:36Z","2020-10-04T20:04:06Z"
"","9300","KAFKA-10491: Check authorizations first in KafkaApis","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","rondagostino","2020-09-17T17:44:49Z","2021-02-03T09:47:02Z"
"","9292","KAFKA-8238: adding number of messages/bytes read","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","vamossagar12","2020-09-16T15:00:44Z","2020-10-27T03:33:28Z"
"","9289","Dev/pasriva/json acl","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","pasriva","2020-09-15T12:24:53Z","2022-02-04T20:27:14Z"
"","9254","KAFKA-10462: Added support to pass headers in producerPerformance script","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","vgvineet4","2020-09-05T07:44:45Z","2020-11-21T17:56:00Z"
"","9233","Testing","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rondagostino","2020-08-31T12:48:36Z","2020-08-31T12:51:28Z"
"","9209","Minor enhance copy array","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","khaireddine120","2020-08-22T12:54:30Z","2020-09-12T12:16:44Z"
"","9208","Minor init singleton list","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","khaireddine120","2020-08-22T12:53:42Z","2020-09-12T11:59:45Z"
"","9207","Minor remove semicolon","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","khaireddine120","2020-08-22T12:38:36Z","2020-09-13T16:30:46Z"
"","9203","MINOR: Fix typo in LeaderEpochFileCacheTest","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","huxihx","2020-08-20T06:22:04Z","2020-08-21T00:43:52Z"
"","9190","2.5.x rebase from upstream","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jwijgerd","2020-08-17T09:02:41Z","2020-08-17T09:03:08Z"
"","9093","Throw error on when keys not found in FileConfigProvider","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","cyrusv","2020-07-28T20:01:28Z","2020-07-29T03:09:44Z"
"","9010","KAFKA-10262: Ensure that creating task directory is thread safe","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","mjsax","2020-07-10T23:56:25Z","2020-07-11T18:20:23Z"
"","8875","Update to run coverage on Jenkins","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","thomasrockhu","2020-06-15T19:21:03Z","2020-06-15T19:48:05Z"
"","8867","KC-298: Implement DescribeQuorum API","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-06-13T04:21:58Z","2020-06-13T04:22:21Z"
"","8862","Dev/t toacin/2 4 1 mirror maker","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","tommyacin","2020-06-12T21:27:49Z","2022-02-10T16:32:44Z"
"","8855","DO NOT MERGE","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","mjsax","2020-06-12T00:11:12Z","2020-07-09T01:05:58Z"
"","8817","HOT_FIX: Update javadoc since imports added","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","bbejeck","2020-06-05T18:46:55Z","2020-06-05T22:32:41Z"
"","8797","Fixing KAFKA-10094","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","mtillu","2020-06-03T22:02:09Z","2020-06-06T18:03:47Z"
"","8781","Read kafka","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","collabH","2020-06-02T15:45:27Z","2020-06-02T15:45:43Z"
"","8780","Read kafka","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","collabH","2020-06-02T15:44:12Z","2020-06-02T15:44:33Z"
"","8732","KAFKA-10017: disable flaky EosBetaUpgradeIntegrationTest to stabilize build","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","mjsax","2020-05-27T17:31:22Z","2020-05-28T03:55:41Z"
"","8729","KC-276: Enhanced raft exception handling","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-05-26T23:03:55Z","2020-05-26T23:05:37Z"
"","8721","2.3 fork update","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","birdgodtech","2020-05-23T04:18:37Z","2020-05-23T04:20:16Z"
"","8639","KAFKA-9962: Make the auth operations fields ignorable","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jsancio","2020-05-10T00:28:26Z","2020-06-03T15:53:21Z"
"","8570","Change type to optional in config entry","*More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","leonardge","2020-04-28T08:55:08Z","2020-05-01T22:02:22Z"
"","8544","[WIP]KAFKA-9893: Configurable TCP connection timeout and improve the initial metadata fetch","*More detailed description of your change,  **Selector** The Selector class will now take the new config CONNECTIONS_TIMEOUT_MS_CONFIG in its constructions.    **idleExpiryManager** Currently, we have an idleExpiryManager that uses the LRU algorithm evicting the oldest idle connected socket channels. Similarly, we can instantiate a new LinkedHashMap to keep those socket channels initiating the connection and evict the timeout channels.  Currently, all the channels will be kept on the same LRU map. We will split the connected socket channels and connecting socket channels into different LRU map (we will call them ""lruConnectingConnections"" and ""lruConnectedConnections"" later).  Here's the state transition:  When the socket channel is initiating the connection, we will put the socket channel to the lruConnectingConnections.  When the connection is successfully built, we will move the channel from lruConnectingConnections into lruConnectedConnections.  In each selector poll, we will remove the oldest timeout socket channel in both lruConnectingConnections and lruConnectedConnections, if possible.   **LeastLoadedNodeProvider** Currently, when no nodes provided in --boostrap-server option is connected, the LeastLoadedNodeProvider will provide an unconnected node for the client. The Cluster class shuffled the nodes to balance the initial pressure and the LeastLoadedNodeProvider will always provide the same node, which is the last node after shuffling. Consequently, though we may provide several bootstrap servers, the client not be able to connect to the cluster if any of the servers in the --bootstrap-server list is offline.  I'm changing the provider to interact with the ClusterConnectionStates to determine which node to provide when no connection exists.   **ClusterConnectionStates** ClusterConnectionStates will keep the index of the most recently provided node. Meanwhile, a public API looks like below will be added to simulate the round-robin node picking.  public synchronized int nextNodeIdx(int nodeSize) {           return (this.nextNodeIdx++) % nodeSize; }  The LeastLoadedNodeProvider will provide the nodeSize to prevent the out of bound excpetion.   When the LeastLoadedNodeProvider iterates the node list, it can consult the ClusterConnectionStates for the index of the node it should provide.   *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ctan888","2020-04-24T10:22:05Z","2020-06-30T22:26:34Z"
"","9076","MINOR - fix typo","*FIx typo in ProducerConfig*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","wangxianghu","2020-07-25T10:47:52Z","2020-07-27T02:07:44Z"
"","9120","KAFKA-10316: Consider renaming getter method for Interactive Queries","*Deprecated the existing getters and added new getters `activeHost()`, `standbyHosts()`, and `partition()` in KeyQueryMetadata.java.  *Updated the existing Tests to use the new getters of KeyQueryMetadata.java . Below are the Test classes that were updated with new getters.      OptimizedKTableIntegrationTest.java     QueryableStateIntegrationTest.java     StoreQueryIntegrationTest.java     StreamsMetadataStateTest.java  *Corrected JavaDoc nits in the deprecated methods.  @mjsax @abbccdda @vvcephei @brary Since you've voted on the KIP, please feel free to review.   ### Committer Checklist (excluded from commit message) - [x] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","johnthotekat","2020-08-04T07:32:07Z","2020-08-07T05:00:17Z"
"","9255","KAFKA-6585: Consolidate duplicated logic on reset tools","*Consolidated Duplicate DateTime logic from ConsumerGroupCommand and StreamResetter in common Client Utils*  [https://issues.apache.org/jira/browse/KAFKA-6585](https://issues.apache.org/jira/browse/KAFKA-6585)  *Summary of testing strategy (including   ##rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tools,","manijndl7","2020-09-05T19:48:24Z","2020-09-30T17:13:15Z"
"","8557","MINOR: fix typo ""transation"" in AddPartitionsToTxnRequest.json","**transation** -> **transaction**  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-04-27T06:24:43Z","2020-05-01T22:04:17Z"
"","8680","KAFKA-10027: Implement read path for feature versioning system (KIP-584)","**TL;DR:** In this PR, I have implemented various classes and integration for the read path of the feature versioning system ([KIP-584](https://cwiki.apache.org/confluence/display/KAFKA/KIP-584%3A+Versioning+scheme+for+features)). The ultimate plan is that the cluster-wide **finalized** features information is going to be stored in ZK under the node `/feature`. The read path implemented in this PR is centered around reading this **finalized** features information from ZK, and, processing it inside the Broker.  Here is a summary of what's in this PR (a lot of it is **new** classes):   - A facility is provided in the broker to declare it's supported features, and advertise it's supported features via it's own `BrokerIdZNode` under a `features` key. - A facility is provided in the broker to listen to and propagate cluster-wide **finalized** feature changes from ZK. - When new **finalized** features are read from ZK, feature incompatibilities are detected by comparing against the broker's own supported features. - `ApiVersionsResponse` is now served containing supported and finalized feature information (using the newly added tagged fields).  More details below.  **New IBP config value:** The feature versioning system is implemented such that it is activated only if the IBP >= `KAFKA_2_7_IV0` (newly defined value in this PR). That is because, we would like to keep the feature version system disabled (almost as if it is non-existent) until the user upgrades the cluster to or beyond IBP `KAFKA_2_7_IV0`.  **New common libraries (Java):**  A set of common libraries abstracting features have been introduced. Features are a map with key being `String` (feature name) and value being a  `VersionRangeType` (the range of supported or finalized versions for the feature). These common libraries are defined as 4 new classes in: `org.apache.kafka.common.feature.{Features, BaseVersionRange, SupportedVersionRange, FinalizedVersionRange}`.  The reason why it is kept in this common package is that future client and tooling development could reuse some/all of these abstractions.  **New broker libraries (Scala):**  The above common libraries are used within the Broker code to implement the read path for feature information, as explained below.    1. **`FinalizedFeatureCache`**: Implemented a cache of cluster-wide finalized features (see companion object: `FinalizedFeatureCache`). This cache stores the latest finalized features and epoch read from the `/feature` node in ZK. Currently the main reader of this cache is the read path that serves an `ApiVersionsRequest` returning the features information in the response. In the future, as we start using the versioning system more, the cache could be read by future read paths intending to learn the finalized feature information. **Note:** this is defined as a companion object (a singleton),  because, this way it will be easy to share read access with any code path in the Broker.    2. **`FinalizedFeatureChangeListener`**: Implemented a feature ZK node change listener, that, listens to changes in the `/feature` node in ZK, and, invalidates the cache defined in `FinalizedFeatureCache` (see above point). See class: `FinalizedFeatureChangeListener`.  An instance of this class is maintained in `KafkaServer`, and initialized only if the IBP is set to `KAFKA_2_7_IV0` or higher.    3. **`SupportedFeatures`**: Implemented a facility to define supported features within the Broker (these are specific to a broker binary). See companion object: `SupportedFeatures`. Currently the list of supported features is empty, because, we have not identified features (yet). In the future this class can be populated as we begin to define supported features. Also, the public interface of this class provides a way to compare supported vs finalized features to detect incompatibilities. **Note:** this is a companion object (a singleton), because, it makes it easy to define supported features at a common point and also share read access with any code path in the Broker.  **New Zookeeper node: `/feature`:** The finalized feature information is going to be stored in ZK under the node `/feature`. 1. The class backing the new node is `FeatureZNode`. It provides required state and encode/decode APIs that abstract the structure of the new feature ZK node. 2. Implemented new APIs in `KafkaZkClient.scala` to read/update/delete the `/feature` ZK node.  **Broker advertisements:** A facility is provided in the broker to declare it's supported features (via the `SupportedFeatures` class), and advertise it's supported features via it's own `BrokerIdZNode` under a `features` key (only if IBP >=`KAFKA_2_7_IV0`). The encode/decode logic for the new `features` key is provided in this PR in the class `BrokerIdZNode`.    **Updated ApiVersionsResponse**:  Defined new tagged fields in existing `ApiVersionsResponse` schema. In the request serving path (in `KafkaApis.scala`), these fields are populated in the response with the latest supported features (from `SupportedFeatures`) and latest finalized features (from `FinalizedFeatureCache`).  **Tests:** Added test suites for all of the new classes, and changes made in this PR.","closed","","kowshik","2020-05-17T09:00:58Z","2020-06-11T18:28:58Z"
"","9001","KAFKA-10028: Implement write path for feature versioning system (KIP-584)","**Summary:** In this PR, I have implemented the write path of the feature versioning system (KIP-584).  Here is a summary of what's in this PR:  - New APIs in `org.apache.kafka.clients.admin.Admin` interface, and their client and server implementations. These APIs can be used to describe features and update finalized features. These APIs are: `Admin#describeFeatures` and `Admin#updateFeatures`.     - The write path is provided by the `Admin#updateFeatures` API. The corresponding server-side implementation is provided in `KafkaApis` and `KafkaController` classes. This can be a good place to start the code review.     - The write path is supplemented by `Admin#describeFeatures` client API. This does not translate 1:1 to a server-side API. Instead, under the hood the API makes an explicit `ApiVersionsRequest` to the Broker to fetch the supported and finalized features.  - Implemented a suite of integration tests in `UpdateFeaturesTest.scala` that thoroughly exercises the various cases in the write path.  **Other changes:**  - The data type of the `FinalizedFeaturesEpoch` field in `ApiVersionsResponse` has been modified from `int32` to `int64`. This change is to conform with the latest changes to the KIP explained in the voting thread (see [this link](https://lists.apache.org/thread.html/rf7fb6a033638c43a338be5cc316e9e69df6e2589fab66b69d8b67f0f%40%3Cdev.kafka.apache.org%3E)).  - Along the way, the class `SupportedFeatures` has been renamed to be called `BrokerFeatures`, and, it now holds both supported features as well as default minimum version levels.  - For the purpose of testing, both the `BrokerFeatures` and `FinalizedFeatureCache` classes have been changed to be no longer singleton in implementation. Instead, these are now instantiated once and maintained in `KafkaServer`. The singleton instances are passed around to various classes, as needed.  **Test plan:**  - Relying on existing and unit and integration tests added in this PR.","closed","core,","kowshik","2020-07-09T10:50:51Z","2020-10-08T09:26:13Z"
"","8516","Minor: KAFKA-4650 - 100% Test Coverage of TaskState.java","**Disclaimer** This is my first Contribution to this project, not even sure I am doing this correctly.  Ticket found [here](https://issues.apache.org/jira/browse/KAFKA-4650?jql=project%20%3D%20KAFKA%20AND%20labels%20%3D%20newbie%20AND%20status%20%3D%20Open)  *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  I am adding test code to increase coverage for the packages.  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  I generated new test functions in order to get 100% code coverage on the project.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","benbianchi","2020-04-19T19:22:20Z","2020-04-20T21:09:19Z"
"","9244","Consolidate duplicated logic on reset tools","**Consolidated Duplicate DateTime logic from ConsumerGroupCommand and StreamResetter in common Client Utils**  [https://issues.apache.org/jira/browse/KAFKA-6585](url)  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tools,","manijndl7","2020-09-02T09:29:15Z","2020-09-05T20:15:10Z"
"","8611","MINOR: Format the notation content for better readability","**before:** ![image](https://user-images.githubusercontent.com/43372967/80954688-745c4580-8e30-11ea-9330-fe7f6321adce.png)  Here, the notation words are not in different format, makes it hard to read.  Especially the last arrow example `/hello -> world`, it's hard to understand it if you don't read carefully.  **after:** ![image](https://user-images.githubusercontent.com/43372967/80954777-9ce43f80-8e30-11ea-851f-ab45a4f8f133.png)   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","docs,","showuon","2020-05-04T10:04:26Z","2020-05-08T23:45:16Z"
"","8654","KAFKA-9931: Implement KIP-605 to expand support for Connect worker internal topic configurations","**[KIP-605](https://cwiki.apache.org/confluence/display/KAFKA/KIP-605%3A+Expand+Connect+Worker+Internal+Topic+Settings) has passed.**  Expanded the allowed values for the internal topics’ replication factor and partitions from positive values to also include -1 to signify that the broker defaults should be used.  The Kafka storage classes were already constructing a `NewTopic` object (always with a replication factor and partitions) and sending it to Kafka when required. This change will avoid setting the replication factor and/or number of partitions on this `NewTopic` if the worker configuration uses -1 for the corresponding configuration value.  Quite a few new tests were added to verify that the `TopicAdmin` utility class is correctly using the AdminClient, that the `DistributedConfig` validators for these configurations are correct, and that the `DistributedConfig` is correctly assembling the configuration properties that define the topic settings, which are now accessed by the three Kafka storage objects before they create the topics.  Also added support for additional topic settings used when creating the config, status, and offset internal topics.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","rhauch","2020-05-12T14:18:54Z","2020-05-23T14:00:33Z"
"","8642","MINOR: Use `forEach` and `ifPresent` to simplify Scala code","* Use `forEach` instead of `asScala.foreach` for Java Iterables. * Use `ifPresent` instead of `asScala.foreach` for Java Optionals. * Use `forEach` instead of `entrySet.forEach` for Java maps. * Keep `asScala.foreach` for `Properties` as the Scala implementation has a better interface (keys and values are of type `String`). * A few clean-ups: unnecessary `()`, `{}`, `new`, etc.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-05-10T16:04:24Z","2020-05-11T14:26:38Z"
"","8546","MINOR: document how to escape json parameters to ducktape tests","* update the readme with an example of correctly escaped JSON to be passed as the parameters to a parameterized ducktape tests in docker  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-04-24T21:04:08Z","2020-04-27T23:22:07Z"
"","8672","KAFKA-10002; Improve performances of StopReplicaRequest with large number of partitions to be deleted","* Update checkpoint files once for all deleted partitions instead of updating them for each deleted partitions. With this, a stop replica requests with 2000 partitions to be deleted takes ~2 secs instead of ~40 secs previously. * Refactor the checkpointing methods to not compute the `logsByDir` all the time. It is now reused as much as possible. * Refactor the exception handling. Some checkpointing methods were handling `IOException` but the underlying write process already catches them and throws KafkaStorageException instead. * Reduce the logging in the log cleaner manager. It does not log anymore when a partition is deleted as it is not a useful information.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-05-15T09:27:45Z","2020-10-06T20:09:18Z"
"","9146","KAFKA-10316 Updated Kafka Streams upgrade-guide.html","* This PR updates the upgrade guide for the changes in https://github.com/apache/kafka/pull/9120. * Added the details on KIP-648 to 2.7.0 upgrade notes - docs/streams/upgrade-guide.html. @mjsax","closed","docs,","johnthotekat","2020-08-08T04:39:29Z","2020-08-26T21:22:15Z"
"","9133","KAFKA-10316: Updated Kafka Streams upgrade notes.","* This PR updates the upgrade guide for the changes in https://github.com/apache/kafka/pull/9120. * Added the details on KIP-648 to 2.7.0 upgrade notes - `docs/streams/upgrade-guide.html`.  @mjsax","closed","docs,","johnthotekat","2020-08-07T04:29:36Z","2020-08-08T04:58:41Z"
"","9367","KAFKA-10570 Rename JMXReporter configs for KIP-629","* rename whitelist/blacklist to include/exclude * add utility methods to translate deprecated configs","closed","","xvrl","2020-10-02T22:11:29Z","2020-10-13T19:36:29Z"
"","8527","Remove dependencies on deprecated --zookeeper command flags in junit tests","* Removed the --zookeeper flag related tests. Scram credential related tests are also get removed since they are using --zookeeper flag.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ctan888","2020-04-22T03:38:27Z","2020-05-04T21:34:24Z"
"","8528","System tests should use --bootstrap-server rather than --zookeeper when testing new Kafka versions","* Remove the --zookeeper flags for node versions supporting --bootstrap-server for TopicCommand. For the scram credential related code piece, switched to using --bootstrap-server even we don't support it yet.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ctan888","2020-04-22T04:44:14Z","2020-12-02T17:43:16Z"
"","8882","KAFKA-10165: Remove Percentiles from e2e metrics","* Remove problematic Percentiles measurements until the implementation is fixed * Fix leaking e2e metrics when task is closed * Fix leaking metrics when tasks are recycled  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-06-16T20:14:37Z","2020-06-17T19:26:59Z"
"","9072","KAFKA-10162; Make the rate based quota behave more like a Token Bucket (KIP-599, Part III)","* Introduce a new SampledStat named TokenBucket * Change the ControllerMutationManager to use it by default  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-07-24T09:55:19Z","2020-10-06T20:07:25Z"
"","8935","KAFKA-10189: reset event queue time histogram when queue is empty","* https://issues.apache.org/jira/browse/KAFKA-10189 * add a timeout for event queue time histogram * reset `eventQueueTimeHist` when the controller event queue is empty * unit test for resetting event queue time histogram   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jeffkbkim","2020-06-27T00:40:58Z","2020-08-21T21:32:40Z"
"","8643","KAFKA-9956: Authorizer APIs may be invoked more than once for a given request","* Fix describeConfigs and alterConfigs not to invoke authorizer more than once * Add tests to KafkaApisTest to verify the fixes * Rename `filterAuthorized` to `filterByAuthorized` * Tweak `filterByAuthorized` to take resources instead of resource names and improve implementation * Introduce `partitionMapByAuthorized` and `partitionSeqByAuthorized` and simplify code by using it * Replace List with Seq in some AdminManager methods * Remove stray `println` in `KafkaApisTest`  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-05-10T21:54:15Z","2020-05-11T20:38:09Z"
"","8574","KAFKA-9925: decorate pseudo-topics with app id","* ensure that pseudo-topics get correctly prefixed with the app id at run time * update test to expect the app id prefix  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-04-28T16:26:46Z","2020-04-29T22:31:07Z"
"","8618","KAFKA-9955: Prevent SinkTask::close from shadowing other exceptions","* Catches exceptions from WorkerSinkTask::closePartitions call * If two exceptions are thrown the `closePartitions` exception is suppressed * Add unit test that throws exceptions in put and close to verify that   the exception from put is propagated out of WorkerSinkTask::execute  Signed-off-by: Greg Harris   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","gharris1727","2020-05-05T03:58:33Z","2020-05-16T00:53:33Z"
"","8756","KAFKA-10049: Fix default SubscriptionWrapper inner serde","* Allow wrapper serdes to choose whether they need to wrap the   default key or value serde. * Fix the SubscriptionWrapperSerde to wrap the default key serde,   not the default value serde.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-05-29T17:07:31Z","2020-05-29T18:15:23Z"
"","9388","KAFKA-10562: Properly invoke new StateStoreContext init","* all wrapping stores should pass StateStoreContext init through to the same   method on the wrapped store and not translate it to ProcessorContext init * base-level stores should handle StateStoreContext init so that callers passing   a non-InternalProcessorContext implementation will be able to initialize the store * extra tests are added to verify the desired behavior  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","vvcephei","2020-10-07T03:23:36Z","2021-01-08T02:04:05Z"
"","8699","KAFKA-9673: Filter and Conditional SMTs","* Add Predicate interface * Add Filter SMT * Add the predicate implementations defined in the KIP. * Create abstraction in ConnectorConfig for configuring Transformations and Connectors with the ""alias prefix"" mechanism * Add tests and fix existing tests.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","tombentley","2020-05-20T18:33:59Z","2020-05-28T13:54:31Z"
"","8541","KAFKA-6145: KIP-441: Add TaskAssignor class config","* add a config to set the TaskAssignor * set the default assignor to HighAvailabilityTaskAssignor * fix broken tests  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-04-23T23:21:42Z","2020-04-28T20:57:12Z"
"","8617","MINOR: MockAdminClient should return InvalidReplicationFactorException if brokers.size < replicationFactor","* `MockAdminClient` should behave the same way as `Admin` for `createTopics()` * Changed from throwing an `IllegalArgumentException` to `InvalidReplicationFactorException` when `brokers.size() < replicationFactor`  ``` Jeff-Kims-MBP15:kafka_2.13-2.6.0-SNAPSHOT jeff.kim$ bin/kafka-topics.sh --create --topic test-topic --replication-factor 3 --bootstrap-server localhost:9092 Error while executing topic command : org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1. [2020-05-04 19:40:34,855] ERROR java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1. 	at org.apache.kafka.common.internals.KafkaFutureImpl.wrapAndThrow(KafkaFutureImpl.java:45) 	at org.apache.kafka.common.internals.KafkaFutureImpl.access$000(KafkaFutureImpl.java:32) 	at org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:89) 	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:260) 	at kafka.admin.TopicCommand$AdminClientTopicService.createTopic(TopicCommand.scala:248) 	at kafka.admin.TopicCommand$TopicService.createTopic(TopicCommand.scala:200) 	at kafka.admin.TopicCommand$TopicService.createTopic$(TopicCommand.scala:195) 	at kafka.admin.TopicCommand$AdminClientTopicService.createTopic(TopicCommand.scala:223) 	at kafka.admin.TopicCommand$.main(TopicCommand.scala:62) 	at kafka.admin.TopicCommand.main(TopicCommand.scala) Cause ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jeffkbkim","2020-05-05T02:48:53Z","2020-05-05T08:31:36Z"
"","8798","KAFKA-10098: Remove unnecessary escaping in regular expression.","'<' or '>' do not need to be escaped.  This is a newbie PR to learn the contribution flow.  Reviewer: @jghoman","closed","","cancecen","2020-06-03T23:03:10Z","2020-09-02T15:30:57Z"
"","8646","KAFKA-9974: Fix flaky test by removing unneeded asserts","> java.lang.AssertionError: Expected: is <0L> but: was <43L> at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20) at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:6) at org.apache.kafka.streams.integration.OptimizedKTableIntegrationTest.shouldApplyUpdatesToStandbyStore(OptimizedKTableIntegrationTest.java:138)  The tests failed at `assertThat(listener.startOffset, is(equalTo(0L)));`. It looks like that it did a restore before the assert. But we should expect the restore sometimes happen to resume the failed tasks by itself. It should not cause the test failure under this situation.   On the other hands, I checked the original tests in below PR link: https://github.com/apache/kafka/pull/7238/files#diff-7b659da73450d5bf7a1731b5606e4c83R205 The original tests added the `assertThat(listener.startOffset, is(equalTo(0L)));` is because in the end of the test, we'll also test the `startOffset` value. But in the newer version of the test, we don't really care about the `startOffset` or `totalNumRestored`  value. All we want to test in this test is: **Assert that the current value in store reflects all messages being processed**   So, removing the assert can avoid flaky test failure, and also be able to test what the test case want to test.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","showuon","2020-05-11T08:53:22Z","2020-06-16T17:23:48Z"
"","8500","Make Kafka Connect Source idempotent","#KIP-318: Make Kafka Connect Source idempotent  The main idea here was to add the idempotent configuration to Source. This pull request is trying to solve this [KIP](https://cwiki.apache.org/confluence/display/KAFKA/KIP-318%3A+Make+Kafka+Connect+Source+idempotent#KIP-318:MakeKafkaConnectSourceidempotent-Status)   *Summary of testing strategy (including rationale) For now i'm just opening the discussion after the changes made and i'm waiting to any proposal    ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","Schmidt96u","2020-04-16T12:46:59Z","2020-10-23T16:30:55Z"
"","9417","MINOR: Fix flaky ControllerMutationQuotaTest.testQuotaMetric","### What `ClientQuotaManager.updateQuota` updates `quotaCallback` before updating metric configs. `ClientQuotaManager.quota()` performs an unlocked call to `quotaLimit()`, so we can run into a case where `quota` returns the updated quota, but the metric config hasn't been updated.  The fix is to acquire the read lock before attempting to read the quota. An alternative would be to have `verifyQuotaMetric` run in a `waitUntilTrue`.   ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","splett2","2020-10-12T22:47:52Z","2020-10-20T19:15:12Z"
"","8846","KAFKA-9800: [KIP-580] Client Exponential Backoff Implementation","### Tasks KafkaProducer: - [x] Accumolator and ProducerBatch - [x] TransactionManager and TransactionHandler  KafkaAdminClient: - [x] AdminClient  Common: - [x] Metadata  KafkaConsumer: - [x] Blocking loops - [x] TopicPartitionState  Tests: - [x] Tests for exponential backoff in each component - [x] Refactor existing tests  ### Design  Please refer to Jira for more details: https://issues.apache.org/jira/browse/KAFKA-9800  Please note that the util class GeometricProgression will be merged by the KIP-601's patch. But feedbacks on this module are welcome.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","ctan888","2020-06-10T20:05:25Z","2021-12-02T02:16:56Z"
"","8583","2.2 WorkerSinkTask.convertMessages loss of offset","### original  origOffsets.clear();  ### update: if (msgs.count() > 0)     origOffsets.clear();  when sinkTask throw RetriableException,  then step1: Pausing partitions.  step2:Not returning fetched records for assigned partition since it is no longer fetchable.  step3:convertMessages step3.1:origOffsets.clear(); -> this line loss of offset step4:Skipping offset commit, no change since last commit step4.1:Finished offset commit successfully in 0 ms for sequence number. so if no record returon from poll methdo, when execute convertMessages the origOffsets should be cleared when msgs is not empty ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","jiangchuan-java","2020-04-29T07:34:20Z","2020-04-30T02:36:57Z"
"","9259","KAFKA-10466: Allow regex for MaskField SMT to replacement","### Goal  Allow regex for MaskField SMT to replacement  ### Details  The existing `org.apache.kafka.connect.transforms.MaskField` SMT allow to masking with literal replacement. This PR introduces addtional config param `regex`, which will be applied to match for replacement.  example config :  ``` transforms=IPMask transforms.IPMask.type=org.apache.kafka.connect.transforms.MaskField$Value transforms.IPMask.fields=ipAddress transforms.IPMask.replacement=$1.$2.xxx.xxx transforms.IPMask.regex=(\\d*)\\.(\\d*)\\.\\d*\\.\\d* ```  example input & output :   ``` # input  {    ""no"" : 1, ""name"" : ""who"", ""ipAddress"" : ""123.45.67.89"" }  # output {    ""no"" : 1, ""name"" : ""who"", ""ipAddress"" : ""123.45.***.***"" } ```  ### Restrictions :  * only string values ar supported * regex is ignored when `replacement` is not set up.  if `regex` config is set without `replacement` config, the `regex` config is ignored. and then field value will be replaced with null value.  ``` transforms=RegexMask transforms.RegexMask.type=org.apache.kafka.connect.transforms.MaskField$Value transforms.RegexMask.fields=message transforms.RegexMask.regex=^.* ```  ### Testing   * Unit tests are provided.  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","connect,","daehokimm","2020-09-07T16:06:03Z","2022-04-20T00:38:33Z"
"","9176","Allow replace all for RegexRouter","### Context  I need to create topics on the fly from database table names (cdc) and I'm replacing all `_` with `-`. With current RegexRouter I can't do this in one call (actually if I don't know the number of `_` I don't know how many times I need to call the transformer).  That's the reason why I implemented a new flag to allow replaceAll on RegexRouter.  ### Change applied I added a new flag `replaceAll` of type `Boolean` with default value `false` which allows to apply a regex replacement in all occurencces of the topic name. I updated the description of the transformer and added 2 tests to cover previous and new behaviour.  ### Testing strategy (Unit test) I created a new topic name with two `_` symbols (`sample_table_name`). I called a regex with current implementation expecting only the first `_` to be substituted. I called a regex with new flag expecting all `_` to be replaced with `-`.  ### Committer Checklist (excluded from commit message) - [x] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","kip,","carlos-verdes","2020-08-13T12:48:30Z","2020-08-19T13:46:29Z"
"","9450","MINOR: Use `PartitionResponse.errorMessage` in exceptions in KafkaProducer","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rajinisivaram","2020-10-16T14:47:13Z","2020-10-20T09:15:02Z"
"","9414","KAFKA-10585: Kafka Streams should clean up the state store directory from cleanup","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","dongjinleekr","2020-10-12T13:36:07Z","2021-06-10T19:59:57Z"
"","9354","KAFKA-10134 Follow-up: Set the re-join flag in heartbeat failure","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-09-29T23:39:09Z","2020-10-02T00:57:04Z"
"","9336","MINOR: Don't publish javadocs for raft module","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","ijuma","2020-09-24T10:12:59Z","2020-10-06T20:02:56Z"
"","9323","KAFKA-10514: Fix unit test for state directory cleanup","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","cadonna","2020-09-23T10:11:45Z","2020-10-05T20:22:59Z"
"","9321","KAFKA-9929: fix: add missing default implementations","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jeqo","2020-09-22T23:54:18Z","2020-10-06T18:21:24Z"
"","9303","MINOR: Remove unused variable","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","cadonna","2020-09-18T09:27:15Z","2020-09-23T11:49:24Z"
"","9270","KAFKA-10284: Group membership update due to static member rejoin should be persisted","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","feyman2016","2020-09-09T08:53:03Z","2020-10-23T02:42:53Z"
"","9258","MINOR: Add unit tests for StreamsRebalanceListener","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","cadonna","2020-09-07T15:34:20Z","2020-09-16T07:01:15Z"
"","9186","KAFKA-10277: Allow null keys with non-null mappedKey in KStreamKGlobalTable join","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","JoelWee","2020-08-16T08:50:47Z","2020-09-30T18:59:29Z"
"","9165","MINOR: bump 2.5 versions to 2.5.1","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","vvcephei","2020-08-11T18:16:12Z","2020-08-11T20:18:34Z"
"","9153","MINOR: Fix state transition diagram for stream threads","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","cadonna","2020-08-10T12:31:52Z","2020-08-31T11:51:52Z"
"","9107","KAFKA-5488: Add type-safe split() operator","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","kip,","inponomarev","2020-07-30T22:30:31Z","2021-02-05T00:24:15Z"
"","9087","HOTFIX: Set session timeout and heartbeat interval to default to decrease flakiness","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","cadonna","2020-07-27T17:44:10Z","2020-08-31T11:51:58Z"
"","9056","MINOR: Fix deprecation version for NotLeaderForPartitionException","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rajinisivaram","2020-07-22T17:46:50Z","2020-07-22T19:33:56Z"
"","9049","MINOR: fix scala warnings","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","abbccdda","2020-07-21T18:54:23Z","2020-07-27T03:39:59Z"
"","9044","KAFKA-10279; Allow dynamic update of certificates with additional SubjectAltNames","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rajinisivaram","2020-07-20T10:57:50Z","2020-07-21T09:36:40Z"
"","9036","MINOR: Publish o.a.k.c.metrics ad o.a.k.c.metrics.stats packages in the public javadoc","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-07-17T15:57:54Z","2020-10-06T20:07:34Z"
"","9030","MINOR: Filter out quota configs for ConfigCommand using --bootstrap-server","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rajinisivaram","2020-07-16T11:51:55Z","2020-07-17T07:55:54Z"
"","9011","KAFKA-10134: Still depends on existence of any fetchable partitions to block on join","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-07-12T19:10:15Z","2020-10-15T16:36:35Z"
"","8992","MINOR: Closing resources in SaslClientsWithInvalidCredentialsTest","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","akatona84","2020-07-08T11:23:34Z","2020-07-09T14:39:22Z"
"","8986","KAFKA-10233; Add backoff after AuthorizationExceptions in consumer","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","rajinisivaram","2020-07-06T10:21:16Z","2020-11-06T18:46:50Z"
"","8959","MINOR: Fix log entry in FetchSessionHandler to specify throttle correctly","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rajinisivaram","2020-06-30T13:29:34Z","2020-07-01T20:17:03Z"
"","8958","MINOR: Update AlterConfigsOptions' Javadoc","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-06-30T13:25:19Z","2020-06-30T14:07:20Z"
"","8896","KAFKA-10185: Restoration info logging","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","vvcephei","2020-06-18T17:28:44Z","2020-06-19T19:18:04Z"
"","8887","KAFKA-10135: Extract Task#executeAndMaybeSwallow to be a general utility function into TaskManager…","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","streams,","feyman2016","2020-06-17T10:52:00Z","2020-06-23T01:44:36Z"
"","8880","KAFKA-10169: Error message when transit to Aborting / AbortableError / FatalError","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-06-16T17:09:46Z","2020-06-16T17:30:30Z"
"","8848","MINOR: Fix PluginUtilsTest that resulted from a bad backport","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","rhauch","2020-06-11T02:18:12Z","2020-10-16T05:46:10Z"
"","8739","KAFKA-10056; Ensure consumer metadata contains new topics on subscription change","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rajinisivaram","2020-05-28T11:17:55Z","2020-05-29T16:03:50Z"
"","8717","KAFKA-10033: Throw UnknownTopicOrPartitionException when modifying a non-existent topic's config","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","bdbyrne","2020-05-22T16:48:58Z","2020-06-06T15:34:16Z"
"","8713","KAFKA-6145: Add unit tests for assignments of only stateless tasks","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","cadonna","2020-05-22T12:55:08Z","2020-05-25T15:43:10Z"
"","8705","KAFKA-10029; Don't update completedReceives when channels are closed to avoid ConcurrentModificationException","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","rajinisivaram","2020-05-21T10:57:26Z","2020-05-29T08:32:58Z"
"","8693","MINOR: Fix redundant typos in comments and javadocs","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","connect,","ocadaruma","2020-05-19T08:10:35Z","2020-10-16T05:46:09Z"
"","8660","MINOR: fix stream javadoc","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","chia7712","2020-05-12T19:16:26Z","2020-07-23T03:59:50Z"
"","8641","MINOR: Remove allow concurrent test","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","guozhangwang","2020-05-10T05:01:10Z","2020-05-12T17:38:27Z"
"","8629","MINOR: Log4j Improvements on Fetcher","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-05-07T05:58:15Z","2020-05-07T23:30:05Z"
"","8624","KAFKA-9942: Fix bootstrap-server default users/clients handling in ConfigCommand.","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","bdbyrne","2020-05-06T17:01:18Z","2020-05-07T23:31:07Z"
"","8609","KAFKA-9946; StopReplicaRequest deletePartition changes may cause premature topic deletion handling in controller","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","dajac","2020-05-04T09:15:51Z","2020-05-06T07:56:31Z"
"","8548","KAFKA-9823: Follow-up, check state for handling commit error response","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","guozhangwang","2020-04-25T02:46:01Z","2020-04-28T21:44:16Z"
"","8532","HOTFIX: Fix broker bounce system tests","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","tests,","cadonna","2020-04-22T15:46:11Z","2020-04-24T15:49:48Z"
"","8531","KAFAKA-9904: Use ThreadLocalConcurrent to Replace Random","### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","","belugabehr","2020-04-22T15:45:17Z","2020-04-22T15:45:17Z"
"","8841","KAFKA-10123 Fix incorrect value for AWAIT_RESET#hasPosition","## Background  When a partition subscription is initialized it has a `null` position and is in the INITIALIZING state. Depending on the consumer, it will then transition to one of the other states. Typically a consumer will either reset the offset to earliest/latest, or it will provide an offset (with or without offset metadata). For the reset case, we still have no position to act on so fetches should not occur.  Recently we made changes for KAFKA-9724 (#8376) to prevent clients from entering the AWAIT_VALIDATION state when targeting older brokers. New logic to bypass offset validation as part of this change exposed this new issue.  ## Bug and Fix  In the partition subscriptions, the AWAIT_RESET state was incorrectly reporting that it had a position. In some cases a position might actually exist (e.g., if we were resetting offsets during a fetch after a truncation), but in the initialization case no position had been set. We saw this issue in system tests where there is a race between the offset reset completing and the first fetch request being issued.  Since AWAIT_RESET#hasPosition was incorrectly returning `true`, the new logic to bypass offset validation was transitioning the subscription to FETCHING (even though no position existed).  The fix was simply to have AWAIT_RESET#hasPosition to return `false` which should have been the case from the start.   Additionally, this fix includes some guards against NPE when reading the position from the subscription.","closed","","mumrah","2020-06-09T21:16:08Z","2020-06-18T03:23:47Z"
"","8740","KIP-318: Make Kafka Connect Source idempotent","# KIP-318: Make Kafka Connect Source idempotent (Note : i made a mistake and didn't created a branch)  The main idea here was to add the idempotent configuration to Source. This pull request is trying to solve this [KIP](https://cwiki.apache.org/confluence/display/KAFKA/KIP-318%3A+Make+Kafka+Connect+Source+idempotent#KIP-318:MakeKafkaConnectSourceidempotent-Status)   *Summary of testing strategy (including rationale) For now i'm just opening the discussion after the changes made and i'm waiting to any proposal    ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","open","kip,","Schmidt96u","2020-05-28T14:25:56Z","2020-06-11T01:21:53Z"
"","9100","Add AlterISR RPC and use it for ISR modifications","# Background  On the broker side, ISR changes in the following cases: * Follow catches up to the leader, we expand the ISR * On a timer, we check for followers which have fallen out of sync, we shrink the ISR  Previously, we would synchronously update the partition state in ZK which includes the current leader+epoch as well as the ISR. The ZK version is used for concurrency control and is known to the broker (kept in LeaderAndIsr struct). In order to notify the controller of the ISR changes, the leader would periodically write to a special ""isr_change_notification"" znode which the controlled kept a ZK watch on. A list of modified partitions was written to this znode so the controller would only reload the necessary ISRs.  With [KIP-497](https://cwiki.apache.org/confluence/display/KAFKA/KIP-497%3A+Add+inter-broker+API+to+alter+ISR), we introduce an asynchronous ISR workflow that makes the controller the only component which can change the ISR state.  # TLDR  * ISR updates are now sent asynchronously to the controller * ISRs are now only persisted by the controller  * Leader can immediately assume a larger ISR during ISR expansion * No more ZK watch mechanism for ISR propagation * Gated behind IBP 2.7-IV2  # Broker changes  Now when the broker wants to modify the ISR, it will send an AlterIsr request to the controller. Since this request can include any number of partition's ISR modifications, we will want to allow batching of ISR updates. This is done by adding a small delay (50ms) before sending the request to the controller after an ISR change is requested. By adding this delay, other ISR changes can accumulate before getting sent off as a single AlterIsr request.   Once the controller makes the update, it will return the updated ISR to the leader and send UpdateMetadata requests to the other interested brokers. As specified in the KIP, while a leader is waiting on the controller to respond it will assume the largest ISR (i.e., the union of the actual ISR and the pending ISR). For ISR expansions, this allows the leader to assume the new ISR right away. For ISR shrinks however, the leader must wait for confirmation from the controller that the ISR has been persisted (see the KIP for more details). We call this oversubscribed ISR the ""maximal"" ISR  A new `AlterIsrManager` class is added which accumulates ISR changes and uses a background `BrokerToControllerChannelManager` thread to send AlterIsr requests to the controller.  The use of AlterIsr is only enabled when a broker is configured with IBP version 2.7-IV2 or greater.  # Controller changes  A new `AlterIsrReceived` controller event is added along with supporting methods for handling AlterIsr requests from KafkaApis as well as actually processing the request and modifying ZooKeeper. The proposed ISRs are validated against the controller's metadata before writing to ZK. Once all of the ISRs have been written out (or failed), the controller will return the AlterIsr response which includes the updated ISRs and zk versions.  After returning the response, the controller will then send out UpdateMetadata requests for all partitions included in the AlterIsr request.  In order to support rolling upgrades and brokers on older IBP, the controller will accept AlterIsr and monitor the ZK watch for ISR changes. Once we fully migrate away from ZK, AlterIsr will be the only mechanism for updating the ISR.  # Configs  TODO   # Metrics  TODO","closed","","mumrah","2020-07-29T21:05:27Z","2020-11-18T03:15:10Z"
"","8692","KAFKA-10018: Change command line tools from /bin/sh to /bin/bash","""#!/bin/sh"" is used in kafka-server-stop.sh and zookeeper-server-stop.sh. [[ is a bash-builtin and used. Modern Debian and Ubuntu systems, which symlink sh to dash by default. So ""[[: not found"" will occur. Change ""#!/bin/sh"" into ""#!/bin/bash"" can avoid this error. Modify and make all scripts using bash.  Change-Id: I733c6e31f76d768e71ac0e040a33da8f4bd8f005 Signed-off-by: Jiamei Xie   *More detailed description of your change, if necessary. The PR title and PR message become the squashed commit message, so use a separate comment to ping reviewers.*  *Summary of testing strategy (including rationale) for the feature or bug fix. Unit and/or integration tests are expected for any behaviour change and system tests should be considered for larger changes.*  ### Committer Checklist (excluded from commit message) - [ ] Verify design and implementation  - [ ] Verify test coverage and CI build status - [ ] Verify documentation (including upgrade notes)","closed","","jiameixie","2020-05-19T01:20:27Z","2020-06-11T01:52:22Z"
"","9459","MINOR: Add some class javadoc to Admin client","","closed","","tombentley","2020-10-20T13:13:14Z","2020-10-22T12:19:06Z"
"","9439","KAFKA-10587 MirrorMaker CLI change for KIP-629","","closed","","xvrl","2020-10-14T23:49:37Z","2021-07-02T01:22:13Z"
"","9433","KAFKA-10607: Consistent behaviour for response errorCounts()","","closed","","tombentley","2020-10-14T11:25:55Z","2021-07-25T23:29:07Z"
"","9263","KAFKA-10468: Fix CNFE on deserialization of Log4jController#getLoggers","","closed","","tombentley","2020-09-08T14:07:32Z","2020-09-08T14:55:16Z"
"","9246","Minor: publish static analysis reports in PR builds","","closed","","mumrah","2020-09-02T14:36:01Z","2020-09-14T14:27:47Z"
"","9009","KAFKA-6453: Document how timestamps are computed for aggregations and joins","","closed","docs,","JimGalasyn","2020-07-10T23:48:28Z","2020-07-14T18:03:39Z"
"","8956","MINOR[docs]: fix typo in ssl.client.auth requested to required.","","closed","","jeqo","2020-06-30T10:21:25Z","2020-06-30T13:25:33Z"
"","8953","MINOR: re-enable EosBetaUpgradeIntegrationTest","","closed","","ableegoldman","2020-06-29T20:00:25Z","2020-11-04T18:23:13Z"
"","8808","KAFKA-10109: Fix double AdminClient creation in AclCommand","","closed","","tombentley","2020-06-05T13:49:06Z","2020-07-09T09:29:15Z"
"","8703","MINOR: add a getOrCreate function to KRPC collections","","open","","cmccabe","2020-05-21T04:44:26Z","2021-02-08T12:51:29Z"
"","8690","KAFKA-9965: Fix uneven distribution in RoundRobinPartitioner","","open","producer,","cmccabe","2020-05-18T23:35:18Z","2022-07-14T08:48:27Z"
"","8640","MINOR: equals() should check _unknownTaggedFields","","closed","","cmccabe","2020-05-10T04:44:08Z","2020-06-08T19:57:49Z"
"","8638","KAFAKA-9958: Add metrics support to Authorizer","","open","","jeffhuang26","2020-05-09T23:20:30Z","2020-05-17T20:28:44Z"
"","8598","KAFKA-9945: TopicCommand should support --if-exists and --if-not-exists when --bootstrap-server is used","","closed","","cmccabe","2020-05-01T06:00:24Z","2020-06-02T23:18:24Z"
"","8569","KIP-551: Expose disk read and write metrics","","closed","","cmccabe","2020-04-28T05:32:34Z","2022-02-15T14:14:56Z"
"","8556","MINOR: Add a duplicate() method to Message classes","","closed","","cmccabe","2020-04-26T05:04:29Z","2020-05-13T22:26:51Z"
"","8539","MINOR: equals() should compare all fields for generated classes","","closed","","cmccabe","2020-04-23T20:15:06Z","2020-04-24T04:11:43Z"
"","8526","KAFKA-6867: corrected the typos in upgrade.html","","closed","","surabhidixit","2020-04-21T19:42:47Z","2020-04-21T21:46:31Z"