"#","No","Issue Title","Issue Details","State","Labels","User name","created","Updated"
"","435","KAFKA-2755: NPE thrown while handling DescribeGroup request for non-e…","…xistent consumer group","closed","","SinghAsDev","2015-11-05T20:30:31Z","2015-11-05T21:11:30Z"
"","379","KAFKA-2702: ConfigDef toHtmlTable() sorts in a way that is a bit conf…","…using","closed","","granthenke","2015-10-29T03:52:37Z","2015-11-17T17:06:33Z"
"","382","KAFKA-2666: Docs: Automatically generate documentation from config classes","…the way we always planned to","closed","","gwenshap","2015-10-29T18:14:50Z","2015-11-09T04:47:44Z"
"","447","KAFKA-2768: New-consumer sends invalid describeGroupResponse while re…","…stabilizing","closed","","SinghAsDev","2015-11-06T22:35:01Z","2015-11-13T20:50:38Z"
"","300","KAFKA-2598: Adding integration test for the authorizer at API level. …","…Some bug fixes that I encountered while running the tests.","closed","","Parth-Brahmbhatt","2015-10-12T23:21:58Z","2015-10-29T15:30:26Z"
"","356","KAFKA-2449: Update mirror maker (MirrorMaker) docs - remove reference…","…s to multiple source clusters","closed","","gwenshap","2015-10-24T16:39:12Z","2015-10-26T17:12:23Z"
"","337","KAFKA-2645: Document potentially breaking changes in the release note…","…s for 0.9.0","closed","","granthenke","2015-10-20T20:55:53Z","2015-11-17T17:06:31Z"
"","442","KAFKA-2760: Clean up interface of AdminClient.describeConsumerGroup(g…","…roupId)","closed","","SinghAsDev","2015-11-06T06:17:46Z","2015-11-06T21:26:03Z"
"","254","KAFKA-2588 ReplicaManager partitionCount metric should actually be re…","…plicaCount","closed","","granthenke","2015-09-28T15:32:56Z","2020-06-07T22:40:42Z"
"","117","KAFKA-2393: Correctly Handle InvalidTopicException in KafkaApis.getTo…","…picMetadata()","closed","","granthenke","2015-08-05T21:47:15Z","2015-11-17T17:06:12Z"
"","412","KAFKA-2734: kafka-console-consumer throws NoSuchElementException on n…","…ot specifying topic","closed","","SinghAsDev","2015-11-03T22:42:45Z","2015-11-06T21:36:40Z"
"","98","KAFKA-2055; Fix transient ConsumerBounceTest.testSeekAndCommitWithBro…","…kerFailures failure;","closed","","lvfangmin","2015-07-24T20:30:02Z","2015-08-04T18:28:38Z"
"","308","KAFKA-2650: Change ConfigCommand --deleted-config option to align wit…","…h TopicCommand","closed","","granthenke","2015-10-14T15:25:53Z","2015-11-17T17:06:30Z"
"","262","KAFKA-2599 Metadata#getClusterForCurrentTopics can throw NPE even wit…","…h null checking","closed","","eribeiro","2015-09-29T20:48:42Z","2015-10-06T20:35:55Z"
"","428","KAFKA-2738: Replica FetcherThread should connect to leader endpoint m…","…atching its inter-broker security protocol","closed","","gwenshap","2015-11-05T06:31:19Z","2015-11-05T17:09:48Z"
"","325","KAFKA-2665: Docs: Images that are part of the documentation are not p…","…art of the code github","closed","","gwenshap","2015-10-16T23:35:03Z","2015-10-17T00:47:37Z"
"","181","KAFKA-2278; JmxTool should support querying all objects when object-n…","…ame is omitted","closed","","lindong28","2015-08-31T22:54:40Z","2015-09-13T03:52:55Z"
"","174","KAFKA-2485; Allow producer performance to take properties from a file…","… via --consumer.config command line parameter","closed","","lindong28","2015-08-28T00:11:02Z","2015-08-31T20:06:50Z"
"","401","KAFKA-2681: Added SASL documentation. It doesn't look great, but contains all the…","… info from the wiki","closed","","gwenshap","2015-11-02T00:19:40Z","2015-11-02T18:17:16Z"
"","215","KAFKA-2549: Fixing checkstyle failure resulting due to unused imports…","… in Selector.","closed","","Parth-Brahmbhatt","2015-09-14T21:44:42Z","2015-09-14T22:03:33Z"
"","6","Unmap before resizing","While I was studying how MappedByteBuffer works, I saw a sharing runtime exception on Windows. I applied what I learned to generate a patch which uses an internal open JDK API to solve this problem.  ---  Caused by: java.io.IOException: The requested operation cannot be performed on a  file with a user-mapped section open         at java.io.RandomAccessFile.setLength(Native Method)         at kafka.log.OffsetIndex.liftedTree2$1(OffsetIndex.scala:263)         at kafka.log.OffsetIndex.resize(OffsetIndex.scala:262)         at kafka.log.OffsetIndex.trimToValidSize(OffsetIndex.scala:247)         at kafka.log.Log.rollToOffset(Log.scala:518)         at kafka.log.Log.roll(Log.scala:502)         at kafka.log.Log.maybeRoll(Log.scala:484)         at kafka.log.Log.append(Log.scala:297)","closed","","lizziew","2013-07-25T07:07:49Z","2017-12-22T01:24:43Z"
"","335","Fix bash scripts to use `/usr/bin/env`.","Which makes them compatible with NixOS.","closed","","aloiscochard","2015-10-20T13:27:53Z","2017-12-22T20:23:11Z"
"","94","MINOR: Added to .gitignore Kafka server logs directory","When running Kafka server from sources, logs directory gets created in root of repository, and kafka server logs end up there. Currently that directory is not ignored by git.  This change adds root logs directory to .gitignore so that Kafka server logs are ignored and do not get tracked by git.","closed","","sslavic","2015-07-23T21:47:05Z","2015-08-03T21:20:53Z"
"","236","KAFKA-2576; ConsumerPerformance hangs when SSL enabled for Multi-Partition Topic","We now write to the channel with an empty buffer when there are pending bytes remaining and all data has been sent.","closed","","ijuma","2015-09-23T14:54:26Z","2016-03-01T22:50:13Z"
"","357","KAFKA-2680: Use IBM ConfigFile class to load jaas config if IBM JDK","Use IBM ConfigFile class with IBM JDK since JavaLoginConfig provided by SUN provider is not included with IBM JDK.","closed","","rajinisivaram","2015-10-25T21:01:31Z","2015-10-31T16:02:17Z"
"","237","KAFKA-2554: change 0.8.3 to 0.9.0 in ApiVersion and other files","Updated the version from 0.8.3 to 0.9.0. in ApiVersion.  Also updated in gradle.propeties.","closed","","omkreddy","2015-09-24T11:08:32Z","2015-09-24T19:38:59Z"
"","201","MINOR: Added scripts to automate Vagrant setup for system tests","Updated testing README accordingly.","closed","","granders","2015-09-09T17:30:53Z","2015-09-21T20:49:14Z"
"","242","KAFKA-2562: update kafka scripts to use new tools/code","Updated  kafka-producer-perf-test.sh to use org.apache.kafka.clients.tools.ProducerPerformance.  Updated build.gradle to add kafka-tools-0.9.0.0-SNAPSHOT.jar to kafka/libs  folder.","closed","","omkreddy","2015-09-25T11:44:25Z","2015-10-30T22:30:57Z"
"","205","KAFKA-2534: Fixes and unit tests for SSLTransportLayer buffer overflow","Unit tests which mock buffer overflow and underflow in the SSL transport layer and fixes for the couple of issues in buffer overflow handling described in the JIRA.","closed","","rajinisivaram","2015-09-11T10:29:55Z","2015-10-07T16:57:38Z"
"","413","KAFKA-2737: Added single- and multi-consumer integration tests for round-robin assignment","Two tests: 1. One consumer subscribes to 2 topics, each with 2 partitions; includes adding and removing a topic. 2. Several consumers subscribe to 2 topics, several partition each; includes adding one more consumer after initial assignment is done and verified.","closed","","apovzner","2015-11-04T00:32:29Z","2015-11-04T18:06:02Z"
"","76","KAFKA-2320; Test commit","Trying to test the CI build created via KAFKA-2320.","closed","","ijuma","2015-07-14T23:36:46Z","2015-07-15T17:26:43Z"
"","56","Merge pull request #1 from apache/trunk","Trunk","closed","","mastersingh24","2015-04-25T10:04:02Z","2015-04-25T10:04:34Z"
"","320","KAFKA-2120","Trivial fix to get rid of unused statements in kafkaProducer.","closed","","MayureshGharat","2015-10-15T21:42:30Z","2015-10-16T16:47:43Z"
"","204","KAFKA-2477: Fix a race condition between log append and fetch that causes OffsetOutOfRangeException.","Tried two fixes. I prefer the second approach because it saves an additional offset search.","closed","","becketqin","2015-09-11T03:08:52Z","2015-10-08T17:03:33Z"
"","279","KAFKA-2479: Transient exception","Transient exception handling.","closed","","Ishiihara","2015-10-05T21:44:21Z","2016-05-10T00:29:28Z"
"","329","KAFKA-2146. adding partition did not find the correct startIndex","TopicCommand provide a tool to add partitions for existing topics. It try to find the startIndex from existing partitions. There's a minor flaw in this process, it try to use the first partition fetched from zookeeper as the start partition, and use the first replica id in this partition as the startIndex. One thing, the first partition fetched from zookeeper is not necessary to be the start partition. As partition id begin from zero, we should use partition with id zero as the start partition. The other, broker id does not necessary begin from 0, so the startIndex is not necessary to be the first replica id in the start partition.","closed","","shangan","2015-10-19T14:59:14Z","2016-01-22T00:18:57Z"
"","281","KAFKA-2476: Add Decimal, Date, and Timestamp logical types.","To support Decimal, this also adds support for schema parameters, which is an extra set of String key value pairs which provide extra information about the schema. For Decimal, this is used to encode the scale parameter, which is part of the schema instead of being passed with every value.","closed","","ewencp","2015-10-06T17:38:05Z","2015-10-07T04:58:45Z"
"","219","MINOR: Make SenderMetrics class private with private final members","to reduce accessibility of the inner class.","closed","","rajatvig","2015-09-15T17:30:42Z","2016-12-22T00:11:47Z"
"","351","KAFKA-2684: Add force option to topic / config command so they can be called programatically","Tiny change to add a force option to the topic and config commands so they can be called programatically without requiring user input.","closed","","benstopford","2015-10-22T12:28:34Z","2016-05-04T13:27:23Z"
"","130","KIP-28: First patch","This work has been contributed by Jesse Anderson, Randall Hauch, Yasuhiro Matsuda and Guozhang Wang. The detailed design can be found in https://cwiki.apache.org/confluence/display/KAFKA/KIP-28+-+Add+a+processor+client.","closed","","guozhangwang","2015-08-11T01:45:03Z","2015-09-26T00:24:33Z"
"","294","MINOR: Use the correct processor id in the processor thread name","This restores the behaviour before 1265d7cb7.","closed","","ijuma","2015-10-10T23:49:30Z","2016-03-01T22:47:38Z"
"","313","KAFKA-2641: Upgrade path for ZK authentication","This pull request adds a configuration parameter and a migration tool. It is also based on pull request #303, which should go in first.","closed","","fpj","2015-10-15T09:01:07Z","2015-10-23T22:11:30Z"
"","110","KAFKA-2071: Replace Producer Request/Response with their org.apache.kafka.common.requests equivalents","This PR replaces all occurrences of kafka.api.ProducerRequest/ProducerResponse by their common equivalents.","closed","","dajac","2015-08-04T19:14:09Z","2020-08-11T06:46:51Z"
"","334","KAFKA-1686; Implement SASL/Kerberos","This PR implements SASL/Kerberos which was originally submitted by @harshach as https://github.com/apache/kafka/pull/191.  I've been submitting PRs to Harsha's branch with fixes and improvements and he has integrated all, but the most recent one. I'm creating this PR so that the Jenkins can run the tests on the branch (they pass locally).","closed","","ijuma","2015-10-20T08:47:26Z","2016-03-01T22:47:16Z"
"","171","KAFKA-2425; Copy latest docs to kafka repo docs/ directory","This PR copies the latest kafka docs to kafka repo docs directory. Here I have copied 0.8.3/ directory contents from svn website repo to kafka/docs repository.  Some questions: This PR contains generated javadocs also.  Do we need to copy javadocs here?","closed","","omkreddy","2015-08-27T10:24:30Z","2015-10-03T13:51:30Z"
"","127","KAFKA-2411; [WIP] remove usage of blocking channel","This PR builds on the work from @harshach and only the last commit is relevant. Opening the PR for getting feedback.","closed","","ijuma","2015-08-10T12:47:23Z","2015-08-13T16:57:13Z"
"","170","KAFKA-2072: Add StopReplica request/response to o.a.k.common.requests","This PR adds StopReplica request and response as it is required by @ijuma for KAFKA-2411. Migration of core module is addressed a separate PR (#141).  @ijuma Could you review it? @gwenshap Could you take a look as well?","closed","","dajac","2015-08-26T16:32:52Z","2015-08-27T05:25:34Z"
"","307","KAFKA-2484: Add schema projection utilities","This PR adds schema projection utilities to copycat.","closed","","Ishiihara","2015-10-14T01:24:23Z","2015-10-16T22:45:03Z"
"","427","KAFKA-2258: add failover to mirrormaker test","This PR adds failover to simple end to end mirror maker test  Marked as WIP for 2 reasons: - We may want to add a couple more test cases where kafka is being used to store offsets - There appears to be a test failure in the hard failover case","closed","","granders","2015-11-05T01:48:43Z","2015-11-10T03:23:27Z"
"","29","Upgrade Gradle wrapper to Gradle 2.0","This patch upgrades gradle wrapper to gradle 2.0. As consequence license plugin dependency had to be upgraded as well.  Issue: KAFKA-1559","closed","","sslavic","2014-07-27T10:53:29Z","2015-07-08T09:07:36Z"
"","23","KAFKA-1372 Upgrade to Gradle 1.10","This patch upgrades Gradle wrapper from 1.6 to 1.10","closed","","sslavic","2014-04-08T12:20:43Z","2015-07-08T09:08:54Z"
"","173","MINOR: kafkatest add manifest","This patch makes it possible to publish kafkatest (system test package) to pypi and use it as a library in other projects by: - including necessary static resources with the package - renaming the version to conform w/PEP 440, since python packaging tools reject the current version name","closed","","granders","2015-08-28T00:07:51Z","2015-08-29T16:36:45Z"
"","147","KAFKA-2203: Getting Java8 to relax about javadoc and let our build pass","This patch is different than the one attached to the JIRA - I'm applying the new javadoc rules to all subprojects while the one in the JIRA applies only to ""clients"". We need this since Copycat  has the same issues.","closed","","gwenshap","2015-08-18T01:07:43Z","2015-10-12T20:32:00Z"
"","24","KAFKA-1375: Fix formatting in README.md","This patch fixes formatting of instructions for using particular version of Scala when running a Gradle build task.","closed","","sslavic","2014-04-09T13:52:06Z","2015-07-29T23:22:36Z"
"","21","KAFKA-1371 Ignore build output dirs","This patch extends git ignore patterns to all build and .gradle dirs","closed","","sslavic","2014-04-07T15:13:57Z","2015-07-29T23:25:03Z"
"","67","Ignore gradle wrapper download directory","This patch adds gradle wrapper download directory to .gitignore","closed","","sslavic","2015-05-29T14:04:24Z","2015-07-29T23:05:04Z"
"","22","KAFKA-1370 Added Gradle startup script for Windows","This patch adds Gradle startup script for Windows","closed","","sslavic","2014-04-08T12:03:20Z","2015-07-29T23:26:32Z"
"","43","Finer locking in log append","This patch adds finer locking when appending to log. It breaks global append lock into 2 sequential and 1 parallel phase.  Basic idea is to allow every thread to ""reserve"" offsets in non overlapping ranges, then do compression in parallel and then ""commit"" write to log in the same order offsets where reserved.","closed","","redbaron","2015-02-08T18:47:49Z","2015-02-08T21:00:03Z"
"","2","KAFKA-294","This issue can be caused by a non-existing path but also a misunderstanding from the config file. A short example will help the user.","closed","","fsaintjacques","2013-01-30T21:20:57Z","2015-07-20T14:41:26Z"
"","99","KAFKA-2366: Copycat","This is an initial patch implementing the basics of Copycat for KIP-26.  The intent here is to start a review of the key pieces of the core API and get a reasonably functional, baseline, non-distributed implementation of Copycat in place to get things rolling. The current patch has a number of known issues that need to be addressed before a final version: - Some build-related issues. Specifically, requires some locally-installed dependencies (see below), ignores checkstyle for the runtime data library because it's lifted from Avro currently and likely won't last in its current form, and some Gradle task dependencies aren't quite right because I haven't gotten rid of the dependency on `core` (which should now be an easy patch since new consumer groups are in a much better state). - This patch currently depends on some Confluent trunk code because I prototyped with our Avro serializers w/ schema-registry support. We need to figure out what we want to provide as an example built-in set of serializers. Unlike core Kafka where we could ignore the issue, providing only ByteArray or String serializers, this is pretty central to how Copycat works. - This patch uses a hacked up version of Avro as its runtime data format. Not sure if we want to go through the entire API discussion just to get some basic code committed, so I filed KAFKA-2367 to handle that separately. The core connector APIs and the runtime data APIs are entirely orthogonal. - This patch needs some updates to get aligned with recent new consumer changes (specifically, I'm aware of the ConcurrentModificationException issue on exit). More generally, the new consumer is in flux but Copycat depends on it, so there are likely to be some negative interactions. - The layout feels a bit awkward to me right now because I ported it from a Maven layout. We don't have nearly the same level of granularity in Kafka currently (core and clients, plus the mostly ignored examples, log4j-appender, and a couple of contribs). We might want to reorganize, although keeping data+api separate from runtime and connector plugins is useful for minimizing dependencies. - There are a variety of other things (e.g., I'm not happy with the exception hierarchy/how they are currently handled, TopicPartition doesn't really need to be duplicated unless we want Copycat entirely isolated from the Kafka APIs, etc), but I expect those we'll cover in the review.  Before commenting on the patch, it's probably worth reviewing https://issues.apache.org/jira/browse/KAFKA-2365 and https://issues.apache.org/jira/browse/KAFKA-2366 to get an idea of what I had in mind for a) what we ultimately want with all the Copycat patches and b) what we aim to cover in this initial patch. My hope is that we can use a WIP patch (after the current obvious deficiencies are addressed) while recognizing that we want to make iterative progress with a bunch of subsequent PRs.","closed","","ewencp","2015-07-27T06:54:51Z","2015-08-26T21:16:02Z"
"","284","KAFKA-2620: Introduce Scalariform","This is a WIP. There will likely need to be discussion around a rule set we want to use and if we actually want to include this in the build. This could also be used as a one time rebase.   This commit does not include the actual formatting changes. To see what effect the patch has run `gradle formatScala`","closed","","granthenke","2015-10-07T19:06:30Z","2017-12-23T08:59:32Z"
"","178","KAFKA-1387: Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time","This is a patch to get around the problem discussed in the KAFKA-1387 jira. The tests are not passing in my box when I run them all, but they do pass when I run them individually, which indicates that there is something leaking from a test to the next. I still need to work this out and also work on further testing this. I wanted to open this PR now so that it can start getting reviewed.","closed","","fpj","2015-08-29T15:17:50Z","2015-09-24T17:14:42Z"
"","305","KAFKA-2536: topics tool should allow users to alter topic configuration","This is a minimal revert of some backward incompatible changes made in KAFKA-2205, with the addition of the deprecation logging message.","closed","","granthenke","2015-10-13T22:40:40Z","2015-11-17T17:06:27Z"
"","213","KAFKA-2443  Expose windowSize on Rate; KAFKA-2567 - Throttle time should not return NaN","This is a followup ticket from KAFKA-2084 to improve the windowSize calculation in Quotas. I've made the following changes: 1. Added a windowSize function on Rate 2. Calling Rate.windowSize in ClientQuotaManager to return the exact window size to use when computing the delay time. 3. Changed the window size calculation subtly. The current calculation had a bug wherein, it used the number of elapsed seconds from the ""lastWindowSeconds"" of the most recent Sample object. However, the lastWindowSeconds is the time when the sample is created.. this causes an issue because it implies that the current window elapsed time is always ""0"" when the sample is created. This is incorrect as demonstrated in a testcase I added in MetricsTest. I've fixed the calculation to count the elapsed time from the ""oldest"" sample in the set since that gives us an accurate value of the exact amount of time elapsed","closed","","auradkar","2015-09-14T18:30:37Z","2015-10-12T19:23:05Z"
"","114","KAFKA-2406: Throttle ISR propagation","This is a follow up patch for KAFKA-2406. Further test to verify if this change alone is enough to solve the problem or not.","closed","","becketqin","2015-08-05T07:11:36Z","2015-08-13T21:55:04Z"
"","477","KAFKA-2787: Refactor gradle build","This is a first pass. I stopped here given its already a decent amount of change.  I can follow up with more in another pull request in the future if this is received well.  What was done: - Move gradle ""script plugins"" into /gradle folder - Update rat plugin grgit dep (can update since java 1.6 support was dropped) - De-duplicate common test deps and configs by moving to subprojects config - De-duplicate common Checkstyle deps by moving to subprojects config   - Fix Checkstyle on java in core - Centralize dependencies/versions in dependencies.gradle - Setup Scala version dependencies to be more flexible (could support 2.12) - De-duplicate common artifact definitions - Fix examples Checkstyle - Remove javadoc modification except where needed - Fix docs paths when calling from subproject - Move release orchestartion into separate file","closed","","granthenke","2015-11-09T23:53:19Z","2015-11-12T19:29:40Z"
"","369","KAFKA-2663, KAFKA-2664 - [Minor] Bugfixes","This has 2 fixes: KAFKA-2664 - This patch changes the underlying map implementation of Metrics.java to a ConcurrentHashMap. Using a CopyOnWriteMap caused new metrics creation to get extremely slow when the existing corpus of metrics is large. Using a ConcurrentHashMap seems to speed up metric creation time significantly  KAFKA-2663 - Splitting out the throttleTime from the remote time. On throttled requests, the remote time went up artificially.  Some status on using a ConcurrentMap. Time to create : - 100k sensors (1.5 seconds) - 200k sensors (3 seconds) - 400k sensors (9 seconds) - 500k sensors (14 seconds)  Please refer this test (originally written by Joel) http://pastebin.com/LnKjbY9a","closed","","auradkar","2015-10-27T17:09:13Z","2015-10-29T19:00:15Z"
"","109","KAFKA-2384; Encode/decode to utf-8 for commit title IO in kafka-merge-pr.py","This fix should be fine for Linux and OS X. Not sure about Windows though. This is a very specific fix for new functionality added in KAFKA-2384. There are other places where a similar error could occur, but are less likely.  The script doesn't really support Unicode input at the moment.","closed","","ijuma","2015-08-04T09:15:42Z","2015-08-14T09:48:25Z"
"","290","KAFKA-2459: connection backoff, timeouts and retries","This fix applies to three JIRAs, since they are all connected.  KAFKA-2459Connection backoff/blackout period should start when a connection is disconnected, not when the connection attempt was initiated Backoff when connection is disconnected  KAFKA-2615Poll() method is broken wrt time Added Time through the NetworkClient API. Minimal change.  KAFKA-1843Metadata fetch/refresh in new producer should handle all node connection states gracefully I’ve partially addressed this for a specific failure case in the JIRA.","closed","","enothereska","2015-10-09T00:05:30Z","2015-10-21T17:00:14Z"
"","144","KAFKA-2015: Enable ConsoleConsumer to use new consumer","This extends the original patch done by GZ to provide Console access to both the new and old consumer API's. The code follows a pattern similar to that already used in ConsoleProducer.","closed","","benstopford","2015-08-17T07:54:22Z","2015-08-20T19:59:41Z"
"","79","[Minor] fix new consumer heartbeat reschedule bug","This commit fixes a minor issue introduced in the patch for KAFKA-2123. The schedule method requires the time the task should be executed, not a delay.","closed","","hachikuji","2015-07-16T00:24:27Z","2015-07-16T02:00:56Z"
"","71","KAFKA-2289: KafkaProducer logs erroneous warning on startup","This change fixes the problem.","closed","","hgschmie","2015-06-19T23:20:26Z","2017-12-22T20:09:52Z"
"","152","Fix for KAFKA-2446","This bug was introduced while committing KAFKA-2205. Basically, the path for topic overrides was renamed to ""topic"" from ""topics"". However, this causes existing topic config overrides to break because they will not be read from ZK anymore since the path is different.  https://reviews.apache.org/r/34554/","closed","","auradkar","2015-08-20T00:15:02Z","2015-08-20T02:13:16Z"
"","154","KAFKA-2170, KAFKA-1194: Fixes for Windows","This branch fixes several Windows specific issues, both in the code and in the tests.  With these changes the whole test suite passes on my Windows machine.  I found the following issues that were relevant in Jira: KAFKA-2170 and KAFKA-1194, but there may be some others.  I also have a branch with these changes done against 0.8.2.1 if there's any interest in merging to the 0.8 series.","closed","","mpoindexter","2015-08-20T22:51:06Z","2016-12-26T22:38:09Z"
"","133","KAFKA-2429: Add annotations to mark classes as stable/unstable","This also marks the consumer as unstable to show an example of using these annotations.","closed","","ewencp","2015-08-12T21:05:54Z","2015-08-12T21:57:58Z"
"","241","KAFKA-2372: Add Kafka-backed storage of Copycat configs.","This also adds some other needed infrastructure for distributed Copycat, most importantly the DistributedHerder, and refactors some code for handling Kafka-backed logs into KafkaBasedLog since this is shared betweeen offset and config storage.","closed","","ewencp","2015-09-25T02:27:37Z","2015-10-13T17:23:55Z"
"","321","KAFKA-2371: Add distributed support for Copycat.","This adds coordination between DistributedHerders using the generalized consumer support, allowing automatic balancing of connectors and tasks across workers. A few pieces that require interaction between workers (resolving config inconsistencies, forwarding of configuration changes to the leader worker) are incomplete because they require REST API support to implement properly.","closed","","ewencp","2015-10-15T22:22:56Z","2015-10-23T23:37:53Z"
"","10","commitOffsets can be passed the offsets to commit","This adds another version of `commitOffsets` that takes the offsets to commit as a parameter.  Without this change, getting correct user code is very hard.  Despite kafka's at-least-once guarantees, most user code doesn't actually have that guarantee, and is almost certainly wrong if doing batch processing.  Getting it right requires some very careful synchronization between all consumer threads, which is both: 1) painful to get right 2) slow b/c of the need to stop all workers during a commit.  This small change simplifies a lot of this.  This was discussed extensively on the user mailing list, on the thread ""are kafka consumer apps guaranteed to see msgs at least once?""  You can also see an example implementation of a user api which makes use of this, to get proper at-least-once guarantees by _user_ code, even for batches: https://github.com/quantifind/kafka-utils/pull/1  I'm open to any suggestions on how to add unit tests for this.","closed","","squito","2013-11-25T01:44:48Z","2014-06-30T11:31:21Z"
"","253","MINOR: Make indenting in `checkstyle.xml` and `import-control.xml` consistent","They now both use 2 spaces for indents, which is what `checkstyle.xml` was already doing. `import.xml` had a mixture of tabs and 4 spaces previously.","closed","","ijuma","2015-09-28T13:33:35Z","2016-03-01T22:49:59Z"
"","343","MINOR: Update to Gradle 2.8","There have been a number of improvements between the version we are currently using (2.4) and the current version (2.8):  https://gradle.org/docs/2.5/release-notes https://gradle.org/docs/2.6/release-notes https://gradle.org/docs/2.7/release-notes http://gradle.org/docs/current/release-notes  I'm particularly interested in the performance improvements.","closed","","ijuma","2015-10-21T16:58:45Z","2016-03-01T22:47:23Z"
"","107","KAFKA-2386; increase timeouts for transient test failure in ConsumerCoordinatorResponseTests","There are two race conditions in the test case ""testGenerationIdIncrementsOnRebalance."" First, a delay before the second join group request can timeout the initial group and cause the generationId to unexpectedly reset. Second, a delay in the join group request handling will timeout the request itself and cause the test to fail.  This commit doesn't address these race conditions, but increases the timeouts to make them more unlikely. If the problem reoccurs, then we'll probably need a better solution.","closed","","hachikuji","2015-08-03T22:03:45Z","2015-08-04T00:02:35Z"
"","364","MINOR: Expose ReplicaManager gauges","There are several gauges in core that are registered but cannot be accessed programmatically. For example, gauges ""LeaderCount"", ""PartitionCount"", ""UnderReplicatedParittions"" are all registered in ReplicaManager.scala but there is no way to access them programmatically if one has access to the kafka.server object. Other metrics,  such as isrExpandRate (also in ReplicaManager.scala) can be accessed. The solution here is trivial, add a var  in front of newGauge, as shown below val partitionCount newGauge(      ""PartitionCount"",      new Gauge[Int] {        def value = allPartitions.size      } )","closed","","enothereska","2015-10-26T20:25:30Z","2015-10-28T11:25:02Z"
"","419","KAFKA-2740: Convert Windows bin scripts from CRLF to LF line encodings","There are no functional changes to the modified scripts.","closed","","miguno","2015-11-04T09:00:31Z","2015-11-04T17:14:22Z"
"","418","KAFKA-2470: Convert Windows bin scripts from CRLF to LF line encodings","There are no functional changes to the modified scripts.","closed","","miguno","2015-11-04T08:52:12Z","2015-11-04T09:01:07Z"
"","417","Convert Windows bin scripts from CRLF to LF line encodings","There are no functional changes to the modified scripts.","closed","","miguno","2015-11-04T08:50:00Z","2015-11-04T09:00:37Z"
"","333","KAFKA-2667: Fix transient error in KafkaBasedLogTest.","The test required a specific sequence of events for each Consumer.poll() call, but the MockConsumer.waitForPollThen() method could not guarantee that, resulting in race conditions. Add support for scheduling sequences of events even when running in multi-threaded environments.","closed","","ewencp","2015-10-20T07:59:50Z","2015-10-21T18:15:44Z"
"","180","KAFKA-2486; fix performance regression in new consumer","The sleep() in KafkaConsumer's poll blocked any pending IO from being completed and created a performance bottleneck. It was intended to implement the fetch backoff behavior, but that was a misunderstanding of the setting ""retry.backoff.ms"" which should only affect failed fetches.","closed","","hachikuji","2015-08-31T19:33:43Z","2015-08-31T21:23:41Z"
"","84","KAFKA-2328; merge-kafka-pr.py script should not leave user in a detached branch","The right command to get the branch name is `git rev-parse --abbrev-ref HEAD` instead of `git rev-parse HEAD`. The latter gives the commit hash causing a detached branch when we checkout to it. Seems like a bug we inherited from the Spark script.","closed","","ijuma","2015-07-17T16:31:56Z","2015-08-14T09:48:52Z"
"","38","[kafka-1828]add judgement for ConsumerPerformance against negative number","The result is negative number when runnning a short time for consumer performance testing, but user doesn't the reason, so add judgement for this, and then according to the reason, user can do ConsumerPerformance.  negative result like: start.time, end.time, fetch.size, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec 2014-12-23 19:32:39:120, 2014-12-23 19:32:39:152, 1048576, 0.0790, -0.1689, 1000, -2136.7521  anybody, could you help to check this?","closed","","maji2014","2014-12-24T03:31:03Z","2016-01-13T02:03:16Z"
"","37","[Kafka-1828]add judgement for ConsumerPerformance against negative number","The result is negative number when runnning a short time for consumer performance testing, but user doesn't the reason, so add judgement for this, and then according to the reason, user can do ConsumerPerformance.","closed","","maji2014","2014-12-24T03:30:08Z","2014-12-24T03:32:08Z"
"","402","KAFKA-2722: Improve ISR change propagation.","The patch has two changes: 1. fixed a bug in controller that it sends UpdateMetadataRequest of all the partitions in the cluster. 2. Uses the following rules to propagate ISR change: 1) if there are ISR changes pending propagation and the last ISR change is more than five seconds ago, propagate the changes. 2) if there is ISR change at T in the recent five seconds, delay the propagation until T + 5s. 3) if the last propagation is more than 1 min ago, ignore rule No.2 and propagate ISR change if there are changes pending propagation.  This algorithm avoids a fixed configuration of ISR propagation interval as we discussed about in KIP-29.","closed","","becketqin","2015-11-02T01:36:39Z","2015-11-04T13:52:33Z"
"","90","KAFKA-2344; kafka-merge-pr improvements","The first 4 commits are adapted from changes that have been done to the Spark version and the last one is the feature that @gwenshap asked for.","closed","","ijuma","2015-07-21T09:50:24Z","2015-08-14T09:48:50Z"
"","157","KAFKA-2457; StackOverflowError during builds","The default is typically `1m` for 64-bit machines and the Scala compiler sometimes needs more than this.","closed","","ijuma","2015-08-21T10:55:46Z","2015-09-03T07:09:02Z"
"","172","KAFKA-2475: Make Copycat only have a Converter class instead of Serializer, Deserializer, and Converter.","The Converter class now translates directly between byte[] and Copycat's data API instead of requiring an intermediate runtime type like Avro's GenericRecord or Jackson's JsonNode.","closed","","ewencp","2015-08-27T21:16:50Z","2015-08-31T19:26:39Z"
"","138","Log the real exception which triggered a reconnect","The commit here improves the logging in SimpleConsumer to log the real reason why a reconnect was attempted. Relates to https://issues.apache.org/jira/browse/KAFKA-2221.  The same patch was submitted a while back but wasn't merged because SimpleConsumer was considered deprecated and users' aren't expected to use it. However, more and more users in the user mailing list are running into this log message but have no way to understand what the root cause is. So IMO, this change still adds value  to such users who are using SimpleConsumer.","closed","","jaikiran","2015-08-14T17:13:20Z","2016-01-29T04:26:53Z"
"","462","HOTFIX: bug updating cache when loading group metadata","The bug causes only the first instance of group metadata in the topic to be written to the cache (because of the putIfNotExists in addGroup). Coordinator fail-over won't work properly unless the cache is loaded with the right metadata.","closed","","hachikuji","2015-11-09T17:27:27Z","2015-11-09T18:21:26Z"
"","368","MINOR: Fix compiler error in `KafkaLog4jAppender`","The branch wasn't rebased after the capitalisation fix for SSL classes.","closed","","ijuma","2015-10-27T16:51:29Z","2016-03-01T22:49:50Z"
"","259","KAFKA-2597: Add to .gitignore the Eclipse IDE directories","The `.metadata` and `.recommenders` keep IDE workspace state and should not be committed.","closed","","rhauch","2015-09-29T01:12:49Z","2015-10-27T15:07:57Z"
"","150","KAFKA-2377: Add basic system test for copycat using source and sink file connectors.","Tests standalone mode by running separate source and sink connectors, catting data into the source file, and validating the output in the sink file. Restarts the service to verify that clean restarts will result in tasks resuming where they left off.","closed","","ewencp","2015-08-19T06:40:23Z","2015-08-27T20:53:19Z"
"","373","HOTFIX: call consumer.poll() even when no task is assigned","StreamThread should keep calling consumer.poll() even when no task is assigned. This is necessary to get a task.  @guozhangwang","closed","","ymatsuda","2015-10-27T20:47:23Z","2015-11-03T19:45:07Z"
"","51","ConsumerConfig now expects ""bootstrap.servers"" in config.","Small typo to have the documentation in line with `KafkaProducer.java`. Kudos on the awesome documentation work!","closed","","pyr","2015-03-20T07:46:04Z","2015-03-20T07:54:10Z"
"","199","Small change to API doc for seekToEnd() to clarify lazy evaluation.","Small clarification to docs. Current behaviour could confuse when doing something like: consumer.seekToEnd() consumer.send(msg) consumer.poll() //would return msg as seek evaluates lazily","closed","","benstopford","2015-09-08T22:14:39Z","2015-09-08T22:26:14Z"
"","238","KAFKA-2548; kafka-merge-pr tool fails to update JIRA with fix version 0.9.0.0","Simplified the logic to choose the default fix version. We just hardcode it for `trunk` and try to compute it based on the branch name for the rest.  Removed logic that tries to handle forked release branches as it seems to be specific to how the Spark project handles their JIRA.","closed","","ijuma","2015-09-24T16:55:56Z","2016-03-01T22:50:04Z"
"","224","KAFKA-2558: ServerShutdownTest is failing intermittently","See jira for a description.","closed","","fpj","2015-09-20T01:15:02Z","2015-09-22T01:22:39Z"
"","96","KAFKA-2358 Cluster collection returning methods never return null","See https://issues.apache.org/jira/browse/KAFKA-2358","closed","","sslavic","2015-07-24T09:05:07Z","2017-05-31T21:55:15Z"
"","323","KAFKA-2419 - Fix to prevent background thread from getting created when not required","See here for more discussion: https://issues.apache.org/jira/browse/KAFKA-2419 Basically, the fix involves adding a param to Metrics to indicate if it is capable of metric cleanup or not.","closed","","auradkar","2015-10-16T03:55:23Z","2015-10-16T16:47:25Z"
"","358","KAFKA-2644: Run relevant ducktape tests with SASL_PLAINTEXT and SASL_SSL","Run sanity check, replication tests and benchmarks with SASL/Kerberos using MiniKdc.","closed","","rajinisivaram","2015-10-26T08:13:30Z","2015-11-04T05:25:31Z"
"","399","KAFKA-2718: Avoid reusing temporary directories in core unit tests","Retry to find new directory and cleanup on exit.","closed","","rajinisivaram","2015-11-01T10:01:15Z","2015-11-20T23:37:29Z"
"","312","KAFKA-2656: Remove hardcoded default key and truststores","Removed default hardcoded keystore and truststore in /tmp so that default JVM keystore/truststore may be used when keystore/truststore is not specified in Kafka server or client properties","closed","","rajinisivaram","2015-10-14T22:23:02Z","2015-10-19T20:49:31Z"
"","380","KAFKA-2705: Remove static JAAS config file for ZK auth tests","Remove static login config file.","closed","","fpj","2015-10-29T14:33:51Z","2015-10-29T19:01:11Z"
"","265","KAFKA-2591: Fix StreamingMetrics","Remove state storage upon unclean shutdown and fix streaming metrics used for local state.","closed","","guozhangwang","2015-09-30T02:32:31Z","2015-10-03T03:08:51Z"
"","85","MINOR: Fixed ConsumerRecord constructor javadoc","Refactoring of ConsumerRecord made in https://github.com/apache/kafka/commit/0699ff2ce60abb466cab5315977a224f1a70a4da#diff-fafe8d3a3942f3c6394927881a9389b2 left ConsumerRecord constructor javadoc inconsistent with implementation.  This patch fixes ConsumerRecord constructor javadoc to be inline with implementation.","closed","","sslavic","2015-07-18T12:01:35Z","2015-07-30T01:23:57Z"
"","479","MINOR: Refactor .gitignore","Refactor .gitignore with thorough coverage compiled from https://github.com/github/gitignore and inline documentation of why files are ignored.","closed","","granthenke","2015-11-10T02:49:38Z","2019-05-11T08:10:03Z"
"","214","MINOR: Make private class FetchManagerMetrics as a static private class with","reduced visibility for members in Fetcher.  Use Collections.singletonList instead of Arrays.asList in the Unit Test","closed","","rajatvig","2015-09-14T20:15:52Z","2016-12-22T00:18:41Z"
"","314","KAFKA-2295; Support given for dynamically loaded classes (encoders, e…","Rebased code..","closed","","omkreddy","2015-10-15T10:09:59Z","2015-10-15T18:07:11Z"
"","350","MINOR: Restore `SslConsumerTest` which was accidentally deleted in client-side assignment commit","Probably happened while resolving conflicts, commit: 86eb74d9236c586af5889fe79f4b9e066c9c2af3","closed","","ijuma","2015-10-22T09:52:42Z","2016-03-01T22:51:02Z"
"","400","KAFKA-2719: Use wildcard classpath for dependant-libs","PR switches to wildcard classpath for dependant libs to restrict the length of classpath, thereby reducing command line length.","closed","","rajinisivaram","2015-11-01T12:49:02Z","2015-11-03T16:10:58Z"
"","40","KAFKA-1834: No Response when handle LeaderAndIsrRequest some case","PR for [KAFKA-1834](https://issues.apache.org/jira/browse/KAFKA-1834)  When a replica become leader or follower, if this broker no exist in assigned replicas, there are no response.","closed","","tedxia","2014-12-29T07:56:13Z","2016-02-02T23:10:01Z"
"","39","KAFKA-1833: OfflinePartitionLeaderSelector may return null leader when ISR and Assgi...","PR for [KAFKA-1833](https://issues.apache.org/jira/browse/KAFKA-1833)  In OfflinePartitonLeaderSelector::selectLeader, when liveBrokerInIsr is not empty and have no common broker with liveAssignedreplicas, selectLeader will return no leader;","closed","","tedxia","2014-12-29T07:25:43Z","2016-12-21T01:52:24Z"
"","132","KAFKA-1215: Rack-Aware replica assignment option","Please see https://cwiki.apache.org/confluence/display/KAFKA/KIP-36+Rack+aware+replica+assignment for the overall design.  The update to TopicMetadataRequest/TopicMetadataResponse will be done in a different PR.","closed","","allenxwang","2015-08-11T18:06:08Z","2016-03-15T17:03:33Z"
"","271","KAFKA-2581: Run some existing ducktape tests with SSL","Parametrize console consumer sanity test, replication tests and benchmarks tests to run with both PLAINTEXT and SSL.","closed","","rajinisivaram","2015-10-01T20:08:34Z","2015-10-13T00:15:29Z"
"","391","MINOR: Fix homophone typo in Design documentation","Noticed that there was a small typo in section 4.1 of the Design documentation on the [website](https://kafka.apache.org/documentation.html#majordesignelements) ('new' vs. 'knew'). This patch corrects that.","closed","","chrnola","2015-10-30T13:57:10Z","2015-11-06T23:28:27Z"
"","186","Replace ""it's"" with ""its"" where appropriate","No Jira ticket created, as the Contributing Code Changes doc says it's not necessary for javadoc typo fixes.","closed","","reftel","2015-09-02T16:35:12Z","2015-09-02T17:47:38Z"
"","125","Reducing code duplication in DefaultEventHandler","No functionality was changed -- just removed code duplication & [get advantage of case class copy method](http://stackoverflow.com/questions/7249396/how-to-clone-a-case-class-instance-and-change-just-one-field-in-scala).","closed","","lazyval","2015-08-07T15:09:02Z","2016-12-26T22:38:10Z"
"","53","KAFKA-873, KAFKA-2079: curator + exhibitor integration","My motivation for introducing curator to kafka was to get optional exhibitor support, however I noticed this  is also a solution to ticket KAFKA-873 (https://issues.apache.org/jira/browse/KAFKA-873).  Structurally I believe the code is sound, however some tests are blocking which I believe is duet o races related to in-memory Zookeeper but not entirely sure. Am looking into it and testing outside of in-memory ZK, as well. But would love comments/discussion on this PR. I imagine exhibitor support is something that many are interested in, especially those of us in AWS & cloud environments.  Some notes on this PR: -- A ZkClient-Curator bridge is used so that Kafka code continues to use the ZkClient abstraction -- Exhibitor support implemented here is _optional_ (enabled if and only if exhibitor is configured in Kafka server or consumer configuration)","closed","","atdixon","2015-03-30T23:17:55Z","2017-12-22T01:39:43Z"
"","68","KAFKA-2232: Make MockProducer generic","MockConsumer and MockProducer have been moved to test source set. KeySerializer and ValueSerializer have been added to mimic actual KafkaProducer behavior.","closed","","apakulov","2015-06-08T20:42:43Z","2015-07-16T22:19:14Z"
"","187","Updated testing readme","Minor update to point to testing tutorial, and install the correct version of vagrant-hostmanager","closed","","granders","2015-09-02T18:30:45Z","2015-09-09T17:05:43Z"
"","141","KAFKA-2072 [WIP]: Add StopReplica request/response to o.a.k.common.requests and replace the usage in core module","Migration is done but this PR will need to be rebased on #110. I have copied some code (ef669a5) for now.  I'd appreciate feedback on it mainly around how I handle things in the ControllerChannelManager. I have introduced a new 'sendRequest' method for o.a.k.common.requests and kept the old one for compatibility reason. We'll be able to remove the old one in the future when migration of all requests and responses to o.a.k.common.requests is completed.","closed","","dajac","2015-08-15T08:15:54Z","2015-08-26T16:33:28Z"
"","19","Update LogManager.scala","Make sure newer segments would not be deleted","closed","","glorage","2014-03-11T03:31:12Z","2014-06-20T04:26:59Z"
"","177","MINOR: Make private class FetchManagerMetrics as a static private class","Make private class FetchManagerMetrics as a static private class with reduced visibility for members in Fetcher.  Use Collections.singletonList instead of Arrays.asList in the Unit Test","closed","","rajatvig","2015-08-29T07:45:05Z","2015-09-14T20:15:32Z"
"","160","KAFKA-2442: Fixing transiently failing test","Made the following changes: 1. Made the quotas very small. (100 and 10 bytes/sec for producer and consumer respectively) 2. For the producer, I'm asserting the throttle_time with a timed loop using waitUntilTrue 3. For the consumer, I'm simply calling a timed poll in a loop until the server side throttle time metric returns true","closed","","auradkar","2015-08-21T21:26:36Z","2016-12-26T22:38:00Z"
"","429","MINOR: Remove unnecessary println","Looks like this println might have been left in there by mistake.","closed","","rajinisivaram","2015-11-05T14:37:39Z","2015-11-06T23:30:30Z"
"","327","KAFKA-2669; Fix LogCleanerIntegrationTest","LogCleanerIntegrationTest calls LogCleaner.awaitCleaned() to wait until cleaner has processed up to given offset. However, existing awaitCleaned() implementation doesn't wait for this. This patch fix the problem.","closed","","lindong28","2015-10-17T09:18:16Z","2016-05-24T12:56:56Z"
"","287","KAFKA-2624: Change log message position","Log warning message before truncating log in order to display right offset value for the truncated log.","closed","","dopuskh3","2015-10-08T15:31:20Z","2015-11-14T17:26:19Z"
"","8","Escape the . in the kafka.Kafka chain","Little modification to the stop script to be able to stop the kill the proper process. - Escape the . in the kafka.Kafka chain - Also add a grep java to get the real java process and exclude the kafka-run-class.sh process","closed","","vpernin","2013-08-27T16:03:58Z","2016-12-26T22:38:23Z"
"","103","KAFKA-2397: leave group request","Let's say every consumer in a group has session timeout s. Currently, if a consumer leaves the group, the worst case time to stabilize the group is 2s (s to detect the consumer failure + s for the rebalance window). If a consumer instead can declare they are leaving the group, the worst case time to stabilize the group would just be the s associated with the rebalance window.  This is a low priority optimization!","closed","","onurkaraman","2015-08-02T11:00:08Z","2015-10-17T00:41:46Z"
"","5","KAFKA-948 : Update ReplicaStateMachine.scala","KAFKA-948 When the broker which is the leader for a partition is down, the ISR list in the LeaderAndISR path is updated. But if the broker , which is not a leader of the partition is down, the ISR list is not getting updated. This is an issue because ISR list contains the stale entry.","closed","","dibbhatt","2013-06-20T05:11:40Z","2016-01-29T01:57:39Z"
"","50","KAFKA-724: auto socket buffer set","KAFKA-724: Allow automatic socket.send.buffer from operating system  If socket.receive.buffer.bytes/socket.send.buffer.bytes set to non-zero/-1, the OS defaults work.Do not explicitly set buffers.","closed","","rekhajoshm","2015-02-23T01:59:51Z","2016-06-05T01:03:52Z"
"","49","KAFKA-269: run-test.sh async test","KAFKA-269: run-test.sh async test","closed","","rekhajoshm","2015-02-23T01:44:45Z","2016-12-21T02:35:48Z"
"","361","MINOR: Add new build target for system test libs","KAFKA-2644 adds MiniKdc for system tests and hence needs a target to collect all MiniKdc jars. At the moment, system tests run `gradlew jar`. Replacing that with `gradlew systemTestLibs` will enable kafka jars and test dependency jars to be built and copied into appropriate locations. Submitting this as a separate PR so that the new target can be added to the build scripts that run system tests before KAFKA-2644 is committed. A separate target for system test artifacts will allow dependency changes to be made in future without breaking test runs.","closed","","rajinisivaram","2015-10-26T19:19:25Z","2015-10-28T22:35:31Z"
"","80","KAFKA-2341 Add standard deviation as metric","KAFKA-2341 Add standard deviation as metric","closed","","sebadiaz","2015-07-16T08:56:00Z","2020-06-07T22:43:33Z"
"","45","KAFKA-1972: JMXTool multiple attributes","KAFKA-1972: JMX Tool output for CSV format does not handle attributes with comma in their value","closed","","rekhajoshm","2015-02-22T21:46:35Z","2018-03-06T00:28:15Z"
"","46","KAFKA-1621 : Standardize --messages option","KAFKA-1621: Standardize --messages option in perf scripts","closed","","rekhajoshm","2015-02-22T23:18:48Z","2016-12-26T22:38:14Z"
"","48","KAFKA-1545: KafkaHealthcheck.register failure","KAFKA-1545: java.net.InetAddress.getLocalHost in KafkaHealthcheck.register may fail on some irregular hostnames","closed","","rekhajoshm","2015-02-23T00:02:22Z","2016-02-02T23:12:20Z"
"","47","KAFKA-1545: KafkaHealthcheck.register failure","KAFKA-1545: java.net.InetAddress.getLocalHost in KafkaHealthcheck.register may fail on some irregular hostnames","closed","","rekhajoshm","2015-02-22T23:51:46Z","2015-02-22T23:58:45Z"
"","207","support commit offset after consumed","Kafka Of Original Version do not support ""commit offset after consuming"",when kafka.consumer.ConsumerIterator[K, V].next() return a MessageAndMetadata,which consumed offset is already being set,and commit thread maybe commit this offset before ""consuming process finished"",when jvm restart or being down，this msg will not be consumed next time","closed","","wyzssw","2015-09-11T13:43:26Z","2019-05-11T07:56:09Z"
"","206","let kafka support ""commit offset after consuming""","Kafka Of Original Version do not support ""commit offset after consuming"",when kafka.consumer.ConsumerIterator[K, V].next() return a MessageAndMetadata,which consumed offset is already being set,and commit thread maybe commit this offset before ""consuming process finished"",when jvm restart or being down，this msg will not be consumed next time","closed","","wyzssw","2015-09-11T11:32:46Z","2015-10-13T03:15:48Z"
"","75","kafka-2320; Test PR builder","Just trying to trigger a build in Jenkins.","closed","","ijuma","2015-07-14T23:28:03Z","2015-07-14T23:35:57Z"
"","182","MINOR: Quota's equals() is buggy.","It compares upper bound with itself.","closed","","eribeiro","2015-09-01T02:27:39Z","2015-09-29T20:08:51Z"
"","41","Improvements to server stop scripts","Interrupt signal doesn't work to stop the servers (at least not on Amazon Linux.)  Also, improved the selectivity of the stop command for the Zookeeper stop script, so that it doesn't accidentally kill the wrong processes.  Finally, modified the Zookeeper stop script so that it doesn't give a cryptic message in case zookeeper is not already stopped.","closed","","jric","2015-01-14T00:32:34Z","2019-05-19T03:06:53Z"
"","70","KAFKA-2276: KIP-25 initial patch","Initial patch for KIP-25  Note that to install ducktape, do _not_ use pip to install ducktape. Instead:  ``` $ git clone git@github.com:confluentinc/ducktape.git $ cd ducktape  $ python setup.py install ```","closed","","granders","2015-06-16T21:50:00Z","2015-07-29T15:53:19Z"
"","91","MINOR: auto.offset.reset docs not in sync with validation","In this commit https://github.com/apache/kafka/commit/0699ff2ce60abb466cab5315977a224f1a70a4da#diff-5533ddc72176acd1c32f5abbe94aa672 among other things auto.offset.reset possible options were changed from smallest to earliest and from largest to latest, but not in documentation for that configuration property.  This patch fixes documentation for auto.offset.reset consumer configuration property so it is in sync with validation logic.","closed","","sslavic","2015-07-21T14:45:34Z","2015-08-05T23:36:01Z"
"","36","Remove non-functional variable definition in log4j.properties","In log4j.properties, a property kafka.logs.dir was defined. However, modifying this property has no effect because log4j.properties does not support variable substitution in this manner. Rather ${kafka.logs.dir} is looked up as a System property, which is set in bin/kafka-run-class.sh, and must currently be changed there if the log4j logging location is to be modified.","closed","","rocketraman","2014-11-19T22:56:20Z","2015-07-20T16:19:43Z"
"","66","validate configuration while parsing ConfigDef","In java client, configDef class's parse() function should return parsed and validated values (if validator is present) but it does not validate the configuration. e.g. i can create a KafkaProducer instance with a negative value for batch.size and then it throws NullPointerException while sending which is hard to debug.  This commit fix that","closed","","gprabhat90","2015-05-15T15:22:37Z","2017-12-22T20:21:09Z"
"","83","KAFKA-1595; Remove deprecated and slower Scala JSON parser","In a test by @onurkaraman involving 3066 topics and 95895 partitions, Controller initialisation time spent on JSON parsing would be reduced from 37.1 seconds to 0.7 seconds by switching from the current JSON parser to Jackson. See the following JIRA comment for more details:  https://issues.apache.org/jira/browse/KAFKA-5328?focusedCommentId=16027086  I tested that we only use Jackson methods introduced in 2.0 in the main codebase by compiling it with the older version locally. We use a constructor introduced in 2.4 in one test, but I didn't remove it as it seemed harmless. The reasoning for this is explained in the mailing list thread:  http://search-hadoop.com/m/uyzND1FWbWw1qUbWe  Finally, this PR only handles the parsing side. It would be good to use Jackson for serialising to JSON as well. I filed KAFKA-5631 for that.","closed","","ijuma","2015-07-17T11:24:41Z","2018-12-04T08:04:12Z"
"","341","KAFKA-2658: Add PLAIN mechanism to SASL implementation","Implementation and unit tests for SASL/PLAIN. A simple login module and SaslServer implementation for PLAIN mechanism are included in the implementation, but these can be replaced to integrate with authentication servers.","closed","","rajinisivaram","2015-10-21T11:20:53Z","2016-04-25T17:01:15Z"
"","136","KAFKA-2430; Listing of PR commits in commit message should be optional","If there is a single commit in the PR, then it's never listed.","closed","","ijuma","2015-08-13T11:05:21Z","2015-08-14T09:48:09Z"
"","89","MINOR: Fixed javadoc for committed return value","If no offset has been committed, then committed method does not return (null) value, instead NoOffsetForPartitionException is thrown in that case.","closed","","sslavic","2015-07-20T23:38:12Z","2015-08-05T23:34:28Z"
"","303","KAFKA-2639: Refactoring of ZkUtils","I've split the work of KAFKA-1695 because this refactoring touches a large number of files. Most of the changes are trivial, but I feel it will be easier to review this way.  This pull request includes the one @Parth-Brahmbhatt started to address KAFKA-1695.","closed","","fpj","2015-10-13T13:07:14Z","2015-10-18T22:24:19Z"
"","324","KAFKA-2640: Add tests for ZK authentication","I've added a couple of initial tests to verify the functionality. I've tested that the JAAS config file loads properly and SASL with DIGEST-MD5 works with ZooKeeper.","closed","","fpj","2015-10-16T22:02:35Z","2015-10-28T20:20:45Z"
"","7","Modified the async producer so it re-queues failed batches.","I'm working on an application that needs the throughput offered by an async producer but also needs to handle send failures gracefully like a sync producer.  I modified the ProducerSendThread so it will re-queue failed batches.  This allowed me to determine the behavior I wanted from my producer with the queue config parameters.  A ""queue.enqueue.timeout.ms=0"" allowed me to get runtime exceptions when sends failed often enough to fill the queue.  This also allowed me to use ""queue.buffering.max.messages"" to control how tolerant the application is to network blips.","closed","","hiloboy0119","2013-07-25T19:03:46Z","2015-11-02T22:26:50Z"
"","246","MINOR: Fix Vagrant setup script for use on Fedora","I tested and verified that `vagrant --version | egrep -o ""\d+\.\d+\.\d+""` works on Mac but failed on RedHad 6.4, while `vagrant --version | egrep -o ""[0-9]\.[0-9]\.[0-9]""` works on both OS.","closed","","lindong28","2015-09-25T23:15:28Z","2015-10-21T03:43:55Z"
"","28","Clarify log deletion configuration options in server.properties (for trunk)","I spent a bit of time tracking down why files were being deleted before they reached log.retention.hours of age. It turns out that the time and size log retention schemes function independently, and not as the original comment ""The minimum age of a log file to be eligible for deletion"" might indicate to a new user.","closed","","MarkRose","2014-07-22T15:40:04Z","2016-12-21T03:34:28Z"
"","27","Clarify log deletion configuration options in server.properties (for 0.8.1)","I spent a bit of time tracking down why files were being deleted before they reached log.retention.hours of age. It turns out that the time and size log retention schemes function independently, and not as the original comment ""The minimum age of a log file to be eligible for deletion"" might indicate to a new user.","closed","","MarkRose","2014-07-22T15:38:21Z","2016-12-26T22:39:18Z"
"","212","KAFKA-2300: Error in controller log when broker tries to rejoin cluster","I have reopened this issue because the controller isn't cleaning up the state upon an exception and the test case was legitimately failing for me every now and then. I'm proposing a change to fix this.","closed","","fpj","2015-09-14T13:51:58Z","2015-09-21T18:56:45Z"
"","398","KAFKA-2717: Add kafka logbak appender","https://issues.apache.org/jira/browse/KAFKA-2717","closed","","vesense","2015-10-31T10:54:51Z","2016-12-26T22:38:04Z"
"","62","add support libvirt as provider. KAFKA-2183","https://issues.apache.org/jira/browse/KAFKA-2183","closed","","pronix","2015-05-10T20:07:59Z","2022-02-09T19:34:49Z"
"","120","KAFKA-1997: Follow-up patch, hardcode key/value serializer in mirror maker to byte serializer.","Hardcode the key/value serializer to ByteArraySerializer according to Jun’s comments.","closed","","becketqin","2015-08-07T03:19:25Z","2015-08-08T06:42:05Z"
"","54","KAFKA-2098: gradle files","gradle files, tiny footprint.lets have it in.thanks","closed","","rekhajoshm","2015-04-06T21:03:43Z","2016-12-26T22:38:12Z"
"","218","KAFKA-2514: change default JVM options in kafka-run-class.sh.","GC is set to G1 collector.","closed","","omkreddy","2015-09-15T13:35:30Z","2015-09-28T15:41:22Z"
"","32","Merge pull request #1 from apache/trunk","Fork sync","closed","","copester","2014-09-09T19:41:22Z","2014-09-09T19:41:38Z"
"","363","KAFKA-2689: Expose select gauges and metrics programmatically (not just through JMX)","For now just exposing the replica manager gauges.","closed","","enothereska","2015-10-26T19:51:19Z","2015-10-26T19:54:32Z"
"","3","zkclient and scalatest library updates","Following https://issues.apache.org/jira/browse/KAFKA-826 I forked the code and included fixes for 2 bugs I reported, https://issues.apache.org/jira/browse/KAFKA-807 and https://issues.apache.org/jira/browse/KAFKA-809  All tests pass except kafka.log.LogTest which fails on my Mac--I don't think it is related to the zkclient fix, I could be wrong.","closed","","polymorphic","2013-03-25T23:37:48Z","2016-02-02T23:09:18Z"
"","381","KAFKA-2502 - Documentation for quotas","Followed the approach specified here: https://issues.apache.org/jira/browse/KAFKA-2502 I also made a minor fix to ConfigCommand to expose the right options on add-config.","closed","","auradkar","2015-10-29T16:18:10Z","2015-10-30T01:34:19Z"
"","216","Kafka 2504","Fixed unused imports","closed","","jholoman","2015-09-14T21:55:32Z","2015-09-14T22:06:23Z"
"","44","Update DelayedFetch.scala","Fix typo","closed","","arcz","2015-02-17T08:21:01Z","2015-09-22T15:55:13Z"
"","104","KAFKA-2134: fix replica offset truncate to beginning during leader migration.","Fix replica truncates log to beginning during leader migration.","closed","","becketqin","2015-08-03T02:26:38Z","2015-08-10T18:38:53Z"
"","301","KAFKA-2637: Cipher suite setting should be configurable for SSL","Enables Cipher suite setting. Code was previously reviewed by @ijuma, @harshach. Moving to an independent PR.","closed","","benstopford","2015-10-13T09:20:29Z","2015-10-13T13:59:46Z"
"","185","KAFKA-2309; ISR shrink rate not updated on LeaderAndIsr request with shrunk ISR","Currently, a LeaderAndIsrRequest does not mark the isrShrinkRate if the received ISR is smaller than the existing ISR. This can happen if one of the replicas is shut down.","closed","","auradkar","2015-09-02T01:20:46Z","2019-05-11T07:59:43Z"
"","440","Do not merge: Multi-consumer integration tests for consumer group subsribe and timeouts and corresponding fixes","Couple of new multi-consumer integration tests for new consumer and fixes for initial review. Intending to close this pull request and add more tests.   -- Refactored multi-consumer integration group assignment validation tests for round-robin assignment -- Added multi-consumer integration tests for session timeout expiration -- Fixes to issues found with session timeout expiration tests woth help from Jason Gustafson.     1. shouldKeepMemberAlive(): when we are in the sync phase, we do want to expire members if we don't get any response     2. Try to avoid  SendFailedException exception by canceling the scheduled tasks and retrying leave group request several times.","closed","","apovzner","2015-11-06T04:14:20Z","2015-11-09T21:49:01Z"
"","63","Corrected the Changes in ZkUtils.scala - KAFKA-2167","Corrected Spelling errors.","closed","","nssalian","2015-05-12T05:25:17Z","2015-05-12T21:25:09Z"
"","92","MINOR: ConsumerRecords are organized per topic partition","ConsumerRecords has records organized per topic partition, not per topic as ConsumerRecords javadoc suggested.","closed","","sslavic","2015-07-22T13:41:11Z","2015-08-05T23:33:27Z"
"","197","KAFKA-2522: ConsumerGroupCommand writes error messages to STDERR","ConsumerGroupCommand sends errors and valuable output to different streams. It simplifies results parsing.  @joestein @johann8384 could you please review this PR?  The contribution is my original work and I license the work to the project under the project's open source license.","closed","","melan","2015-09-06T07:20:42Z","2016-01-30T05:42:59Z"
"","123","KAFKA-2408 ConsoleConsumerService direct log output to file","console consumer writes to System.out, while (some) log4j loggers operate in other threads.  This occasionally led to funky interleaved output which disrupted parsing of consumed messages by ConsoleConsumerService, leading to spurious test failures.  This fix directs log output to a separate file.","closed","","granders","2015-08-07T06:43:21Z","2015-08-27T17:57:54Z"
"","1","Switch to using scala 2.9.2","Compiled and used fine. I had issues with the tests though.","closed","","azymnis","2012-08-14T19:28:35Z","2016-02-02T23:09:08Z"
"","210","KAFKA-2478: Fix manual committing example in javadoc","Committing before inserting all records into the database might lead to some records being lost.  I've changed the example to commit only after all records  returned by `poll` are inserted into the database.","closed","","shtratos","2015-09-13T22:20:13Z","2016-01-29T12:49:47Z"
"","460","KAFKA-2779: Close SSL socket channel on remote connection close","Close socket channel in finally block to avoid file descriptor leak when remote end closes the connection","closed","","rajinisivaram","2015-11-09T13:06:38Z","2015-11-09T15:26:06Z"
"","34","changed List type in RequestPurgatory.Watchers","class Watchers is declared, having member  ``` private val requests = new util.ArrayList[T] ```  in purgeSatisfied(), an iterator is created which conditionally removes elements from the list as it goes:   RequestPurgatory.scala, lines 193-201:  ```    val iter = requests.iterator()     var purged = 0     while(iter.hasNext) {       val curr = iter.next       if(curr.satisfied.get()) {         iter.remove()         purged += 1       }     } ```  Using the .remove operation on an ArrayList iterator is very expensive as the ArrayList promises a contiguous backing array and all higher elements must be shifted on every operation.  A LinkedList is optimized for for the removal of arbitrary elements. Therefore recommending: -    private val requests = new util.ArrayList[T] -    private val requests = new util.LinkedList[T]  This case was identified due to an observed failure In a high-load production environment, which found one or more cores pinned (ie. @100 usage) insider this loop.  Once the pin was established, it tended to remain until the system was restarted.   As the loop is within a synchronized block, checkAndMaybeAdd (0.8.2) or add (0.8.1) which are also synchronized on the same object, may become blocked by this inefficiency.","closed","","mdykman","2014-10-06T14:58:56Z","2016-12-26T22:38:19Z"
"","57","KAFKA-1054; Eliminate Scala Compilation Warnings","Changes: - Suppressed compiler warnings about type erasure in matching via unboxing   by Jon Riehl. - Suppressed warning caused by slight difference in input function type   by John Riehl. - Fix compiler warnings: ServerShutdownTest, DelayedJoinGroup function   signature by Blake Smith. - Fix Scala 2.11 warnings. `Pair` has been deprecated, `try` without   `catch` and `finally` is useless and initialisation order fix by Ismael   Juma.","closed","","ijuma","2015-04-27T06:40:10Z","2015-04-28T06:18:36Z"
"","18","Fix to run hadoop-consumer with hadoop 2","Changes to use hadoop-core-1.2.1.jar in hadoop-consumer Changes to import from maven the packages needed to run hadoop-consumer in HDFS","closed","","mvalleavila","2014-02-26T16:33:32Z","2014-06-20T04:27:05Z"
"","298","KAFKA-2209 - Change quotas dynamically using DynamicConfigManager","Changes in this patch are: 1. ClientIdConfigHandler now passes through the config changes to the quota manager. 2. Removed static KafkaConfigs for quota overrides. These are no longer needed since we can override configs through ZooKeeper. 3. Added testcases to verify that the config changes are propogated from ZK (written using AdminTools) to the actual Metric objects.","closed","","auradkar","2015-10-12T22:15:42Z","2015-10-21T23:08:00Z"
"","64","Kafka 2167","Changed ZkUtils.scala for KAFKA-2167","closed","","nssalian","2015-05-12T21:24:39Z","2017-12-22T20:20:42Z"
"","302","KAFKA-2638: Added default properties file to ConsumerPerformance","Blocker for SSL integration","closed","","benstopford","2015-10-13T11:52:57Z","2015-10-13T12:01:54Z"
"","280","MINOR: Reduce logging level for controller connection failures from `error` to `warn`","Before we switched from `BlockingChannel` to `NetworkClient`, we were always reporting a successful connection due to the fact that `BlockingChannel.connect` catches and swallows all exceptions. We are now reporting failures (which is better), but `error` seems too noisy (as can be seen in our tests).","closed","","ijuma","2015-10-06T11:32:04Z","2016-03-01T22:47:44Z"
"","167","KAFKA-2468: SIGINT during Kafka server startup can leave server deadlocked","As we handle exceptions or invalid states in Kafka server by shutting it down, there is no reason to use exit() and not halt() in shutdown itself.","closed","","SinghAsDev","2015-08-25T07:36:54Z","2015-08-28T04:18:58Z"
"","58","KAFKA-1621 : Standardize --messages option","As per review comments from @nehanarkhede Thanks.","closed","","rekhajoshm","2015-04-27T21:01:31Z","2015-07-21T05:51:13Z"
"","403","KAFKA-2698: Add paused() method to o.a.k.c.c.Consumer","As per KAFKA-2698, this adds a `paused()` method to the Consumer interface such that client code can query Consumer implementations for paused partitions.  Somewhat new to the code base but I understand this may require a KIP given this changes APIs: is this required even for backward-compatible changes like this?","closed","","thomaslee","2015-11-02T01:51:10Z","2016-12-26T22:38:02Z"
"","111","KAFKA-2405 Don't kill the JVM on session establishment failure","As noted in the JIRA https://issues.apache.org/jira/browse/KAFKA-2405 currently the KafkaHealthCheck causes the JVM to terminate in cases where session establishment with Zookeeper fails. I don't know if retrying (after a while) is a better way to fix this but at least, IMO, the session establishment failure shouldn't kill the JVM. This commit removes the `System.exit()` call.","closed","","jaikiran","2015-08-04T22:39:20Z","2015-08-05T02:26:00Z"
"","233","KAFKA-2419; Garbage collect unused sensors","As discussed in KAFKA-2419 - I've added a time based sensor retention config to Sensor. Sensors that have not been ""recorded"" for 'n' seconds are eligible for expiration.  In addition to the time based retention, I've also altered several tests to close the Metrics and scheduler objects since they can cause leaks while running tests. This causes TestUtils.verifyNonDaemonThreadStatus to fail.","closed","","auradkar","2015-09-23T00:49:01Z","2020-04-22T02:36:08Z"
"","448","KAFKA-2766: use new producer by default in tooling","Also update the API docs for new consumer.","closed","","guozhangwang","2015-11-06T22:59:54Z","2015-11-07T01:55:54Z"
"","390","KAFKA-2711; SaslClientAuthenticator no longer needs KerberosNameParser in constructor","Also refactor `KerberosNameParser` and `KerberosName` to make the code clearer and easier to use when `shortName` is not needed.","closed","","ijuma","2015-10-30T11:20:08Z","2016-03-01T22:49:27Z"
"","431","KAFKA-2748: Ensure sink tasks commit offsets upon rebalance and rewind if the SinkTask flush fails.","Also fix the incorrect consumer group ID setting which was giving each task its own group instead of one for the entire sink connector.","closed","","ewencp","2015-11-05T17:33:59Z","2015-11-05T18:08:03Z"
"","168","KAFKA-1811 Ensuring registered broker host:port is unique","Adds a ZKLock recipe implementation to guarantee that the host:port pair is unique among the brokers registered on ZooKeeper.","closed","","eribeiro","2015-08-25T15:53:04Z","2020-10-23T15:48:41Z"
"","161","KAFKA-1543: Changing replication factor","Adding support to change replication-factor via kafka-topics to avoid additional hassle of defining replicas explicilty. This change will allow to make this change with one line:  ``` kafka-topics.sh --zookeeper host:port --alter --topic name --replication-factor 3 ```  Also, made a small cleanup by replacing old junit.framework.Assert with org.junit.Assert","closed","","apakulov","2015-08-22T00:50:02Z","2021-05-12T06:26:46Z"
"","16","Adding rack-aware replication option.","Adding rack-aware replication option. rack-id defaults to -1. use the max-rack-replication option when creating a topic to distribute replicas such that no more than max-rack-replication replicas are hosted on the same rack-id. This option is also enforced when adding new partitions. The option does not enforce manual (re)assignment.","closed","","jmlvanre","2014-02-01T00:25:34Z","2015-07-20T17:31:48Z"
"","15","Rack aware replication","Adding rack-aware replication option. rack-id defaults to -1. use the max-rack-replication option when creating a topic to distribute replicas such that no more than max-rack-replication replicas are hosted on the same rack-id. This option is also enforced when adding new partitions. The option does not enforce manual (re)assignment.","closed","","jmlvanre","2014-02-01T00:08:39Z","2014-06-16T06:31:13Z"
"","14","Rack-Aware replica assignment option","Adding a rack-id to kafka config. This rack-id can be used during replica assignment by using the max-rack-replication argument in the admin scripts (create topic, etc.). By default the original replication assignment algorithm is used because max-rack-replication defaults to -1. max-rack-replication > -1 is not honored if you are doing manual replica assignment (preffered).  If this looks good I can add some test cases specific to the rack-aware assignment.","closed","","jmlvanre","2014-01-23T02:17:52Z","2014-02-01T00:25:52Z"
"","73","KAFKA-2327; broker doesn't start if config defines advertised.host but not advertised.port","Added unit tests as well. These fail without the fix, but pass with the fix.","closed","","granders","2015-07-09T19:04:31Z","2015-12-09T19:41:27Z"
"","415","KAFKA-2735 BrokerEndPoint should support uppercase hostnames","Added support for uppercase hostnames in BrokerEndPoint. Added unit test to cover this scenario.","closed","","jholoman","2015-11-04T02:47:50Z","2015-11-05T21:25:33Z"
"","371","KAFKA-2690: Hide passwords while logging the config.","Added PASSWORD_STRING in ConfigDef that returns ""[hidden]"" when method toString is invoked.","closed","","j-nowak","2015-10-27T19:21:09Z","2015-12-03T11:15:00Z"
"","309","KAFKA-2649 Add support for custom partitioning in topology sinks","Added option to use custom partitioning logic within each topology sink.","closed","","rhauch","2015-10-14T15:45:45Z","2016-01-07T22:46:52Z"
"","148","KAFKA-2439: Add MirrorMaker service class for system tests","Added MirrorMaker service and a few corresponding sanity checks, as well as necessary config template files. A few additional updates to accomodate the change in wait_until from ducktape0.2.0->0.3.0","closed","","granders","2015-08-18T08:18:35Z","2015-08-27T17:57:36Z"
"","367","KAFKA-2696: New KafkaProducer documentation doesn't include all necessary config properties","Added in documentation to add missing properties, as well as highlight those minimum required properties.","closed","","edwardmlyte","2015-10-27T15:50:52Z","2015-10-27T16:04:38Z"
"","137","MINOR: expose vagrant base box as variable","Added base_box variable to Vagrantfile. This makes it possible to override the base box in Vagrantfile.local.","closed","","granders","2015-08-13T21:22:59Z","2015-08-18T08:16:07Z"
"","256","KAFKA-2594 Added InMemoryLRUCacheStore","Added a new `KeyValueStore` implementation called `InMemoryLRUCacheStore` that keeps a maximum number of entries in-memory, and as the size exceeds the capacity the least-recently used entry is removed from the store and the backing topic. Also added unit tests for this new store and the existing `InMemoryKeyValueStore` and `RocksDBKeyValueStore` implementations. A new `KeyValueStoreTestDriver` class simplifies all of the other tests, and can be used by other libraries to help test their own custom implementations.  This PR depends upon [KAFKA-2593](https://issues.apache.org/jira/browse/KAFKA-2593) and its PR at https://github.com/apache/kafka/pull/255. Once that PR is merged, I can rebase this PR if desired.  Two issues were uncovered when creating these new unit tests, and both are also addressed as separate (small) commits in this PR: - The `RocksDBKeyValueStore` initialization was not creating the file system directory if missing. - `MeteredKeyValueStore` was casting to `ProcessorContextImpl` to access the `RecordCollector`, which prevent using `MeteredKeyValueStore` implementations in tests where something other than `ProcessorContextImpl` was used. The fix was to introduce a `RecordCollector.Supplier` interface to define this `recordCollector()` method, and change `ProcessorContextImpl` and `MockProcessorContext` to both implement this interface. Now, `MeteredKeyValueStore` can cast to the new interface to access the record collector rather than to a single concrete implementation, making it possible to use any and all current stores inside unit tests.","closed","","rhauch","2015-09-28T19:35:31Z","2015-10-27T15:08:14Z"
"","274","KAFKA-2603: Add timeout arg to ConsoleConsumer","Added --timeout-ms argument to ConsoleConsumer that works with both old and new consumer. Also modified ducktape ConsoleConsumer service to use this arg instead of consumer.timeout.ms config that works only with the old consumer.","closed","","rajinisivaram","2015-10-04T16:21:26Z","2015-10-14T21:11:04Z"
"","255","KAFKA-2593 Key value stores can use specified serializers and deserializers","Add support for the key value stores to use specified serializers and deserializers (aka, ""serdes""). Prior to this change, the stores were limited to only the default serdes specified in the topology's configuration and exposed to the processors via the ProcessorContext.  Now, using InMemoryKeyValueStore and RocksDBKeyValueStore are similar: both are parameterized on the key and value types, and both have similar multiple static factory methods. The static factory methods either take explicit key and value serdes, take key and value class types so the serdes can be inferred (only for the built-in serdes for string, integer, long, and byte array types), or use the default serdes on the ProcessorContext.","closed","","rhauch","2015-09-28T18:44:38Z","2015-10-27T15:08:30Z"
"","282","KAFKA-2428","Add sanity test in kafkaConsumer for the timeouts. This is a followup ticket for Kafka-2120.","closed","","MayureshGharat","2015-10-07T02:44:55Z","2015-10-08T01:26:51Z"
"","74","KAFKA-1595; Remove deprecated and slower scala JSON parser","A thin wrapper over Jackson's Tree Model API is used as the replacement. This wrapper increases safety while providing a simple, but powerful API through the usage of the `DecodeJson` type class. Even though this has a maintenance cost, it makes the API much more convenient from Scala. A number of tests were added to verify the behaviour of this wrapper.  The Scala module for Jackson doesn't provide any help for our current usage, so we don't depend on it.  An attempt has been made to maintain the existing behaviour regarding when exceptions are thrown. There are a number of cases where `JsonMappingException` will be thrown instead of `ClassCastException`, however. It is expected that users would not try to catch `ClassCastException`.","closed","","ijuma","2015-07-14T08:47:46Z","2015-07-14T23:28:25Z"
"","134","KAFKA-2389: remove commit type from new consumer.","A shot to remove commit type from new consumer. The coordinator constructor takes a default offset commit callback mainly for testing purpose.","closed","","becketqin","2015-08-13T01:28:56Z","2015-09-11T22:47:35Z"
"","270","KAFKA-2600 Align Kafka Streams' interfaces with Java 8 functional interfaces","A few of Kafka Stream's interfaces and classes are not as well-aligned with Java 8's functional interfaces. By making these changes, when Kafka moves to Java 8 these classes can extend standard Java 8 functional interfaces while remaining backward compatible. This will make it easier for developers to use Kafka Streams, and may allow us to eventually remove these custom interfaces and just use the standard Java 8 interfaces.  The changes include: 1. The 'apply' method of KStream's `Predicate` functional interface was renamed to `test` to match the method name on `java.util.function.BiPredicate`. This will allow KStream's `Predicate` to extend `BiPredicate` when Kafka moves to Java 8, and for the `KStream.filter` and `filterOut` methods to accept `BiPredicate`. 2. Renamed the `ProcessorDef` and `WindowDef` interfaces to `ProcessorSupplier` and `WindowSupplier`, respectively. Also the `SlidingWindowDef` class was renamed to `SlidingWindowSupplier`, and the `MockProcessorDef` test class was renamed to `MockProcessorSupplier`. The `instance()` method in all were renamed to `get()`, so that all of these can extend/implement Java 8's `java.util.function.Supplier` interface in the future with no other changes and while remaining backward compatible. Variable names that used some form of ""def"" were changed to use ""supplier"".  These two sets of changes were made in separate commits.","closed","","rhauch","2015-10-01T17:16:21Z","2015-10-27T15:07:30Z"
"","87","KAFKA-2348; Drop support for Scala 2.9","`testAll` passed locally.","closed","","ijuma","2015-07-20T10:31:52Z","2015-08-14T09:48:47Z"
"","106","KAFKA-2399; Replace `Stream.continually` with `Iterator.continually`","`Iterator.continually` is more efficient (it doesn't allocate a `Cons` instance per element) and we don't need the extra functionality provided by `Stream.continually`.","closed","","ijuma","2015-08-03T19:12:48Z","2016-03-01T22:54:31Z"
"","430","MINOR: Remove copyDependantTestLibs from jar dependencies","_copyDependantTestLibs_ was added temporarily as a dependency of _jar_ task to enable SASL system tests to be run with MiniKdc without changing the automated system test runs which run _gradlew clean jar_. Since the build target _systemTestLibs_ is already in Kafka build.gradle, the Confluent automated test runs can now run _gradlew clean systemTestLibs_ instead. This PR provides the final change to remove _copyDependantTestLibs_ from the _jar_ task. This should be committed only after the Confluent automated sytem test build script is updated, to avoid breaking any builds.","closed","","rajinisivaram","2015-11-05T15:40:58Z","2016-05-09T22:38:49Z"
"","26","KAFKA-1414: Speedup broker shutdown and startup after hard reset","[KAFKA-1414](https://issues.apache.org/jira/browse/KAFKA-1414)","closed","","ataraxer","2014-07-15T21:30:14Z","2014-07-28T19:37:51Z"
"","20","[KAFKA-1344] - Added compression codec option feature for ConsoleProducer","[KAFKA-1344] - Added compression codec option feature for ConsoleProducer","closed","","edgefox","2014-03-31T17:38:54Z","2016-02-02T23:09:45Z"
"","276","HOTFIX: Persistent store in ProcessorStateManagerTest","@ymatsuda @junrao Could you take a quick look? The current unit test is failing on this.","closed","","guozhangwang","2015-10-05T17:59:22Z","2015-10-05T20:55:12Z"
"","316","KAFKA-2660; Correct cleanableRatio calculation","@onurkaraman Could you have a look? This is the patch I discussed with you.","closed","","lindong28","2015-10-15T17:37:19Z","2015-10-31T02:26:46Z"
"","328","KAFKA-2668; Add a metric that records the total number of metrics","@onurkaraman @becketqin Do you have time to review this patch? It addresses the ticket that @jjkoshy filed in KAFKA-2668.","closed","","lindong28","2015-10-19T05:37:21Z","2015-12-09T18:12:13Z"
"","264","MINOR: Set `sendTime` in `doSend` instead of `InFlightRequests.add` and rename method names for consistency","@hachikuji @MayureshGharat @jjkoshy Thoughts?","closed","","ijuma","2015-09-30T00:45:49Z","2016-03-01T22:47:48Z"
"","221","KAFKA-2555: Infinite recursive function call when call commitSync in …","@hachikuji @ewencp I found this problem when adding new consumer to mirror maker which commits offset in the rebalance callback. It is not clear to me why we are triggering rebalance for commitSync() and fetchCommittedOffset(). Can you help review to see if I miss something?  Regarding commitSync, After each poll() the partitions will be either assigned to a consumer or it will be already revoked. As long as user is using internal offset map, the offset map will always be valid. i.e. the offset map will always only contain the assigned partitions when commitSync is called. Hence there is no need to trigger a rebalance in commitSync().  The same guarantee also apply to fetchCommittedOffset(), isn't the only requirement is to ensure we know the coordinator?  Another related issue is that today the IllegalGenerationIdException is a bit confusing. When we receive an IllegalGenerationIdException from heartbeat, we need to use that same generation Id to commit offset and the coordinator will take it. So the generation ID was not really illegal. I will file a ticket for this issue.","closed","","becketqin","2015-09-18T17:53:03Z","2015-09-25T18:58:28Z"
"","407","KAFKA-2726: Fix port collision between ntpdate and ntp daemon","@gwenshap Can you take a quick look? I have verified the change allows successful `vagrant provision` even with ntp daemon already running on the vm.","closed","","granders","2015-11-02T20:45:44Z","2015-11-10T03:24:13Z"
"","396","MINOR: Remove unreachable if check","@gwenshap @granders could you guys take a look at this trivial change. This piece makes one think that for SSL, not passing `new_consumer=True` should be fine. It was fine until recently, before https://github.com/apache/kafka/commit/e6b343302f3208f7f6e0099fe2a7132ef9eaaafb.","closed","","SinghAsDev","2015-10-31T00:07:48Z","2015-11-13T00:45:54Z"
"","347","MINOR: fix checkstyle failures","@guozhangwang could you take a look at this. These failures are a bit annoying as it never leads to a successful build.","closed","","SinghAsDev","2015-10-21T21:21:14Z","2015-10-22T02:06:09Z"
"","209","KAFKA-1901: follow-up on KAFKA-1901; Added error handling.","@guozhangwang  added .git/refs/heads/ file existence check.","closed","","omkreddy","2015-09-13T16:54:25Z","2016-01-06T20:49:06Z"
"","289","MINOR: typing ProcessorDef","@guozhangwang  This code change properly types ProcessorDef. This also makes KStream.process() typesafe.","closed","","ymatsuda","2015-10-08T23:08:07Z","2015-10-26T21:14:52Z"
"","315","KAFKA-2654: optimize unnecessary poll(0) away","@guozhangwang  This change aims to remove unnecessary `consumer.poll(0)` calls. - `once` after some partition is resumed - whenever the size of the top queue in any task is below `BUFFERED_RECORDS_PER_PARTITION_CONFIG`","closed","","ymatsuda","2015-10-15T16:39:47Z","2015-10-26T21:15:57Z"
"","317","MINOR: set up temp directories properly in StreamTaskTest","@guozhangwang  StreamTaskTest did not set up a temp directory for each test. This occasionally caused interference between tests through state directory locking.","closed","","ymatsuda","2015-10-15T18:31:18Z","2015-10-26T21:16:22Z"
"","304","MINOR: flush record collector after local state flush","@guozhangwang  Fix the order of flushing. Undoing the change I did sometime ago.","closed","","ymatsuda","2015-10-13T21:44:45Z","2015-10-26T21:16:12Z"
"","292","MINOR: putting back kstream stateful transform methods","@guozhangwang  - added back type safe stateful transform methods (kstream.transform() and kstream.transformValues()) - changed kstream.process() to void","closed","","ymatsuda","2015-10-09T22:07:51Z","2015-10-26T21:14:59Z"
"","353","KAFKA-2652: integrate new group protocol into partition grouping","@guozhangwang  - added `PartitionGrouper` (abstract class)   - This class is responsible for grouping partitions. Each group forms a task.   - Users may implement this class for custom grouping. - added `DefaultPartitionGrouper`   - our default implementation of `PartitionGrouper` - added `KafkaStreamingPartitionAssignor`   - We always use this as `PartitionAssignor` of stream consumers.   - Actual grouping is delegated to `PartitionGrouper`. - `TopologyBuilder`   - added `topicGroups()`     - This returns groups of related topics according to the topology   - added `copartitionSources(sourceNodes...)`     - This is used by DSL layer. It asserts the specified source nodes must be copartitioned.   - added `copartitionGroups()`     - This returns groups of copartitioned topics - KStream layer   - keep track of source nodes to determine copartition sources when steams are joined   - source nodes are set to null when partitioning property is not preserved (ex. `map()`, `transform()`), and this indicates the stream is no longer joinable","closed","","ymatsuda","2015-10-22T19:08:44Z","2015-11-03T19:46:54Z"
"","365","KAFKA-2694: Task Id","@guozhangwang  - A task id is now a class, `TaskId`, that has a topic group id and a partition id fields. - `TopologyBuilder` assigns a topic group id to a topic group. Related methods are changed accordingly. - A state store uses the partition id part of the task id as the change log partition id.","closed","","ymatsuda","2015-10-26T21:38:33Z","2015-11-03T19:47:12Z"
"","411","KAFKA-2727: Topology partial construction","@guozhangwang","closed","","ymatsuda","2015-11-03T18:06:02Z","2015-11-04T21:49:39Z"
"","408","KAFKA-2707: make KStream processor names deterministic","@guozhangwang","closed","","ymatsuda","2015-11-02T21:34:51Z","2015-11-03T19:49:00Z"
"","374","HOTFIX: correct sourceNodes for kstream.through()","@guozhangwang","closed","","ymatsuda","2015-10-27T23:08:11Z","2015-11-03T19:44:40Z"
"","372","HOTFIX: fix off-by-one stream offset commit","@guozhangwang","closed","","ymatsuda","2015-10-27T20:19:52Z","2015-11-03T19:43:55Z"
"","275","KAFKA-2527; System Test for Quotas in Ducktape","@granders Can you take a look at this quota system test?","closed","","lindong28","2015-10-05T07:09:35Z","2015-10-13T21:01:57Z"
"","392","KAFKA-2715: Removed previous system_test folder","@ewencp Nothing too complicated here","closed","","granders","2015-10-30T21:14:03Z","2015-11-10T03:24:14Z"
"","232","Should stop offset backing store in Copycat Worker's stop method","@ewencp @gwenshap This is a trivial bug fix","closed","","Ishiihara","2015-09-23T00:17:25Z","2015-09-23T00:47:55Z"
"","229","KAFKA-1888: rolling upgrade test","@ewencp @gwenshap  This needs some refactoring to avoid the duplicated code between replication test and upgrade test, but in shape for initial feedback.  I'm interested in feedback on the added `KafkaConfig` class and `kafka_props` file. This addition makes it: - easier to attach different configs to different nodes (e.g. during broker upgrade process) - easier to reason about the configuration of a particular node  Notes: - in the default values in the KafkaConfig class, I removed many properties which were in kafka.properties before. This is because most of those properties were set to what is already the default value. - when running non-trunk VerifiableProducer, I append the trunk tools jar to the classpath, and run it with the non-trunk kafka-run-class.sh script","closed","","granders","2015-09-21T21:13:18Z","2015-12-09T19:41:49Z"
"","383","MINOR: update to correct clock skew","@ewencp  Updated the provisioning script to install ntp daemon.","closed","","granders","2015-10-29T18:33:28Z","2015-12-09T19:41:46Z"
"","179","KAFKA-2489: add benchmark for new consumer","@ewencp  The changes here are smaller than they look - mostly refactoring/cleanup. - ConsumerPerformanceService: added new_consumer flag, and exposed more command-line settings - benchmark.py: refactored to use `@parametrize` and `@matrix` - this reduced some amount of repeated code - benchmark.py: added consumer performance tests with new consumer (using `@parametrize`) - benchmark.py: added more detailed test descriptions - performance.py: broke into separate files","closed","","granders","2015-08-29T16:50:00Z","2015-09-09T17:05:40Z"
"","385","MINOR: Update system test MANIFEST.in","@ewencp  Some *.properties files were missing from `kafkatest` package. This update makes `kafkatest` services once again useable by external dependencies  I've tested this change on aws with confluent system tests","closed","","granders","2015-10-29T22:48:09Z","2015-11-10T03:24:17Z"
"","384","KAFKA-2714: Added integration tests for exceptional cases in fetching","1. When reset policy is NONE, verify that NoOffsetForPartitionException is thrown if no initial position is set. Verify that OffsetOutOfRange is thrown if you seek out of range. 2. Verify RecordTooLargeException is thrown if a message is too large for the configured fetch size.","closed","","apovzner","2015-10-29T22:27:08Z","2015-10-30T21:24:58Z"
"","60","Patch for KAFKA-2055: ConsumerBounceTest.testSeekAndCommitWithBrokerFail...","...ures transient failure","closed","","lvfangmin","2015-05-01T14:29:52Z","2015-07-24T20:28:44Z"
"","59","Adding ability to provide a prefix for the destination topic name. This ...","...can be used to allow two clusters to mirror to each other without causing a loop.","closed","","pedersen","2015-04-30T19:15:00Z","2020-06-07T22:28:06Z"
"","472","KAFKA-2769:  Multi-consumer integration tests for consumer assignment incl. session timeouts and corresponding fixes","-- Refactored multi-consumer integration group assignment validation tests for round-robin assignment -- Added multi-consumer integration tests for session timeout expiration: 1. When a consumer stops polling 2. When a consumer calls close()  -- Fixes to issues found with session timeout expiration tests woth help from Jason Gustafson: Try to avoid  SendFailedException exception by cancelling the scheduled tasks and ensuring metadata update before sending group leave requests + send leave group request with retries.","closed","","apovzner","2015-11-09T22:02:56Z","2015-11-10T01:02:11Z"
"","288","KAFKA-2614; No more clients can connect after `TooManyConnectionsException` threshold (max.connections.per.ip) is reached","- Call `ConnectionQuotas.decr` when calling `Selector.close` and when disconnections happen. - Expand `SocketServerTest` to test for this and to close sockets. - Refactor and clean-up `SocketServer` and `Acceptor` to make the code easier to understand.","closed","","ijuma","2015-10-08T15:44:46Z","2016-03-01T22:47:42Z"
"","322","KAFKA-2338: Warn on max.message.bytes change","- Both TopicCommand and ConfigCommand warn if message.max.bytes increases - Log failures on the broker if replication gets stuck due to an oversized message - Added blocking call to warning.","closed","","benstopford","2015-10-15T23:59:28Z","2015-10-21T00:22:04Z"
"","217","KAFKA-2431: Easier Testing of SSL","- Allow cipher suites to be specified relevant properties - Avoid System.exit in ProducerPerformance so this can be externally invoked - Add command line option so that a default properties can be specified in ConsumerPerformance (needed for ssl properties) - Allow cipher suites to be specified via properties - Increase timeout in ConsumerPerformance (useful when running with SSL under load) - Use a relative default value for the reporting interval in Consumer Performance - Add option for show-all-stats (includes intermediary and summary stats) in Consumer Performance","closed","","benstopford","2015-09-15T02:12:42Z","2015-10-22T11:56:39Z"
"","387","KAFKA-2706: make state stores first class citizens in the processor topology","- Added StateStoreSupplier - StateStore   - Added init(ProcessorContext context) method - TopologyBuilder   - Added addStateStore(StateStoreSupplier supplier, String... processNames)   - Added connectProessorAndStateStores(String processorName, String... stateStoreNames)     - This is for the case processors are not created when a store is added to the topology. (used by KStream) - KStream   - add stateStoreNames to process(), transform(), transformValues(). - Refactored existing state stores to implement StateStoreSupplier  @guozhangwang","closed","","ymatsuda","2015-10-29T23:30:54Z","2015-11-03T19:45:35Z"
"","183","MINOR: MockClient's disconnect() method has two bugs","(and a prospetive refactoring) - First, it compares Strings using `==` instead of `equals()` - Second, it tries to remove a String from a Set. As disconnect() method is only called by a single method on SenderTest then it's safe to refactor it to make it both explicit that its argument is a node id and perform a Integer.valueOf() before trying to remove from `ready`. - Third, not a bug, but the Iterator logic can be simplified, shrinking the scope of the Iterator without changing the logic.","closed","","eribeiro","2015-09-01T03:32:46Z","2016-02-02T23:11:14Z"
"","162","Exclude conflicting zookeeper version from 'com.101tec:zkclient' dependencies","'com.101tec:zkclient:0.5' package brings in a dependency on older zookeper version: `3.4.4`  This causes conflicts if consumers of kafka jar are trying to use `maven-enforcer` plugin. This plugin ensures there are no conflicts in your dependency clojure.","closed","","shtratos","2015-08-24T14:58:52Z","2015-09-02T16:20:48Z"
"","445","Kafka 2761","#412 is a pre-req.","closed","","SinghAsDev","2015-11-06T19:56:33Z","2015-11-08T19:30:34Z"
"","13","Added changes so that bin/*.sh files can work with CYGWIN under windows,...","### Background  The script files to run Kafka under Windows don't work as is.  One needs to hand tweak them since their location is not `bin` but `bin/windows`.  Further, the script files under `bin/windows` are not a complete replica of those under `bin`.  To be sure, this isn't a complaint.  To the contrary most projects now-a-days don't bother to support running on Windows or do so very late.  Just that because of these limitation it might be more prudent to make the script files under `bin` itself run under windows rather than trying to make the files under `bin/windows` work or to make them complete. ### Change Summary  Most common unix-like shell on windows is the bash shell which is a part of the cygwin project.  Out of the box the scripts don't work mostly due to peculiarities of the directory paths and class path separators.  This change set makes a focused change to a single file under `bin` so that all of the script files under `bin` would work as is on windows platform when using bash shell of Cygwin distribution. ### Motivation  Acceptance of this change would enable a vast body of developers that use (or have to use) Windows as their development/testing/production platform to use Kafka's with ease.  More importantly by making the running of examples smoothly on Windoes+Cygwin-bash it would make the process of evaluation of Kafka simpler and smoother and potentially make for a favorable evaluation.  For, it would show commitment of the Kafka team to espouse deployments on Windows (albeit only under cygwin).  Further, as the number of people whom use Kafka on Windows increases, one would attract people who can eventually fix the script files under `bin/Windows` itself so that need to run under Cygwin would also go away, too. ### Testing details  The change have been tested under `GNU bash, version 4.1.11(2)-release (x86_64-unknown-cygwin)` running on Windows 7 Enterprise.","closed","","aloklal99","2014-01-21T19:21:12Z","2015-07-20T19:08:51Z"
"","478","KAFKA-2784: swallow exceptions when mirror maker exits.","","closed","","becketqin","2015-11-10T00:02:20Z","2016-03-03T02:22:51Z"
"","476","KAFKA-2786: Only respond to SinkTask onPartitionsRevoked after the WorkerSinkTask has finished starting up.","","closed","","ewencp","2015-11-09T23:41:37Z","2015-11-10T04:43:33Z"
"","475","KAFKA-2379: Add basic documentation for Kafka Connect.","","closed","","ewencp","2015-11-09T23:34:37Z","2015-11-10T00:29:55Z"
"","474","MINOR: remove Kafka Streams in 0.9.0","","closed","","guozhangwang","2015-11-09T23:32:09Z","2015-11-10T00:28:08Z"
"","473","KAFKA-2785: Include Kafka Connect jars in releaseTarGz.","","closed","","ewencp","2015-11-09T22:57:30Z","2015-11-09T23:08:52Z"
"","471","MINOR: Improve exception message that gets thrown for non-existent group","","closed","","SinghAsDev","2015-11-09T20:46:44Z","2015-11-09T21:44:32Z"
"","470","KAFKA-2770: Catch and ignore WakeupException for commit upon closing","","closed","","guozhangwang","2015-11-09T20:22:27Z","2015-11-11T03:18:49Z"
"","469","MINOR: Make sure generated docs don't get checked in","","closed","","granthenke","2015-11-09T20:19:50Z","2015-11-17T17:06:49Z"
"","468","MINOR: remove old producer in config sections to align with APIs","","closed","","guozhangwang","2015-11-09T20:04:36Z","2015-11-09T21:37:40Z"
"","467","KAFKA-2674: clarify onPartitionsRevoked behavior","","closed","","hachikuji","2015-11-09T19:03:49Z","2015-11-09T19:11:53Z"
"","466","KAFKA-2783: Drop outdated hadoop contrib modules","","closed","","granthenke","2015-11-09T18:33:14Z","2015-11-17T17:06:38Z"
"","465","KAFKA-2274: verifiable consumer and integration testing","","closed","","hachikuji","2015-11-09T18:29:56Z","2015-11-10T02:32:38Z"
"","464","HOTFIX: bug updating cache when loading group metadata (0.9.0)","","closed","","hachikuji","2015-11-09T18:21:40Z","2015-11-09T18:22:56Z"
"","463","KAFKA-2782: Fix KafkaBasedLogTest assertion and move it to the main test thread.","","closed","","ewencp","2015-11-09T18:18:56Z","2015-11-09T18:40:20Z"
"","461","KAFKA-2781: Only require signing artifacts when uploading archives.","","closed","","ewencp","2015-11-09T16:57:42Z","2015-11-09T17:10:45Z"
"","459","KAFKA-2778: Use zero loss settings by default for Connect source producers.","","closed","","ewencp","2015-11-09T06:24:45Z","2015-11-09T18:37:27Z"
"","458","KAFKA-2776: Fix lookup of schema conversion cache size in JsonConverter.","","closed","","ewencp","2015-11-09T06:18:15Z","2015-11-09T18:19:53Z"
"","457","KAFKA-2775: Move exceptions into API package for Kafka Connect.","","closed","","ewencp","2015-11-09T06:15:44Z","2015-11-09T18:27:58Z"
"","456","KAFKA-2774: Rename Copycat to Kafka Connect","","closed","","ewencp","2015-11-09T05:02:33Z","2015-11-09T06:24:13Z"
"","455","KAFKA-2773: (0.9.0 branch)Fixed broken vagrant provision scripts for static zk/broker cluster","","closed","","granders","2015-11-09T02:11:38Z","2015-11-10T03:23:14Z"
"","454","KAFKA-2773: Fixed broken vagrant provision scripts for static zk/broker cluster","","closed","","granders","2015-11-09T02:10:38Z","2015-11-10T03:23:12Z"
"","453","HOTFIX: fix group coordinator edge cases around metadata storage callback (0.9.0)","","closed","","hachikuji","2015-11-08T20:10:26Z","2015-11-08T20:53:47Z"
"","452","KAFKA-2723: new consumer exception cleanup (0.9.0)","","closed","","hachikuji","2015-11-08T06:07:43Z","2015-11-08T19:57:26Z"
"","451","HOTFIX: fix group coordinator edge cases around metadata storage callback","","closed","","hachikuji","2015-11-08T04:11:17Z","2015-11-08T20:23:20Z"
"","450","KAFKA-2480: Handle retriable and non-retriable exceptions thrown by sink tasks.","","closed","","ewencp","2015-11-07T18:36:00Z","2015-11-09T04:41:59Z"
"","449","KAFKA-2767: Upgrade ZkClient version to 0.7","","closed","","fpj","2015-11-06T23:11:57Z","2015-11-07T02:22:52Z"
"","446","KAFKA-2765: Add versions to Copycat Connector and Task interfaces and log versions when instantiating connectors and tasks.","","closed","","ewencp","2015-11-06T21:49:59Z","2015-11-07T01:51:14Z"
"","444","KAFKA-2764: Change use of Properties in Copycat to Maps.","","closed","","ewencp","2015-11-06T19:15:47Z","2015-11-06T21:22:12Z"
"","443","KAFKA-2713: Run task start and stop methods in worker threads so they execute in parallel and cannot block the herder thread.","","closed","","ewencp","2015-11-06T16:56:31Z","2015-11-06T18:27:49Z"
"","441","KAFKA-2723: new consumer exception cleanup","","closed","","hachikuji","2015-11-06T06:05:46Z","2015-11-08T19:26:38Z"
"","439","HOTFIX: unsubscribe does not clear user assignment properly","","closed","","hachikuji","2015-11-06T04:10:00Z","2015-11-06T04:32:44Z"
"","438","KAFKA-2756: Use request version Id instead of latest version Id to parse the corresponding response.","","closed","","guozhangwang","2015-11-05T23:28:20Z","2015-12-14T22:49:59Z"
"","437","MINOR: KAFKA-2751 Improve documentation for log.retention.ms","","closed","","lindong28","2015-11-05T22:53:45Z","2015-11-17T02:17:42Z"
"","436","KAFKA-2721; Avoid handling duplicate LeaderAndISR requests","","closed","","lindong28","2015-11-05T21:33:40Z","2015-11-17T02:18:00Z"
"","434","MINOR: follow-up KAFKA-2730 to use two tags for broker id and fetcher id combination","","closed","","guozhangwang","2015-11-05T20:22:03Z","2015-11-05T23:43:55Z"
"","433","KAFKA-2753: improve SyncGroup error handling in client","","closed","","hachikuji","2015-11-05T18:07:23Z","2015-11-05T18:16:49Z"
"","432","KAFKA-2752: Add VerifiableSource/Sink connectors and rolling bounce Copycat system tests.","","closed","","ewencp","2015-11-05T17:43:36Z","2015-11-10T23:31:49Z"
"","426","MINOR: add test case for fetching from a compacted topic","","closed","","hachikuji","2015-11-05T00:32:43Z","2015-11-05T01:26:03Z"
"","425","KAFKA-2745: Update JavaDoc for new / updated consumer APIs","","closed","","guozhangwang","2015-11-04T23:22:48Z","2015-11-06T00:42:48Z"
"","424","HOTFIX: Fix incorrect version used for group metadata version","","closed","","hachikuji","2015-11-04T22:30:52Z","2015-11-04T22:57:02Z"
"","423","KAFKA-2744: Commit source task offsets after task is completely stopped to ensure no additional messages are processed during the offset commit when stopping tasks for rebalancing.","","closed","","ewencp","2015-11-04T19:33:21Z","2015-11-04T20:00:12Z"
"","422","KAFKA-2743: Make forwarded task reconfiguration requests asynchronous, run on a separate thread, and backoff before retrying when they fail.","","closed","","ewencp","2015-11-04T19:33:05Z","2015-11-05T16:44:25Z"
"","421","KAFKA-2742: Fix SourceTaskOffsetCommitter to handle removal of commit tasks when they are already in progress.","","closed","","ewencp","2015-11-04T19:32:25Z","2015-11-05T16:37:14Z"
"","420","KAFKA-2741: Make SourceTaskContext and SinkTaskContext interfaces and keep implementations in runtime jar.","","closed","","ewencp","2015-11-04T19:31:49Z","2015-11-05T16:39:12Z"
"","416","KAFKA-2730: use thread-id as metrics tags","","closed","","guozhangwang","2015-11-04T07:59:16Z","2015-11-05T20:16:23Z"
"","414","KAFKA-2697: client-side support for leave group","","closed","","hachikuji","2015-11-04T00:33:32Z","2015-11-04T22:58:33Z"
"","410","KAFKA-2732: Add class for ZK Auth.","","closed","","fpj","2015-11-03T16:23:22Z","2015-11-28T16:24:08Z"
"","409","KAFKA-2724: ZK Auth documentation.","","closed","","fpj","2015-11-02T22:57:00Z","2015-11-03T17:42:50Z"
"","406","KAFKA-2441: SSL/TLS in official docs","","closed","","gwenshap","2015-11-02T19:03:55Z","2015-11-03T22:19:50Z"
"","405","KAFKA-2716: Make Kafka core not depend on log4j-appender","","closed","","SinghAsDev","2015-11-02T18:55:59Z","2015-11-03T18:30:30Z"
"","404","KAFKA-2518: Update NOTICE file","","closed","","gwenshap","2015-11-02T17:32:55Z","2015-11-02T19:08:45Z"
"","397","MINOR: getRootLogger() should be accessed in static way","","closed","","vesense","2015-10-31T01:31:24Z","2016-01-29T12:43:11Z"
"","395","HOTFIX: log4j-appender not getting built","","closed","","SinghAsDev","2015-10-30T23:47:35Z","2015-10-31T02:05:24Z"
"","394","KAFKA-2691: Improve handling of authorization failure during metadata refresh","","closed","","hachikuji","2015-10-30T23:41:22Z","2015-11-04T19:02:53Z"
"","393","KAFKA-2714: Added integration tests for exceptional cases in fetching","","closed","","apovzner","2015-10-30T21:26:52Z","2015-10-30T21:54:41Z"
"","389","MINOR: ignore subproject .gitignore file for eclipse IDE","","closed","","vesense","2015-10-30T08:56:05Z","2016-01-05T04:31:32Z"
"","388","KAFKA-2687: Add support for ListGroups and DescribeGroup APIs","","closed","","hachikuji","2015-10-30T07:22:41Z","2015-11-03T22:40:37Z"
"","386","KAFKA-2017: Persist Group Metadata and Assignment before Responding","","closed","","guozhangwang","2015-10-29T23:24:33Z","2015-11-03T07:36:35Z"
"","378","KAFKA-2369: Add REST API for Copycat.","","closed","","ewencp","2015-10-29T02:35:38Z","2015-10-30T22:00:24Z"
"","377","MINOR: Fix missing copyright in config file added in KAFKA-2640.","","closed","","ewencp","2015-10-29T02:35:25Z","2015-10-29T03:39:36Z"
"","376","KAFKA-2675; SASL/Kerberos follow up","","closed","","ijuma","2015-10-28T14:45:07Z","2016-03-01T22:49:26Z"
"","375","HOTFIX: Rename WakeupException in MirrorMaker","","closed","","guozhangwang","2015-10-28T02:24:18Z","2015-10-28T02:27:48Z"
"","370","HOTFIX: group rebalance can throw illegal generation or rebalance in progress","","closed","","hachikuji","2015-10-27T19:11:13Z","2015-10-27T20:39:54Z"
"","366","KAFKA-2683: ensure wakeup exceptions raised to user","","closed","","hachikuji","2015-10-27T05:46:07Z","2015-10-28T00:34:30Z"
"","362","KAFKA-2648: group.id is required for new consumer and cannot be empty","","closed","","hachikuji","2015-10-26T19:41:13Z","2015-10-28T21:09:02Z"
"","360","MINOR: KAFKA-2371 follow-up, DistributedHerder should wakeup WorkerGroupMember after assignment to ensure work is started immediately","","closed","","ewencp","2015-10-26T17:50:07Z","2015-10-28T19:42:27Z"
"","359","KAFKA-2688; Avoid forcing reload of `Configuration`","","closed","","ijuma","2015-10-26T13:00:38Z","2016-03-01T22:49:52Z"
"","355","KAFKA-2460; Fix capitalisation in SSL classes","","closed","","ijuma","2015-10-24T16:34:28Z","2016-03-01T22:49:53Z"
"","354","MINOR: follow-up to KAFKA-2464 for renaming/cleanup","","closed","","hachikuji","2015-10-23T03:20:51Z","2015-10-27T01:25:39Z"
"","352","KAFKA-2686: Reset needsPartitionAssignment in SubscriptionState.assign()","","closed","","guozhangwang","2015-10-22T19:01:45Z","2015-10-23T04:01:28Z"
"","349","KAFKA-2677: ensure consumer sees coordinator disconnects","","closed","","hachikuji","2015-10-22T00:11:49Z","2015-10-27T23:19:05Z"
"","348","MINOR: Clean-up MemoryRecords variables and APIs","","closed","","guozhangwang","2015-10-21T21:41:04Z","2015-10-28T17:06:14Z"
"","346","KAFKA-2678; partition level lag metrics can be negative","","closed","","lindong28","2015-10-21T21:12:59Z","2015-10-29T00:46:23Z"
"","345","KAFKA-2626: Handle null keys and value validation properly in OffsetStorageWriter.","","closed","","ewencp","2015-10-21T17:51:05Z","2015-10-24T02:36:01Z"
"","344","KAFKA-2626: Handle null keys and value validation properly in OffsetStorageWriter.","","closed","","ewencp","2015-10-21T17:47:42Z","2015-10-21T17:50:52Z"
"","342","KAFKA-2456 KAFKA-2472; SSL clean-ups","","closed","","ijuma","2015-10-21T14:25:04Z","2016-03-01T22:47:36Z"
"","340","KAFKA-2480: Add backoff timeout and support rewinds","","closed","","Ishiihara","2015-10-21T01:08:10Z","2015-11-03T21:17:53Z"
"","339","KAFKA-2618; Disable SSL renegotiation for 0.9.0.0","","closed","","ijuma","2015-10-20T22:31:31Z","2016-03-01T22:47:17Z"
"","338","KAFKA-2617: Move protocol field default values to Protocol.","","closed","","j-nowak","2015-10-20T21:28:04Z","2017-12-22T20:23:28Z"
"","336","KAFKA-2657; Kafka clients fail to start if one of broker isn't resolved by DNS","","closed","","apakulov","2015-10-20T19:51:22Z","2016-09-22T00:42:49Z"
"","332","HOTFIX: check logic of KAFKA-2515 should be on buffer.limit()","","closed","","guozhangwang","2015-10-20T01:24:19Z","2015-10-20T02:28:48Z"
"","331","MINOR: Capture stderr in ConsumerPerformanceService.","","closed","","ewencp","2015-10-19T23:59:35Z","2015-10-20T00:14:12Z"
"","330","KAFKA-2671: Enable starting Kafka server with a Properties object","","closed","","SinghAsDev","2015-10-19T20:21:33Z","2015-10-23T05:28:16Z"
"","326","MINOR: update the command to run a particular test method in readme","","closed","","lindong28","2015-10-17T06:45:09Z","2015-10-21T03:44:10Z"
"","319","KAFKA-2574: Add ducktape based ssl test for KafkaLog4jAppender","","closed","","SinghAsDev","2015-10-15T21:31:03Z","2015-10-31T00:50:34Z"
"","318","KAFKA-2515: Handle oversized messages properly in new consumer","","closed","","guozhangwang","2015-10-15T18:36:18Z","2015-10-17T00:35:09Z"
"","311","TRIVIAL: add @throws ConsumerWakeupException in KafkaConsumer","","closed","","guozhangwang","2015-10-14T21:50:04Z","2015-10-14T21:53:33Z"
"","310","KAFKA-2516: Rename o.a.k.client.tools to o.a.k.tools","","closed","","granthenke","2015-10-14T16:53:16Z","2015-11-17T17:06:28Z"
"","306","MINOR: ignore wakeups when committing offsets on consumer close","","closed","","hachikuji","2015-10-13T23:58:10Z","2015-10-14T01:51:34Z"
"","299","KAFKA-2490: support new consumer in ConsumerGroupCommand","","closed","","SinghAsDev","2015-10-12T23:20:23Z","2015-11-06T06:19:10Z"
"","297","KAFKA-2487: change kafka.examples.Consumer to use the new java consumer","","closed","","SinghAsDev","2015-10-12T18:24:50Z","2015-10-16T00:24:03Z"
"","296","KAFKA-2633: Default logging from tools to Stderr","","closed","","granthenke","2015-10-12T16:52:26Z","2015-11-17T17:06:20Z"
"","295","KAFKA-2632: move fetchable check ahead in handleFetchResponse","","closed","","guozhangwang","2015-10-11T06:37:56Z","2015-10-14T01:49:09Z"
"","293","KAFKA-2613: Make maxParallelForks configurable via Gradle config so it can be turned down on shared build infrastructure.","","closed","","ewencp","2015-10-09T23:31:57Z","2015-10-13T01:27:30Z"
"","291","MINOR: Fix exception message in Copycat's Time logical type.","","closed","","ewencp","2015-10-09T19:55:53Z","2015-10-09T20:04:38Z"
"","286","KAFKA-2621; nextOffsetMetadata should be changed after rolling a new log segment","","closed","","lindong28","2015-10-08T05:09:58Z","2015-10-13T00:48:19Z"
"","285","KAFKA-2622: Add Time logical type for Copycat.","","closed","","ewencp","2015-10-07T22:03:57Z","2015-10-09T19:56:29Z"
"","283","KAFKA-2391 [WIP]: add timeout to KafkaConsumer blocking calls","","closed","","onurkaraman","2015-10-07T18:13:31Z","2016-12-26T22:38:05Z"
"","278","TRIVIAL: remove TODO in KafkaConsumer after KAFKA-2120","","closed","","guozhangwang","2015-10-05T21:06:45Z","2015-10-05T21:08:02Z"
"","277","Kafka-2587:  Only notification handler will update the cache and all verifications will use waitUntilTrue.","","closed","","Parth-Brahmbhatt","2015-10-05T18:25:17Z","2015-10-08T01:14:17Z"
"","273","KAFKA-2517; Performance Regression post SSL implementation (zero copy)","","closed","","ijuma","2015-10-02T10:21:14Z","2016-03-01T22:47:47Z"
"","272","KAFKA-2604; Remove `completeAll` and improve timeout passed to `Selector.poll` from `NetworkClient.poll`","","closed","","ijuma","2015-10-02T09:31:23Z","2016-03-01T22:47:46Z"
"","269","KAFKA-2601: ConsoleProducer tool shows stacktrace on invalid command parameters","","closed","","GabrielNicolasAvellaneda","2015-10-01T13:51:07Z","2015-10-05T05:04:34Z"
"","268","MINOR: Fixed README examples on running specific tests.","","closed","","GabrielNicolasAvellaneda","2015-10-01T01:02:51Z","2015-10-19T05:40:49Z"
"","267","KAFKA-2596: reject commits from unknown groups with positive generations","","closed","","hachikuji","2015-10-01T00:17:58Z","2015-10-09T06:35:14Z"
"","266","KAFKA-2452: Add new consumer option to mirror maker.","","closed","","becketqin","2015-09-30T17:49:20Z","2015-10-27T15:00:31Z"
"","263","KAFKA 2578 Client Metadata internal state should be synchronized","","closed","","eribeiro","2015-09-29T21:24:03Z","2015-12-16T22:41:44Z"
"","261","HOTFIX: Checkstyle import fix","","closed","","ijuma","2015-09-29T20:07:31Z","2016-03-01T22:47:50Z"
"","260","KAFKA-2587:Increasing timeout for the test verification.","","closed","","Parth-Brahmbhatt","2015-09-29T02:14:51Z","2015-09-29T22:20:04Z"
"","258","MINOR: remove no longer needed CommitType","","closed","","hachikuji","2015-09-29T00:29:51Z","2015-10-02T22:05:43Z"
"","257","KAFKA-2570: commit offsets on rebalance/close when auto-commit is enabled","","closed","","hachikuji","2015-09-28T20:46:54Z","2015-09-30T00:45:28Z"
"","252","KAFKA-2586; Enable SSL for inter-broker communication when SSL is enabled in tests","","closed","","ijuma","2015-09-28T13:19:13Z","2016-03-01T22:50:02Z"
"","251","MINOR: Fix FileStreamSourceTask to create the reader around System.in when using stdin as the input source.","","closed","","ewencp","2015-09-28T07:01:38Z","2015-09-28T12:46:39Z"
"","250","KAFKA-2474: Add caching of JSON schema conversions to JsonConverter.","","closed","","ewencp","2015-09-28T06:57:57Z","2015-10-06T22:27:29Z"
"","249","KAFKA-2482: Allow sink tasks to get their current assignment, as well as pause and resume topic partitions.","","closed","","ewencp","2015-09-28T06:45:39Z","2015-10-06T21:22:10Z"
"","248","HOTFIX: Checkstye fixes follow up for KAKFA-2531.","","closed","","ewencp","2015-09-28T06:43:42Z","2015-09-28T13:34:04Z"
"","247","KAFKA-2585; ConsoleConsumer should not hang infinitely upon exception","","closed","","lindong28","2015-09-28T05:39:12Z","2015-09-28T21:48:02Z"
"","245","KAFKA-2582; ConsumerMetdata authorization error not returned to user","","closed","","hachikuji","2015-09-25T21:28:36Z","2015-09-25T22:40:54Z"
"","244","HOTFIX: remove unused import causing checkstyle to fail","","closed","","hachikuji","2015-09-25T20:47:28Z","2015-09-25T21:08:47Z"
"","243","KAFKA-2409; have KafkaConsumer.committed return null when there is no commit","","closed","","hachikuji","2015-09-25T16:46:02Z","2015-09-25T18:05:19Z"
"","240","KAFKA-2579; prevent unauthorized clients from joining groups","","closed","","hachikuji","2015-09-25T00:39:43Z","2015-09-25T08:03:42Z"
"","239","KAFKA-2390-followup; add unit test for OffsetOutOfRange exception","","closed","","lindong28","2015-09-24T17:54:51Z","2015-10-17T05:31:21Z"
"","235","KAFKA-2531: Add Ducktape based tests for KafkaLog4jAppender","","closed","","SinghAsDev","2015-09-23T06:04:19Z","2015-09-27T01:33:09Z"
"","234","KAFKA-2573: Mirror maker system test hangs and eventually fails","","closed","","SinghAsDev","2015-09-23T05:58:56Z","2015-10-06T21:07:36Z"
"","231","KAFKA-2571: KafkaLog4jAppender dies while specifying acks config","","closed","","SinghAsDev","2015-09-22T23:23:02Z","2015-09-25T02:16:45Z"
"","230","KAFKA-2212: Authorizer CLI implementation.","","closed","","Parth-Brahmbhatt","2015-09-22T22:11:09Z","2015-10-02T01:04:29Z"
"","228","more test","","closed","","jinxing64","2015-09-21T03:57:13Z","2015-11-12T04:44:00Z"
"","227","okok-test","","closed","","jinxing64","2015-09-21T03:53:39Z","2015-09-21T04:12:52Z"
"","226","MOD: test again","","closed","","jinxing64","2015-09-21T03:43:52Z","2015-09-21T04:01:21Z"
"","225","MOD: for test","","closed","","jinxing64","2015-09-21T03:27:11Z","2015-09-21T03:37:59Z"
"","223","KAFKA-2229:  KIP-4 Phase 1: Requests and KafkaApis","","closed","","abiletskyi","2015-09-19T09:13:05Z","2016-12-26T22:38:06Z"
"","222","KAFKA-2557: separate REBALANCE_IN_PROGRESS and ILLEGAL_GENERATION error codes","","closed","","onurkaraman","2015-09-18T23:14:58Z","2015-09-23T15:51:36Z"
"","220","KAFKA-2533: Create a member Metadata.Listener inside KafkaConsumer","","closed","","SinghAsDev","2015-09-16T20:39:23Z","2015-09-21T19:04:48Z"
"","211","KAFKA-2504: Stop logging WARN when client disconnects","","closed","","jholoman","2015-09-14T00:37:23Z","2015-09-14T22:31:28Z"
"","208","KAFKA-2538: Fixing a compilation error in trunk.","","closed","","Parth-Brahmbhatt","2015-09-12T02:33:37Z","2016-03-07T21:37:00Z"
"","203","KAFKA-2532; Remove Consumer reference from rebalance callback","","closed","","hachikuji","2015-09-11T00:27:39Z","2015-09-21T20:11:02Z"
"","202","KAFKA-2373: Add Kafka-backed offset storage for Copycat.","","closed","","ewencp","2015-09-10T02:35:06Z","2015-09-25T02:14:44Z"
"","200","KAFKA-2512: Add version check to broker and clients.","","closed","","becketqin","2015-09-09T17:18:44Z","2022-02-09T19:35:03Z"
"","198","0.8.2","","closed","","leoricxu","2015-09-06T14:12:05Z","2015-09-08T13:33:50Z"
"","196","KAFKA-2072: Replace StopReplica Request/Response with their org.apache.kafka.common.requests equivalents","","closed","","dajac","2015-09-05T19:34:26Z","2020-08-11T06:47:32Z"
"","195","KAFKA-2211: Adding simpleAclAuthorizer implementation and test cases.","","closed","","Parth-Brahmbhatt","2015-09-04T22:23:12Z","2015-09-22T00:54:08Z"
"","194","KAFKA-2440; Use `NetworkClient` instead of `SimpleConsumer` to fetch data from replica","","closed","","ijuma","2015-09-04T20:51:06Z","2016-03-01T22:50:27Z"
"","193","KAFKA-2519; NetworkClient.close should remove node from inFlightRequests","","closed","","ijuma","2015-09-04T14:59:01Z","2016-03-01T22:50:27Z"
"","192","MINOR: Fix trace/debug logs in RequestChannel","","closed","","SinghAsDev","2015-09-03T20:21:50Z","2015-09-04T01:22:52Z"
"","191","KAFKA-1686: Implement SASL/Kerberos.","","closed","","harshach","2015-09-03T04:13:18Z","2015-10-21T01:18:09Z"
"","190","Kafka 1686. Implement SASL/Kerberos.","","closed","","harshach","2015-09-03T03:33:18Z","2015-09-03T05:34:37Z"
"","189","KAFKA-2437: Fix ZookeeperLeaderElector to handle node deletion correctly.","","closed","","becketqin","2015-09-03T00:46:35Z","2015-09-03T04:04:07Z"
"","188","KAFKA-2491; update ErrorMapping with new consumer errors","","closed","","hachikuji","2015-09-02T20:08:22Z","2015-09-04T17:40:40Z"
"","184","KAFKA-2492; Upgraded zkclient dependency from 0.5 to 0.6","","closed","","sslavic","2015-09-01T09:36:42Z","2015-09-02T20:06:25Z"
"","176","KAFKA-2332; Add quota metrics to old producer and consumer","","closed","","lindong28","2015-08-28T20:24:29Z","2015-09-01T21:49:14Z"
"","175","KAFKA-2447: Add capability to KafkaLog4jAppender to be able to use SSL","","closed","","SinghAsDev","2015-08-28T17:19:26Z","2015-10-27T16:54:06Z"
"","169","KAFKA-2461: request logger no longer logs extra information in debug mode","","closed","","SinghAsDev","2015-08-25T22:33:37Z","2015-09-03T05:07:23Z"
"","166","KAFKA-2467: Fix changes to behavior in ConsoleConsumer: properly parse consumer.config option, handle exceptions during message processing, and print number of processed messages to stderr.","","closed","","ewencp","2015-08-25T06:10:31Z","2015-08-27T01:36:57Z"
"","165","KAFKA-2464: client-side assignment for new consumer","","closed","","hachikuji","2015-08-25T04:36:29Z","2015-11-02T18:53:14Z"
"","164","KAFKA-2462: allow modifying soft limit for open files in Kafka startup script","","closed","","gwenshap","2015-08-24T23:22:53Z","2017-12-22T20:22:31Z"
"","163","KAFKA-2367: Add Copycat runtime data API.","","closed","","ewencp","2015-08-24T22:52:10Z","2015-08-27T18:59:10Z"
"","159","KAFKA-2457; Fix how the argument is passed to `compileScala`","","closed","","ijuma","2015-08-21T19:34:11Z","2015-09-03T07:08:55Z"
"","158","KAFKA-2453: Enable new consumer in EndToEndLatency","","closed","","benstopford","2015-08-21T16:53:15Z","2015-09-08T22:16:10Z"
"","156","KAFKA-1566: Kafka environment configuration (kafka-env.sh)","","closed","","harshach","2015-08-21T02:27:00Z","2017-12-22T20:22:10Z"
"","155","KAFKA-1683: persisting session information in Requests","","closed","","gwenshap","2015-08-21T01:48:02Z","2015-08-26T20:49:52Z"
"","153","KAFKA-2454: Deadlock between log segment deletion and server shutdown.","","closed","","becketqin","2015-08-20T18:23:23Z","2015-10-21T20:24:28Z"
"","151","KAFKA-2411; remove usage of blocking channel","","closed","","ijuma","2015-08-19T15:16:12Z","2015-09-03T07:06:54Z"
"","149","MINOR: Use `EasyMock.newCapture` instead of deprecated `new Capture`","","closed","","ijuma","2015-08-18T10:31:55Z","2016-03-01T22:54:30Z"
"","146","KAFKA-2435: Fair consumer partition assignment strategy","","closed","","noslowerdna","2015-08-17T15:19:24Z","2018-02-25T21:39:56Z"
"","145","KAFKA-2434: Remove identical topic subscription constraint for roundrobin strategy in old consumer API","","closed","","noslowerdna","2015-08-17T15:19:17Z","2017-01-03T16:58:13Z"
"","143","KAFKA-2438: add maxParallelForks to build.gradle to speedup tests.","","closed","","harshach","2015-08-17T03:31:10Z","2015-08-17T08:21:47Z"
"","142","KAFKA-2436; log.retention.hours should be honored by LogManager","","closed","","lindong28","2015-08-16T23:13:07Z","2015-08-19T17:31:11Z"
"","140","KAFKA-1782: Follow up - add missing @Test annotations.","","closed","","ewencp","2015-08-14T22:44:52Z","2015-08-17T09:02:53Z"
"","139","KAFKA-2388 [WIP]; refactor KafkaConsumer subscribe API","","closed","","hachikuji","2015-08-14T20:20:36Z","2015-08-27T01:37:23Z"
"","135","KAFKA-Junit3 Misusage","","closed","","ewencp","2015-08-13T01:42:06Z","2015-08-14T21:42:22Z"
"","131","MINOR: Fix hard coded strings in ProduceResponse","","closed","","granthenke","2015-08-11T15:29:06Z","2015-11-17T17:06:12Z"
"","129","KAFKA-2143: fix replica offset truncate to beginning during leader migration.","","closed","","becketqin","2015-08-10T18:04:29Z","2020-01-13T04:17:17Z"
"","128","KAFKA-1893: Allow regex subscriptions in the new consumer","","closed","","SinghAsDev","2015-08-10T18:02:12Z","2015-09-11T02:18:22Z"
"","126","Minor: Fixes to Selector's javadoc","","closed","","ijuma","2015-08-07T16:00:41Z","2015-08-14T09:48:19Z"
"","124","MINOR: documentation fix in StringDecoder","","closed","","davecromberge","2015-08-07T15:06:48Z","2015-08-07T23:10:41Z"
"","122","KAFKA-2413: fix ConsumerCoordinator updateConsumer","","closed","","onurkaraman","2015-08-07T04:56:40Z","2015-08-07T22:20:28Z"
"","121","KAFKA-2415: Fix transient failure in LogRecoveryTest","","closed","","becketqin","2015-08-07T03:27:35Z","2015-08-07T23:16:51Z"
"","119","KAFKA-2403; Add support for commit metadata in KafkaConsumer","","closed","","hachikuji","2015-08-06T22:42:03Z","2015-09-23T21:18:43Z"
"","118","KAFKA-2390; OffsetOutOfRangeException should contain the Offset and Partition info.","","closed","","lindong28","2015-08-06T00:06:40Z","2015-09-25T23:04:24Z"
"","116","KAFKA-2400; expose heartbeat interval in KafkaConsumer configuration","","closed","","hachikuji","2015-08-05T18:56:23Z","2015-08-06T21:16:39Z"
"","115","KAFKA-2407: Only create log directory when it will be used","","closed","","granthenke","2015-08-05T18:00:08Z","2015-11-17T17:06:11Z"
"","113","KAFKA-2401: fix transient failure in ProducerSendTest.testCloseWithZeroTimeoutFromSenderThread","","closed","","becketqin","2015-08-05T01:37:44Z","2015-08-05T19:49:19Z"
"","112","KAFKA-2340; improve KafkaConsumer Fetcher test coverage","","closed","","hachikuji","2015-08-05T00:42:07Z","2015-08-06T22:52:52Z"
"","108","KAFKA-2402: Create IsrChangeNotificationPath when server statrs.","","closed","","becketqin","2015-08-04T05:37:21Z","2015-08-14T18:38:12Z"
"","105","KAFKA-2384; Override commit message title in kafka-merge-pr.py","","closed","","ijuma","2015-08-03T14:57:56Z","2015-09-03T07:09:14Z"
"","102","KAFKA-2300: Error in controller log when broker tries to rejoin cluster","","closed","","fpj","2015-07-29T18:01:04Z","2015-08-12T21:30:28Z"
"","101","MINOR - Fix typo in ReplicaVerificationTool output","","closed","","ottomata","2015-07-29T15:05:01Z","2015-08-05T23:50:44Z"
"","100","KAFKA-2350; KafkaConsumer pause/resume API","","closed","","hachikuji","2015-07-29T01:40:05Z","2015-07-30T21:23:15Z"
"","97","KAFKA-2321; Introduce CONTRIBUTING.md","","closed","","ijuma","2015-07-24T12:09:28Z","2015-08-14T09:49:33Z"
"","95","KAFKA-2356 Added support for retrieving partitions of ConsumerRecords","","closed","","sslavic","2015-07-23T22:10:51Z","2016-02-02T23:10:53Z"
"","93","KAFKA-1695: Adding zookeeper authentication. Zookeeper acls should be set so only broker can modify zk entries with the exception of /consumers.","","closed","","Parth-Brahmbhatt","2015-07-23T19:21:44Z","2016-02-02T23:10:44Z"
"","88","KAFKA-2342; KafkaConsumer rebalance with in-flight fetch can cause invalid position","","closed","","hachikuji","2015-07-20T23:31:54Z","2015-07-22T20:00:10Z"
"","86","KAFKA-2236; Offset request reply racing with segment rolling","","closed","","jhspaybar","2015-07-19T03:00:41Z","2016-05-04T09:32:48Z"
"","82","KAFKA-2324; Update to Scala 2.11.7","","closed","","ijuma","2015-07-17T00:02:07Z","2015-07-17T08:15:12Z"
"","81","KAFKA-2320; Test commit","","closed","","ijuma","2015-07-16T13:15:10Z","2015-07-16T14:13:47Z"
"","78","KAFKA-2335; fix comment about thread safety","","closed","","hachikuji","2015-07-15T17:11:25Z","2015-07-15T22:46:58Z"
"","77","KAFKA-2145: Add a log config so users can define topic owners.","","closed","","Parth-Brahmbhatt","2015-07-15T00:55:20Z","2019-01-24T22:58:46Z"
"","72","KAFKA-2304: Supported enabling JMX in Kafka Vagrantfile","","closed","","sslavic","2015-07-07T09:44:30Z","2015-07-07T20:10:48Z"
"","69","KAFKA-2092: New partitioning for better load balancing","","closed","","gdfm","2015-06-13T16:09:14Z","2020-06-07T22:31:43Z"
"","65","MINOR: remove unnecessary imports","","closed","","xuwei-k","2015-05-14T04:02:49Z","2016-03-02T12:18:03Z"
"","61","KAFKA-2169: Moving to zkClient 0.5 release.","","closed","","Parth-Brahmbhatt","2015-05-07T20:16:58Z","2015-07-20T16:19:25Z"
"","55","Kafka 1595 remove deprecated json parser","","closed","","ijuma","2015-04-21T00:47:24Z","2015-04-26T18:02:42Z"
"","52","0.8.1 migrator","","closed","","syyang","2015-03-24T18:39:56Z","2015-03-24T18:52:20Z"
"","42","Trunk","","closed","","SylviaVargasCTL","2015-01-15T18:50:01Z","2015-07-20T14:00:45Z"
"","35","Trunk","","closed","","futtre","2014-10-31T22:52:31Z","2014-10-31T22:53:03Z"
"","33","KAFKA-1635: Fixed incorrect java doc of makeLeaders() in ReplicaManager","","closed","","LantaoJin","2014-09-16T08:28:59Z","2014-09-17T10:44:29Z"
"","31","KAFKA-1369 - snappy version update 1.1.x","","closed","","thinker0","2014-08-19T10:23:16Z","2016-02-19T15:07:34Z"
"","30","KAFKA-1369 snappy-1.1.x update (RHEL4,5,6)","","closed","","thinker0","2014-08-19T10:19:41Z","2016-02-19T15:07:33Z"
"","25","add change.log and check git branch","","closed","","darionyaphet","2014-04-25T08:15:39Z","2014-06-20T04:26:36Z"
"","17","fixed typo","","closed","","mosch","2014-02-04T12:47:34Z","2015-07-20T11:28:23Z"
"","12","Update README","","closed","","ailzhang","2014-01-13T19:36:04Z","2014-08-02T08:36:01Z"
"","11","KAFKA-1180 WhiteList topic filter gets a NullPointerException on complex Regex","","closed","","joestein","2013-12-22T14:42:06Z","2014-07-05T12:26:30Z"
"","9","maven + windows","","closed","","guptakuldeep","2013-09-03T09:39:19Z","2016-12-26T22:38:21Z"
"","4","Fix mis-spell in ConsumerConfig.scala","","closed","","MichaelBlume","2013-04-25T21:01:13Z","2016-01-29T01:31:14Z"