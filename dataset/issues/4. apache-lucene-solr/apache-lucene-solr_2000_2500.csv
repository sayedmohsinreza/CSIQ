"#","No","Issue Title","Issue Details","State","Labels","User name","created","Updated"
"","1","SOLR-8573: Implement ConnectionImpl,StatementImpl,ResultSetImpl clear…","…Warnings and getWarnings","closed","","joel-bernstein","2016-01-24T03:03:41Z","2016-01-24T03:45:02Z"
"","281","Cleaning up class casts and making sure sheilded response isn't sent …","…up the filter chain","closed","","millerjeff0","2017-12-01T23:17:17Z","2018-01-23T16:50:25Z"
"","20","SOLR-8839: Angular admin/segments display: display of deleted docs no…","…t proportional","closed","","LucVL","2016-03-14T10:40:49Z","2019-01-18T21:56:44Z"
"","271","SOLR-3191: Fixes earlier issues with the patch, namely CSVWriter and …","…streaming errors","open","","sstults","2017-11-06T18:20:11Z","2017-11-06T18:20:11Z"
"","311","SOLR-11873: Use a time based expiration cache for one off HDFS FileSy…","…stem instances in all functions.","closed","","misutoth","2018-01-24T06:04:42Z","2019-01-19T00:25:47Z"
"","200","SOLR-10654 - Expose Prometheus metrics under /admin/metrics with wt=p…","…rometheus","closed","","kelaban","2017-05-09T19:06:19Z","2019-01-18T23:45:28Z"
"","144","SOLR-10046 - Add UninvertDocValuesMergePolicyFactory and lucene/OneMe…","…rgeWrappingMergePolicy","closed","","kelaban","2017-01-26T22:07:25Z","2019-01-18T23:25:04Z"
"","173","[SOLR-10360] Remove an extra space from Hadoop distcp cmd used by Sol…","…r backup/restore","closed","","hgadre","2017-03-24T19:09:14Z","2017-05-31T18:25:57Z"
"","140","[SOLR-9997] Enable configuring SolrHttpClientBuilder via java system …","…property  - Added support to configure SolrHttpClientBuilder via java system property - Added a concrete implementation of HttpClientBuilderFactory which supports   preemptive basic authentication. - Removed the hardcoded basic auth support from SolrCLI (and verified that   it works with basic auth plugin as well as with kerberos). - Added support to log HTTP request/response for debugging authentication issues   in HadoopAuthPlugin.","closed","","hgadre","2017-01-19T05:28:50Z","2019-01-18T22:39:04Z"
"","258","SOLR-10078: Handle MatchNoDocsQuery in BooleanQuery nested in Complex…","…PhraseQuery When a BooleanQuery is nested inside a ComplexPhrase, and one of the terms returns a MatchNoDocsQuery (which was introduced in LUCENE-7337), ComplexPhraseQuery.addComplexPhraseClause throws an exception ""Unknown query type:org.apache.lucene.search.MatchNoDocsQuery""  Example: ""(john OR nosuchword*)  smith""  The fix is to handle MatchNoDocsQuery the same way as it is done in ComplexPhraseQuery.rewrite","closed","","bjarkebm","2017-10-04T09:17:35Z","2018-05-10T03:05:19Z"
"","121","[SOLR-9817] Make ""working directory"" for Solr server during startup c…","…onfigurable  - Added an environment variable ""SOLR_CONFIG_DIR"" to specify the working directory.   If this env variable is missing, then we use value of SOLR_SERVER_DIR as the default.   This allows us to maintain backwards compatibility. - Updated solr-jetty-context.xml to use the jetty.home system property (instead of jetty.base).   This is required since the jetty.base would point to SOLR_CONFIG_DIR and we need the location   specified by SOLR_SERVER_DIR variable.  Testing: Manual testing with (and without) specifying SOLR_CONFIG_DIR parameter. The server          starts properly in both cases.","closed","","hgadre","2016-11-30T17:02:51Z","2016-12-06T20:25:19Z"
"","179","SOLR-10320: Perform secondary sort using both values in and outside S…","…olr index   This is an ideas pull request to address issue SOLR-10320. Any suggestions/feedback is welcome. Still needs more testing and unit tests.","open","","bkinlaw","2017-03-30T18:30:17Z","2017-03-30T18:30:17Z"
"","178","SOLR-10320: Perform secondary sort using both values in and outside S…","…olr index","closed","","bkinlaw","2017-03-30T18:28:24Z","2017-03-30T18:28:28Z"
"","658","LUCENE-8780: Improve ByteBufferGuard with Java 11 VarHandles and new …","…memory model","open","","uschindler","2019-04-28T09:35:40Z","2020-06-08T12:54:00Z"
"","137","SOLR-9954: Prevent against failure during failed snapshot cleanup fro…","…m swallowing the actual cause for the snapshot to fail.","closed","","thelabdude","2017-01-11T00:35:23Z","2019-05-16T07:16:35Z"
"","210","[SOLR-10814] Solr RuleBasedAuthorizationPlugin works seamlessly with …","…Kerberos authentication","open","","hgadre","2017-06-05T21:57:00Z","2017-08-08T20:12:38Z"
"","444","SOLR-12708: Aggregate failures from downstream async jobs; add error …","…handling for RestoreCmd","closed","","manokovacs","2018-08-30T16:31:58Z","2019-06-14T12:01:43Z"
"","28","SOLR-8010 Adding the ability to optionally enable breaking words wher…","…e one side is a word but the other is not.  Integrated with re-based trunk to re-submit the pull request.","open","","Admje14","2016-04-11T16:24:03Z","2017-02-19T00:01:52Z"
"","225","SOLR-11145, SOLR-11146: Added comprehensive unit tests for Analytics …","…Component 2.0 as well as analytics bug fixes.","closed","","HoustonPutman","2017-08-01T17:25:11Z","2018-05-25T18:56:52Z"
"","435","SOLR-12591: add tests to ensure ParseDateFieldUpdateProcessor compati…","…blity with ExtractionDateUtil","closed","","barrotsteindev","2018-08-11T16:14:15Z","2018-08-22T16:40:06Z"
"","286","[LUCENE-8075] Possible null pointer dereference in core/src/java/org/…","…apache/lucene/codecs/blocktree/IntersectTermsEnum.java  Fix it","closed","","imgpulak","2017-12-06T06:48:01Z","2018-01-09T13:43:36Z"
"","500","LUCENE-8517: do not wrap FixedShingleFilter with conditional in TestR…","…andomChains","closed","","msokolov","2018-11-17T13:43:13Z","2020-02-15T21:46:29Z"
"","414","SOLR-12007 When a SolrCore is closed, cleanupOldIndexDirectories is c…","…alled in a background thread  that will race with DirectoryFactory close.  Change-Id: I8b77fd1469a956f20245835e6db2819294c2b58a","open","","gaborkaszab","2018-07-06T10:26:06Z","2018-07-06T10:26:06Z"
"","486","SOLR-12801: Fix the tests, remove BadApples and AwaitsFix annotations…","…, improve env for test development.  SOLR-12804: Remove static modifier from Overseer queue access.  SOLR-12896: Introduce more checks for shutdown and closed to improve clean close and shutdown. (Partial)  SOLR-12897: Introduce AlreadyClosedException to clean up silly close / shutdown logging. (Partial)  SOLR-12898: Replace cluster state polling with ZkStateReader#waitFor. (Partial)  SOLR-12923: The new AutoScaling tests are way to flaky and need special attention. (Partial)  SOLR-12932: ant test (without badapples=false) should pass easily for developers. (Partial)","open","","markrmiller","2018-10-30T20:32:18Z","2018-11-30T16:57:53Z"
"","45","LUCENE-7287: normalize Ukrainian morfologik dictionary to have unique…","… token+lemma pair","closed","","arysin","2016-06-24T23:41:52Z","2017-10-09T13:40:43Z"
"","344","LUCENE-8228: IndexDeletionPolicy has obsolete clone() requirements in…","… the javadoc.","closed","","dweiss","2018-03-28T12:20:07Z","2018-03-29T07:55:55Z"
"","145","SOLR-10047 - SolrIndexSearcher, UninvertingReader, uninvert docvalues…","… per segment","closed","","kelaban","2017-01-26T22:30:27Z","2017-04-24T16:09:01Z"
"","314","SOLR-11459 Clear AddUpdateCommand#prevVersion to fix in-place updates…","… for non existed documents","closed","","werder06","2018-01-29T22:57:43Z","2018-02-06T18:51:54Z"
"","307","SOLR-11459 Clear AddUpdateCommand#prevVersion to fix in-place updates…","… for non existed documents","closed","","werder06","2018-01-17T02:18:48Z","2018-01-29T22:22:24Z"
"","290","Removed deprecated reference","XmlUpdateRequestHandler has been replaced by UpdateRequestHandler as of SOLR-2857","closed","","steeveb972","2017-12-13T13:22:06Z","2019-02-08T06:31:30Z"
"","594","SOLR-13259: Add new section on Reindexing in Solr","While Solr frequently recommends to users that they reindex in various situations, we've had no central place in the Ref Guide that stated when they must or should do that, or how to do it.  This PR adds a new page `reindexing.adoc` under the section ""Indexing and Basic Data Operations"".  It also adds links to this new section in a few places (but probably not everywhere it could), and standardizes spelling on ""reindex"" instead of ""re-index"" throughout the guide.","closed","","ctargett","2019-02-28T19:34:39Z","2020-10-20T01:51:54Z"
"","503","LUCENE-8571: Don't block on FrozenBufferedUpdates#apply during IW#processEvents","While indexing we try to apply frozen deletes packages concurrently on indexing threads if necessary. This is done in an opaque way via IndexWriter#processEvents. Yet, when we commit or refresh we have to ensure we apply all frozen update packages before we return. Today we execute the apply method in a blocking fashion which is unnecessary when we are in a IndexWriter#processEvents context, we block indexing threads while they could just continue since it's already being applied. We also might wait in BufferedUpdatesStream when we apply all necessary updates were we can continue with other work instead of waiting. This change also tries to apply the packages that are not currently applied first in order to not unnecessarily block.","closed","","s1monw","2018-11-21T09:31:08Z","2018-11-25T20:18:19Z"
"","491","Update for multiple term's suggestion scoring","While calculating coefficient, used all suggestion's query term position. Tried to make better scoring for suggestion.","open","","UtsavVanodiya7","2018-11-05T04:56:26Z","2019-09-19T05:46:00Z"
"","616","LUCENE-8734: Record nextWriteGens in SegmentCommitInfo","When opening an IndexWriter, we will set nextWriteDelGen, nextWriteFieldInfosGen, and nextWriteDocValuesGen beyond what we have in the directory to avoid double writes in cases where the previous IW was not closed gracefully or the new IW is opened with a previous commit (not the latest commit). We need to persist these values; otherwise, they will be lost when the current IW is closed.","closed","","dnhatn","2019-03-22T02:45:24Z","2019-03-22T14:47:27Z"
"","638","LUCENE-8756: Fix MLT like text with custom frequencies","When an analyzer with custom term frequencies is used with MLT like texts, the custom term frequencies are incorrectly omitted and a fixed frequency of 1 is used instead.  This commit fixes the issue by using `TermFrequencyAttribute` to get the term frequencies instead of using fixed 1. Also adds test cases for them mentioned issue.","open","","ollik1","2019-04-08T14:11:57Z","2019-04-30T11:35:16Z"
"","295","SOLR-11800: Improve error message when parsing RankQuery","When a user specifies something wrong for the parameter `rq` sometimes it is hard to understand where is the problem, this patch attempts to improve the error message returned in the response.","open","","diegoceccarelli","2017-12-28T16:38:39Z","2017-12-28T16:44:06Z"
"","327","SOLR-10078: Handle MatchNoDocsQuery in BooleanQuery nested in ComplexPhraseQuery","When a BooleanQuery is nested inside a ComplexPhrase, and one of the terms returns a MatchNoDocsQuery (which was introduced in LUCENE-7337), ComplexPhraseQuery.addComplexPhraseClause throws an exception ""Unknown query type:org.apache.lucene.search.MatchNoDocsQuery""  Example: ""(john OR nosuchword*) smith""  The fix is to handle MatchNoDocsQuery the same way as it is done in ComplexPhraseQuery.rewrite","closed","","bjarkebm","2018-02-26T13:02:57Z","2018-05-10T03:05:19Z"
"","264","Fix NPE on connection failure","We're using ZK for node discovery. During rare evens of when some nodes are unavailable, we observe NPEs. I'm not quite familiar with the solr client logic but by looking at the code further, I concluded that the iteration misses a null check.   ```java java.lang.NullPointerException: null     at org.apache.solr.client.solrj.impl.CloudSolrClient.requestWithRetryOnStaleState(CloudSolrClient.java:1143)     at org.apache.solr.client.solrj.impl.CloudSolrClient.request(CloudSolrClient.java:1037)     at org.apache.solr.client.solrj.SolrRequest.process(SolrRequest.java:149)     at org.apache.solr.client.solrj.SolrClient.query(SolrClient.java:974)     at org.apache.solr.client.solrj.SolrClient.query(SolrClient.java:990)     at com.company.search.SolrQueryServiceImpl.query(SolrQueryServiceImpl.java:65)     at com.company.search.SolrQueryServiceImpl.query(SolrQueryServiceImpl.java:50)     at com.company.search.server.ServiceServer.searchMedia(ServiceServer.java:358)     at com.company.search.server.SearchServer.searchMedia(SearchServer.java:97)     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)     at java.util.concurrent.FutureTask.run(FutureTask.java:266)     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)     at java.lang.Thread.run(Thread.java:748) ```","closed","","SerCeMan","2017-10-19T01:31:35Z","2017-12-31T03:09:44Z"
"","218","feat: Separate SuggestModes for WordBreak and WordJoin","We should be able to specify suggestModes for WordBreakSolrspellChecker, and also separately for WordBreak and WordJoin. The feature will let `WordJoin` and `WordBreak` override the suggestMode if they have been specified OR use their parents', if not set.  See the latest update on https://issues.apache.org/jira/browse/SOLR-10263 for more details.","open","","abhidemon","2017-07-10T07:39:47Z","2017-09-18T07:28:36Z"
"","620","LUCENE-8477: Automatically rewrite disjunctions when internal gaps matter","We have a number of IntervalsSource implementations where automatic minimization of  disjunctions can lead to surprising results: * PHRASE queries can miss matches because a longer matching sub-source is minimized  away, leaving a gap * MAXGAPS queries can miss matches for the same reason * CONTAINING, NOT_CONTAINING, CONTAINED_BY and NOT_CONTAINED_BY queries     can miss matches if the 'big' interval gets minimized  The proper way to deal with this is to rewrite the queries by pulling disjunctions to the top of the query tree, so that `PHRASE(""a"", OR(PHRASE(""b"", ""c""), ""c""))` is rewritten to `OR(PHRASE(""a"", ""b"", ""c""), PHRASE(""a"", ""c""))`.  To be able to do this generally, we need to add a new `pullUpDisjunctions()` method to `IntervalsSource` that performs this rewriting for each source that it would apply to.  Because these rewritten queries will in general be less efficient due to the duplication of effort (eg the rewritten PHRASE query above pulls 5 term iterators rather than 4 in the original), we also add an option to `Intervals.or()` that will prevent this happening, so that consumers can choose speed over accuracy if it suits their usecase.","closed","","romseygeek","2019-03-25T13:40:39Z","2019-03-27T11:23:44Z"
"","656","revert making DocValuesTermsCollector & TermsQuery public","We don't need to make these changes to our local fork","closed","","noblepaul","2019-04-25T21:51:05Z","2019-06-03T11:33:24Z"
"","103","SOLR-6994: Implement Windows version of bin/post","Very much work in progress","closed","","janhoy","2016-10-26T14:58:32Z","2022-05-18T11:27:56Z"
"","522","LUCENE-8599: Use sparse bitset to store docs in SingleValueDocValuesFieldUpdates","Using a sparse bitset in SingleValueDocValuesFieldUdpates allows storing which documents have an update much more efficient and prevents the need to sort the docs array altogether that showed to be a significant bottleneck in LUCENE-8598. Using the spares bitset yields another 10x performance improvement in applying updates versus the changes proposed in LUCENE-8598.","closed","","s1monw","2018-12-10T16:06:17Z","2018-12-10T18:22:30Z"
"","404","Comment to explain how to use URLClassifyProcessorFactory","URLClassifyProcessorFactory didn't have even a basic example on how to use this. I've added that now.","closed","missing Jira,","ohtwadi","2018-06-14T16:09:13Z","2020-06-30T15:40:16Z"
"","197","[SOLR-10506] Fixes a memory leak in zk schema watching","Upon manual Solr Collection reloading, references to the closed SolrCore are not fully removed by the garbage collector as a strong reference to the ZkIndexSchemaReader is held in a ZooKeeper Watcher that watches for schema changes.  In our case, this leads to a massive memory leak as managed resources are still referenced by the closed SolrCore. Our Solr cloud environment utilizes rather large managed resources (synonyms, stopwords). To reproduce, we fired out environment up and reloaded the collection 13 times. As a result we fully exhausted our heap. A closer look with the Yourkit profiler revealed 13 SolrCore instances, still holding strong references to the garbage collection root.  Each SolrCore instance holds a single path with strong references to the gc root via a Watcher in ZkIndexSchemaReader. The ZkIndexSchemaReader registers a close hook in the SolrCore but the Zookeeper is not removed upon core close.  We supplied this Github Pull Request that extracts the zookeeper Watcher as a static inner class. To eliminate the memory leak, the schema reader is held inside a WeakReference and the reference is explicitly removed on core close.  Initially I wanted to supply a test case but unfortunately did not find a good starting point ...  N.B.: I did this second PR for the same issue to separate code changes for both SOLR-10506 and SOLR-10550 which I maintained on the same fork branch :-/","closed","","tboeghk","2017-05-04T11:26:31Z","2019-01-18T23:52:34Z"
"","190","[SOLR-10506] Fixes a memory leak in zk schema watching","Upon manual Solr Collection reloading, references to the closed `SolrCore` are not fully removed by the garbage collector as a strong reference to the `ZkIndexSchemaReader` is held in a ZooKeeper `Watcher` that watches for schema changes.  In our case, this leads to a massive memory leak as managed resources are still referenced by the closed `SolrCore`. Our Solr cloud environment utilizes rather large managed resources (synonyms, stopwords). To reproduce, we fired out environment up and reloaded the collection 13 times. As a result we fully exhausted our heap. A closer look with the Yourkit profiler revealed 13 `SolrCore` instances, still holding strong references to the garbage collection root.  Each `SolrCore` instance holds a single path with strong references to the gc root via a `Watcher` in `ZkIndexSchemaReader`. The `ZkIndexSchemaReader` registers a close hook in the `SolrCore` but the Zookeeper is not removed upon core close.  We supplied this Github Pull Request that extracts the zookeeper `Watcher` as a static inner class. To eliminate the memory leak, the schema reader is held inside a `WeakReference` and the reference is explicitly removed on core close.  Initially I wanted to supply a test case but unfortunately did not find a good starting point ...","closed","","tboeghk","2017-04-18T10:19:09Z","2017-05-04T11:26:57Z"
"","558","SOLR-11763: Upgrade Guava to 25.1-jre","Upgrades Guava and related dependencies like Calcite.","closed","","risdenk","2019-02-02T21:30:02Z","2019-02-19T22:29:59Z"
"","468","jira/SOLR-12423","Upgrade to Tika 1.19.1, first draft","closed","","tballison","2018-10-11T17:29:12Z","2018-10-17T17:07:56Z"
"","259","SOLR-10335","Upgrade to Tika 1.16","closed","","tballison","2017-10-05T16:52:35Z","2017-11-28T13:34:04Z"
"","172","SOLR-9552","Upgrade to Tika 1.14","closed","","tballison","2017-03-21T16:22:47Z","2019-01-18T23:28:33Z"
"","135","SOLR-9930 - Updated documentation regarding analyzer dependencies.","Updated documentation, see JIRA issue https://issues.apache.org/jira/browse/SOLR-9930","open","","jakobkylberg","2017-01-05T10:29:42Z","2017-02-19T00:02:03Z"
"","12","[SOLR-8713] Update wiki-query-syntax link to point towards : https://cw…","Update wiki-query-syntax link to point towards https://cwiki.apache.org/confluence/display/solr/Query+Syntax+and+Parsing  Along the way I've updated the links that existed in some other solrconfig.xml files.","closed","","mariusneo","2016-02-26T19:20:27Z","2016-02-26T19:51:54Z"
"","14","SOLR-8713 Update wiki-query-syntax link","Update wiki-query-syntax link to point towards : https://cwiki.apache.org/confluence/display/solr/Query+Syntax+and+Parsing  Along the way I've updated the Solr query syntax link also within several solrconfig.xml files.","closed","","mariusneo","2016-02-26T19:56:21Z","2019-01-18T21:55:14Z"
"","356","SOLR-12232","Update to use uninterruptible file channel due to interrupted threads closing connection until solrcore is recreated","closed","","millerjeff0","2018-04-18T02:54:08Z","2019-01-19T00:46:46Z"
"","162","SOLR-8776: Support RankQuery in grouping","Update SOLR-8776 to current master   - Reranking and grouping work together in non-distributed setting when grouping is done by field   - Still have to fix for distribute setting and for grouping based on the unique values of a function query.","open","","diegoceccarelli","2017-02-28T17:16:05Z","2019-05-28T09:05:38Z"
"","100","Merge pull request #1 from apache/master","update from oirgin","closed","","coffeedou","2016-10-19T07:33:41Z","2016-10-19T07:42:00Z"
"","99","Merge pull request #1 from apache/master","update from oirgin","closed","","coffeedou","2016-10-19T07:20:51Z","2016-10-19T07:26:37Z"
"","60","SOLR-9002: Patch against latest master","Upayavira's patch applied (cleanly) against latest master and tested. It works correctly and does not seem to break other views.","closed","","arafalov","2016-08-03T10:15:17Z","2016-08-13T22:24:52Z"
"","215","SOLR-10123: Fix to better support numeric PointFields in Analytics.","Unit tests now use randomized numeric fields.","closed","","HoustonPutman","2017-06-29T20:23:11Z","2021-10-09T15:17:13Z"
"","409","LUCENE-8286: UH initial support for Weight.matches","UnifiedHighlighter support for Weight.matches.  See LUCENE-8286","closed","","dsmiley","2018-06-25T03:51:07Z","2018-08-30T03:31:55Z"
"","596","Under this branch, the dataDimensionCount is definitely not zero.","Under this branch, the dataDimensionCount is definitely not zero.","closed","","hanbj","2019-03-04T06:24:26Z","2020-07-06T02:09:33Z"
"","10","LUCENE-7041 Upgrade to Apache Tika 1.12","Trivial update. @uschindler I attempted running ant test locally with the following failures  ```    [junit4] Suite: org.apache.solr.search.TestSolrJ    [junit4] Completed [579/579 (6!)] on J3 in 0.02s, 1 test    [junit4]    [junit4]    [junit4] Tests with failures [seed: 64AD6FE9325CC7B0]:    [junit4]   - org.apache.solr.cloud.TestRequestStatusCollectionAPI.test    [junit4]   - org.apache.solr.cloud.DistribCursorPagingTest.test    [junit4]   - org.apache.solr.cloud.DeleteLastCustomShardedReplicaTest.test    [junit4]   - org.apache.solr.cloud.SimpleCollectionCreateDeleteTest.test    [junit4]   - org.apache.solr.cloud.TestMiniSolrCloudCluster.testSegmentTerminateEarly    [junit4]   - org.apache.solr.cloud.TestMiniSolrCloudCluster.testStopAllStartAll    [junit4]   - org.apache.solr.cloud.TestMiniSolrCloudCluster.testCollectionCreateWithoutCoresThenDelete    [junit4]   - org.apache.solr.cloud.TestMiniSolrCloudCluster.testCollectionCreateSearchDelete    [junit4]   - org.apache.solr.handler.admin.CoreAdminHandlerTest.testDeleteInstanceDir    [junit4]   - org.apache.solr.handler.admin.CoreAdminHandlerTest (suite)    [junit4]    [junit4]    [junit4] JVM J0:     0.60 ..   655.76 =   655.16s    [junit4] JVM J1:     0.85 ..   656.59 =   655.74s    [junit4] JVM J2:     0.85 ..   200.28 =   199.44s    [junit4] JVM J3:     0.60 ..  1037.32 =  1036.72s    [junit4] Execution time total: 17 minutes 17 seconds    [junit4] Tests summary: 579 suites (8 ignored), 2331 tests, 2 suite-level errors, 8 errors, 1 failure, 1320 ignored (59 assumptions)  BUILD FAILED /usr/local/lucene-solr/build.xml:59: The following error occurred while executing this line: /usr/local/lucene-solr/solr/build.xml:233: The following error occurred while executing this line: /usr/local/lucene-solr/solr/common-build.xml:524: The following error occurred while executing this line: /usr/local/lucene-solr/lucene/common-build.xml:1457: The following error occurred while executing this line: /usr/local/lucene-solr/lucene/common-build.xml:1014: There were test failures: 579 suites (8 ignored), 2331 tests, 2 suite-level errors, 8 errors, 1 failure, 1320 ignored (59 assumptions) [seed: 64AD6FE9325CC7B0]  Total time: 34 minutes 7 seconds ```","closed","","lewismc","2016-02-22T21:07:04Z","2016-04-20T00:16:26Z"
"","379","LUCENE-8353: add ë, ö and ï to norm()","tremats are not supported. I added them","open","","Bruno86","2018-05-22T11:07:44Z","2019-11-27T07:48:08Z"
"","43","Trivial name spelling fix for SOLR-445","ToleranteUpdateProcessorFactory -> TolerantUpdateProcessorFactory","closed","","arafalov","2016-06-13T13:26:29Z","2016-06-28T10:54:26Z"
"","526","LUCENE-8608: Extract utility class to iterate over terms docs","Today we re-implement the same algorithm in various places when we want to consume all docs for a set/list of terms. This caused serious slowdowns for instance in the case of applying updates fixed in LUCENE-8602. This change extracts the common usage and shares the interation code including logic to reuse Terms and PostingsEnum instances as much as possble and adds tests for it.","closed","","s1monw","2018-12-12T15:40:50Z","2018-12-13T14:32:22Z"
"","523","LUCENE-8602: Share TermsEnum if possible while applying DV updates","Today we pull a new terms enum when we apply DV updates even though the field stays the same which is the common case. Benchmarking this on a larger term dictionary with a significant number of updates shows a 2x improvement in performance.","closed","","s1monw","2018-12-11T16:33:31Z","2018-12-11T18:16:01Z"
"","610","LUCENE-8671: Load FST off-heap if reader is not opened from an index writer","Today we never load FSTs of ID-like fields off-heap since we need very fast access for updates. Yet, a reader that is not loaded from an index wirter can also leave the FST on disk. This change adds this information to SegmentReadState to allow the postiings format to make this decision without configuration.","closed","","s1monw","2019-03-19T14:58:56Z","2019-03-20T10:29:24Z"
"","527","LUCENE-8609: Allow getting consistent docstats from IndexWriter","Today we have #numDocs() and #maxDoc() on IndexWriter. This is enough to get all stats for the current index but it's subject to concurrency and might return numbers that are not consistent ie. some cases can return maxDoc < numDocs which is undesirable. This change adds a getDocStats() method to index writer to allow fetching consistent numbers for these stats.","closed","","s1monw","2018-12-13T15:09:41Z","2018-12-14T18:38:50Z"
"","502","LUCENE-8569: Never count soft-deletes if reader has no hard-deletes","Today we count the actual soft-deletes during a merge which is unnecessary if there are no hard-deletes present. In this case, which is considered to be the common case we can get accurate counts by substracting the number of deleted docs in the wrapped reader from the number of soft-deletes in that reader.","closed","","s1monw","2018-11-20T15:55:38Z","2018-11-21T13:46:05Z"
"","445","LUCENE-8484: Drop fully deleted reader in SubReaderWrapper","Today we can only wrap readers in SubReaderWrapper but never filter them out entirely. This causes a invariant for soft-deletes that exposes fully deleted segments with SoftDeletesDirectoryReaderWrapper. This change drops fully deleted readers after they are wrapped.","closed","","s1monw","2018-09-04T13:16:03Z","2018-09-05T10:46:51Z"
"","513","LUCENE-8590: Optimize DocValues update datastructures","Today we are using a LinkedHashMap to buffer doc-values updates in BufferedUpdates. This on the one hand uses an Object based datastructure and on the other requires re-encoding the data into a more compact representation once the BufferedUpdates are frozen. This change uses a more compact represenation for the updates already in the BufferedUpdates in a parallel-array like datastructure that can be reused in FrozenBufferedDeletes. It also adds an much simpler to use API to consume the updates and allows for internal memory optimization for common case updates.","closed","","s1monw","2018-12-04T17:33:11Z","2020-03-30T03:54:34Z"
"","78","LUCENE-7436: Changes MinHashFilter to have public constructor/defaults","To use MinHashFilter directly, made constructor & defaults public","closed","","softwaredoug","2016-09-06T16:42:40Z","2019-01-18T22:06:32Z"
"","76","UH round 3 (refactor to create FieldOffsetsEnum)","this time don't squash commit.  I suspect squash commits might be fine in more typical scenarios but in this back & forth collaboration I keep having to repoint my branches at your newly squashed commits","closed","","dsmiley","2016-09-04T19:20:56Z","2016-09-04T19:21:21Z"
"","439","LUCENE-8462: New Arabic snowball stemmer","This the PR corresponding to the following JIRA issue: https://issues.apache.org/jira/browse/LUCENE-8462  Added a new Arabic snowball stemmer based on https://github.com/snowballstem/snowball/blob/master/algorithms/arabic.sbl  As well an Arabic test dataset in `TestSnowballVocabData.zip` from the snowball-data available here https://github.com/snowballstem/snowball-data/tree/master/arabic","closed","","Ryado","2018-08-22T13:54:55Z","2018-09-13T12:35:06Z"
"","561","SOLR-13215 Upgrade dropwizard metrics to 4.0.5.","This removes the ganglia reporter which is now missing from the metrics library.  See https://github.com/dropwizard/metrics/issues/1319","closed","","henrik242","2019-02-04T11:08:36Z","2019-08-05T04:01:44Z"
"","106","SOLR-9616: Return empty result, when expand component is used with empty result set.","This pull request:  * Add's early return in expand component, when there is nothing to expand * Add's a regression test for SOLR-9616  Since i am very new to the code i am not sure if this has any other side effects, by checking the other tests it looks good for me, but help is appreciated.","closed","","timohund","2016-10-31T14:57:36Z","2019-01-18T22:30:00Z"
"","191","LUCENE-7498","This Pull Request related to the JIRA issue : LUCENE-7498  It involves the introduction of a big refactor of the More Like This module and the introduction of the BM25 similarity.  It is not supposed to be a final patch but to put the basis for a big improvement in the More Like This code base. Any feedback is welcome  **Summary** MoreLikeThis becomes a facade, just to expose the main More Like This functionality. Responsibility are now separated in : - Interesting Terms retriever ( from a docId in the index or from a Lucene Document passed in input) - Scorer ( to identify how much a term is interesting : BM25 and TFIDF supported - Mlt query builder ( to build the query from the interesting terms)  Every component is specifically tested.  The modification impact as a side effect :   **Classification** Knn CLassifiers to use the refactored More Like This Knn query in Lucene will be slightly different  **Single Solr Instance** The refactored MLT usage by Solr  **SolrCloud** The refactored MLT usage by SolrCloud","open","","alessandrobenedetti","2017-04-18T14:49:02Z","2019-01-18T23:32:30Z"
"","64","SOLR-9395: Add ceil/floor to stats component","This pull request limits stats calculations based on local params floor/ceil calculations. As in the following snippet:  `stats=true&stats.field={!floor=18 ceil=60}employee_age`  Limits to 18-60 inclusive.  See more [at this JIRA](https://issues.apache.org/jira/browse/SOLR-9395)","open","","softwaredoug","2016-08-08T19:56:49Z","2017-02-19T00:01:54Z"
"","66","SOLR-8146: Allowing SolrJ CloudSolrClient to have preferred replica for query/read","This pull request is to get feedback on the approach of implementing routingRule.   The unit test is not ready yet as facing challenges on how to mock/ inject dependency to simulate a cluster with different IP addresses machines and only matching one gets added to urlList which ultimately gets passed to LBHttpSolrClient.","closed","","susheelks","2016-08-10T01:29:54Z","2017-01-24T13:58:20Z"
"","369","SOLR-12299","This Pull Request is about the first step in the More Like This refactor. The overall scope of the refactor is to improve the test coverage, readability and maintenance of the More Like This module.  Scope of this patch is to extract the More Like This parameters in a cohesive and tested class. Other patches will follow.","open","","alessandrobenedetti","2018-05-03T16:52:09Z","2018-05-04T12:31:52Z"
"","618","#Lucene-2562: Make Luke a Lucene/Solr Module","This pull request integrates Luke (https://github.com/DmitryKey/luke) into Lucene as a submodule. See https://issues.apache.org/jira/browse/LUCENE-2562  Binary distribution package's directory sturucture is: ``` [lucene-9.0.0-SNAPSHOT]$ tree luke luke/ ├── lib │   ├── log4j-api-2.11.2.jar │   └── log4j-core-2.11.2.jar ├── lucene-luke-9.0.0-SNAPSHOT.jar ├── luke.bat └── luke.sh ```  For developers, Luke can be launched by this command after checking out Lucene source code. ``` [lucene-solr]$ ant -f lucene/luke/build.xml run ```","closed","","mocobeta","2019-03-24T11:02:44Z","2019-04-16T07:56:05Z"
"","368","[SOLR-12304] More Like This component interesting term fix +tests","This Pull Request cover the bug fix and tests for the Interesting Term parameter of the More Like This component.","closed","","alessandrobenedetti","2018-05-02T16:41:37Z","2019-06-14T21:43:26Z"
"","580","LUCENE-8700: IndexWriter.yield()","This provides a new `IndexWriter.yield()` method, and adds testing for it to `RandomIndexWriter` which will now use `yield()` to flush concurrently during `commit()`. I also added a flag for disabling this behavior. I'm not sure if it's needed though, since no tests failed I pulled out the flushing logic from `DocumentupdateDocument` into a standalone method `flushPending` - I initially wanted to refactor and share but the code doesn't lend itself to that without adding arguments to these methods, and it wasn't clear the result would be better.","closed","","msokolov","2019-02-19T20:22:44Z","2019-03-13T14:09:47Z"
"","535","LUCENE-8639: Prevent new threadstates from being created while we cut over to a new delete queue","This prevents an edge case where suddenly a lot of threads start indexing while we carry over sequence ids from the previous to the new delete queue. We now lock creation of new thread states for a very short time until we created and assigned a new delete queue.","closed","","s1monw","2019-01-15T15:39:23Z","2019-01-16T15:37:50Z"
"","575","SOLR-13235: Split Collections API Ref Guide page","This PR takes the massive collections-api.adoc page for the Collections API and splits it into several smaller, more focused, child pages.  The following new pages will be added:  - Cluster and Node Management (cluster-node-management.adoc): Define properties for the entire cluster; check the status of a cluster; remove replicas from a node; utilize a newly added node; add or remove roles for a node. - Collection Management (collection-management.adoc): Create, list, reload and delete collections; set collection properties; migrate documents to another collection; rebalance leaders; backup and restore collections. - Collection Aliasing (collection-aliasing.adoc): Create, list or delete collection aliases; set alias properties. - Shard Management (shard-management.adoc): Create and delete a shard; split a shard into two or more additional shards; force a shard leader. - Replica Management (replica-management.adoc): Add or delete a replica; set replica properties; move a replica to a different node.  Remaining on the Collections API page is the detail about how to make asynchronous API requests, since it applies to all commands. Intro text on collections-api.adoc is also changed to reflect it's new role.  Link references to specific API commands throughout the Ref Guide are also updated.  The page still ""lives"" in the same place under ""SolrCloud Configuration and Parameters"", where it has been in the page hierarchy. A broader re-org of the pages under the SolrCloud section is warranted, but is out of scope for now.  Also not included in this PR is any new content for v2-style API commands or missing params or examples, and those are out of scope for this change.","closed","","ctargett","2019-02-15T21:26:10Z","2019-06-12T15:09:45Z"
"","569","LUCENE-8687: Optimise radix partitioning for points on heap","This PR revives the idea of path slices so we do not have to hold many copies of the same data on memory.","closed","","iverase","2019-02-08T07:21:26Z","2019-02-11T07:15:55Z"
"","598","LUCENE-8712: Polygon2D does not detect crossings in some cases","This PR reverts the logic for line crossing to boolean and adds logic to skip crossing checks for query lines over the dateline.","closed","","iverase","2019-03-07T08:11:20Z","2019-03-12T07:40:55Z"
"","299","docs(intelliJSetup): Mention the link related to project-setup in IDE","This PR is to show some solr-wiki-page-links on the README.md page. The instructions mentioned on the README.md page is not enough to set up the project in the IDEs.   The wiki pages are very helpful, but are not easily accessible. Having their references on the `README.md` page will be quite helpful for beginners.","closed","","abhidemon","2018-01-06T15:32:27Z","2019-01-20T20:20:12Z"
"","120","SOLR-4735 Improve Solr metrics reporting","This PR is based on the initial patch by Kelvin Wong, with portions from Jeff Wartes (see Jira issue for more details).  Changes include: * centralized metric registry management in `SolrMetricManager` * hierarchical names for metrics, both inside registries and when reported by JMX. * more reusable API outside of `SolrCore` context.","closed","","sigram","2016-11-29T13:59:29Z","2019-01-18T21:54:01Z"
"","19","LUCENE-7064: Make MultiPhraseQuery immutable","This PR is based at the highest commit point common to master, branch_6x and branch_6_0 so it should be easy to merge with any or all of them.  My original mail to the dev list doesn't seem to get through, so I repeat it here:  > While checking how to migrate my custom components from lucene/solr 5.1 to 6.x I stumbled upon the fact that oal.search.MultiPhraseQuery is not immutable like most other implementations (see e.g.: https://issues.apache.org/jira/browse/LUCENE-6531) >  > Since it is part of the public API I would suggest splitting it in an immutable class and a builder like was done for most other Queries _before_ releasing an official 6.x version. >  > I did a quick scan through all derived classes of Query and I compiled the following list (ignoring sources in test or contrib folders) > Some of them are already marked as experimental (but should perhaps receive the ""official"" @lucene.experimental tag ?) > For some it's possibly not an issue since they should never end up in a filter cache (like MoreLikeThisQuery ?), but then a comment specifying the exception to the rule should perhaps be added. >  > I'll probably already have a go at the MultiPhraseQuery case shortly and create a JIRA issue with a PR for it. >  > Luc Vanlerberghe >  > lucene/search: > - org.apache.lucene.search.MultiPhraseQuery >  > lucene/queries: > - org.apache.lucene.queries.CommonTermsQuery > - org.apache.lucene.queries.CustomScoreQuery (marked as @lucene.experimental) > - org.apache.lucene.queries.mlt.MoreLikeThisQuery >  > lucene/suggest: > - org.apache.lucene.search.suggest.document.ContextQuery (marked as @lucene.experimental) >  > lucene/facet: > - org.apache.lucene.facet.DrillDownQuery (marked as @lucene.experimental) >  > solr/core: > - org.apache.solr.search.ExtendedQueryBase >   Several derived classes, among which: >   - org.apache.solr.query.FilterQuery >   - org.apache.solr.query.SolrRangeQuery (marked as @lucene.experimental) >   - org.apache.solr.search.RankQuery (marked in comment as experimental, but not its derived classes) >   - org.apache.solr.search.WrappedQuery > - org.apache.solr.search.join.GraphQuery (marked as @lucene.experimental) > - org.apache.solr.search.SolrConstantScoreQuery (marked in comment as experimental, but not the derived FunctionRangeQuery)","closed","","LucVL","2016-03-03T13:27:44Z","2016-03-04T10:31:10Z"
"","31","SOLR-8716 Upgrade to Apache Tika 1.12","This PR is an attempt to address https://issues.apache.org/jira/browse/SOLR-8716, I ran the test suite with no issues. Please let me know if there are additional issues I need to deal with here.","closed","","lewismc","2016-04-20T00:14:22Z","2018-08-01T03:37:20Z"
"","585","LUCENE-8698: Fix replaceIgnoreCase method bug in EscapeQuerySyntaxImpl","This PR is about bug fixing for the replaceIgnoreCase method in the EscapeQuerySyntaxImpl class. Current latest code can occur **StringIndexOutOfBoundsException**.  Please refer to the following JIRA link: [LUCENE-8698](https://issues.apache.org/jira/browse/LUCENE-8698)  Signed-off-by: Namgyu Kim","open","","danmuzi","2019-02-22T19:22:01Z","2019-03-26T17:03:00Z"
"","652","LUCENE-8775: Tessellator: Improve the election of diagonals when splitting the polygon","This PR introduces:  - Make sure that resulting polygons from splitting logic are valid CW polygons.  - Make sure an error is thrown if a polygon cannot be splitted.  - Adds several test to the tessellator.","closed","","iverase","2019-04-23T10:27:07Z","2019-06-06T07:14:55Z"
"","345","LUCENE-8229: Add Weight.matches() method","This PR adds a method to Weight that allows iterating over the matching positions (and offsets if available) for a particular document and field.","closed","","romseygeek","2018-03-28T14:45:57Z","2019-01-19T00:40:37Z"
"","50","SOLR-9280 - make nodeName a configurable parameter in solr.xml","This patch makes live nodeName configurable via solr.xml by setting  ``` xml               ${solr.nodeName:}        ```  To test, I randomly set nodeName in `AbstractFullDistribZkTestBase` for complete coverage.  I've gotten all tests to pass both when ALWAYS using a random nodeName and with it being set randomly. However during one particular run I got a test failure for the following: `ant test  -Dtestcase=TestReqParamsAPI -Dtests.method=test -Dtests.seed=391BC4715DE8C2FE -Dtests.slow=true -Dtests.locale=pl-PL -Dtests.timezone=Asia/Chungking -Dtests.asserts=true -Dtests.file.encoding=UTF-8` but am unable to reproduce the issue in eclipse and at this time am not sure if its related","open","","kelaban","2016-07-08T19:44:22Z","2017-02-19T00:01:54Z"
"","357","[SOLR-12238] Synonym Queries boost","This patch involves the synonym management in the query building/parser phase. It adds the possibility of getting the payloads from a Graph Token Stream and then use the payload to build boost queries for terms and phrase queries.  Tests are included for a better understanding of the use cases. This is an initial patch, happy to extend it or improve it !","closed","","alessandrobenedetti","2018-04-19T01:55:08Z","2020-02-24T10:29:42Z"
"","204","SOLR-10710: Fix LTR contrib failures","This patch fixes the tests failing in LTR. There will be more work to do on the tests because some rely on absolute scores from Apache Solr, so change in the index / scoring function could break them (in this case it was LUCENE-7730). I would merge this to fix the problems with the tests failing, and then open a new Jira item to enhance the tests.","closed","","diegoceccarelli","2017-05-19T16:13:54Z","2017-05-25T16:50:46Z"
"","202","SOLR-10703 DocTransformer implements Closeable","This patch adds a prepare and a finish method to the interface of DocTransformer allowing a developer to perform actions before/after a doc transformer is applied to a result set. My use case was to benchmark the performance of a transformer, since transformer time is not part of QTime.","open","","diegoceccarelli","2017-05-18T09:04:05Z","2019-08-04T14:32:41Z"
"","636","SOLR-10409 - Added support for rows=x in /export to limit number of docs exported (With unit tests)","This lets user add rows=x  parameter to request to limit number of docs they get from /export query  rows=x { x=0 => returns numFound=0 and no docs in results - this is existing behavior (I guess, unintended) x=undefined or x>=numFound => will not have any effect on existing behavior  x < numFound => will return first x docs only (in specified sorted order ) in results. }  Note Reg. Unit Testing. Given **DOCUMENT_BATCH_SIZE = 30000;** in **ExportWriter.java:87** , ideal testing should be done on index with >30k docs. I have tested all edge cases with the batch_sizes to 100 and 1.  Or is it ok to add a unit test with 30k small docs?","open","","b-pradeeprao","2019-04-04T16:59:26Z","2019-06-11T18:52:33Z"
"","512","#Lucene-2562: Make Luke a Lucene/Solr module","This is the draft pull request for LUCENE-2562, based on this repository (Swing version Luke). https://github.com/DmitryKey/luke  This adds `luke` module to the Lucene tar/zip distribution.","closed","","mocobeta","2018-12-04T14:43:30Z","2019-11-10T10:16:19Z"
"","490","#Lucene-2562: Make Luke a Lucene/Solr module","This is the draft pull request for LUCENE-2562, based on this repository (Swing version Luke). https://github.com/DmitryKey/luke","closed","","mocobeta","2018-11-04T03:40:09Z","2019-11-10T10:16:16Z"
"","584","SOLR-10751: PULL Replicas don’t replicate empty index","This is still WIP. Should also solve SOLR-11094 (and maybe SOLR-12100). This PR also includes changes to TestTlogReplica, which I’m going to separate to a different commit","closed","","tflobbe","2019-02-22T05:05:38Z","2019-10-23T21:24:17Z"
"","241","SpanishLightStemmer fix for plural words like casas","This is for check the final len before return the result, singular words in spanish has a minimum len of 4 so if the final len is lower the final word is not a valid word, this fix the stemmer for stem words like ""casas"". The plural of casa is casas, before this, casas was stemmed like cas, now is casa. The same thing happens for other words like casos, pasos, etc.","open","","JONAF2103","2017-09-01T13:43:03Z","2017-09-01T13:50:03Z"
"","301","test: Add test case for ResponseBuilder.isDistributed()","This is being done for https://issues.apache.org/jira/browse/SOLR-3089","closed","","abhidemon","2018-01-09T20:15:50Z","2018-01-09T20:17:18Z"
"","220","SOLR-8984 Add field name to exception message.","This is an old issue, but I figured it was something simple to start learning your codebase.  I added the field name to the exception message and used the syntax used in another exception then updated the tests.","closed","","AnnAddicks","2017-07-14T12:13:02Z","2017-07-14T18:36:01Z"
"","365","[SOLR-12243] span query generalization + query parser tests","This is an extension of Elizabeth Haubert patch, the addition is :   - spanNearQuery generalized to SpanQuery as it may happen to have SpanOrQuery - added a test that verifies the correct query is (built) parsed .  It is a draft, additional tests and review are welcome, I have not investigated further but it seems to solve the bug","closed","","alessandrobenedetti","2018-04-27T22:11:29Z","2020-02-15T23:43:42Z"
"","263","Backporting of SOLR-11477 on branch_5_5","This is an adaptation of last weeks' security fix SOLR-11477 by (Michael Stepankin, Olga Barinova, Uwe Schindler, Christine Poerschke) (aka @cpoerschke @uschindler ) to the 5_5 branch.  The main difference with the original patch is in the inability of using lambdas, and not having some of the new generation testing helpers.  In the CHANGES file I wasn't sure how to name this, I've opted to call it ""version 5.5.6"". Maybe I should simply omit the version?  HTH","closed","","Sanne","2017-10-17T09:38:53Z","2017-10-17T21:24:59Z"
"","607","Concurrently flush next buffer during commit in RandomIndexWriter","This is a spinn-off from `LUCENE-8700` that is satisfied by IndexWriter#flushNextBuffer. The idea here is to additionally call flushNextBuffer in RandomIndexWriter for better test coverage.","closed","","s1monw","2019-03-13T14:08:41Z","2019-03-14T14:43:41Z"
"","650","LUCENE-8768: Javadoc search support","This is a PR to support **""Javadoc search""** released in Java 9.  **[Before - Lucene Nightly Core Module Javadoc]** ![javadoc-nightly](https://user-images.githubusercontent.com/14330832/56313117-c7fbe280-618c-11e9-8c47-58341959919a.png)  **[After]** ![new-javadoc](https://user-images.githubusercontent.com/14330832/56313118-c7fbe280-618c-11e9-8305-23caaf4da2f3.png)  For more information, please refer to the following JIRA link. (https://issues.apache.org/jira/browse/LUCENE-8768)  Signed-off-by: Namgyu Kim","closed","","danmuzi","2019-04-17T18:50:00Z","2019-04-20T18:02:05Z"
"","146","Rename Terms to IndexedField and some related renamings, LUCENE-7633","This is a more extensive renaming:  Class renames:  Terms to IndexedField Fields to IndexedFields MultiTerms to MultiField FilterLeafReader.FilterTerms to FilterLeafReader.FilterField AssertingTerms to AssertingField  Method renames:  Terms.iterator() to IndexedField.getTermsEnum() Fields.terms() to IndexedFields.indexedField() MultiFields.getTerms() to MultiFields.getIndexedField()  Not renamed:  class MultiFields local variables IndexedField terms  *Terms extends IndexedFields in codecs package","closed","","ghost","2017-01-28T12:10:07Z","2019-06-14T11:39:32Z"
"","24","SOLR-7729: ConcurrentUpdateSolrClient ignoring the collection parameter in some methods","This is a fix for SOLR-7729. I submitted a similar patch on JIRA for the 5.2.1 version, this is an updated version for the master branch.","closed","","nicolasgavalda","2016-03-22T17:51:29Z","2016-04-20T09:36:20Z"
"","69","SOLR-9399: Delete requests do not send credentials & fails for Basic Authentication","This is a bug fix to set Authentication credential in case of delete requests.    There is a duplicate code between update & delete requests which most likely has caused this issue and left to set credentials in case of delete requests.  I'll create a separate jira to refactor the code and also tests for authentication seems to be broken.   The test class BasicAuthIntegrationTest doesn't have any test methods except the protected method doExtraTests which doesn't seems to be called from anywhere and delete tests needs to be added.","closed","","susheelks","2016-08-11T01:11:58Z","2019-01-18T22:12:33Z"
"","622","Update Tessellator logic to label if triangle edges belongs to the original polygon.","This information is then encoded and triangles are decoded using LatLonShape.decodeTriangle.","closed","","iverase","2019-03-26T15:57:13Z","2019-07-09T11:58:52Z"
"","642","SOLR-12860: MetricsHistoryHandler now always uses PKI Auth","This gets rid of the 401 errors currently seen when using e.g. basic auth.","closed","","janhoy","2019-04-11T09:07:58Z","2019-04-12T08:21:20Z"
"","23","SOLR-8626: Fix urls for nodes in cloud graph view","This fixes SOLR-8626 (identical patch submitted on JIRA) by removing the invalid (404) links on collections and cores in the graph view. The issue existed - and has been fixed - in both the flat graph view and the radial view. Additionally, when one was in the radial view and clicked on the link for a node, it would switch back to flat graph view when navigating to the other node, so the patch also improves the link in the radial view so that it preserves the user's current view type on the URL when navigating between nodes.","closed","","treygrainger","2016-03-20T04:36:41Z","2016-06-28T11:13:27Z"
"","375","LUCENE-8287: Ensure that empty regex completion queries always return no results.","This ensures consistency with the `PrefixCompletionQuery`, which returns no results for an empty regex. It also fixes the exception described in the ticket when an empty regex is provided to a context query, as the empty prefix no longer matches any suggestion terms.","closed","","jtibshirani","2018-05-16T06:28:28Z","2018-05-25T20:09:09Z"
"","649","Use Map.copyOf in lucene core","This cuts over several places that use the pattern of creating a copy of the supplied map with Map.copyOf.","closed","","s1monw","2019-04-16T14:52:34Z","2019-04-17T13:26:16Z"
"","339","SOLR-12126 Add SolrConfig to SolrRequestParsers constructor in EmbeddedSolrServer","This commit allow users to use some settings in EmbeddedSolr mode, for example - stream.body in solrconfig","closed","","squallsama","2018-03-20T11:31:16Z","2018-03-20T12:44:55Z"
"","338","Add SolrConfig to SolrRequestParsers constructor in EmbeddedSolrServer","This commit allow users to use some settings in EmbeddedSolr mode, for example - stream.body in solrconfig","closed","","squallsama","2018-03-20T11:22:47Z","2018-03-20T11:28:45Z"
"","492","Answer to TODO: Replace Manual Encoding with JSON Module","This commit adds the python `json` module to replace manual json encoding.","open","missing Jira,","MarcusSorealheis","2018-11-06T01:38:02Z","2020-03-06T11:18:45Z"
"","581","LUCENE-3041: QueryVisitor","This commit adds a visit() method to Query, allowing you to traverse query trees and analyse their structure and the terms they use for matching.","closed","","romseygeek","2019-02-20T14:13:14Z","2019-03-14T15:04:33Z"
"","377","Solr-12361: change _childDocuments to Map","This change will allow childDocuments to keep their relation to their parent document in SolrInputDocument.","closed","","moshebla","2018-05-17T06:43:23Z","2018-05-23T13:57:15Z"
"","517","LUCENE-8595: Fix interleaved DV update and reset","This change fixes a bug where interleaved update and reset value to the same doc in the same updates package looses an update if the reset comes before the update as well as loosing the reset if the update comes frist.","closed","","s1monw","2018-12-06T20:39:03Z","2018-12-07T07:27:29Z"
"","226","LUCENE-7655 Speed up geo-distance queries that match most documents","This change applies optimisation introduced in LUCENE-7641 to speed up geo-distance queries that match most documents. As in LUCENE-7641, it's done by computing the set of documents that do not match the distance predicate.","closed","","mzasada","2017-08-04T18:25:18Z","2017-08-07T11:45:40Z"
"","606","LUCENE-8671: Allow more fine-grained control over off-heap term dictionaries","This change allows to control if term-dictionaries are loaded off-heap or on heap on a per reader basis. None NRT readers will access all term dictionaries off heap including ID fields while readers that require fast ID access like all readers used within index writer will by default only load non-ID like fields heap. Additionally, IOContext has now the ability to specify if ram-usage should be minimized and can control the off vs. on-heap decisions on a per-reader basis.  Off heap term dictionaries are still only used if the index input is memory mapped.","closed","","s1monw","2019-03-12T14:44:53Z","2019-03-19T14:59:55Z"
"","601","Adding reader settings for moving fst offheap","This change adds setting for moving fst offheap, specifically address [JIRA-8671](https://issues.apache.org/jira/browse/LUCENE-8671)","open","","jainankitk","2019-03-08T22:04:13Z","2019-03-12T14:49:43Z"
"","449","[LUCENE-8462] New Arabic snowball stemmer and test dataset","This change adds an Arabic snowball stemmer based on   https://github.com/snowballstem/snowball/blob/master/algorithms/arabic.sbl  as well as an Arabic test dataset in `TestSnowballVocabData.zip` based on https://github.com/ibnmalik/golden-corpus-arabic/blob/develop/core/words.txt  It also updates the `ant patch-snowball` target to be compatible with the java classes generated by the last snowball version (tree: 1964ce688cbeca505263c8f77e16ed923296ce7a). The `ant patch-snowball` target is retro-compatible with the version of snowball stemmers used in lucene 7.x and ignores already patched classes.","closed","","Ryado","2018-09-13T12:39:42Z","2019-01-19T01:29:32Z"
"","579","LUCENE-8681: prorated early termination","This adds support for prorated early termination in TopFieldsCollector, a new unit test that demonstrates that, and a convenience method for creating a CollectorManager that uses that. It also refactors IndexSearcher to use the new convenience method and cleans up some leftover javadocs about a search parameter that was removed. See LUCENE-8681","closed","","msokolov","2019-02-19T14:48:05Z","2020-03-18T03:30:32Z"
"","183","LUCENE-7778 Removed synchronized from RAMFile methods","These methods don't seem to benefit from locking - the methods that mutate the underlying fields aren't synchronized themselves, for example  Removing these methods gives me a 2x throughput increase under concurrent load on internal benchmarks","closed","","spmason","2017-04-11T16:12:21Z","2017-05-17T12:48:18Z"
"","25","SOLR-8785: Use Metrics library for core metrics","There were three main areas that used the copied classes in org.apache.solr.util.stats: - AnalyticsStatisticsCollector - Overseer.Stats - RequestHandlerBase  This patch adds depreciation tags to all the copied classes, and also replaces all usage of those classes with classes from the Metrics library. I added one new class (org.apache.solr.util.stats.Metrics) to provide some common access patterns for metrics gathering.  This patch only adds Registry-based tracking to RequestHandlerBase, although all three areas are a fit for it. The effect is that all one needs to do is add a Reporter to the SharedMetricRegistry named “solr.registry.requesthandler” and all named request handler stats will be exported automatically.  Compatibility notes: - The “totalTime” stat has been deleted from all three areas. This never seemed very useful, and Metrics didn’t support it in the Timer class, so it would have required some extra code to keep. - RequestHandler stats are now persistent, and will no longer reset on reload.","closed","","randomstatistic","2016-03-24T20:56:42Z","2019-01-18T21:51:28Z"
"","108","Minor - Fix error message","There was a missing space in error message","closed","","hornn","2016-11-03T19:45:34Z","2019-11-27T08:29:04Z"
"","156","SOLR-10072: Fix test reliability","There is no guarantee to order of docs with the same score","closed","","mnilsson23","2017-02-10T20:07:52Z","2019-01-18T23:16:01Z"
"","541","minor syntax corrections in CSS files of Solr's Angular UI","There are some minor syntax bugs in the CSS files of the Angular UI module.","closed","missing Jira,","saschaszott","2019-01-18T11:47:23Z","2019-01-20T19:32:30Z"
"","540","minor syntax corrections in CSS files of Angular UI","There are some minor syntax bugs in the CSS files of the Angular UI module.","closed","","saschaszott","2019-01-18T10:46:15Z","2019-01-18T11:30:49Z"
"","452","SOLR-12773: Fix typos widely spread around codebase","The typos below that are widely spread around the codebase, mostly on comments plus one occurrence in the documentation and another one in a test name.  `equivilent` instead of `equivalent`  `respones` instead of `responses`  `the the` instead of `to the`","closed","","eribeiro","2018-09-15T02:02:04Z","2018-09-17T10:26:15Z"
"","401","Autoscaling Suggestions API page typo","The suggestions api is on `/api/cluster/autoscaling/suggestions` and not `/api/cluster/autoscaling/suggestion`","closed","","janhoy","2018-06-11T14:58:07Z","2018-06-11T19:28:52Z"
"","484","solr 7.5 suggest The recommended result is empty","The solr 7.5 recommendation is empty and you can specify your own dictionary","open","","lunxian8","2018-10-26T05:58:30Z","2018-11-05T18:57:08Z"
"","381","[LUCENE-8329] disk size estimator MB bug fixes","The size estimator dev tool ( dev-tools/size-estimator-lucene-solr.xls )currently : Wrongly calculates disk size in MB ( showing GB) Doesn't specify clearly that the space needed by the optimize is FREE space Avg. Document Size (KB) when they are more correctly Avg. Document Field Size (KB) Scope of this issue is just to fix these small mistakes. Out of scope is any improvement to the tool ( potentially separate Jira issues will follow)","open","","alessandrobenedetti","2018-05-23T10:23:54Z","2018-05-23T10:23:54Z"
"","62","[SOLR-9242] Fix unit test failure on Windows platform.","The root cause of the failure is the usage of URI::getPath() method in the backup/restore functionality (e.g. in BackupManager::downloadFromZK OR in the OverseerCollectionMessageHandler::processBackupAction methods). On the Windows platform, usage of URI.getPath() returns an invalid path string (e.g.  URI file:///C:/lucene-solr/solr returns /C:/lucene-solr/solr as the result of getPath() method).  Refer to following discussion for more details, http://stackoverflow.com/questions/9834776/java-nio-file-path-issue  Since the caller may have used this method to generate the string representation for the pathComponents, we implement a work-around specifically for Windows platform to remove the leading '/' character.","closed","","hgadre","2016-08-03T21:24:35Z","2016-08-05T03:08:35Z"
"","354","SOLR-12244: Change method names","The method seems to add ""sliceName"" to ""shardNames"", thus the method name ""addShardNames"" should be better ""getShardNames"" since ""get"" means getting something.","open","","Kui-Liu","2018-04-17T13:04:38Z","2021-02-03T02:42:55Z"
"","624","WIP SOLR-12860 MetricsHistoryHandler does not work with BasicAuth","The issue is that the following test break now. I think I don't like the deleted lines because of this coment   > //if this is not running inside a Solr threadpool (as in testcases)         // then no need to add any header  I will be reordering some tests as the fails are not overall to understand better the situation.  ``` [junit4] - org.apache.solr.handler.TestReplicationHandlerDiskOverFlow.testDiskOverFlow [junit4] - org.apache.solr.security.PKIAuthenticationIntegrationTest.testPkiAuth [junit4] - org.apache.solr.security.hadoop.TestDelegationWithHadoopAuth.testDelegationTokenRenew [junit4] - org.apache.solr.security.hadoop.TestDelegationWithHadoopAuth.testDelegationTokenVerify [junit4] - org.apache.solr.security.hadoop.TestDelegationWithHadoopAuth.testDelegationTokenRenewFail [junit4] - org.apache.solr.security.hadoop.TestDelegationWithHadoopAuth.testZNodePaths [junit4] - org.apache.solr.security.hadoop.TestDelegationWithHadoopAuth.testDelegationTokenCancel [junit4] - org.apache.solr.security.hadoop.TestDelegationWithHadoopAuth.testDelegationTokenSolrClient [junit4] - org.apache.solr.security.hadoop.TestDelegationWithHadoopAuth.testDelegationTokenCancelFail [junit4] - org.apache.solr.security.BasicAuthIntegrationTest.testBasicAuth ```","closed","","yael-lorenzo","2019-03-28T12:02:13Z","2019-04-01T12:54:06Z"
"","576","LUCENE-8631: Longest-Matching for User words in Nori Tokenizer","The issue is described in [LUCENE-8631](https://issues.apache.org/jira/browse/LUCENE-8631).   The existing nori tokenizer is able to do Longest-Matching for system words, but not for user words. The reason why it doesn’t work for user words is because their large costs severely mitigate bigram costs. Longest-Matching is a natural behavior in that system words, whose costs were generated from large Korean corpus, can be applied. Also, it is needed when to search exact words. So, we want it also apply to user words.  Thankfully, Jim Ferenczi, who is a nori developer, gave to me some suggestions to fix it (ref. [LUCENE-8631](https://issues.apache.org/jira/browse/LUCENE-8631)). I followed the “Implement longest-match first in the dictionary” because it is simplest and efficient way. As Jim mentioned, it provides not only Longest-Matching, but also speed-up because it retains a single path for user words.  The idea is, whenever to iterate the input stream by character step, the longest word is only stored and its subset words are ignored. There are two steps to implement this. First, before break in the for-loop, we call at once add function with posAheadMax info. Second, we remember global_posAheadMax during while-loop and use it to avoid  storing subset words at different positions.   For checking how robust is the implementation, we tested using about 100,000 Korean words, where subset words are included, and all test cases were passed.   Yeongsu Kim high_yeongsu@wemakeprice.com Wemakeprice Inc., South Korea https://www.wemakeprice.com","closed","","gritmind","2019-02-16T17:01:46Z","2019-03-12T09:46:00Z"
"","303","Guide update: Grouping XML commands and curl description extension","The guide does not say anything about grouping XML commands with the  element, I =found it only once in some wiki. In addition I have faced problems myself wuth curl when dealing with multi gigabyte XML files. The solution I describe here works nicely. Tested with SOLR 7.1.","closed","","dwojtas","2018-01-11T16:56:31Z","2018-02-01T21:27:47Z"
"","508","Simplified JAVA_VER_NUM to utilize single expr execution","The fragility of the previous JAVA_VER_NUM causes solr to fail to start when JAVA_TOOL_OPTIONS is set:  ``` + /jenkins/tools/hudson.model.JDK/jdk8-latest/bin/java -version + JAVA_VER=Picked up JAVA_TOOL_OPTIONS: -Dmaven.ext.class.path=""/jenkins/workspace/Bates/bates-java_ver-test/7@tmp/withMavena29da72d/pipeline-maven-spy.jar"" -Dorg.jenkinsci.plugins.pipeline.maven.reportsFolder=""/jenkins/workspace/Bates/bates-java_ver-test/7@tmp/withMavena29da72d""  java version ""1.8.0_172"" Java(TM) SE Runtime Environment (build 1.8.0_172-b11) Java HotSpot(TM) 64-Bit Server VM (build 25.172-b11, mixed mode) + echo Picked up JAVA_TOOL_OPTIONS: -Dmaven.ext.class.path=""/jenkins/workspace/Bates/bates-java_ver-test/7@tmp/withMavena29da72d/pipeline-maven-spy.jar"" -Dorg.jenkinsci.plugins.pipeline.maven.reportsFolder=""/jenkins/workspace/Bates/bates-java_ver-test/7@tmp/withMavena29da72d"" java version ""1.8.0_172"" Java(TM) SE Runtime Environment (build 1.8.0_172-b11) Java HotSpot(TM) 64-Bit Server VM (build 25.172-b11, mixed mode) + head -1 + awk -F "" /version/ {print $2} + sed -e s/^1\.// + sed -e s/[._-].*$// + JAVA_VER_NUM=/jenkins/workspace/Bates/bates + echo /jenkins/workspace/Bates/bates ```","open","","LinkMJB","2018-11-26T21:06:52Z","2020-04-22T22:10:42Z"
"","58","SOLR-8379: Text file extension is 'txt'","The do-not-highlight comparison was expecting type to be text, but it is based on extension, so was actually 'txt'. This was causing a stack trace and aborted population of the content box.","closed","","arafalov","2016-07-28T02:40:24Z","2016-07-29T07:36:29Z"
"","272","Correct inconsistency on plugin support","The deleted sentence contradicts the sentence near the top of this document that says “All authentication and authorization plugins can work with Solr whether they are running in SolrCloud mode or standalone mode.”","closed","","jrpool","2017-11-11T03:41:07Z","2019-11-27T07:56:15Z"
"","97","[SOLR-9642] Refactor the snapshot cleanup mechanism to rely on Lucene","The current snapshot cleanup mechanism is based on reference counting the index files shared between multiple segments. Since this mechanism completely skips the Lucene APIs, it is not portable (e.g. it doesn't work on 4.10.x version).  This patch provides an alternate implementation which relies exclusively on Lucene IndexWriter (+ IndexDeletionPolicy) for cleanup.","closed","","hgadre","2016-10-16T23:54:36Z","2016-10-18T23:05:37Z"
"","68","[SOLR-9269] Refactor the snapshot cleanup mechanism to rely on Lucene","The current snapshot cleanup mechanism is based on reference counting the index files shared between multiple segments. Since this mechanism completely skips the Lucene APIs, it is not portable (e.g. it doesn't work on 4.10.x version).  This patch provides an alternate implementation which relies exclusively on Lucene IndexWriter (+ IndexDeletionPolicy) for cleanup.","closed","","hgadre","2016-08-11T00:18:43Z","2016-10-16T23:57:15Z"
"","446","LUCENE-8890: Improve parallel iteration of two lists of same length.","The class `BooleanWeight` takes a `BooleanQuery` (a list of `BooleanClause`s) as input and maintains a list of weights corresponding to the clauses. The clauses and the weights are iterated in parallel in various places throughout the class. At these code locations, it is not obvious that these two lists always have the same length, i.e., that the parallel iteration is safe. Moreover, the parallel iteration is not well supported by the Java language, which is why this operation is implemented differently throughout the code.  This patch joins the two lists to enable parallel iteration without managing two separate lists. This makes the code’s intent more obvious and prevents bugs due to the lists getting out of sync by a future change.  This problem was identified by our automated detector [MUDetect](https://github.com/stg-tud/MUDetect/). We would very much appreciate your feedback on our patch. Thank you very much!","closed","","salsolatragus","2018-09-05T11:39:38Z","2019-06-28T07:50:38Z"
"","411","Debugging PriorityQueue.java","The change I'm proposing eliminates a problem by properly checking the validity of maxSize itself, before even computing heapSize=maxSize+1.  In the constructor, when maxSize has a value == Integer.MAX_VALUE, then heapSize = maxSize+1 ends up being negative, more exactly -2147483648 (aka. Integer.MIN_VALUE.)  This is quite a bug because then the if statement checking whether heapSize is larger than ArrayUtil.MAX_ARRAY_LENGTH ends up false, so the IllegalArgumentException is never thrown. Yet the code in PriorityQueue.java fails immediately afterwards when reaching ""new Object[heapSize]"" because of heapSize being negative, causing a NegativeArraySize exception.  We saw this problem with our software which was using (correction--> ) Solr 6.6.1 in cloud mode.","closed","","rsaavedraf","2018-06-26T19:23:52Z","2019-01-18T23:42:39Z"
"","563","Support for moving FST offheap except PK","The change adds support for initializing FST offheap using mapped files during index open. To avoid impact on PKLookup performance, this change initializes FST offheap only if docCount != sumDocFreq (implying field is not PK) and indexInput isinstanceof ByteBufferIndexInput (implying MMapDirectory is being used). More details can be found in the issue below:  https://issues.apache.org/jira/browse/LUCENE-8635","closed","","jainankitk","2019-02-04T19:04:36Z","2019-02-19T18:48:39Z"
"","515","LUCENE-8593: Specialize single value numeric DV updates","The case when all values are the the same on a numeric field update is common for soft_deletes. With the new infrastucture for buffering DV updates we can gain an easy win by specializing the applied updates if all values are the same.","closed","","s1monw","2018-12-05T21:05:29Z","2018-12-06T08:46:37Z"
"","308","Add a suggester that operates on tokenized values from a field","The `TokenizingSuggester` is suspiciously similar to the `AnalyzingInfixSuggester` (and presumably it could be merged into or extend the `AnalyzingInfixSuggester`), but with an additional feature (the `tokenizingAnalyzer`) that allows us to pre-tokenizing suggestions into a manageable size (perhaps single words, shingles of multiple words, or perhaps even NLP-extracted noun phrases) .  Our use case is providing autocomplete suggestions for searching within OCR text of a document (searching within is powered by highlighting), and we're dealing with some page-level OCR that can easily exceed the 32k size limit for the `AnalyzingInfixSuggester`'s exacttext string field.","open","","cbeer","2018-01-17T17:33:07Z","2018-09-12T21:45:33Z"
"","464","SOLR-12555: refactor tests in package org.apache.solr.search","Tests are refactored to use expectThrows instead of try/catch.","closed","","barrotsteindev","2018-10-07T18:57:10Z","2018-11-03T14:49:58Z"
"","138","EdgeNGramTokenFilter drops payloads","Test and fix for https://issues.apache.org/jira/browse/LUCENE-7630.","closed","","xabbu42","2017-01-13T15:00:41Z","2017-01-16T10:18:07Z"
"","159","Merge pull request #1 from apache/master","sync","closed","","lyc1116","2017-02-19T07:37:05Z","2017-02-19T07:38:31Z"
"","415","SOLR-12458: ADLS support for SOLR","Support for ADLS","open","","hbasejanitor","2018-07-09T14:58:29Z","2019-06-14T12:53:21Z"
"","371","SOLR-9685 tag a query in JSON syntax","Support following structure: {""#RCOLOR"": { ""term"": { ""f"": ""color"",""v"": ""blue""}}}  RCOLOR will be tag name","closed","","squallsama","2018-05-05T11:57:40Z","2019-01-19T01:11:17Z"
"","300","SOLR-11831: Skip second grouping step if group.limit is 1 (aka Las Vegas Patch)","Summary: In cases where we do grouping and ask for  {{group.limit=1}} only it is possible to skip the second grouping step. In our test datasets it improved speed by around 40%.  Essentially, in the first grouping step each shard returns the top K groups based on the highest scoring document in each group. The top K groups from each shard are merged in the federator and in the second step we ask all the shards to return the top documents from each of the top ranking groups.  If we only want to return the highest scoring document per group we can return the top document id in the first step, merge results in the federator to retain the top K groups and then skip the second grouping step entirely.","open","","mjosephidou","2018-01-08T17:30:03Z","2019-12-10T14:18:21Z"
"","373","SOLR-7767: New Zookeeper cluster view, first cut","Still needs some buttons for showing details and refresh and probably some cleanup","closed","","janhoy","2018-05-08T09:05:30Z","2018-08-15T11:40:12Z"
"","336","SOLR-11774 langid.map.individual broken","Some failing tests. It is `langid.map.individual` that is broken, independent from `keepOrig` setting.","closed","","janhoy","2018-03-15T08:44:02Z","2019-01-15T16:30:59Z"
"","101","SOLR-9668 Support cursor paging in SolrEntityProcessor","SolrEntityProcessor paginates using the start and rows parameters which can be very inefficient at large offsets. In fact, the current implementation is impracticable to import large amounts of data (10M+ documents) because the data import rate degrades from 1000docs/second to 10docs/second and the import gets stuck. This patch introduces support for cursor paging which offers more or less predictable performance. In my tests the time to fetch the 1st and 1000th pages was about the same and the data import rate was stable throughout the entire import.  To enable cursor paging a user needs to add a ""sort"" attribute in the entity configuration:  ``` xml                url=""http://localhost:8983/solr/collection1"">          ```  If the ""sort"" attribute is missing then the default start/rows pagination is used.","closed","","YegorKozlov","2016-10-20T08:50:32Z","2019-01-18T22:27:19Z"
"","164","SOLR-10250: SolrCloudClient doesn't return 'adds' in Response when' versions' is requested","SolrCloudClient doesn't return 'adds' in Response when' versions' is requested  https://issues.apache.org/jira/browse/SOLR-10250","closed","","BorisNaguet","2017-03-08T17:40:30Z","2017-10-17T11:20:59Z"
"","44","SOLR-8981","SOLR-8981 upgrade to Tika 1.13","closed","","tballison","2016-06-16T16:57:18Z","2016-06-18T17:09:55Z"
"","437","SOLR-12672","SOLR-12672 initial commit.","open","","cahilltr","2018-08-16T16:56:07Z","2018-08-16T16:56:07Z"
"","363","SOLR-12276","SOLR-12276  This pull request is a start.  Done so far:  - Menus - Dashboard tab - Collections tab (not finished) - ""ant server""","open","","jdyer1","2018-04-25T20:12:09Z","2018-07-07T07:07:08Z"
"","312","Solr 11898","SOLR-11898 adding classes missed in SOLR-11898","closed","","millerjeff0","2018-01-24T20:22:10Z","2018-04-06T14:38:57Z"
"","289","SOLR-11745: change logging references to getName","SOLR-11745  this doesn't resolve to anything by object name, Eg: org.apache.solr.core.SolrCore@4812a0d7","closed","","millerjeff0","2017-12-11T21:57:06Z","2021-09-29T21:21:11Z"
"","291","jira/solr-11701","SOLR-11701 upgrade to Tika 1.17","closed","","tballison","2017-12-15T02:21:42Z","2019-01-19T01:56:11Z"
"","262","SOLR-11443: Remove the usage of workqueue for Overseer","SOLR-11443: Remove the usage of workqueue for Overseer","closed","","CaoManhDat","2017-10-14T02:34:25Z","2017-10-14T08:06:46Z"
"","233","Branch 6 6","SOLR-11222: Facet estimation on stream","closed","","peshashulc","2017-08-13T09:55:58Z","2019-01-19T01:24:33Z"
"","294","ZkStateReader: cache LazyCollectionRef (SOLR-8327)","SOLR-10524 introduced zk state update batching, with a default interval of 2 seconds.  That opens the door for a simple, time-based cache on the read side to address the issue described in SOLR-8327","closed","","slackhappy","2017-12-19T18:22:48Z","2019-01-19T00:23:24Z"
"","240","SOLR-10317","SOLR-10317: Integrate new benchmark suite [https://issues.apache.org/jira/browse/SOLR-10317]","open","","viveknarang","2017-08-29T19:15:18Z","2017-08-29T19:15:18Z"
"","40","SOLR-8542: Integrate Learning to Rank into Solr","Solr Learning to Rank (LTR) provides a way for you to extract features directly inside Solr for use in training a machine learned model. You can then deploy that model to Solr and use it to rerank your top X search results. This concept was previously presented by the authors at Lucene/Solr Revolution 2015.  See the [README](https://github.com/bloomberg/lucene-solr/tree/master-ltr-plugin-release/solr/contrib/ltr) for more information on how to get started.","closed","","mnilsson23","2016-05-27T14:35:37Z","2019-01-18T21:58:18Z"
"","4","SOLR-8542: Integrate Learning to Rank into Solr","Solr Learning to Rank (LTR) provides a way for you to extract features directly inside Solr for use in training a machine learned model. You can then deploy that model to Solr and use it to rerank your top X search results. This concept was previously presented by the authors at Lucene/Solr Revolution 2015","closed","","diegoceccarelli","2016-01-29T18:40:09Z","2016-05-27T14:38:26Z"
"","386","SOLR-12416 Add autoDeleteAge to optional router params","Since autoDeleteAge is not in either REQUIRED_ROUTER_PARAMS or OPTIONAL_ROUTER_PARAMS the CollectionsHandler will not pass it on and it will be ignored in the CREATEALIAS command.","closed","","saua","2018-05-29T11:17:00Z","2019-01-19T01:15:40Z"
"","534","SOLR-13137: NPE when /admin/zookeeper/statusin standalone mode","Simply throw an exception with 400 code for a cleaner experience","closed","","janhoy","2019-01-15T11:50:18Z","2019-01-15T16:26:34Z"
"","498","[LUCENE-8565] SimpleQueryParser to support field filtering (aka Add field:text operator)","SimpleQueryParser lacks support for the `field:` operator for creating queries which operate on fields other than the default field. Seems like one can either get the parsed query to operate on a single field, or on ALL defined fields (+ weights). No support for specifying `field:value` in the query.  It probably wasn't forgotten, but rather left out for simplicity, but since we are using this QP implementation more and more (mostly through Elasticsearch) we thought it would be useful to have it in.","open","","synhershko","2018-11-14T10:14:31Z","2018-11-14T11:28:19Z"
"","654","LUCENE-8778: Define analyzer SPI names as static final fields and document the names","See: https://issues.apache.org/jira/browse/LUCENE-8778  Changes in this PR: - Define SPI names as static final fields. - Document SPI names by custom Javadoc tag `@lucene.spi`. - Add validation rules for `NAME` field definition and the Javadoc tag. - Change SPI loader to get the names from the new `NAME` fields","closed","","mocobeta","2019-04-25T17:04:40Z","2019-06-22T04:36:08Z"
"","384","LUCENE-8332 move CompletionTokenStream to ConcatenateGraphFilter","See JIRA issue for overview comments.","closed","","dsmiley","2018-05-25T21:58:33Z","2018-06-11T15:02:57Z"
"","518","SOLR-13025: SchemaSimilarityFactory fallback to LegacyBM25Similarity","See https://issues.apache.org/jira/browse/SOLR-13025","closed","","janhoy","2018-12-07T10:25:54Z","2018-12-12T10:22:20Z"
"","254","LUCENE-7978: Improve Readme with ivy-bootstrap and Ivy known workaround","See https://issues.apache.org/jira/browse/LUCENE-7978 for the full description.","closed","","antonmry","2017-09-27T12:07:13Z","2017-09-29T12:56:21Z"
"","390","Refactor QueryElevationComponent to prepare query subset matching [SOLR-11865]","See comments in https://issues.apache.org/jira/browse/SOLR-11865","closed","","bruno-roustant","2018-05-31T16:10:44Z","2019-12-10T21:33:23Z"
"","505","LUCENE-8548: Reevaluate scripts boundary break in Nori's tokenizer","See [LUCENE-8548](https://issues.apache.org/jira/browse/LUCENE-8548).","closed","","cbismuth","2018-11-23T16:17:43Z","2019-04-03T21:12:57Z"
"","223","SOLR-11154: return useDocValuesAsStored fields in child documents","return useDocValuesAsStored fields in child documents","closed","","onumossn","2017-07-26T23:08:41Z","2019-01-18T23:56:34Z"
"","166","LUCENE-7580 of 8 Mar 2017.","Resolves a conflict with recent simplification of NearSpanUnordered. Includes recent SpanSynonymQuery.","closed","","ghost","2017-03-08T22:27:05Z","2017-03-26T18:52:54Z"
"","5","SOLR-8639 replace static SimpleDateFormat with threadsafe jodatimeDateFormatter","Resolve issue SOLR-8639:  sinceDateParser and afterFmt are declared as static variables of type SimpleDateFormat which is not threadsafe. This may cause data corruption and an incorrect value to be returned by the methods that use them.","closed","","mbreslow","2016-02-04T03:06:43Z","2020-09-21T16:44:10Z"
"","110","Update SearchFiles.java","Replaced the Lucene version number in the usage string by 6_2_1 (it was 4_1_0).  It might be easier if a path like ""http://lucene.apache.org/core/latest/demo/"" was supported, that would always point to the latest version of the demo without the need for a version number. Or else perhaps a version number in a Java file on a central location, that could be used by the demo classes?","open","","FreekDB","2016-11-06T22:02:49Z","2017-02-19T00:02:00Z"
"","335","SOLR-11617 rename alias metadata as alias properties","Renamed the usage in the API and made the code match where I could to avoid confusion in the future.","closed","","nsoft","2018-03-10T20:42:24Z","2019-01-19T00:32:46Z"
"","611","SOLR-9079: Remove commons-lang as a dependency","Removes commons-lang as a dependency. Migrates to commons-lang3 where appropriate. Removes deprecated usages where appropriate as well.","closed","","risdenk","2019-03-19T15:22:09Z","2019-03-21T00:05:03Z"
"","84","Solr 9506 Parallalize/Cache per segment fingerprint","Removed old serial fingerprint computation","closed","","praste","2016-09-28T17:01:38Z","2019-01-18T22:21:27Z"
"","48","moved common string to constant file","removed magic code. moved repeated string in final variable","open","","vcharmcaster","2016-07-05T19:15:39Z","2017-02-19T00:01:54Z"
"","609","SOLR-13330: Improve HDFS tests","Related JIRAs: * SOLR-11010 * SOLR-11381 * SOLR-12040 * SOLR-13297  Changes: * Consolidate hdfs configuration into HdfsTestUtil * Ensure socketTimeout long enough for HDFS tests * Ensure HdfsTestUtil.getClientConfiguration used in tests * Replace deprecated HDFS calls * Use try-with-resources to ensure closing of HDFS resources","closed","","risdenk","2019-03-18T19:30:32Z","2019-03-19T09:29:52Z"
"","614","[SOLR-12532] - Slop specified in query string is not preserved","Refreshing the PR for master","open","","mrkarthik","2019-03-20T17:58:04Z","2019-03-20T17:58:04Z"
"","627","LUCENE-8746: Make EdgeTree (aka ComponentTree) support different type of components","Refactoring of `EdgeTree` class to support geometry collections","closed","","iverase","2019-03-29T17:08:00Z","2019-09-13T14:58:32Z"
"","36","Solr snapshots","Refactor the Solr collection backup implementation (refactoring ""restore"" implementation in progress).  Following changes introduced - Added Solr/Lucene version to check the compatibility between the backup version and the version of Solr on which it is being restored. - Similarly added a backup implementation version to check the compatibility between the ""restore"" implementation and backup format. - Introduced a Strategy interface to define how the Solr index data is backed up (e.g. using file copy approach). - Introduced a Repository interface to define the file-system used to store the backup data. (currently works only with local file system but can be extended).","closed","","hgadre","2016-04-29T22:39:10Z","2016-07-28T09:22:32Z"
"","425","WIP SOLR-12555: refactor tests to use expectThrows","Refactor tests to use expectThrows instead of the old try catch method.","closed","","barrotsteindev","2018-07-23T03:41:33Z","2018-08-09T20:01:05Z"
"","640","LUCENE-8671: Introduce Reader attributes","Reader attributes allows a per IndexReader configuration of codec internals. For instance this allows a per reader configuration if FSTs are loaded into memory or are left on disk.","closed","","s1monw","2019-04-10T14:03:17Z","2019-06-27T03:45:37Z"
"","125","SOLR-9868 RangeFacet : Use DocValues for accs and docSet collection instead of RangeQuery","RangeFacet initiates a range query for each range bucket to get the docSet. DocSet later used for accs collection. For singleValued numeric fields, we can use docValues to find the matching slots for each doc to collect accumulators while iterating over base docSet. If there is a subFacet, docSet per range bucket can be collected from base docSet as well. Gains :      One iteration over base docSet vs querying over baseDocSet for each range bucket     Memory saving If there is no subFacet, since per bucket docSet is not needed","closed","","rustamhsmv","2016-12-15T09:55:55Z","2020-11-17T23:45:45Z"
"","556","LUCENE-8673: Use radix partitioning when merging dimensional points","Radix selection implementation when merging BKD segments","closed","","iverase","2019-01-31T12:34:21Z","2019-02-07T07:22:41Z"
"","260","SOLR-10888: Python script to access V2 APIs","Python script that uses _introspect to dynamically create a CLI to perform actions which target the v2 API.  This is still in discussion in [SOLR-10888](https://issues.apache.org/jira/browse/SOLR-10888) but thought having the PR will probably help the review/discussion better than just the attachment.  Idea by @cpoerschke 😄","closed","","mariocj89","2017-10-07T12:00:52Z","2018-05-20T12:18:04Z"
"","243","SOLR-11319: Update guide on using Python with json","Python has support for json since version 2.6 (2008). All supported versions at the moment has json on it, this commit updates the guide by removing the instructions on how to add the external library ""simplejson"" as the standard one is nowadays   preferred from the community.  https://issues.apache.org/jira/browse/SOLR-11319","closed","","mariocj89","2017-09-04T15:59:28Z","2017-10-19T21:13:11Z"
"","105","LUCENE-7526 Improvements to UnifiedHighlighter OffsetStrategies","Pull request for LUCENE-7526","closed","","Timothy055","2016-10-28T19:03:15Z","2017-04-09T18:07:45Z"
"","423","xxSolr 12357","Premptive Creation of collections in Time Routed Aliases","closed","","nsoft","2018-07-19T03:52:46Z","2019-01-19T01:26:24Z"
"","432","LUCENE-8438: RAMDirectory speed improvements and cleanup","PR for the issue.","closed","","dweiss","2018-08-06T10:38:21Z","2019-06-14T20:44:36Z"
"","514","LUCENE-8591: add LegacyBM25Similarity#getDiscountOverlaps","PR for https://issues.apache.org/jira/browse/LUCENE-8591","closed","","javanna","2018-12-05T15:24:47Z","2018-12-07T11:35:17Z"
"","451","LUCENE-8496: Add selective indexing to BKD/POINTS codec","PR for [LUCENE-8496](https://issues.apache.org/jira/browse/LUCENE-8496) enabling fields to use the first `numIndexDimensions` from `numDataDimensions` while creating the BKD index.","closed","","nknize","2018-09-14T18:51:18Z","2018-10-18T17:05:41Z"
"","71","[SOLR-9441] Support configuring umask for HDFS backup repository.","Please refer to following document for details https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsPermissionsGuide.html","closed","","hgadre","2016-08-25T00:08:19Z","2016-10-25T16:19:19Z"
"","136","Branch 6 3","Please delete this request. I was trying to get source code of branch_6_3, unfortunately this request got created. I am unable to delete this.","closed","","nagakrishna","2017-01-09T19:24:55Z","2019-01-18T23:43:33Z"
"","186","SOLR-1384 minShouldMatch parameter is supported for boolean query","Please consider adding min-should-match support to boolean query. We need it and can't switch to eDisMax because of it's restriction. (eDisMax stops min-should-match processing if it finds boolean operators in subqueries.)","open","","timofal","2017-04-13T17:12:16Z","2017-04-13T17:12:16Z"
"","565","SOLR-7515","Patch to fix behaviour of checkboxes under highlight section in the admin interface query tab.","open","","mattflax","2019-02-06T14:58:18Z","2019-02-06T14:58:18Z"
"","511","LUCENE-8563: Remove k1+1 from the numerator of  BM25Similarity","Patch for https://issues.apache.org/jira/browse/LUCENE-8563.  This PR removes the k1+1 factor from the numerator of `BM25Similarity` and adds a new `LegacyBM25Similarity` under misc that exposes the old behaviour. Note that I haven't found a way to easily reproduce the previous behaviour in the explain method, so I left that part out of `LegacyBM25Similarity` for now.","closed","","javanna","2018-11-28T14:53:28Z","2018-11-30T10:47:21Z"
"","304","SOLR-11722","patch #3 including docs, test SSL fix and precommit fixes","closed","","nsoft","2018-01-11T20:20:40Z","2019-01-19T00:26:55Z"
"","382","WIP: SOLR-12361","pass tests but the TestChildDocTransformer. We have to think of a how we want to change the transformer, which should probably be discussed in another issue. Currently it does not add the _childDocuments_ field to fl, causing the childDocuments to be ommited from the response.","closed","","moshebla","2018-05-23T15:25:12Z","2018-05-28T05:48:52Z"
"","168","SOLR-10256: Make parentheses around spell-suggestions configurable","Parentheses around spell suggestions which have whitespace between them means all the tokens inside  the braces are at the same position (the way Edismax parser parses it). This needs to be made  configurable because braces around tokens is unwanted in cases where we use  WordBreakSolrSpellChecker","open","","abhidemon","2017-03-14T12:58:01Z","2017-09-17T18:25:19Z"
"","247","Branch 5 5","Ouup, sorry, I've made a mistake, do please ignore. _/\_","closed","","totoaumikelabo","2017-09-10T09:28:09Z","2019-01-19T00:05:55Z"
"","298","SOLR-11897 Add web app logging interface auto-refresh toggle.","Our team wanted to be able to pause the logs, to have a bit more time to go over stack traces.","closed","","tommymh","2018-01-04T21:17:59Z","2018-02-16T21:44:25Z"
"","441","SOLR-11690: Improve documentation about DIH password encryption","Only refguide doc change","closed","","janhoy","2018-08-29T09:52:55Z","2019-01-15T16:30:43Z"
"","55","SOLR-8715: Added special condition to match server","One-line fix. Just a missed condition to match server-side special case.","closed","","arafalov","2016-07-26T23:18:12Z","2016-08-12T14:16:38Z"
"","305","SOLR-11853: Make check for used tool ""service"" compatible with SuSE Linux","On current SuSE Linux releases like SLES or OpenSuSE the Solr installer stops with the error message ""Script requires the 'service' command"".  This happens because before installation the installer checks if the used command ""service"" exists by its option ""service --version"".  The command line option ""--version"" doesn't exist for ""service"" on current SuSE Linux stable releases.  Since the command ""service"" is there and has an option ""--help"", this option can be used as additional fallback.  So in the pull request i extended the check with ""service --help"" as second check / fallback before printing this error and exiting.","closed","","Mandalka","2018-01-14T02:27:19Z","2019-01-02T17:00:06Z"
"","176","SOLR-10263 : Override spellcheck's SuggestMode by WordBreakSolrSpellChecker","Now `suggestMode` can be specified for WordBreakSolrSpellChecker, if this value is not null, it will  override the `suggestMode` of SpellCheckComponent.  Fixes Performance and Relevancy","open","","abhidemon","2017-03-28T15:13:29Z","2017-03-29T04:33:53Z"
"","115","SOLR-9772 FieldSortValues should reuse comparator and only invalidate leafComparator","No need to recreate the comparator as leaf changes. There was a bug where lastIdx was not set and was recreating the comparator and re-initializing the leafComparator for each document.","closed","","johnthcall","2016-11-15T20:39:30Z","2016-11-17T16:11:50Z"
"","433","SOLR-12357 Premptive creation of collections in Time Routed Aliases","new PR to clean up the strange merge conflicts","closed","","nsoft","2018-08-08T02:36:24Z","2018-09-07T03:40:22Z"
"","360","SOLR-8207 Admin UI Nodes tab","New nodes tab","closed","","janhoy","2018-04-23T14:26:51Z","2018-08-15T11:40:01Z"
"","214","SOLR-10963 fix documentation for json format","MultipleAdditiveTreesModel wants strings for all values","closed","","stefan-langenmaier","2017-06-27T12:05:59Z","2019-01-18T23:53:30Z"
"","380","LUCENE-8326","More Like This can be refactored to improve the code readability, test coverage and maintenance. Scope of this Jira issue is to start the More Like This refactor from the More Like This Params. This Jira will not improve the current More Like This but just keep the same functionality with a refactored code. Other Jira issues will follow improving the overall code readability, test coverage and maintenance.","open","","alessandrobenedetti","2018-05-22T12:35:45Z","2018-12-17T16:51:19Z"
"","275","SOLR-11662: Configurable query when terms overlap","Modifies QueryBuilder and Solr Field Type to allow configurable overlap scoring asides from SynonymQuery","closed","","softwaredoug","2017-11-21T21:50:24Z","2019-01-19T00:09:50Z"
"","33","Skip flag checks for when they are unavailable SOLR-8715","Matches the special case in the LukeRequestHandler","closed","","arafalov","2016-04-22T06:50:36Z","2016-08-12T14:16:15Z"
"","590","SOLR-13152","make maxCardinality part of createCRACmd constructor para,s and validate CRA params during construction of alias.","closed","","moshebla","2019-02-26T16:18:01Z","2019-03-04T17:32:04Z"
"","595","Load freqs lazily in Postings","LUCENE-8901: Load freqs lazily in postings and impacts  Load freqs lazily only when needed in BlockDocsEnum and BlockImpactsEverythingEnum","closed","","mayya-sharipova","2019-03-01T21:37:19Z","2019-07-10T06:43:07Z"
"","141","Minor corrections, see also LUCENE-7624","LUCENE-7637","closed","","ghost","2017-01-21T14:34:38Z","2019-06-14T12:36:34Z"
"","139","Fieldterms","LUCENE-7633  Rename Terms to FieldTerms.  The only reason for this is that the name Terms is a little too general.","closed","","ghost","2017-01-15T13:20:00Z","2017-01-28T12:35:07Z"
"","75","LUCENE-7434, first draft","LUCENE-7434, first draft","open","","tballison","2016-09-01T19:34:17Z","2017-02-19T00:01:55Z"
"","483","SOLR-12904: Log Delete Query Processor custom solr component","Log Delete Query Processor custom solr component","open","","tirthmehta1994","2018-10-23T16:56:07Z","2019-01-09T20:12:03Z"
"","109","[SOLR-9688] Add a command-line script to manage Solr collection snapshots","Locally tested the script using following commands,  // Start solr and initialize a sample collection bin/solr start -c bin/solr create_collection -c books curl 'http://localhost:8983/solr/books/update?commit=true' -H 'Content-type:application/json' -d ' [ {""id"" : ""book1"",  ""title"" : ""American Gods"",  ""author"" : ""Neil Gaiman"" } ]'  //Create and export a snapshot ./snapshotscli.sh --create snap-1 -c books -z localhost:9983 ./snapshotscli.sh --list -c books -z localhost:9983 ./snapshotscli.sh --describe snap-1 -c books -z localhost:9983 ./snapshotscli.sh --export snap-1 -c books -z localhost:9983 -d /tmp ./snapshotscli.sh --delete snap-1 -c books -z localhost:9983  // Restore the backup and verify the doc count curl 'http://localhost:8983/solr/admin/collections?action=restore&name=snap-1&location=/tmp&collection=books_restored' curl 'http://localhost:8983/solr/books_restored/select?q=*:*'","closed","","hgadre","2016-11-05T00:20:13Z","2019-01-18T22:30:51Z"
"","571","SOLR-13234: Prometheus Metric Exporter Not Threadsafe","Link to the referenced Jira: https://issues.apache.org/jira/projects/SOLR/issues/SOLR-13234","closed","","danyalprout","2019-02-12T22:20:39Z","2019-03-04T05:33:31Z"
"","608","LUCENE-8620: LatLonShape contains","LatLonShape's implementation for spatial relationship CONTAINS.","closed","","iverase","2019-03-13T15:11:26Z","2019-09-11T07:04:19Z"
"","546","LUCENE-8620: LatLonShape contains","LatLonShape's implementation for spatial relationship CONTAINS.","closed","","iverase","2019-01-22T13:58:06Z","2020-02-07T20:17:28Z"
"","587","LUCENE-8707: Add LatLonShape and XYShape distance query","LatLonShape query distance based heavily in LatLonPoint implementation","closed","","iverase","2019-02-25T12:00:43Z","2020-02-19T15:39:59Z"
"","539","SOLR-13143: Fix discrepencies for RankQueries WRT explanations","Jira Link - https://issues.apache.org/jira/browse/SOLR-13143","open","","samj1912","2019-01-17T14:31:19Z","2019-01-28T04:52:21Z"
"","152","Added log prior calculations in CachingNaiveBayesClassifier.","Jira issue : [LUCENE-7672](https://issues.apache.org/jira/browse/LUCENE-7672)","open","","KevinLeeCrosby","2017-01-31T18:08:31Z","2017-02-19T00:02:06Z"
"","470","SOLR-12874 - Java 9+ GC Logging filesize parameter should be 20M instead of 20000","JEP 158 (https://openjdk.java.net/jeps/158) says the filesize parameter is the “file size in kb” however that appears to not be the case since when it is set to a value of 20000 you end up with GC logs that are only 20000 bytes in length.  Setting the value to 20M produces the desired result of GC log files that are 20MB in size.","closed","","tpunder","2018-10-15T20:06:50Z","2018-10-17T21:26:36Z"
"","13","Inherit SOLR_LOGS_DIR from environment","It is sometimes useful to override SOLR_LOGS_DIR from within a wrapping script; these changes make it possible while maintaining existing defaults.  (This behavior already exists in the Linux shell script; this PR adds equivalent behavior to the Windows wrapper).","closed","","demiankatz","2016-02-26T19:54:02Z","2016-10-18T12:29:50Z"
"","8","Do not log error messages, if client has been interrupted","It is annoying to get the log flushed with error messages, if the CloudSolrClient has been interrupted during a request. So instead a debug message will be logged and the exception re-thrown.","open","","markus-s24","2016-02-18T11:05:12Z","2020-11-01T15:22:49Z"
"","393","LUCENE-8347 BlendedInfixSuggester to handle multi term matches better","Introduced multi term management for the BlendedInfix suggester. The score of each suggestion will be calculated based on :   - the positional coefficient of each token matched - the length of the suggestion ( minor)  This patch is supposed to go in after LUCENE-8343","open","","alessandrobenedetti","2018-06-04T17:20:22Z","2019-06-14T12:50:55Z"
"","665","Fixes SOLR-13539","Introduce EmbeddedSolrTestBase for easy and simple integration tests, fixes are included for SOLR-13331 and SOLR-13347.  @gerlowskija Please review","closed","","thomaswoeckinger","2019-05-07T15:35:34Z","2019-10-08T10:49:11Z"
"","11","Limit threadpools by default to 128","Integer.MAX_VALUE could kill the VM instead of providing useful error messages.  128 is a wild guess by myself. Let's discuss a good default value for this :)  Jira: https://issues.apache.org/jira/browse/SOLR-8727","closed","","bjoernhaeuser","2016-02-24T10:57:26Z","2016-05-17T21:06:59Z"
"","355","SOLR-12233","Instead of recreating the classes every time we reload a solr core, just create them once.  The same is done in other classes such as TransformerFactory","closed","","millerjeff0","2018-04-17T22:38:50Z","2019-01-19T00:44:48Z"
"","21","SOLR-8858 SolrIndexSearcher#doc() Completely Ignores Field Filters Unless Lazy Field Loading is Enabled","Instead of just discarding fields if lazy loading is not enabled, SolrIndexSearcher now passes them through to IndexReader. This means IndexReader creates a DocumentStoredFieldVisitor that we can use to later determine which fields need to be read.  https://issues.apache.org/jira/browse/SOLR-8858","closed","","maedhroz","2016-03-16T18:21:33Z","2016-06-29T04:25:08Z"
"","350","SOLR match mode change for the rouding off instead of taking floor","Instead of directly using the floor of  the mm %, we need to take the round of value,  Ecample,  When we have 5 boolean clauses and mm=75%, we get calc as 3.75 currently it took 3, so instead of 3 it should have taken 4. as Math.round()","open","","MighTguY","2018-04-03T08:56:55Z","2018-04-05T18:05:24Z"
"","79","LUCENE-7438 UnifiedHighlighter","Initial pull request for [LUCENE-7438](https://issues.apache.org/jira/browse/LUCENE-7438)","closed","","Timothy055","2016-09-07T15:10:48Z","2016-10-28T19:00:49Z"
"","591","SOLR-9840: Add a unit test for LDAP integration (Hrishikesh Gadre, Kevin Risden)","Initial pass at merging LDAP support. precommit and the test change (`TestSolrCloudWithHadoopAuthPlugin`) passes. Sadly this requires a LOT of test dependencies from Apache DS. I took trial and error to make sure it was the minimal dependencies needed to make this test work.","open","","risdenk","2019-02-27T02:59:02Z","2020-02-08T18:38:48Z"
"","185","SOLR-10487: Support to specify connection and socket read timeout in DataImportHandler for SolrEntityProcessor.","Includes changes for [SOLR-10487](https://issues.apache.org/jira/browse/SOLR-10487). Added two more attributes to [SolrEntityProcessor](https://wiki.apache.org/solr/DataImportHandler#SolrEntityProcessor) in DataImportHandler. `connectionTimeout` to set the Connection Timeout `readTimeout` to set Socket Read Timeout  Additionally renamed `timeout` to `queryTimeout` to differentiate between the various timeouts. The older `timeout` is still retained to ensure backward compatibility. `timeout `would act same as `queryTimeout`. The two new attributes would accept values in the same format and unit (int seconds) as the existing query timeout attribute.","closed","","gmandal","2017-04-13T12:17:37Z","2021-12-08T13:12:05Z"
"","184","Solr 10487 : Add connection/read timeout for SolrEntityProcessor in DataImportHandler","Includes changes for [SOLR-10487](https://issues.apache.org/jira/browse/SOLR-10487). Added two more attributes to [SolrEntityProcessor](https://wiki.apache.org/solr/DataImportHandler#SolrEntityProcessor) in DataImportHandler. `connectionTimeout` to set the Connection Timeout `readTimeout` to set Socket Read Timeout  Additionally renamed `timeout` to `queryTimeout` to differentiate between the various timeouts. The older `timeout` is still retained to ensure backward compatibility. `timeout `would act same as `queryTimeout`. The two new attributes would accept values in the same format and unit (int seconds) as the existing query timeout attribute.","closed","","gmandal","2017-04-13T09:59:58Z","2017-04-13T11:58:50Z"
"","249","SOLR-10451: Remove contrib/ltr/lib from lib includes","in the techproducts example config  I deleted line 84 : ``  in [solrconfig.xml](https://github.com/apache/lucene-solr/blob/master/solr/server/solr/configsets/sample_techproducts_configs/conf/solrconfig.xml) file","closed","","sungjunyoung","2017-09-19T03:51:41Z","2017-09-21T05:08:58Z"
"","637","LUCENE-8754: Prevent ConcurrentModificationException in SegmentInfo","In order to prevent ConcurrentModificationException this change makes an unmodifiable copy on write for all maps in SegmentInfo. MergePolicies can access these maps without synchronization and cause exceptions if it's modified in the merge thread.","closed","","s1monw","2019-04-07T07:58:05Z","2019-04-10T07:29:26Z"
"","96","SOLR-6246 - Fix core reload if suggester has been built.","In my testing, it is not required to keep the writer open for the suggester to keep working. Add and Update call ensureOpen, which will open a new writer if it has been set = null. This change closes it at the end of a build and sets the reference = null such that Add and Update will continue to work correctly. Additionally, commit is updated to not throw if the writer is null. This is correct because nothing has been added or updated since the last build. The only thing I'm left with uncertainty about is reloading a core with NRT updates pending. This would appear to still cause the issue to appear again. The difference being that a rebuild would alleviate the issue. This requires additional thought.","closed","","Peter-LaComb","2016-10-13T20:43:54Z","2016-10-14T14:58:44Z"
"","236","Branch 5x small optimisations","In a test with a high concurrency, high write workload on the NRTCachingDirectory, these changes gives me a ~10-15% throughput improvement. To get that, I had to increase the buffer size to 4 KiB. I have left it as is, and just allowed it to be tuned.","closed","","chrisvest","2017-08-18T11:20:26Z","2017-08-19T13:44:51Z"
"","603","LUCENE-8718: Add docValueCount support for SortedSetDocValues","implement docValueCount() for SortedSetDocValues.","closed","","javasoze","2019-03-09T20:54:58Z","2019-03-16T00:42:00Z"
"","405","don't die when java prints tool options","If you have JAVA_TOOL_OPTIONS set (e.g. in my .profile, `export JAVA_TOOL_OPTIONS=""-Dfile.encoding=\""UTF-8\"" -Dawt.useSystemAAFontSettings=on""`) you get a confusing message about having the wrong version of java installed because the launch script only looks at the first line of the output of `java -version`.  Simple 1-liner fix.","open","","tjakway","2018-06-17T23:34:47Z","2019-11-27T09:11:25Z"
"","124","fix small issue in solr shell script","if you are using CDPATH  (and it is really userful OTB function of bash shell), this script will not work. Finally you will see, that $SOLR_SERVER_DIR not found CDPATH is not necessary inside any scripts and we must to break it like  CDPATH='' # empty","closed","","idler","2016-12-14T09:55:39Z","2020-02-15T17:23:20Z"
"","387","SOLR-12421: CoreDescriptor constructor allows a core descriptor name to be passed but can overwrite it with the old name","If we allow the passed in properties object to override the name written to originalCoreProperties then the core.properties file gets written with the wrong name in it.","open","","millerjeff0","2018-05-29T23:56:52Z","2019-06-14T12:49:29Z"
"","35","SOLR-8297 Support Join query over 2 sharded collections","If a shard is found on node and is active allow to query on it. But if multiple shards are found on same node then ""SolrCloud join: multiple shards not yet supported"" is thrown.","open","","shikhasomani","2016-04-29T14:26:12Z","2017-02-19T00:01:53Z"
"","374","[SOLR-12334] Improve detection of recreated lockfiles","I've been running into issues with the detection of deleted and then recreated files when using GlusterFS. Since, on most platforms, there are more reliable ways to detect recreated files, I decided improved the detection of such files.  Background:  As part of LUCENE-6508 [3] detection of recreated files was added. In such a case, another instance may have obtained lock on the newly created file. This isn't something that should happen on a properly configured Solr instance but there is a good chance for this happening when an index is shared by multiple instances that use a different locking mechanism.  Implementation:  On platform that support it, fileKey() [1] is now used. On Unix-like systems this key consists of the device ID and and inode. For locks that keep the lock file open, this should ensure we detect recreation since no two files can have the same device ID and inode even if the last hard link has been removed already. Other locks, that don't keep the file open, should still detect recreation at a low error rate.  Platforms without fileKey() support keep using the creation timestamp or modification timestamp (subject to availability) [2].  [1]: https://docs.oracle.com/javase/8/docs/api/java/nio/file/attribute/BasicFileAttributes.html#fileKey-- [2]: https://docs.oracle.com/javase/8/docs/api/java/nio/file/attribute/BasicFileAttributes.html#creationTime-- [3]: https://issues.apache.org/jira/browse/LUCENE-6508","closed","","pgerber","2018-05-09T14:13:14Z","2019-11-14T14:43:08Z"
"","544","LUCENE-5698 - added test for 20n dataset, minor code adjustments","I've added a test to run Lucene Classifiers against 20Newsgroups dataset. It produces a Markdown output on the System.output. In order to run, the path to the 20n dataset needs to be manually set.","closed","","tteofili","2019-01-18T20:12:25Z","2019-01-24T09:26:58Z"
"","51","SOLR-9303: Refactor CloudSolrClient for extensibility","I'm using a custom Solr plugins which adds extra constraints on which nodes I can access.  To respect these constraints, I needed to use a customized version of CloudSolrClient.  Unfortunately, CloudSolrClient.sendRequest() is currently written as one big chunk of code, breaking OO's SOLID principle and making it is impossible for me to customize it on a subclass.  I have refactored this method in 3 steps: - Finding the usable URLs - Checking if a node can be used for this request - Executing the request","closed","","paulo-raca","2016-07-13T13:46:32Z","2017-01-15T22:45:15Z"
"","352","SOLR-12192 deal with ulimit being unlimited","I noticed: ``` solr@fd8031538f4b:/opt/solr$  ulimit -u unlimited  solr@fd8031538f4b:/opt/solr$  bin/solr /opt/solr/bin/solr: line 1452: [: unlimited: integer expression expected ```  The solr start script should check for ""unlimited"".","closed","","makuk66","2018-04-05T21:57:39Z","2019-01-19T00:59:19Z"
"","440","Lucene 6989 v2","I have made a mistake.please close it","closed","","firewolf2010","2018-08-23T08:38:00Z","2020-11-10T18:20:11Z"
"","238","LUCENE-7940: Bengali Analyzer for Lucene","I have followed the code structure of `lucene/analysis/common/src/java/org/apache/lucene/analysis/hi`.  An issue(https://issues.apache.org/jira/browse/LUCENE-7940) was created in JIRA of apache.org.","closed","","sunkuet02","2017-08-24T12:14:09Z","2017-09-05T22:50:07Z"
"","639","Solve the problem of highlighting Chinese inaccurately.","I found a bug. When I am highlighting Chinese, extra phrases are highlighted.  I solved it according to my understanding.  I added a test case to simulate the problem when highlighting Chinese text.","open","missing Jira,","mengbin16","2019-04-10T11:16:38Z","2020-03-06T11:15:13Z"
"","278","SOLR-11508: core.properties should be stored $solr.data.home/core_name","I ended up simply defaulting coreRootDirectory to solr.data.home, if it is defined, and solr.home.home otherwise.    Both values seem somewhat redundant but comments in SOLR-6671 indicate that others have reasons to keep them separate. This patch simply makes Solr behave in a way that is more intuitive by default.   Those who need to revert to the old way can define coreRootDirectory in solr.xml, if they hadn't already.","closed","","morissm","2017-11-29T17:16:56Z","2017-12-04T01:11:16Z"
"","265","Lucene 7804","i do have an icla signed already.  adding support for point fields based on Alan Woodwards patch","closed","","shawnfeldman","2017-10-24T16:15:52Z","2017-10-24T19:58:52Z"
"","147","SOLR-8146 decouple building url list from CloudSolrClient to separate class for…","I am suggesting to decouple building the url list from CloudSolrClient.sendRequest(..) to a separate class.  The advantage will be the ability to easily write unit test for building the url list part and as we implement more routingRules for querying like query only the same rack replica's / OR query replica's where mem/cpu/disk utilisation is below a threshold can be easily unit tested etc.  I can add more tests if approach looks good. Please review.","closed","","susheelks","2017-01-28T13:44:52Z","2020-07-15T00:55:34Z"
"","359","LUCENE-8265: WordDelimiter*Filter ignores keywords","I added the checks for isKeyword(), a couple of simple unit tests to verify the new behavior, and also removed a bunch of @Test annotations by the by.","closed","","msokolov","2018-04-22T21:10:50Z","2019-01-19T00:47:47Z"
"","547","SOLR-13161: Admin UI - drag/drop replicas","https://issues.apache.org/jira/projects/SOLR/issues/SOLR-13161  drag/drop replica move implemented","open","","jdbranham","2019-01-22T15:20:19Z","2019-02-25T13:46:38Z"
"","112","Allow an encrypted password to be used in a variable.","https://issues.apache.org/jira/browse/SOLR-9725","closed","","jamiejackson","2016-11-10T22:28:52Z","2019-06-10T20:41:21Z"
"","77","[SOLR-9127] XlsxResponseWriter","https://issues.apache.org/jira/browse/SOLR-9127  New response writer and test case (TextXLSXResponseWriter)  passes ant precommit all work squashed into one commit for easy perusal","closed","","desultir","2016-09-06T05:40:49Z","2019-01-18T22:10:20Z"
"","59","SOLR-9127: XLSXResponseWriter","https://issues.apache.org/jira/browse/SOLR-9127  New response writer and test case (TextXLSXResponseWriter)  passes ant precommit","closed","","desultir","2016-08-01T05:27:22Z","2016-09-06T05:36:34Z"
"","47","SOLR-8858 SolrIndexSearcher#doc() Completely Ignores Field Filters Unless Lazy Field Loading is Enabled","https://issues.apache.org/jira/browse/SOLR-8858","closed","","maedhroz","2016-06-29T19:35:32Z","2016-07-07T07:53:09Z"
"","545","SOLR-13157: Convert Unicode double quotes to standard quotes","https://issues.apache.org/jira/browse/SOLR-13157  Updated the dismax parser to find any Unicode double quotes and replace them with a standard double quotes.","closed","","jnyryan","2019-01-21T15:25:04Z","2019-07-11T12:49:54Z"
"","402","SOLR-12477 - Return server error(500) for AlreadyClosedException instead of client Errors(400)","https://issues.apache.org/jira/browse/SOLR-12477  In some cases(for example: corrupt index), addDoc0 throws AlreadyClosedException, but solr server returns client error 400 to client  This will confuse customers and especially monitoring tool.","closed","","jefferyyuan","2018-06-11T20:24:30Z","2018-07-31T21:50:38Z"
"","321","SOLR-11932 Retry ZkOperation on SessionExpired","https://issues.apache.org/jira/browse/SOLR-11932  We are seeing situations where an operation, such as changing a replica's state to active after a recovery, fails because the zk session has expired.  However, these operations seem like they are retryable, because the ZookeeperConnect receives an event that the session expired and tries to reconnect.  That makes the SessionExpired handling scenario seem very similar to the ConnectionLoss handling scenario, so the ZkCmdExecutor seems like it could handle them in the same way.","open","","slackhappy","2018-02-06T04:12:42Z","2018-02-06T04:21:04Z"
"","232","SOLR-11231 Guard against unset fields when performing language detection","https://issues.apache.org/jira/browse/SOLR-11231","closed","","cbeer","2017-08-12T18:37:38Z","2019-09-05T15:59:58Z"
"","169","Add status return for replication SOLR-10249","https://issues.apache.org/jira/browse/SOLR-10249","closed","","millerjeff0","2017-03-17T23:00:42Z","2019-01-18T23:30:11Z"
"","167","LUCENE-7744","https://issues.apache.org/jira/browse/LUCENE-7744","closed","","xabbu42","2017-03-13T13:25:48Z","2017-11-13T12:13:16Z"
"","480","LUCENE-8535: Drop out of the box Block-Join highlight support","Highlighter doesn't support ToParent and ToChildBlockJoinQuery out of the box anymore. In oder to highlight on Block-Join Queries a custom WeightedSpanTermExtractor should be used.","closed","","s1monw","2018-10-18T08:17:46Z","2018-10-18T12:57:50Z"
"","530","Branch 7 4 : IndexOutOfBoundsException randomly appearing while indexing","Hi,  First of all sorry if it is not the right place to write the issue I am encountering. I saw other people where having the same problem on StackOverflow (https://stackoverflow.com/questions/52783491/solr-indexing-error-possible-analysis-error) although there was no solution provided so far. Anyway feel free to reroute my pull request.  So while indexing documents with SOLR 7.4 the following exception appears randomly. It is very annoying because I cannot reproduce it on my machine and I don't have access to customer's data. All I know is that it can appear on pdf, xls, or eml documents. It looks like the issues stems from FlattenGraphFilter class and specifically _restoreState(inputNode.tokens.get(inputNode.nextOut))_  The stack trace shows :    Caused by: java.lang.IndexOutOfBoundsException: Index: 1, Size: 1 	at java.util.ArrayList.rangeCheck(ArrayList.java:657) 	at java.util.ArrayList.get(ArrayList.java:433) 	at org.apache.lucene.analysis.core.FlattenGraphFilter.releaseBufferedToken(FlattenGraphFilter.java:204) 	at org.apache.lucene.analysis.core.FlattenGraphFilter.incrementToken(FlattenGraphFilter.java:258) 	at org.apache.lucene.index.DefaultIndexingChain$PerField.invert(DefaultIndexingChain.java:738) 	at org.apache.lucene.index.DefaultIndexingChain.processField(DefaultIndexingChain.java:428) 	at org.apache.lucene.index.DefaultIndexingChain.processDocument(DefaultIndexingChain.java:392) 	at org.apache.lucene.index.DocumentsWriterPerThread.updateDocument(DocumentsWriterPerThread.java:251) 	at org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:494) 	at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1602) 	at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1594) 	at org.apache.solr.update.DirectUpdateHandler2.updateDocument(DirectUpdateHandler2.java:982) 	at org.apache.solr.update.DirectUpdateHandler2.updateDocOrDocValues(DirectUpdateHandler2.java:971) 	at org.apache.solr.update.DirectUpdateHandler2.doNormalUpdate(DirectUpdateHandler2.java:348) 	at org.apache.solr.update.DirectUpdateHandler2.addDoc0(DirectUpdateHandler2.java:284) 	at org.apache.solr.update.DirectUpdateHandler2.addDoc(DirectUpdateHandler2.java:234)  If more info is needed I would be delighted to provide it as long as I have it (eg documents are customer confidentials so I don't have access to them).  Kind regards","closed","","IntraCherche","2018-12-26T14:49:12Z","2018-12-29T02:35:04Z"
"","427","Fixed Spelling.","Hi there,  I wrote this bot based on the top 10 most misspelled english words. (https://blog.oxforddictionaries.com/2016/08/02/corpus-misspellings/) The bot queries, forks, clones, fixes and commits but I manually create the PRs. All the best, Jimmy","closed","","jimmycasey","2018-07-30T14:09:48Z","2019-01-20T19:50:17Z"
"","288","LUCENE-8086","Here are the changes, in particular:  - Geo3dFactory: Use GeoExactCircle for non-spherical planets. - Geo3dCircleShape: Remove method relate. - Geo3DShape: Use new factory method for building GeoBbox from bounds object. - Geo3dDistanceCalculator: use pointonbearing from planet model. - Test refactoring","closed","","iverase","2017-12-08T15:39:01Z","2018-01-10T12:02:08Z"
"","274","[LUCENE-8028] Arabic light stemmer - stemmer enhancement","Hello, this PR is to add Enhancement for Arabic Stemmer #https://issues.apache.org/jira/browse/LUCENE-8028","open","","Ashamandi","2017-11-15T12:59:16Z","2018-01-12T13:27:52Z"
"","188","Jira/solr 6203","Hello, Christine.  I merged from master through commit 00f0c3022baa0b7 to my fork of the jira/solr-6203 branch, resolved a conflict in TopGroupsFieldCommand.java, and committed.  All unit tests pass, including the ones I added to test the fix which is the subject of this Jira.","closed","","jitka18","2017-04-16T17:20:41Z","2017-04-16T17:34:16Z"
"","189","Jira/solr 6203","Hello, Christine.  I merged from master though commit 00f0c30 to my fork of the jira/solr-6203 branch, resolved a conflict in TopGroupsFieldCommand.java, and committed.  Unit tests all pass, including those added in previous commits to test the fix of the bug which is the subject of this jira. I closed the previous pull request because I thought it was interfering with my attempt to create this one. Judith","closed","","jitka18","2017-04-16T17:41:45Z","2019-05-16T07:20:03Z"
"","39","[SOLR-9105] Fix some typos in solr core module","Hello, I wanted to fix one typo that I've found while reading the code, then I decided to fix some more and that escalated a bit...","closed","","krasinski","2016-05-11T17:03:52Z","2016-05-11T19:25:42Z"
"","248","LUCENE-7971: Fix invalid javadoc example in SpellChecker","Hello Lucene team.  This pull request is to address [LUCENE-7971](https://issues.apache.org/jira/browse/LUCENE-7971) bug from JIRA.  It is a fix for invalid example in ```SpellChecker``` javadoc. Index dictionary can be done by invoking ```checker.indexDictionary(dictionary, config, true)``` but in javadoc example the ```checker.indexDictionary(dictionary)``` method is used instead, which is wrong, because such method does not exist.","open","","sarxos","2017-09-16T12:07:25Z","2017-09-16T20:50:12Z"
"","154","SOLR-10081: Web UI (GenerateTrainingData ) for LTR plugin","Hello ,  https://issues.apache.org/jira/browse/SOLR-10081 This is a New Feature for LTR plugin. It will help you to generate the training data (HUMAN_JUDGEMENT) by using score between 0-4. Live demo http://ltr.qfdk.me gitrepo https://github.com/qfdk/GenTrainingDataSolr Thank you.","open","","qfdk","2017-01-31T21:45:33Z","2017-02-19T00:02:06Z"
"","396","SOLR-12452","Hadoop 2.7.4 libraries have some serious security issues therefore they should be updated to the newest ones","closed","","diegomaradona21","2018-06-06T13:48:19Z","2019-02-02T17:01:40Z"
"","662","SOLR-12584: Describe getting Prometheus metrics from a secure Solr","Getting the Solr-Prometheus-Exporter to work with a secure Solr is possible, but not straight-forward. This pull request extends the documentation to show how it can be done.","closed","","sbillet","2019-05-03T21:07:50Z","2019-05-20T08:54:07Z"
"","351","SOLR-9640 Support PKI authentication in standalone mode","Generating PR for easier review","closed","","janhoy","2018-04-04T11:01:40Z","2022-05-18T11:25:51Z"
"","458","SOLR-12799: Allow Authentication Plugins to intercept internode requests on a per-request basis","Framework support for per-request decision on whether to secure inter-node requests","closed","","janhoy","2018-09-24T09:55:21Z","2018-12-20T14:33:01Z"
"","651","LUCENE-8774: Performance improvement for update?optimize=true","For our use case we have a small number of documents with a large number of docValues.  During optimize we noticed a lot of time being spent in the FilterFieldInfos constructor, on the filterFields.contains(...) function.    The small change from an ArrayList to a LinkedHashSet reduced our optimize time from 60min to < 1min.  This was added to branch 7_2 as that's the version we're still using, but the issue is still present in master: https://github.com/apache/lucene-solr/blob/master/lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldDocValuesFormat.java#L142","closed","","johann-beessip","2019-04-18T20:28:44Z","2019-06-14T11:41:47Z"
"","201","Allocate ArrayList with exact size","For more than 10 terms in a phrase (the default size of an array list), this may save reallocations, and for fewer terms it may save a little bit of memory.","open","","kno10","2017-05-15T09:07:42Z","2017-05-15T09:07:42Z"
"","383","LUCENE-8287: In ContextQuery, use a more comprehensive check for an empty prefix automaton","Follow-up to https://github.com/apache/lucene-solr/pull/375.","closed","","jtibshirani","2018-05-25T20:06:11Z","2021-01-02T04:40:00Z"
"","456","Corrected equals method of QueryValueSource","Fixes the comparison of an extended class of QueryValueSource","closed","","rozuur","2018-09-17T14:42:53Z","2018-09-27T05:16:24Z"
"","277","SOLR-11690: DIH JdbcDataSource - Problem decoding encrypted password using encryptKeyFile","Fixes problem in decrypting jdbc datasource password","closed","","rajeshrmgm","2017-11-28T08:33:33Z","2019-01-19T00:07:46Z"
"","366","[LUCENE-7820] Fixes compile issue of html demo source code","Fixes https://issues.apache.org/jira/browse/LUCENE-7820","open","","soneyworld","2018-04-29T12:47:56Z","2018-04-29T12:50:39Z"
"","346","SOLR-12162: Fixes typo in CorePropertiesLocator","Fixes a simple typo in the CorePropertiesLocator  https://issues.apache.org/jira/browse/SOLR-12162","closed","","rzwiefel","2018-03-29T16:48:07Z","2019-01-19T00:39:14Z"
"","63","SOLR-9232: Fixed Core Swap implementation","Fixed: - Incorrect non-scoped variable use that hid the message and shadowed the root case - Fixed incorrect branch condition - Fixed missing request parameter to actually trigger the SWAP command  Tested on Chrome and Firefox on mac against latest master.","closed","","arafalov","2016-08-04T03:06:24Z","2016-08-12T13:34:00Z"
"","542","LuceneLevenshteinDistance computes distance values outside of interval [0, 1]","fixed two bugs in LuceneLevenshteinDistance's getDistance method that leads to **negative distance values** if luc-lev-dist(s1, s2) > min(s1.length, s2.length).  For example, s1 = `a` and s2 = `bb` result in luc-lev-dist(s1, s2) = -1.  created unit tests","open","missing Jira,","saschaszott","2019-01-18T12:00:03Z","2019-01-22T23:05:31Z"
"","284","[LUCENE-8051] Typo in LevensHtein distance","Fixed a type: ""Looking into an issue in elasticsearch I notices that the Levenshtein distance in lucene is called LevensteinDistance instead of LevenshteinDistance. The algorithm name contains an H and in the rest of the code the Levenshtein name is spelled correctly with an H.""","closed","","imgpulak","2017-12-06T06:01:20Z","2017-12-06T16:31:59Z"
"","54","SOLR-8911: Angular Admin UI: Fix cut-off overflow strings on dashboard page","Fix too long value strings in the dashboard page (primarily versions and args sections) by adding overflow scrolling. The scrollbar appears when hovered or touched on the individual value area.  Tested on several browsers on Mac, Windows and Android. On Windows, the scrollbar makes the page jump a little bit for the args section, but is quite usable. On Mac and Android, the scrollbar is inside the area and does not cause a jump.","closed","","arafalov","2016-07-26T14:40:43Z","2016-08-13T14:31:28Z"
"","30","Ensure text field is not multiValued (SOLR-9004)","Fix the field definition to match the README descriptions.","closed","","arafalov","2016-04-17T00:48:25Z","2016-04-18T00:55:35Z"
"","431","SOLR-12602: fix SignificantTermsStream and StreamExpressionTest","fix SignificantTermsStream so StreamExpressionTest#testSignificantTermsStream passes","closed","","barrotsteindev","2018-08-03T10:27:13Z","2018-08-03T10:38:15Z"
"","488","Fix for wrong Tika versions of Solr at CHANGES.txt","Fix for wrong Tika versions for 6.6.5, 6.6.4 and 6.6.3 versions of Solr at CHANGES.txt","closed","","kamaci","2018-11-03T16:13:44Z","2019-02-20T11:44:32Z"
"","408","Reproduces and fixes LUCENE-8365","Fix for an ArrayIndexOutOfBoundsException in UnifiedHighlighter","closed","","morissm","2018-06-20T02:46:14Z","2018-06-20T14:51:56Z"
"","309","Update ZkConfigManager.java","fix copyConfigDir(String fromConfig, String toConfig) When i call copyConfigDir(String fromConfig, String toConfig),the 'CONFIGS_ZKNODE + ""/""' will be appended to parameter twice.Once in copyConfigDir(String fromConfig, String toConfig),once in copyConfigDir(String fromConfig, String toConfig, Set copiedToZkPaths). Then the 'fromZkPath' will become likes this:""/configs//configs/conf0"",which cause a ""empty node name"" exception","open","","yshhuang","2018-01-19T06:20:53Z","2018-01-19T06:20:53Z"
"","343","SOLR-12121: JWT Token authentication plugin","First version. Still some TODO and NOCOMMIT. Lacks some end-to-end tests etc.","closed","","janhoy","2018-03-23T16:36:11Z","2019-04-04T14:54:46Z"
"","353","SOLR-12194: Deprecate SolrRequest#setBasicAuthCredentials","First step Still need to modify `BasicAuthIntegrationTest` and document in ref-guide, but that could also be done in separate issues.","closed","","janhoy","2018-04-06T11:35:26Z","2019-01-16T10:39:25Z"
"","457","SOLR-12791: Add Metrics reporting for AuthenticationPlugin","First partial patch","closed","","janhoy","2018-09-20T19:59:20Z","2018-12-12T11:28:25Z"
"","600","SOLR-13244: Nodes view fails when a node is temporarily down","First fix. * Do not request metrics from dead nodes * Display dead nodes with red background in table * Fetch host-level metrics from first live node on host  Still needs CHANGES entry","closed","","janhoy","2019-03-08T16:37:20Z","2019-03-15T12:31:56Z"
"","328","SOLR-12034","First draft of SOLR-12034 -- not ready for committing. Some non-flaky tests are now failing.","closed","","tballison","2018-02-26T16:29:31Z","2018-10-02T14:55:56Z"
"","82","First draft of LUCENE-5317","First draft of LUCENE-5317","open","","tballison","2016-09-23T19:21:57Z","2019-11-24T18:15:39Z"
"","465","SOLR-7896: Add a login page to Admin UI, with initial support for Basic Auth","First cut for basic auth","closed","","janhoy","2018-10-09T13:41:23Z","2018-12-12T10:21:49Z"
"","525","LUCENE-8585: Index-time jump-tables for DocValues","First complete attempt of LUCENE-8585, with all jump-tables at index-time and with the not-used-anymore lucene70 codec classes moved to backward-codecs.","closed","","tokee","2018-12-12T14:43:48Z","2019-01-21T08:34:15Z"
"","15","SOLR-8754 add tests for org.apache.solr.util.hll.NumberUtilTest","First commit and first contribution, I haven't created any Jira ticket.  I create a test class for an uncovered class I found using the test coverage report.","closed","","bvanalderweireldt","2016-02-27T05:46:03Z","2019-06-13T10:57:14Z"
"","619","LUCENE-8735: Avoid FileAlreadyExistsException on windows.","FilterDirectory.getPendingDeletions() did not delegate the call, which resulted in a new IndexWriter on same directory not considering pending delete files. This could in turn result in a FileAlreadyExistsException when running windows.","closed","","henningandersen","2019-03-25T13:21:47Z","2019-03-26T13:56:57Z"
"","453","LUCENE-8502: Allow access to delegate in FilterCodecReader","FilterCodecReader doesn't allow access to it's delegate like other filter readers. This adds a new getDelegate method to access the wrapped reader.","closed","","s1monw","2018-09-17T08:24:07Z","2018-09-17T09:17:31Z"
"","454","LUCENE-8503: Call #getDelegate instead of direct member access during unwrap","Filter*Reader instances access the member or the delegate directly instead of calling getDelegate(). In order to track access of the delegate these methods should call #getDelegat()","closed","","s1monw","2018-09-17T09:17:43Z","2018-09-17T14:07:16Z"
"","320","LUCENE-8033: FieldInfos always use dense encoding","FieldInfos always to use an array to store FieldInfo byNumber","closed","","mayya-sharipova","2018-02-03T01:45:28Z","2018-02-13T11:42:47Z"
"","625","Ravn 1578","feedback needed please","closed","","craigmamakin","2019-03-28T14:11:40Z","2019-03-28T14:20:57Z"
"","434","Add example schema settings for Korean analyzer.","Example schema settings for `KoreanTokenizerFactory`, `KoreanPartOfSpeechStopFilterFactory`, `KoreanReadingFormFilterFactory`.","closed","","mocobeta","2018-08-10T12:56:54Z","2019-11-10T10:16:14Z"
"","239","Make FacetField.TYPE public","Everything else in the class is public, and all the other Field.TYPE constants are public. I want to use this in a field factory class.","closed","","msokolov","2017-08-24T18:49:19Z","2017-08-27T13:17:06Z"
"","494","ant compile error","error info: ``` [ivy:retrieve] [ivy:retrieve] :: problems summary :: [ivy:retrieve] :::: WARNINGS [ivy:retrieve]          :::::::::::::::::::::::::::::::::::::::::::::: [ivy:retrieve]          ::          UNRESOLVED DEPENDENCIES         :: [ivy:retrieve]          :::::::::::::::::::::::::::::::::::::::::::::: [ivy:retrieve]          :: org.restlet.jee#org.restlet;2.3.0: configuration not found in org.restlet.jee#org.restlet;2.3.0: 'master'. It was required from org.apache.solr#core;working@BK_4B88D29C compile [ivy:retrieve]          :: org.restlet.jee#org.restlet.ext.servlet;2.3.0: configuration not found in org.restlet.jee#org.restlet.ext.servlet;2.3.0: 'master'. It was required from org.apache.solr#core;working@BK_4B88D29C compile [ivy:retrieve]          :::::::::::::::::::::::::::::::::::::::::::::: ```","closed","","cqvip-jq","2018-11-06T08:34:16Z","2018-11-22T13:30:32Z"
"","664","LUCENE-8785: Ensure threadstates are locked before iterating","Ensure new threadstates are locked before retrieving the number of active threadstates. This causes assertion errors and potentially broken field attributes in the IndexWriter when IndexWriter#deleteAll is called while actively indexing.","closed","","s1monw","2019-05-07T07:56:03Z","2019-05-08T09:19:22Z"
"","420","[Lucene-2562] Make Luke a Lucene/Solr Module","Draft pull request for LUCENE-2562.  It is based on mavenized Luke (slightly adjusted to current master branch, ant scripts and lucene test framework.) https://github.com/DmitryKey/luke","closed","","mocobeta","2018-07-15T05:08:24Z","2019-11-10T10:16:48Z"
"","53","[SOLR-9341] GC logs go to SOLR_LOGS_DIR on Windows","Don't override the SOLR_LOGS_DIR environment variable when it has already been set.  This brings the windows behaviour in line with the bash script.","closed","","afscrome","2016-07-26T12:45:41Z","2016-10-18T17:33:27Z"
"","329","SOLR-12035","don't forget to copy charfilters into nostopanalyzer","closed","","tballison","2018-02-26T18:15:02Z","2018-03-28T04:39:30Z"
"","521","LUCENE-8598: Improve field updates packed values","DocValuesFieldUpdats are using compact settings for packet ints that causes dramatic slowdowns when the updates are finished and sorted. Moving to the default accepted overhead ratio yields up to 4x improvements in applying updates. This change also improves the packing of numeric values since we know the value range in advance and can choose a different packing scheme in such a case. Overall this change yields a good performance improvement since 99% of the times of applying DV field updates are spend in the sort method which essentially makes applying the updates 4x faster.","closed","","s1monw","2018-12-09T18:19:59Z","2018-12-10T17:09:53Z"
"","398","Lucene 8343 data type migration","Different approach, data type migration to fix the bugs  :    1) Weight for the Document dictionary moved to Long from long 2) Suggestion score moved to double from long","closed","","alessandrobenedetti","2018-06-08T15:02:06Z","2019-01-19T01:28:08Z"
"","568","SOLR-13231|SOLR-12708: CREATE collection request doesn't fail or cleanup when the request fails","Detailed description in SOLR-13231 and SOLR-12708","closed","","tflobbe","2019-02-07T19:25:13Z","2019-02-20T21:24:53Z"
"","279","SOLR-11711: Fixed minCount bug in distributed field and pivot facets.","Deprecated the FACET_DISTRIB_MCO option, since the behavior is now built in.","closed","","HoustonPutman","2017-11-30T21:30:50Z","2021-10-09T15:17:15Z"
"","70","SOLR-9319 - DELETEREPLICA should be able to accept just count and remove replicas intelligently","DELETEREPLICA should be able to accept just count and remove replicas intelligently SOLR-9319  Added a test in async mode.","closed","","nitingithub","2016-08-23T02:45:48Z","2016-08-25T22:04:09Z"
"","61","SOLR-9003: Fix various UI/DIH debug features","Debug flag now sets the flag and displays the response Configuration debug-mode now actually sends changed configuration Enabling configuration debug-mode also turns on Debug mode flag  This has been tested on Mac with Chrome and Firefox against DIH DB example.","closed","","arafalov","2016-08-03T15:31:47Z","2016-08-10T11:55:43Z"
"","529","LUCENE-8617: Use SimpleFSDirectory on non-default FS","Currently we use MMapDirectory on a non-default file system on Unix. This will almost always fail as only the default file system can provide mmap().  Switch to SimpleFSDirectory instead for non-default file systems independent of the operating system.","closed","","marschall","2018-12-20T15:20:33Z","2020-02-17T11:25:37Z"
"","391","[LUCENE-8343] introduced weight 0 check and positional coefficient scaling","Currently the BlendedInfixSuggester return a (long) score to rank the suggestions. This score is calculated as a multiplication between : long Weight : the suggestion weight, coming from a document field, it can be any long value ( including 1, 0,.. ) double Coefficient : 0<=x<=1, calculated based on the position match, earlier the better The resulting score is a long, which means that at the moment, any weight<10 can bring inconsistencies. Edge cases  Weight =1 Score = 1( if we have a match at the beginning of the suggestion) or 0 ( for any other match) Weight =0 Score = 0 ( independently of the position match coefficient)","closed","","alessandrobenedetti","2018-06-01T11:54:11Z","2018-09-11T17:33:21Z"
"","322","SOLR-11976 - fix bug in TokenizerChain","Currently overwrites tokenfilters rather than chaining.","closed","","tballison","2018-02-12T21:11:54Z","2019-01-19T00:31:48Z"
"","296","SOLR-11804: Test RankQuery in distributed mode","Currently `RankQuery` is not tested in distributed mode. I added a few tests in `TestDistributedSearch` to check that it works properly.","open","","diegoceccarelli","2017-12-29T13:52:39Z","2017-12-29T13:52:39Z"
"","104","SOLR-8593 - WIP","Creating this PR just so I can leave a few comments.  Relates to https://issues.apache.org/jira/browse/SOLR-8593","closed","","risdenk","2016-10-28T06:09:46Z","2019-05-16T07:29:51Z"
"","246","LUCENE-7951: New wrapper classes for Geo3d","Create a pull request for LUCENE-7951","closed","","iverase","2017-09-07T08:10:04Z","2020-02-07T20:15:54Z"
"","57","SOLR-8645: managed-schema is XML type","Cover the special case of no-extension known-name file.  It was already done in the Files view, but missed in the Cloud/Tree one.","closed","","arafalov","2016-07-28T01:46:15Z","2016-07-28T22:07:09Z"
"","632","LUCENE-8752: Add a Kuromoji dictionary entry for Japanese new era 令和(Reiwa)","Corresponding Lucene issue: https://issues.apache.org/jira/browse/LUCENE-8752  As of May 1st, 2019, Japanese era '元号' (Gengo) will be set to '令和' (Reiwa).   Currently '令和' is splitted up to '令' and '和' by `JapaneseTokenizer`. It should be tokenized as one word so that Japanese texts including era names are searched as users expect.  Because the default Kuromoji dictionary (mecab-ipadic) is not maintained since 2007, this applies a patch to the source CSV file before building the dictionary.","closed","","mocobeta","2019-04-03T10:04:59Z","2019-04-13T13:20:51Z"
"","634","Correcting the sentence.","Correcting the sentence.","closed","","khansuhel","2019-04-04T11:06:41Z","2019-04-04T12:19:24Z"
"","216","Upgrade master to 8 for the 7.0 release","Commits for upgrading master to 8. The commits here remove a bunch of back-combat support that is no longer required.","closed","","anshumg","2017-07-03T15:30:20Z","2017-07-03T19:14:25Z"
"","331","SOLR-11722 combine api","combines CREATEROUTEDALIAS with CREATEALIAS including documentation and an additional unit test","closed","","nsoft","2018-03-04T16:58:44Z","2019-01-19T00:31:04Z"
"","196","SOLR-10233: Add support for different replica types","Code is not done yet (although getting close). Opening the PR to make it easier to review.","closed","","tflobbe","2017-04-28T22:59:58Z","2019-05-16T07:27:26Z"
"","399","fix explicit type declaration","Cleaned up explicit type declaration","open","","nvnmandadhi","2018-06-09T01:49:47Z","2018-06-09T18:52:52Z"
"","211","LUCENE-7870: Use cl.loadClass(...) instead of Class.forName(..., cl)","Class.forName(..., cl) causes SPIClassIterator to ""lock in"" the initiating class loader, preventing a thread's context class loader from loading different classes at different points in time.","closed","","sewe","2017-06-08T12:05:52Z","2019-01-18T23:40:47Z"
"","177","Jira/solr 6203","Christine, I created a fork of the repo and updated our branch from master last weekend.  There were conflicts in SearchGroupsResultTransformer.java, which I resolved.  After that I committed the update to DistributedQueryComponentCustomSortTest.java which was the subject of my most recent patch.  I ran 'ant clean compile' and all tests passed.  Judith","closed","","jitka18","2017-03-29T03:13:05Z","2017-04-16T17:38:15Z"
"","332","LUCENE-8186","check for multitermaware tokenizer in CustomAnalyzer's normalize().","closed","","tballison","2018-03-05T19:31:46Z","2018-03-05T19:33:19Z"
"","578","LUCENE-8699: Use fixed byte array in HeapPointWriter","Changes in this PR:  * HeapPointWriter to use a byte array to hold the dimension points. * Common prefix and histogram are computed in the same pass. * Added a method to point writer to write values from a ByteRef that contains point dimensions and document id.  * Move sorting method from BKDWriter to BKDRadixSelector.","closed","","iverase","2019-02-19T08:46:53Z","2019-02-20T13:07:59Z"
"","310","SOLR-11617","Changes as mentioned in Jira comment, plus rather than decide I provided an option for the user to enable whitespace values. By default this is off and whitespace values are treated as null, but if the user really wants to set a value to 3 spaces they can by passing allowWhitespaceValues=true. I'm fairly set against pure whitespace keys unless someone can supply up with a good reason for that.","closed","","fsparv","2018-01-24T04:04:07Z","2019-01-19T00:28:49Z"
"","46","Variables in dataimport config doesn't resolve","Changed the place of resolving variables. Now it is resolving before using variables.  Bug was found by setting password and encryptKeyFile for dataSource by variables.","closed","","sashevsky","2016-06-25T14:12:05Z","2019-01-22T16:56:02Z"
"","582","Change heap array init index to 1","change heap array init index to 1","closed","","hanbj","2019-02-20T15:02:59Z","2019-07-04T19:49:54Z"
"","267","can i provide index number manually with the document","can i provide index number manually with the document in the index writer","closed","","AtulKumVerma","2017-10-26T13:13:15Z","2019-01-22T02:45:11Z"
"","219","TieredMergePolicy.findMerges improvements","Calculate the total size of index from the beginning by excluding too big segments. When finding all the merges take in account that merges also produces segments.  Just something I have found while looking on the code and understanding how default elasticsearch settings applies to lucese merging strategy.  Not sure if that worth the effort of taking in master.  I have not tested it and have not even tried to compile.","closed","","outcoldman","2017-07-13T17:27:48Z","2019-09-20T06:48:28Z"
"","133","LUCENE-9069: Prevent memory leaks in PerFieldAnalyzerWrapper","By overriding the 'close' method. Otherwise nothing will close the defaultAnalyzer as well as all the fieldAnalyzers.","open","","boris-petrov","2016-12-30T12:38:41Z","2019-11-27T08:23:12Z"
"","553","SOLR-9515: Update to Hadoop 3","Builds on existing branch from @markrmiller. Updated to master branch and made sure that HDFS tests are passing. Added comments to a few files on the PR as to why it was changed.","closed","","risdenk","2019-01-29T14:31:49Z","2019-02-02T14:34:46Z"
"","550","SOLR-13148","Building upon Gus' patch. This PR removes all hard coded mentions of TimeRoutedAlias to pave way for the new CategoryRoutedAlias which will be implemented in upcoming tickets.","closed","","moshebla","2019-01-28T00:44:05Z","2019-03-17T07:28:51Z"
"","389","[LUCENE-6687] not necessary nested for loop removed for terms retriev…","Bug in term frequencies calculation for the MLT","closed","","alessandrobenedetti","2018-05-31T15:40:46Z","2019-06-14T12:38:00Z"
"","119","SOLR-4735 Improve Solr metrics","Branch created from the patch in Jira by Kelvin Wong.  Changes include: * using shared instances of `MetricRegistry` per core. * unit test modifications.","closed","","sigram","2016-11-24T15:38:01Z","2016-11-29T13:53:01Z"
"","98","SOLR-9644: Fix boost handling in SimpleMLTQParser and CloudMLTQParser.","Both parsers tried to handle field boosts but didn't do it properly. This pull request includes the following changes to both: - Parse boosts from qf even if boost=false to avoid errors. - Use the field names from the boost parsing so that they are always clean. - Add tests for the same query with and without boosting.  Also fixed is an additional problem in CloudMLTQParser where it added IndexableField type fields to the filtered document as is, which caused the document to include field definition strings such as ""stored"" and ""indexed"". This caused the MLT query to return records including these terms under some circumstances.","closed","","EreMaijala","2016-10-17T07:39:59Z","2017-01-04T11:21:54Z"
"","56","SOLR-8596: Split only on first equal sign","Being more careful about splitting only on first equal sign, not all of them for raw requests. This avoids breaking local parameters syntax.","closed","","arafalov","2016-07-27T00:13:22Z","2016-07-28T14:23:30Z"
"","613","LUCENE-8671: Expose FST off/on-heap options on Lucene50PostingsFormat","Before we can expose options to configure this postings format on a per-reader basis we need to expose the option to load the terms index FST off or on heap on the postings format. This already allows to change the default in a per-field posting format if an expert user wants to change the defaults. This essentially provides the ability to change defaults globally while still involving some glue code.","closed","","s1monw","2019-03-20T14:13:42Z","2019-04-04T14:59:38Z"
"","592","fix the spacing in ngtimeago","basic change for cosmetics","closed","","MarcusSorealheis","2019-02-27T03:07:30Z","2019-04-27T14:40:15Z"
"","113","SOLR-9760 Avoid temporary files to determine java version","Avoid creating a temporary file so that solr does not require permissions in the current working directory.","closed","","afscrome","2016-11-14T19:37:51Z","2017-09-30T19:41:17Z"
"","242","a little error about TopDocs","as the comment says :""Returns true if first is < second"", but the fact is opposited","closed","","kkewwei","2017-09-03T16:57:42Z","2019-09-19T05:42:04Z"
"","270","[SOLR-11597] Implement RankNet.","As described in [this tutorial](https://github.com/airalcorn2/Solr-LTR) ([Jira](https://issues.apache.org/jira/browse/SOLR-11597)).","closed","","airalcorn2","2017-11-02T18:22:50Z","2018-03-02T20:03:13Z"
"","198","[SOLR-10550] Improve FileFloatSource eviction // reduce FileFloatSource memory footprint","As a follow up from `SOLR-10506` we found another possible memory leak in Solr. The values generated from an `ExternalFileField` are cached in a static cache inside the `FileFloatSource`. That cache caches both a `IndexReader` and `FileFloatSource`s loaded using that `IndexReader`. Cache eviction is left to the internally used WeakHashMap or a full eviction can be triggered via url. We are dealing with large synonym files and word lists stored in managed resources. Those are tied to the SolrCore as described in `SOLR-10506`. We're also using `ExternalFileField`s whose `FileFloatSource` are cached in said static cache. The FileFloatSource hold strong (transitive) references to the SolrCore they have been created for.  After a couple of collection reloads, the cache eviction mechanism of the `WeakHashMap` gets activated pretty close to heap exhaustion. The patch attached adds a mechanism to evict cache entries created in the context of a `SolrCore` upon it's close using a close hook in the `ExternalFileFieldReloader`. It furthermore adds a static cache reset method for all entries bound to a given IndexReader. I'm not sure, if the added cache resets are too aggressive or executed too often, I'd like to leave that to the experts.  N.B.: I did this second PR for the same issue to separate code changes for both SOLR-10506 and SOLR-10550 which I maintained on the same fork branch :-/","open","","tboeghk","2017-05-04T11:30:03Z","2017-05-04T11:30:03Z"
"","510","LUCENE-8573: Use FutureArrays#mismatch in BKDWriter","As [LUCENE-8573](https://issues.apache.org/jira/browse/LUCENE-8573) describes, BKDWriter uses loops in many places to find the first mismatching byte between multiple arrays. This change replaces that with FutureArrays#mismatch.","closed","","cbuescher","2018-11-27T21:53:50Z","2018-11-28T10:02:25Z"
"","533","LUCENE-8636: TestPointQueries and long execution times","Applied Adrien's feedback.","closed","","dweiss","2019-01-14T14:26:01Z","2020-02-15T17:49:33Z"
"","325","SOLR-7798 ExpandComponent support for non-collapsed results","Applications of ExpandComponent that do not involve prior collapsing of results on the expand field had been throwing NPE in `getGroupQuery` due to different count/size tracking.","closed","","magibney","2018-02-22T18:03:39Z","2019-12-08T04:29:34Z"
"","6","[SOLR-8612] DIH JdbcDataSource: Always close ResultSet and Statement","and also some more minor changes for better extensibility (https://issues.apache.org/jira/browse/SOLR-8618)","closed","","tinexw","2016-02-05T22:52:33Z","2016-07-14T12:43:05Z"
"","107","SOLR-9708 UnifiedHighlighter Solr Plugin","An initial implementation of a solr plugin for the unified highlighter.","closed","","Timothy055","2016-10-31T21:14:06Z","2019-01-18T22:28:41Z"
"","577","SOLR-13260: Up to 128 bit integer point type - ByteString","An initial implementation of 128 bit integer point filed type. Would benefit from somebody with a bit more experience with the code base having a look at it to make sure everything is ok.  I've called the file type ""longlong"", as the C standard definition of longlong is ""at least 64 bits"".   Some issues to consider: Input/output: Text based formats (CSV,JSON,XML) are supported Sorting - missing value support not implemented Faceting and Functions not implemented  - is facet functionality even valid without numeric fields? Transaction log support not implemented - JavaBinCodec currently not supported - Is this required for replication to work?","open","","tigerquoll","2019-02-17T10:28:59Z","2020-08-18T01:15:35Z"
"","34","Move hdfs stuff out into a new contrib","An attempt to move hdfs/Hadoop related classes out of core SOLR into a new contrib, and reduce the size of SOLR core by thus removing some of the Hadoop JARs. Notes, in no particular order: - tests that are sub-classed to create new hdfs tests are turned into BaseTest classes in test-framework, and a test sub-class added in core/test and hdfs/test - dependencies on hadoop-auth and hadoop-minikdc not moved in contrib (these JARs are small anyway) - a couple of uses of org.apache.hadoop.fs.Path in core replaced by String manipulations - should blockcache package be moved in its entirety or is this not only used by hdfs? - to get an HdfsUpdateLog you now need to specify this class in solrconfig.xml in the UpdateLog config, instead of this happening automatically by having an hdfs:/ prefix to the data directory. This means for the hdfs tests, which reuse the test-files from core, we use a system property to force the behaviour. Is there a better way? - could move BadHdfsThreadsFilter into hdfs contrib but then would have to make morphines depend on hdfs for this one class, in any case, BadHdfsThreadsFilter does not depend on any Hadoop classes - map-reduce contrib now depends on hdfs contrib","closed","","tomjon","2016-04-28T15:34:33Z","2019-03-19T10:01:50Z"
"","151","LUCENE-7671 - Enhance UpgradeIndexMergePolicy with additional options","Also updates Backwards compatibility tests","open","","kelaban","2017-01-31T17:27:37Z","2017-04-07T18:08:55Z"
"","473","SOLR-12878 - Use the cached SolrIndexSearch.fieldInfos instead of recreating one each time FacetFieldProcessorByHashDV is constructed","Also this updates one of the collect methods to use the `advanceExact` method to match the other collect methods.","closed","","tpunder","2018-10-17T15:36:17Z","2019-01-18T23:41:39Z"
"","149","Cleanup snapshot metadata during collection deletion","Also fixed small issues in the SolrSnapshotsTool","closed","","hgadre","2017-01-30T18:44:06Z","2017-01-31T18:23:51Z"
"","217","added initial .travis.yml","Already reveals [build failure of Maven project](https://travis-ci.org/krichter722/lucene-solr/builds/251276455), so it seems useful to use Travis CI.","closed","","krichter722","2017-07-07T19:21:53Z","2019-11-27T08:02:41Z"
"","126","SOLR-9876 Reuse CountSlotArrAcc internal array for same level subFacets","All facet processors are processed sequentially. We can reuse CountSlotArrAcc internal array across same level facet processors instead of reallocating new array for each.","closed","","rustamhsmv","2016-12-17T21:56:19Z","2020-11-17T23:46:58Z"
"","349","LUCENE-7960 EdgeNGramTokenFilter & NGramTokenFilter: Add ability to keep original tokens.","Adds the following properties to EdgeNGramTokenFilter & NGramTokenFilter: - keepShortTerm: Don't drop input tokens smaller than minGramSize. - keepLongTerm: Don't drop input tokens longer than maxGramSize.","closed","","iwesp","2018-03-31T20:36:58Z","2018-04-25T20:01:19Z"
"","362","LUCENE-7960 N-Gram filters: Add options to keep original terms.","Adds the following properties to EdgeNGramTokenFilter & NGramTokenFilter: - keepShortTerm: Don't drop input terms smaller than minGramSize. - keepLongTerm: Don't drop input terms longer than maxGramSize.","closed","","iwesp","2018-04-25T20:03:57Z","2018-06-11T15:51:26Z"
"","49","SOLR-9279 Adds comparison function queries","Adds the following function queries - gt(lhs,rhs)   (return 1 if lhs > rhs, 0 otherwise) - lt(lhs,rhs)      (return 1 if lhs < rhs, 0 otherwise) - gte(lhs,rhs)     (return 1 if lhs >= rhs, 0 otherwise) - lte(lhs,rhs)    (return 1 if lhs <= rhs, 0 otherwise) - eq(lhs,rhs)    (return 1 if lhs == rhs, 0 otherwise)  Primarilly for use in if statements, ie  ``` boost=if(gt(age_i,30),1,0.8) ```","closed","","softwaredoug","2016-07-06T00:57:47Z","2016-07-29T14:27:54Z"
"","165","LUCENE-7615 of 8 March 2017.","Adds support for SpanSynonymQuery in xml queryparser.","closed","","ghost","2017-03-08T22:16:07Z","2019-06-14T11:38:04Z"
"","130","LUCENE-7603: branch_6x Support Graph Token Streams in QueryBuilder","Adds support for handling graph token streams inside the QueryBuilder util class used by query parsers.  This is a backport to `branch_6x`.","closed","","mattweber","2016-12-28T18:35:46Z","2017-02-17T09:53:52Z"
"","129","LUCENE-7603: Support Graph Token Streams in QueryBuilder","Adds support for handling graph token streams inside the QueryBuilder util class used by query parsers.","closed","","mattweber","2016-12-26T17:09:29Z","2017-01-03T14:02:30Z"
"","158","SOLR-10134 - Support SchemaAPI in EmbeddedSolrServer","Adds support for changing the schema in mutable mode and using EmbeddedSolrServer","closed","","alero","2017-02-17T09:04:59Z","2019-01-18T23:19:27Z"
"","657","LUCENE-8781: FST direct arc addressing","Adds direct-array arc addressing mode to FSTs, enabled via new Builder constructor arg. The new encoding is used when there is a large number of outgoing Arcs that are reasonably dense in the space of labels.","closed","","msokolov","2019-04-27T18:55:16Z","2019-05-06T09:21:01Z"
"","95","SOLR-9481: Authentication and Authorization plugins support for non-cloud","Adds ability to use Auth/Autz plugins in standalone non-cloud mode. - Place `security.json` in $SOLR_HOME - Solr will initialise plugins from local file - Edits through API `/solr/admin/authentication` and `/solr/admin/authorization`supported   - Each edit will update local copy of `security.json` and reload security config   - If you have several nodes in master/slave setup, need to perform the edit on each node - Refactored `SecurityConfHandler`into a base class independent of ZK. Each sub class overrides methods `getSecurityConfig`, `getConf`, `persistConf` and `securityConfEdited`:   - `SecurityConfHandlerZk` is instantiated if zkAware   - `SecurityConfHandlerLocal` is instantiated if in local mode, reads/writes local file in SOLR_HOME   - In local mode there is no callback when `security.json` changes, so `SecurityConfHandlerLocal` explicitly reloads security configs in its `securityConfEdited()` method   - `MockSecurityHandler` used in tests persists to in-memory Map - New object `SecurityConfig` to hold security config, since `ZkStateReader.ConfigData` is tied to ZK. - New test case `BasicAuthStandaloneTest` spins up Jetty, writes local `security.json` through the persistConf API, adds a user through edit API, validates that permission is enforced and that local file contains user name.","closed","","janhoy","2016-10-13T09:01:51Z","2017-07-06T14:53:03Z"
"","32","SOLR-8323","Adds a CollectionStateWatcher API to listen for changes to collection state (SOLR-8323)","closed","","romseygeek","2016-04-20T17:52:24Z","2016-05-13T20:52:44Z"
"","467","SOLR-12853 Add ability to set CreateNodeList.shuffle parameter in Create admin requests","Addition of a simple getter and setter for a missing parameter in CollectionAdminRequest.Create","open","","benedictb","2018-10-11T15:56:38Z","2018-10-11T15:56:38Z"
"","466","SOLR-12853 Add ability to set CreateNodeList.shuffle parameter in Create collection requests","Addition of a simple getter and setter for a missing parameter in CollectionAdminRequest.Create","closed","","benedictb","2018-10-11T15:45:16Z","2018-10-11T15:58:42Z"
"","552","LUCENE-8664: Add equals/hashcode methods to TotalHits class","Adding equals/hashcode to TotalHits is convenient for quick comparisons, especially for users that may use it as part of bigger objects that have their own equals/hashcode.   Fixes https://issues.apache.org/jira/browse/LUCENE-8664","closed","","javanna","2019-01-29T11:43:27Z","2019-01-30T12:11:29Z"
"","171","SOLR-10303","Adding date/time Stream Evaluators for year, month, day, dayOfYear, dayOfQuarter, hour, minute, quarter, week, second, epoch.","closed","","covolution","2017-03-20T16:36:35Z","2017-04-18T15:48:30Z"
"","555","Update language-analysis.adoc","Adding Bengali language section","closed","","MysterionRise","2019-01-30T10:28:50Z","2019-02-08T06:11:19Z"
"","93","SOLR-8754: Adding test cases and additional error checking","Added test cases for log2, fromHex, and toHex. Also added additional error checking to fromHex and toHex functions.","closed","","justenpinto","2016-10-10T03:46:44Z","2019-11-26T20:40:09Z"
"","91","SOLR-9526: Next iteration on data driven schema, _str copyField","Added support for a default typeMapping.","closed","","janhoy","2016-10-07T14:02:29Z","2018-08-15T11:41:25Z"
"","16","SOLR-8721 Added solr & lucene version to the response for debug reasons","Added solr & lucene version to the response of the query handlers for debug purpsoses.","open","","mariusneo","2016-02-27T15:25:49Z","2016-03-01T06:50:21Z"
"","148","SOLR-9483 Add SolrJ support for the modify collection API","Added Modify class and a method modifyCollection as per the suggestion.  Please review.","open","","susheelks","2017-01-30T04:08:10Z","2017-02-19T00:02:05Z"
"","72","SOLR-9319 - DELETEREPLICA should be able to accept just count and remove replicas intelligently","Added functionality and one test in async mode and other in sync mode","closed","","nitingithub","2016-08-25T22:04:52Z","2019-01-18T22:08:07Z"
"","426","SOLR-12595: CloudSolrClient.Builder accepts ZK connection strings","Added additional constructor to `CloudSolrClient.Builder` which accepts ZooKeeper connection strings.","closed","","vpranckaitis","2018-07-28T04:48:25Z","2020-10-21T15:39:22Z"
"","160","SOLR-10190 - Potential NPE in CloudSolrClient when reading stale alias","Added a test case and potential solution to guard against NPE, see JIRA issue https://issues.apache.org/jira/browse/SOLR-10190","closed","","jwoschitz","2017-02-22T15:28:28Z","2017-02-25T01:35:12Z"
"","347","SOLR-9685 tag a query in JSON syntax","Add support of tagging queries in JSON QUERY DSL  Support following structure: {""tagged"": {""name"": ""RCOLOR"",""query"": { ""term"": { ""f"": ""color"",""v"": ""blue""}}}}  This can be used in json.facet=""{colors: { ype:terms, field:color, domain:{ excludeTags: RCOLOR} } }""","closed","","squallsama","2018-03-29T18:00:46Z","2018-05-05T11:52:12Z"
"","193","SOLR-10529: Solr UI Health Check enable/disable ping Button doesn't work","add enable/disable request in Ping service. add core parameter in toggleHealthcheck method. add ng-click action to toggleHealthcheck method.","closed","","youngj523","2017-04-20T09:06:11Z","2021-11-07T23:29:27Z"
"","22","Update files.js","Add content type mapping for xsl -> text/xml","closed","","c-uhland","2016-03-17T09:13:20Z","2019-11-27T08:35:55Z"
"","83","[LUCENE-7466] add axiomatic similarity","Add axiomatic similarity approaches to the similarity family. More details can be found at http://dl.acm.org/citation.cfm?id=1076116 and https://www.eecis.udel.edu/~hfang/pubs/sigir05-axiom.pdf There are in total six similarity models. All of them are based on BM25, Pivoted Document Length Normalization or Language Model with Dirichlet prior.  We think it is worthy to add the models as part of Lucene.","closed","","Peilin-Yang","2016-09-24T18:14:21Z","2019-01-18T22:16:00Z"
"","17","SOLR-7516 add asserts and Improve Javadoc comments (patch from gerlow…","add asserts and Improve Javadoc comments (patch from gerlowskija)","closed","","bvanalderweireldt","2016-02-29T00:12:54Z","2016-03-03T12:37:12Z"
"","388","Update package-info.java","add a missing parenthesis","closed","","yhcharles","2018-05-30T22:15:31Z","2019-06-14T12:54:58Z"
"","378","SOLR-9769 solr stop on a stopped service should be success","According to the LSB specification: In addition to straightforward success, the following situations are also to be considered successful:  - running stop on a service already stopped or not running","open","","jiri-pejchal","2018-05-17T08:45:24Z","2019-04-25T00:17:34Z"
"","199","pass cached query to onQueryCache instead of null","According to the javadocs, LRUQueryCache.onQueryCache can be used to track usage statistics on cached queries. Unfortunately, due to a bug, the query parameter is always passed as null. This PR fixes the problem.","closed","","ChristophKaser","2017-05-05T11:24:21Z","2017-05-11T14:01:13Z"
"","516","LUCENE-8594: DV update are broken for updates on new field","A segmemnt written with Lucene70Codec failes if it ties to update a DV field that didn't exist in the index before it was upgraded to Lucene80Codec. We bake the DV format into the FieldInfo when it's used the first time and therefor never go to the codec if we need to update. yet on a field that didn't exist before and was added during an indexing operation we have to consult the coded and get an exception. This change fixes this issue and adds the relevant bwc tests.","closed","","s1monw","2018-12-06T10:36:13Z","2018-12-06T19:18:17Z"
"","615","Intervals Query Parser","A query parser that converts syntax to an intervals query. This is a completely stand-alone query parser with the sole use of building an query of intervals. One class IntervalsQueryParser One public method getQuery that passes in field name and query and returns an IntervalsQuery One test class TestIntervalsQueryParser  Examples  a b or(a,b)  a b c or(a,b,c)  (a b c) or(a,b,c)  a /5 b MAXWIDTH/5(UNORDERED(a,b))  (a /5 b) c or(MAXWIDTH/5(UNORDERED(a,b)),c)  ""a b"" BLOCK(a,b)  ""a b v"" BLOCK(a,b,v)  ((((a /3 ""b f g"") /3 c) /3 d) /3 e) MAXWIDTH/3(UNORDERED(MAXWIDTH/3(UNORDERED(MAXWIDTH/3(UNORDERED(MAXWIDTH/3(UNORDERED(a,BLOCK(b,f,g))),c)),d)),e))  (a /3 (b /3 (c /3 (d /3 e)))) MAXWIDTH/3(UNORDERED(a,MAXWIDTH/3(UNORDERED(b,MAXWIDTH/3(UNORDERED(c,MAXWIDTH/3(UNORDERED(d,e))))))))  (can could) /12 ""figur*"" MAXWIDTH/12(UNORDERED(or(can,could),MultiTerm(figur*)))  (search*) /75 (could* /10 ""lat* night"") MAXWIDTH/75(UNORDERED(MultiTerm(search*),MAXWIDTH/10(UNORDERED(MultiTerm(could*),BLOCK(MultiTerm(lat*),night)))))  ""can* expect*"" BLOCK(MultiTerm(can*),MultiTerm(expect*))  ""(can might) expect*"" BLOCK(or(can,might),MultiTerm(expect*))  ""(red green blue)(cluster* node* shard*)"" BLOCK(or(red,green,blue),or(MultiTerm(cluster*),MultiTerm(node*),MultiTerm(shard*)))","open","missing Jira,","jmorph99","2019-03-20T18:15:10Z","2020-12-23T19:57:30Z"
"","604","Intervals Query Parser","A query parser that converts syntax to an intervals query.  This is a completely stand-alone query parser with the sole use of building an query of intervals. One class IntervalsQueryParser One public method getQuery that passes in field name and query and returns an IntervalsQuery One test class TestIntervalsQueryParser  Examples    a b or(a,b)  a b c or(a,b,c)  (a b c) or(a,b,c)  a /5 b MAXWIDTH/5(UNORDERED(a,b))  (a /5 b) c or(MAXWIDTH/5(UNORDERED(a,b)),c)  ""a b"" BLOCK(a,b)  ""a b v"" BLOCK(a,b,v)  ((((a /3 ""b f g"") /3 c) /3 d) /3 e) MAXWIDTH/3(UNORDERED(MAXWIDTH/3(UNORDERED(MAXWIDTH/3(UNORDERED(MAXWIDTH/3(UNORDERED(a,BLOCK(b,f,g))),c)),d)),e))  (a /3 (b /3 (c /3 (d /3 e)))) MAXWIDTH/3(UNORDERED(a,MAXWIDTH/3(UNORDERED(b,MAXWIDTH/3(UNORDERED(c,MAXWIDTH/3(UNORDERED(d,e))))))))  (can could) /12 ""figur*"" MAXWIDTH/12(UNORDERED(or(can,could),MultiTerm(figur*)))  (search*) /75 (could* /10 ""lat* night"") MAXWIDTH/75(UNORDERED(MultiTerm(search*),MAXWIDTH/10(UNORDERED(MultiTerm(could*),BLOCK(MultiTerm(lat*),night)))))  ""can* expect*"" BLOCK(MultiTerm(can*),MultiTerm(expect*))  ""(can might) expect*"" BLOCK(or(can,might),MultiTerm(expect*))  ""(red green blue)(cluster* node* shard*)"" BLOCK(or(red,green,blue),or(MultiTerm(cluster*),MultiTerm(node*),MultiTerm(shard*)))","closed","","jmorph99","2019-03-11T13:42:12Z","2019-03-20T18:13:40Z"
"","181","Mt cft 5.5.4","A preview so DerekR can look at my travis config","closed","","shabino","2017-04-06T18:42:50Z","2017-04-06T18:44:29Z"
"","117","SOLR-9324: Support Secure Impersonation / Proxy User for solr authentication","A patch against branch_6x. It also includes unit test fixes applied on the master branch...","closed","","hgadre","2016-11-16T01:14:44Z","2016-12-02T00:47:12Z"
"","370","SOLR-12312: Change buf to not always use up 1 MB","A lot of replicated files aren't 1 MB in size, this causes a lot of heap space waste when we create this for every file, instead create buffer based on the file size with a max of 1 MB","closed","","millerjeff0","2018-05-04T19:03:12Z","2018-05-07T20:09:20Z"
"","268","Fix some spell check issues","A few spell check issues in Javadoc and one in the HTML guide.  Bruno","closed","","kinow","2017-10-30T10:59:52Z","2019-02-13T05:35:31Z"
"","231","WordDelimiterGraphFilter: Better support for camel case splitting.","`WordDelimiterGraphFilter` currently only looks at pairs of characters, with this patch (if enabled) it will split when an upper case character is followed by another upper case character and then there's a lower case character.  Like this in HTTPRequest: 'P'  'R' 'e'  It will also break the word when a lower case character is followed by a number.  With this flag these splits happen:  - HTTPRequest ⭢ HTTP Request - 3DPlot ⭢ 3D Plot - Plot3D ⭢ Plot 3D  I've created a Jira issue: https://issues.apache.org/jira/browse/LUCENE-7929","open","","niqueco","2017-08-11T20:04:12Z","2019-03-29T14:58:49Z"
"","602","docu change: use class TopDocs instead of Hits","`Hits` was removed in Lucene 3.0","open","","saschaszott","2019-03-08T22:14:17Z","2019-12-02T22:12:11Z"
"","41","SOLR-9191: OverseerTaskQueue.peekTopN() fatally flawed","@noblepaul  CC: @shalinmangar","closed","","dragonsinth","2016-06-07T21:03:41Z","2016-06-09T05:00:43Z"
"","42","SOLR-8744 blockedTasks","@noblepaul","closed","","dragonsinth","2016-06-09T22:13:12Z","2016-06-13T19:36:41Z"
"","660","SOLR-13047: Add facet2D Streaming Expression","@joel-bernstein, there are since only 2 levels, we don't call appendJson(...) function recursively. Also, in the fillTuples(..) I looped first the ""x"" bucket then ""y"" bucket and added to the tuple list which has a type of Tuple, but not sure.","closed","","NazerkeBS","2019-04-29T15:55:39Z","2019-06-13T14:52:34Z"
"","659","SOLR-13047: Add facet2D Streaming Expression","@joel-bernstein, there are since only 2 levels, we don't call appendJson(...) function recursively. Also, in the fillTuples(..) I looped first the ""x"" bucket then ""y"" bucket and added to the tuple list which has a type of Tuple,  but not sure.","closed","","NazerkeBS","2019-04-29T15:41:13Z","2019-04-29T15:47:48Z"
"","643","SOLR-13391: Add variance and standard deviation stream evaluators","@joel-bernstein, please have a look to the code.","closed","","NazerkeBS","2019-04-11T12:19:32Z","2019-10-16T00:41:38Z"
"","315","Remove debug comment on top of doc file","@ctargett Think this line should not have been in the docs :-)   https://lucene.apache.org/solr/guide/7_2/stream-source-reference.html","closed","","janhoy","2018-01-30T14:53:07Z","2018-01-30T15:46:54Z"
"","122","Support spanQueries in CoreParser and SolrCoreParser","@cpoerschke for consideration, I think this works. I've kept HelloQueryBuilder and GoodbyeQueryBuilder as the ""old"" style, but HandyQueryBuilder has been updated to use the new API.  The tests pass, but in reality, we never call getSpanQuery() yet, maybe I could change HandyQueryBuilder, so it always returns a SpanQuery and never a normal one...","closed","","dcollins53","2016-12-01T12:42:15Z","2016-12-01T12:42:30Z"
"","442","Fixing an edge case bug when overriding a default PostingsSolrHighligher","* SOLR-####:   LUCENE and SOLR must be fully capitalized. A short description helps people scanning pull requests for items they can work on.  Properly referencing the issue in the title ensures that Jira is correctly updated with code review comments and commits. -->   # Description  Encountered this edge case issue. The impact of this should be limited but in our case (using a default PostingsSolrHighlighter) this was causing a weird issue.  The issue here is that, when passing the parameter hl.method=unified, we enter this switch, and end up in the UNIFIED case. But then we check whether the preconfigured highlighter is an instance of UnifiedSolrHighlighter.  If the preconfigured highlighter is a PostingsSolrHighlighter, which is implemented for depracation reasons as a UnifiedSolrHighlighter, then that highlighter is used instead of a unified one (and effectively the hl.method parameter is ignored).  In our case, the additional parameters that the PostingsSolrHighlighter brings with it (specifically, setting the ellipsis parameter) were causing an issue with highlighting down the line.  # Solution  The fix is a very simple check for whether the class of the preconfigured highlighter is the exact one we want to override with (and since we want this class to be open for subclassing, the same pattern should be used for any other such case to avoid things like that happening).  # Tests  Please describe the tests you've developed or run to confirm this patch implements the feature or solves the problem.  # Checklist  Please review the following and check all that apply:  - [ ] I have reviewed the guidelines for [How to Contribute](https://wiki.apache.org/solr/HowToContribute) and my code conforms to the standards described there to the best of my ability. - [ ] I have created a Jira issue and added the issue ID to my pull request title. - [ ] I am authorized to contribute this code to the ASF and have removed any code I do not have a license to distribute. - [ ] I have given Solr maintainers [access](https://help.github.com/en/articles/allowing-changes-to-a-pull-request-branch-created-from-a-fork) to contribute to my PR branch. (optional but recommended) - [ ] I have developed this patch against the `master` branch. - [ ] I have run `ant precommit` and the appropriate test suite. - [ ] I have added tests for my changes. - [ ] I have added documentation for the [Ref Guide](https://github.com/apache/lucene-solr/tree/master/solr/solr-ref-guide) (for Solr changes only).","open","","Apmats","2018-08-29T10:07:53Z","2019-11-27T14:17:19Z"
"","341","SOLR-12131: ExternalRoleRuleBasedAuthorizationPlugin","...which gets user's roles from request  https://issues.apache.org/jira/browse/SOLR-12131","closed","","janhoy","2018-03-20T23:28:31Z","2020-05-13T21:29:56Z"
"","235","Small correction where windows path specified instead of linux","...For first zookeeper configuration, in the same doc page, path specified is linux and suddently for second and third configuration it seems somwhow changed to windows path which creates confusion. So changed these windows path to linux path as given in first configuration.","closed","","pavan-shetty","2017-08-17T12:27:05Z","2017-08-17T14:52:04Z"
"","102","SOLR-8332: factor HttpShardHandler[Factory]'s url shuffling out ...","... into a ReplicaListTransformer class  (switching from patch attachment to pull request for clarity and convenience)","closed","","cpoerschke","2016-10-25T15:29:11Z","2016-11-14T16:15:56Z"
"","586","SOLR-13268: SOLR-12055 log4j2 async test fixes","- Upgrade log4j2 from 2.11.0 to 2.11.2 - Upgrade lmax from 3.4.0 to 3.4.2 - Add log4j-web dependency based on LOG4J2-1259 and https://logging.apache.org/log4j/2.0/manual/webapp.html","closed","","risdenk","2019-02-23T14:58:44Z","2019-02-26T19:54:44Z"
"","74","[SOLR-9444] Fix path usage for cloud backup/restore","- Refactored code using URI.getPath() API to use URI instance   uniformly. - During serialization of URI instance, used toASCIIString() API   to generate the appropriate String representation.","closed","","hgadre","2016-08-29T03:56:11Z","2016-09-02T12:16:16Z"
"","52","[SOLR-9269] Ability to create/delete/list snapshots for a solr core","- Introduced admin operations to create/delete/list snapshots   at the Solr core level - Introduced Snapshot management functionality utilizing Lucene   IndexDeletionPolicy. The management of data files in the _current_   index directory is deleted to Solr IndexDeletionPolicy. - As part of restore operation (or full replication), Solr changes the   index directory. Since snapshots can be present in the old directory   (before the operation), introduced logic to preserve those index files.   When the snapshot is deleted, this logic deletes those files if they   are not referred by some other snapshot. - Unit tests to verify new functionlity.","closed","","hgadre","2016-07-20T22:59:06Z","2016-07-28T21:02:03Z"
"","67","[SOLR-9055] Make collection backup/restore extensible","- Introduced a parameter for the Backup operation to specify index backup strategy.   - Introduced two strategies for backing up index data.     - One using core Admin API (BACKUPCORE)     - Other skipping the backup of index data altogether. This is useful when       the index data is copied via an external mechanism in combination with named       snapshots (Please refer to SOLR-9038 for details)     - In future we can add additional implementations of this interface (e.g. based on HDFS snapshots etc.)   - Added a backup property to record the Solr version. This helps to check the compatibility     of backup with respect to the current version during the restore operation. This     compatibility check is not added since its unclear what the Solr level compatibility guidelines     are. But at-least having version information as part of the backup would be very useful.","closed","","hgadre","2016-08-10T22:07:04Z","2019-01-18T22:04:09Z"
"","221","SOLR-11086 Fix grouping by TrieDateField and DatePointFiled","- Fix converting MutableValueDate to the format that FieldType.indexedToReadable will handle - this is a quick fix - the proper fix requires changes in group collecting mechanism  https://issues.apache.org/jira/browse/SOLR-11086","closed","","lavrov","2017-07-14T14:58:43Z","2019-10-20T10:39:52Z"
"","666","SOLR-13437: fork noggit code into Solr","- direct use of noggit is a forbidden API now - I can't remove the dependency because spatial4j uses it","closed","","noblepaul","2019-05-08T05:00:24Z","2019-05-16T01:10:28Z"
"","269","Added parameter sections for analytics facets.","- Added parameter sections for all of the facet types - Fixed the example analytics expression, since there was a mistake in one of the lines. - Changed the Strings section in Analytics-expression-sources.adoc to use and unordered list instead of an ordered list. - Changed the Titles of the mismatched pages to reflect their shortnames. (So I removed the 'Reference' at the end of each)","closed","","HoustonPutman","2017-10-30T21:44:05Z","2017-11-02T19:33:11Z"
"","114","SOLR-9513 A generic Solr authentication plugin to integrate with Hadoop","- Added a generic Solr authentication plugin to integrate with Hadoop - Added delegation tokens support - Added proxy users support  Currently the unit tests are using kerberos authentication handler in Hadoop. After Solr is updated to use Hadoop 3, these tests will be modified to use multi-auth support in Hadoop.","closed","","hgadre","2016-11-15T01:17:05Z","2016-12-19T17:16:19Z"
"","460","LUCENE-8497: refactor multi-term analysis handling","- Add `normalize` method to CharFilterFactory and TokenFilterFactory  The goal is to get rid of MultiTermAwareComponent interface, and instead use `normalize` method.  But as solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader.java depends on MultiTermAwareComponent interface, this patch still keeps it.","closed","","mayya-sharipova","2018-09-30T21:47:43Z","2018-11-19T16:50:25Z"
"","628","SOLR-11473: Make HDFSDirectoryFactory support other prefixes (besides hdfs:/)","* Uses Hadoop `Path` for `isAbsolute` check. * Adds test to ensure `isAbsolute` works correctly with non `hdfs://` prefixes. * Ensures that the Path scheme is set to disable the cache when getting from the filesystem.","closed","","risdenk","2019-03-29T21:58:07Z","2019-03-30T18:32:21Z"
"","617","SOLR-13342: Remove dom4j fromj Solr","* Removes dom4j from core dependencies * Adds to it velocity contrib * Replaces dom4j in test with Java xml handling * Updates licenses/notices that had referenced dom4j historically to their new versions.","closed","","risdenk","2019-03-22T21:20:32Z","2019-03-25T12:43:39Z"
"","174","Move Ukrainian dictionary to external dependency","* removes binary blob from lucene repository * uses newer and bigger dictionary * allows easy dictionary update with a version bump  I think it would make sense to push this into stable branches as well.","closed","","arysin","2017-03-26T01:57:34Z","2017-03-29T02:50:03Z"
"","612","SOLR-13335: Upgrade to velocity 2.0 and velocity-tools 3.0","* `SolrVelocityLogger` removed since logging with slf4j now * `contrib/velocity` no longer depends on `commons-collections` and `commons-lang`","closed","","risdenk","2019-03-19T20:19:04Z","2019-03-25T14:18:42Z"
"","461","SOLR-12814: Metrics history causing ""HttpParser URI is too large""",">8192 when many collections.  The fix was to change from `GET` to `POST`","closed","","janhoy","2018-10-02T20:38:39Z","2018-10-04T16:44:03Z"
"","495","LUCENE-8464: Implement ConstantScoreScorer#setMinCompetitiveScore","> We should make it so the iterator returns `NO_MORE_DOCS` after `setMinCompetitiveScore` is called with a value that is greater than the constant score.  See [LUCENE-8464](https://issues.apache.org/jira/browse/LUCENE-8464).","closed","","cbismuth","2018-11-08T16:45:09Z","2019-04-03T21:12:55Z"
"","497","LUCENE-8026: ExitableDirectoryReader does not instrument points","> This means it cannot interrupt range or geo queries.  See [LUCENE-8026](https://issues.apache.org/jira/browse/LUCENE-8026).","closed","","cbismuth","2018-11-12T12:55:27Z","2019-04-03T21:12:59Z"
"","499","LUCENE-8552: Optimize getMergedFieldInfos for one-segment FieldInfos","> FieldInfos.getMergedFieldInfos could trivially return the FieldInfos of the first and only LeafReader if there is only one LeafReader.  See [LUCENE-8552](https://issues.apache.org/jira/browse/LUCENE-8552).","closed","","cbismuth","2018-11-15T09:20:06Z","2019-04-03T21:12:58Z"
"","496","LUCENE-8463: Early-terminate queries sorted by SortField.DOC","> Currently TopFieldCollector only early-terminates when the search sort is a prefix of the index sort, but it could also early-terminate when sorting by doc id.  See [LUCENE-8463](https://issues.apache.org/jira/browse/LUCENE-8463).","closed","","cbismuth","2018-11-12T11:06:05Z","2019-04-03T21:13:00Z"
"","364","Branch 6x  . clzz.cast(object),Lost part of the data in a field of object。","### Env:  - solr-6.5.1 - jdk 1.8  ### Question :  - I got the query result from the solr server and tried to assign it to my java bean. After debugging, I found the problem code：```clzz cast(object)```,the object invoked a class named ""Article"",and has a member variables named “content”，it should got about 2000 bytes but only got about 500 bytes. - Is a bug with solr, or  where am I doing wrong? ，Please help me,thanks. ### Code: ``` java System.out.println(object); // debug in here，successfully got solr's return data,everything is fine. list.add(clzz.cast(object));  System.out.println(object); // debug in here，clzz.cast(object),Lost part of the data in a field of object。 ```","closed","","dingziyang","2018-04-27T05:56:47Z","2019-01-20T20:15:15Z"
"","605","[SOLR-13234] Fix tests for Turkish locales","### Description When`SolrExporterIntegrationTest.jvmMetrics` ran on a JVM with the Turkish locale, (test seed: 62880F3B9F140C89). The JVM metric for terminated thread-count has a dotless-i e.g. `termınated`. This causes the check for matching metrics to fail.    We could normalize the text in this case, however I think it's better to ensure we have the correct total number of JVM thread metrics rather than looking at Prometheus labels which maybe localized.","closed","","danyalprout","2019-03-11T22:19:05Z","2019-03-18T21:59:55Z"
"","224","Fix typo in javadocs","""be default"" should be ""by default""","closed","","AdamFrey","2017-08-01T16:30:19Z","2017-08-10T00:02:45Z"
"","663","Fix NPE at DistributedUpdateProcessorTest.testVersionAdd","","closed","","jefferyyuan","2019-05-05T03:54:20Z","2019-05-22T21:42:22Z"
"","661","Fix Object.wait forever in VersionBucket","","closed","","jefferyyuan","2019-05-02T20:38:16Z","2019-05-05T03:51:32Z"
"","655","SOLR-13414: SolrSchema - Avoid NPE if Luke returns field with no type defined","","closed","","risdenk","2019-04-25T17:58:03Z","2019-04-26T13:41:48Z"
"","653","SOLR-13425: Wrong color in horizontal definition list","","closed","","janhoy","2019-04-24T09:42:54Z","2019-04-25T14:01:30Z"
"","648","LUCENE-8766: Add Luwak as a lucene module","","closed","","romseygeek","2019-04-16T08:52:18Z","2019-09-04T08:49:39Z"
"","647","SOLR-12638: Added docs in the ref-guide for nested atomic updates","","closed","","moshebla","2019-04-15T12:08:13Z","2019-05-01T18:41:53Z"
"","646","SOLR-12371: Fix unintended security edit API caching in standalone mode","","closed","","janhoy","2019-04-14T22:56:45Z","2019-04-30T14:53:51Z"
"","645","SOLR-12121 Refresh JWK from IdP on invalid sig","","closed","","janhoy","2019-04-12T07:08:56Z","2019-04-12T08:15:23Z"
"","644","SOLR-13394: Change default GC from CMS to G1","","closed","","kesharee","2019-04-12T06:52:54Z","2019-06-13T00:35:59Z"
"","641","Add TimedVersionBucket","","closed","","jefferyyuan","2019-04-11T05:17:52Z","2019-05-02T20:27:44Z"
"","635","SOLR-13371 improve security chapters in refguide","","closed","","janhoy","2019-04-04T13:23:00Z","2019-06-10T21:46:26Z"
"","633","LUCENE-8753 UniformSplit PostingsFormat","","closed","","bruno-roustant","2019-04-03T14:54:29Z","2019-12-02T10:26:06Z"
"","631","LUCENE-8750: implement setMissingValue for ValueSource sortFields","","closed","","msokolov","2019-04-02T14:39:20Z","2020-03-18T03:31:02Z"
"","630","SOLR-13344: Admin UI inaccessible with RuleBasedAuthorizationPlugin","","closed","","janhoy","2019-03-30T23:08:03Z","2019-04-04T14:52:18Z"
"","629","SOLR-13359: Make UpdateHandler support other prefixes (besides hdfs:/)","","closed","","risdenk","2019-03-30T19:52:56Z","2019-03-31T14:48:03Z"
"","626","SOLR-13353: Add SolrCli AuthTool test","","closed","","risdenk","2019-03-28T18:08:47Z","2019-03-28T22:37:27Z"
"","623","SOLR-13351: Workaround for VELOCITY-908","","closed","","risdenk","2019-03-27T21:43:37Z","2019-03-28T13:27:00Z"
"","621","SOLR-13112: Upgrade jackson to 2.9.8","","closed","","risdenk","2019-03-25T14:37:03Z","2019-03-25T16:20:34Z"
"","599","SOLR-13307: Ensure HDFS tests clear System properties they set","","closed","","risdenk","2019-03-08T13:32:27Z","2019-03-11T15:23:17Z"
"","597","[SOLR-13272] feat(facet/interval): support json facet requests for interval facet","","closed","","apoorvprecisely","2019-03-04T13:34:39Z","2019-09-22T05:58:48Z"
"","593","SOLR-13272","","closed","","apoorvprecisely","2019-02-27T11:09:05Z","2019-05-08T09:27:18Z"
"","589","feat(facet/interval): support json facet request for interval facets","","closed","","apoorvprecisely","2019-02-26T12:15:58Z","2019-02-27T11:09:21Z"
"","588","feat(facet): support interval faceting for json facets","","closed","","apoorvprecisely","2019-02-26T09:48:42Z","2019-03-05T07:55:11Z"
"","583","SOLR-13151","","closed","","moshebla","2019-02-21T07:41:44Z","2019-02-25T16:04:10Z"
"","574","LUCENE-8292: Make TermsEnum fully abstract","","closed","","s1monw","2019-02-15T13:43:51Z","2019-02-15T16:33:03Z"
"","573","WIP: SOLR-13150","","closed","","moshebla","2019-02-14T17:45:53Z","2019-02-19T14:56:23Z"
"","572","fix grammar in streaming-expressions.adoc","","closed","","kgeis","2019-02-13T17:04:36Z","2019-02-14T18:48:25Z"
"","570","SOLR-13238 Fixed blob handler md5 padding issue","","closed","","jtwalraven","2019-02-09T16:41:10Z","2019-09-21T16:13:23Z"
"","567","SOLR-13229: Cleanup replicasMetTragicEvent after all exceptions","","closed","","tflobbe","2019-02-07T01:05:37Z","2019-02-15T22:51:39Z"
"","566","Set types in ZkController callables","","closed","","tflobbe","2019-02-07T00:57:37Z","2019-02-08T06:26:44Z"
"","564","prorated early termination","","closed","","msokolov","2019-02-05T12:48:54Z","2020-01-26T22:26:13Z"
"","562","Don't create a LeafCollector when the Scorer for the leaf is null","","closed","","msokolov","2019-02-04T13:12:46Z","2019-02-19T14:44:12Z"
"","560","SOLR-13213: Search Components cannot modify ""shards"" parameter","","closed","invalid,","janhoy","2019-02-03T23:52:56Z","2019-02-05T22:36:37Z"
"","559","SOLR-13180: Search Components cannot modify ""shards"" parameter","","closed","","janhoy","2019-02-03T23:46:28Z","2019-02-03T23:48:36Z"
"","557","Removed some unused variables from DistributedUpdateProcessor","","closed","","tflobbe","2019-02-02T00:57:24Z","2019-02-06T19:32:00Z"
"","554","SOLR-13190 Treat fuzzy term search errors as client errors","","closed","","madrob","2019-01-30T02:16:23Z","2019-12-17T21:25:04Z"
"","551","LUCENE-8662: Change TermsEnum.seekExact(BytesRef) to abstract + delegate seekExact(BytesRef) in FilterLeafReader.FilterTermsEnum","","closed","","jefferyyuan","2019-01-28T21:06:54Z","2019-02-08T23:10:39Z"
"","549","WIP:SOLR-13129","","closed","","moshebla","2019-01-27T17:18:10Z","2019-03-14T13:17:55Z"
"","548","LUCENE-8659 - upgrade Lucene/Solr to use OpenNLP 1.9.1","","closed","","tteofili","2019-01-26T12:11:45Z","2019-01-26T13:13:54Z"
"","543","LUCENE-8474: final cleanups and removal of RAMDirectory","","closed","","dweiss","2019-01-18T13:30:57Z","2020-02-15T17:49:43Z"
"","538","LUCENE-8640: added changes for the validation of valid dateString","","closed","","MighTguY","2019-01-17T01:32:33Z","2019-07-18T14:27:30Z"
"","537","LUCENE-8640: added changes for the validation of valid dateString","","closed","","MighTguY","2019-01-16T11:34:55Z","2019-01-17T01:35:36Z"
"","536","LUCENE-8643: Decrease test complexity in the default case. Exclude simple text codec.","","closed","","dweiss","2019-01-16T10:48:42Z","2020-02-15T17:49:10Z"
"","532","SOLR-13125","","open","","moshebla","2019-01-10T18:03:03Z","2019-01-27T09:32:04Z"
"","531","SOLR-12768","","closed","","moshebla","2019-01-01T15:07:54Z","2019-02-27T05:45:11Z"
"","528","SOLR-12955 2","","closed","","barrotsteindev","2018-12-13T20:21:25Z","2019-03-19T17:27:11Z"
"","524","LUCENE-8604: clean up TestRuleLimitSysouts and add an optional hard limit","","closed","","dweiss","2018-12-12T09:44:46Z","2019-01-19T01:47:13Z"
"","520","LUCENE-8596: The replacement of comments is a bug, in ""UserDictionary.java""","","closed","","mish26","2018-12-09T10:22:26Z","2019-12-21T19:17:14Z"
"","519","WIP: SOLR-12955: rebase and split changes to smaller commits","","closed","","barrotsteindev","2018-12-08T16:37:36Z","2018-12-13T20:22:08Z"
"","509","[SOLR-13019] Fix typo in MailEntityProcessor.java","","closed","","tommymh","2018-11-27T15:55:00Z","2018-12-04T13:53:00Z"
"","507","Update jira/gradle to the latest master","","closed","","diegoceccarelli","2018-11-25T16:03:42Z","2019-08-04T14:32:52Z"
"","506","SOLR-13014: URI Too Long with large streaming expressions in SolrJ","","closed","","janhoy","2018-11-24T20:44:57Z","2018-12-10T18:00:29Z"
"","504","SOLR-13008 Indent JSON/XML formatted field value if indent=true and using DocumentTransformer","","open","","epugh","2018-11-22T13:44:00Z","2020-03-23T15:58:30Z"
"","501","SOLR-5211","","closed","","moshebla","2018-11-18T13:19:13Z","2019-01-10T13:03:20Z"
"","493","SOLR-12964: Make use of DocValuesIterator.advanceExact() instead of the advance()/docID() pattern","","closed","","tpunder","2018-11-06T04:54:25Z","2019-01-18T23:41:25Z"
"","489","SOLR-12955: separate DistribUpdateProcessor to Zk and nonZk classes","","closed","","barrotsteindev","2018-11-03T20:21:05Z","2019-01-19T08:57:00Z"
"","487","LUCENE-8557: LeafReader.getFieldInfos should always return the same instance","","closed","","tpunder","2018-11-02T22:25:53Z","2019-01-18T23:41:29Z"
"","485","Fix parameter name in example","","closed","","epugh","2018-10-26T19:51:39Z","2019-01-18T22:54:57Z"
"","482","LUCENE-8539: fix some typos and improve style in TestStopFilter","","closed","","diegoceccarelli","2018-10-22T23:09:10Z","2019-02-13T05:48:01Z"
"","481","LUCENE-8537: ant test command fails under lucene/tools","","closed","","petersomogyi","2018-10-18T18:44:20Z","2018-11-10T08:21:54Z"
"","479","Log Delete Query Processor custom component","","closed","","tirthmehta1994","2018-10-18T00:55:43Z","2018-10-23T16:43:26Z"
"","478","Query Source Tracker custom component","","open","","tirthmehta1994","2018-10-18T00:55:14Z","2018-11-12T02:44:07Z"
"","477","SOLR-12902: Block Expensive Queries custom component","","open","","tirthmehta1994","2018-10-18T00:54:31Z","2019-01-09T20:12:50Z"
"","476","SOLR-12882: Eliminate excessive lambda allocation in FacetFieldProcessorByHashDV.collectValFirstPhase","","closed","","tpunder","2018-10-17T21:49:29Z","2019-01-18T23:31:06Z"
"","475","SOLR-12881: Remove unneeded import statements","","closed","","petersomogyi","2018-10-17T21:02:29Z","2018-11-15T08:58:14Z"
"","474","SOLR-12880: Show the FacetProcessor class name in the “processor” field of the JSON Facets “debug-trace” debug output","","closed","","tpunder","2018-10-17T20:02:03Z","2019-01-18T23:32:42Z"
"","472","SOLR-12875: Added resize logic for UniqueBlockSlotAcc.lastSeenValuesPerSlot and UniqueSlotAcc.counts","","closed","","tpunder","2018-10-16T21:00:17Z","2019-01-18T23:37:05Z"
"","471","SOLR-8335 HdfsLockFactory should eventually release index after crash.","","open","","manokovacs","2018-10-16T06:53:05Z","2019-03-08T16:56:53Z"
"","469","SOLR-12870: Use StandardCharsets instead of String values","","closed","","petersomogyi","2018-10-15T18:46:50Z","2019-07-20T04:52:01Z"
"","463","SOLR-12833: Use timed-out lock in DistributedUpdateProcessor","","closed","","jefferyyuan","2018-10-04T23:28:33Z","2019-01-20T19:39:04Z"
"","462","LUCENE-8523: Fix typo for JapaneseNumberFilterFactory usage","","closed","","ajhalani","2018-10-04T16:35:43Z","2018-10-22T13:51:36Z"
"","459","SOLR-8335 HdfsLockFactory should eventually release index after crash.","","closed","","manokovacs","2018-09-27T09:24:45Z","2018-10-15T13:33:19Z"
"","455","SOLR-12638","","closed","","moshebla","2018-09-17T13:05:45Z","2019-04-10T07:05:11Z"
"","450","Add rule exception for ""imento"" and ""mento"" suffix","","open","","ceciliassis","2018-09-13T16:46:54Z","2018-09-14T17:59:27Z"
"","448","SOLR-12718 StreamContext ctor should always take a SolrClientCache","","open","","gezapeti","2018-09-10T22:15:06Z","2018-10-22T20:12:06Z"
"","447","LUCENE-8416 Add tokenized version of o.o. to Stempel stopwords","","open","","gezapeti","2018-09-10T21:27:16Z","2018-09-10T21:27:16Z"
"","443","SOLR-12722: add fl param to ChildDocTransformer","","closed","","moshebla","2018-08-30T07:24:55Z","2018-09-06T04:32:53Z"
"","438","SOLR-12593: Remove date parsing functionality from extraction contrib","","closed","","barrotsteindev","2018-08-21T19:22:46Z","2018-09-28T20:52:44Z"
"","436","SOLR-12652: Remove SolrMetricManager.overridableRegistryName method","","closed","","petersomogyi","2018-08-15T15:18:01Z","2018-09-27T19:58:28Z"
"","430","SOLR-12485: support labelled children in xml documents","","closed","","moshebla","2018-08-02T16:04:08Z","2018-08-07T17:53:50Z"
"","429","Accept any key in cluster properties","","closed","","jefferyyuan","2018-08-02T00:46:42Z","2018-10-04T23:28:06Z"
"","428","SOLR-12586: deprecate joda-time and use java.time instead","","closed","","barrotsteindev","2018-08-01T17:41:59Z","2018-08-07T15:52:55Z"
"","424","LUCENE-8415: Clean up Directory contracts (write-once, no reads-before-write-completed)","","closed","","dweiss","2018-07-20T09:23:20Z","2019-01-19T01:25:24Z"
"","422","xxSOLR-12357 Premptive creation of collections in Time Routed Aliases","","closed","","nsoft","2018-07-19T03:32:51Z","2018-08-08T02:33:06Z"
"","421","SOLR-7557: Fix parsing of child documents using queryAndStreamResponse","","closed","","computerlove","2018-07-18T12:22:41Z","2018-10-26T23:18:45Z"
"","419","SOLR-12551 - upgrade to Tika 1.18, first draft","","closed","","tballison","2018-07-13T21:20:53Z","2019-01-09T20:04:05Z"
"","418","SOLR-12423 - upgrade to Tika 1.18, first draft","","closed","","tballison","2018-07-13T21:13:42Z","2018-10-11T15:08:05Z"
"","417","Fixes SOLR-12550: ConcurrentUpdateSolrClient doesn't respect timeouts for commits and optimize","","closed","","morissm","2018-07-12T22:13:35Z","2020-02-20T12:29:21Z"
"","416","WIP: SOLR-12519","","closed","","moshebla","2018-07-12T11:15:43Z","2018-08-29T14:33:15Z"
"","413","SOLR-11431: Leader candidate cannot become leader if replica responds 500 to PeerSync","","closed","stale-closed,","petersomogyi","2018-07-04T10:26:46Z","2020-12-23T19:37:59Z"
"","412","SOLR-12533 Collection collection fails if metrics are called during core creation","","closed","","gezapeti","2018-07-02T14:30:07Z","2018-07-04T14:42:08Z"
"","410","SOLR-12441: add deeply nested URP for nested documents metadata","","closed","","moshebla","2018-06-25T08:43:15Z","2018-08-06T07:18:53Z"
"","407","SOLR-12413 - prefer version zero from zookeeper","","closed","","nsoft","2018-06-19T20:57:20Z","2019-01-19T01:19:54Z"
"","406","Fix parameters mapping in JSON Request","","closed","","vlastv","2018-06-19T09:39:54Z","2019-01-18T23:48:32Z"
"","403","SOLR-12193 Move some log messages to TRACE level","","closed","","gezapeti","2018-06-12T20:22:14Z","2019-11-26T19:57:09Z"
"","400","Put example query on its own line. Also fixes bug where asterisks did not show","","closed","","janhoy","2018-06-11T08:22:45Z","2018-06-11T19:28:40Z"
"","397","Matches highlighter: LUCENE-8349","","open","","romseygeek","2018-06-06T14:23:05Z","2018-06-06T14:36:37Z"
"","395","WIP SOLR-12362: add tests for working relational docs","","closed","","moshebla","2018-06-05T12:12:23Z","2018-06-25T11:43:48Z"
"","394","Synchronized disruption","","closed","","cahilltr","2018-06-04T23:22:45Z","2018-06-06T06:32:01Z"
"","392","LUCENE-8345 - add wrapper class constructors to forbiddenapis","","closed","","michaelbraun","2018-06-03T20:48:10Z","2018-07-16T10:26:41Z"
"","385","WIP: SOLR-12361","","closed","","moshebla","2018-05-28T05:48:17Z","2018-06-11T14:50:24Z"
"","376","SOLR-12361: _childDocuments as a map in SolrInputDocument","","closed","","moshebla","2018-05-16T15:42:10Z","2018-05-17T06:33:50Z"
"","372","LUCENE-8267: removed references to memory codecs.","","closed","","dweiss","2018-05-07T13:27:28Z","2019-01-19T01:07:08Z"
"","367","[Docs] Fix incorrect BitUtil.deinterleave() description","","closed","","nyurik","2018-04-29T23:08:23Z","2020-08-14T17:05:43Z"
"","361","SOLR-12271: Fix for analytics component reading negative values from double and float fields","","closed","","HoustonPutman","2018-04-25T15:13:45Z","2019-02-12T22:14:08Z"
"","358","SOLR-11277: Add auto hard commit setting based on tlog size","","closed","","rupss","2018-04-20T00:18:36Z","2018-05-03T22:04:15Z"
"","348","CREATEing SolrCore, Error  non legacy mode coreNodeName missing {schema=schema.xml, dataDir=data, config=solrconfig.xml}","","closed","","hadoop835","2018-03-30T15:25:39Z","2019-01-19T01:57:01Z"
"","342","SOLR-12120: New AuditLoggerPlugin type allowing custom Audit logger plugin","","closed","","janhoy","2018-03-23T11:43:08Z","2019-04-04T14:53:11Z"
"","340","Add SolrConfig to SolrRequestParsers constructor in EmbeddedSolrServer","","closed","","squallsama","2018-03-20T18:03:37Z","2021-10-01T20:13:56Z"
"","337","SOLR-12101 set explicit min/max timeouts","","closed","","nsoft","2018-03-15T23:15:58Z","2019-01-19T00:36:52Z"
"","334","LUCENE-8196","","closed","","romseygeek","2018-03-09T12:39:14Z","2019-01-19T00:37:47Z"
"","333","SOLR-12064: NullPointerException in JSON facet","","closed","","mrkarthik","2018-03-08T00:51:17Z","2018-03-19T14:05:38Z"
"","330","SOLR-12045: Moving the Analytics Component from contrib to core.","","closed","","HoustonPutman","2018-02-28T15:42:11Z","2020-01-23T20:54:39Z"
"","326","Trivial fix+test for LUCENE-8185 to check minWordSize even when removing binding characters","","open","","mkr","2018-02-25T21:07:00Z","2018-02-25T21:07:00Z"
"","324","SOLR-11795: Add Solr metrics exporter for Prometheus","","closed","","kojisekig","2018-02-20T08:09:29Z","2018-02-20T08:23:10Z"
"","323","SOLR-11731: LatLonPointSpatialField could be improved to return the lat/lon from docValues","","closed","","mrkarthik","2018-02-13T21:29:50Z","2018-03-17T16:23:31Z"
"","319","LUCENE-8152: Simplify conditional logic using advanceExact","","closed","","MathBunny","2018-02-02T00:40:43Z","2018-02-13T01:09:34Z"
"","318","LUCENE-8151: Use advanceExact removing redundant conditionals","","closed","","MathBunny","2018-02-02T00:22:19Z","2018-02-05T14:08:37Z"
"","317","LUCENE-8145: OffsetsEnum is now unitary","","closed","","romseygeek","2018-02-01T14:12:45Z","2018-02-02T10:02:19Z"
"","316","make DIH safer by not default checking the clean checkbox","","closed","","epugh","2018-01-31T20:42:25Z","2018-02-07T17:41:55Z"
"","313","SOLR-11924: Added a way to create collection set watchers in ZkStateReader.","","closed","","HoustonPutman","2018-01-29T21:52:25Z","2021-10-09T15:17:26Z"
"","306","Branch 7 2","","closed","","lndlwangwei","2018-01-14T07:33:58Z","2019-01-19T00:24:25Z"
"","302","LUCENE-8126:  Spatial prefix tree based on S2 geometry","","closed","","iverase","2018-01-10T15:35:34Z","2018-03-02T13:30:44Z"
"","297","fix: https://issues.apache.org/jira/browse/SOLR-11624","","closed","","abhidemon","2017-12-30T05:18:14Z","2018-01-13T20:17:50Z"
"","293","spellcheck prefix already contains a trailing dot","","open","","kevinlacire","2017-12-18T12:53:12Z","2018-01-01T12:31:29Z"
"","292","Removed extra whitespace","","closed","","leggiero","2017-12-17T16:50:07Z","2019-11-27T07:53:46Z"
"","287","SOLR-11331: Ability to Debug Solr With Eclipse IDE","","closed","","mrkarthik","2017-12-06T23:28:13Z","2018-03-19T14:03:53Z"
"","285","Lucene 8075","","closed","","imgpulak","2017-12-06T06:36:10Z","2017-12-06T06:41:17Z"
"","283","SOLR-11304: Fix Exception while returning document if LatLonPointSpatialField field is not stored","","closed","","mrkarthik","2017-12-04T17:32:29Z","2018-02-13T16:21:59Z"
"","282","SOLR-11622: Fix mime4j library dependency for Tika","","closed","","mrkarthik","2017-12-03T03:52:50Z","2017-12-05T15:41:13Z"
"","280","LUCENE-8011: Improve similarity explanations","","closed","","mayya-sharipova","2017-12-01T01:13:30Z","2017-12-13T09:07:30Z"
"","276","SOLR-11648: web UI to display and execute suggestions","","closed","","apoorvprecisely","2017-11-26T08:52:21Z","2019-01-19T00:21:32Z"
"","273","SOLR-11622: Fix mime4j library dependency for Tika","","closed","","mrkarthik","2017-11-14T00:24:40Z","2017-12-27T14:43:28Z"
"","266","Lucene 7804","","closed","","shawnfeldman","2017-10-24T19:59:14Z","2017-10-26T22:06:53Z"
"","261","SOLR-11480: Cleanup admin extra","","closed","","epugh","2017-10-12T20:05:14Z","2019-01-19T00:02:35Z"
"","257","SOLR-11423: Overseer queue needs a hard cap (maximum size) that clients respect","","closed","","dragonsinth","2017-10-02T23:21:54Z","2017-10-05T21:19:13Z"
"","256","SOLR-11423: Overseer queue needs a hard cap (maximum size) that clients respect","","closed","","dragonsinth","2017-10-02T21:21:17Z","2017-10-02T22:16:06Z"
"","255","how to use Learning To Rank","","closed","","ZivHsu","2017-10-02T09:00:04Z","2019-01-19T01:59:22Z"
"","253","SOLR-11399: UnifiedHighlighter ignores hl.fragsize value if hl.bs.type=SEPARATOR","","closed","","morissm","2017-09-25T22:13:09Z","2017-12-04T16:27:44Z"
"","252","LUCENE-7973: Update dictionary version for Ukrainian analyzer","","closed","","arysin","2017-09-20T15:46:53Z","2017-10-09T13:40:08Z"
"","251","LUCENE-7973: Update dictionary version for Ukrainian analyzer","","closed","","arysin","2017-09-20T15:46:38Z","2017-10-09T13:39:49Z"
"","250","LUCENE-7973: Update dictionary version for Ukrainian analyzer","","closed","","arysin","2017-09-20T15:46:04Z","2017-10-09T13:40:20Z"
"","245","SOLR-11331: Ability to Debug Solr With Eclipse IDE","","closed","","mrkarthik","2017-09-06T17:41:02Z","2017-12-06T23:30:19Z"
"","244","SOLR-11304: Fix Exception while returning document if LatLonPointSpatialField field is not stored","","closed","","mrkarthik","2017-09-06T17:39:44Z","2017-12-04T17:31:29Z"
"","237","SOLR-11272 - EmbeddedSolrServer: Set path in query request context for known SolrRequestHandlers","","closed","","Stephen-Allen","2017-08-22T01:55:14Z","2019-01-18T23:59:10Z"
"","234","Made minor changes to docstring to fix wording errors","","closed","","Rohan-B","2017-08-14T18:05:42Z","2019-11-27T07:59:28Z"
"","230","[SOLR-11209] Upgrade HttpClient to 4.5.3","","closed","","hgadre","2017-08-11T17:43:18Z","2019-01-18T23:57:37Z"
"","229","SOLR-11144: Initial version of the analytics component reference.","","closed","","HoustonPutman","2017-08-09T17:23:57Z","2017-11-02T19:32:16Z"
"","228","Branch 6 5","","closed","","AdityaParameshwara","2017-08-06T01:43:23Z","2019-01-18T23:54:46Z"
"","227","SOLR-11190: Fix GraphQuery not working if field has only docValues","","closed","","mrkarthik","2017-08-04T21:36:03Z","2017-08-10T13:31:54Z"
"","222","Branch 4x","","closed","","nirupam89","2017-07-19T12:30:23Z","2019-01-18T23:54:20Z"
"","213","SOLR-10877 More informative exceptions and log messages","","open","","sachingsachin","2017-06-13T05:16:02Z","2017-06-13T05:16:02Z"
"","212","SOLR-10877: More informative messages","","closed","","sachingsachin","2017-06-12T16:12:21Z","2017-06-13T05:14:37Z"
"","209","LUCENE-7855 The advanced parameters of the WikipediaTokenizer are added to the factory","","closed","","jpgilaberte","2017-05-29T11:08:11Z","2017-06-07T08:53:14Z"
"","208","[SOLR-10137] Ensure that ConfigSet created via an API is mutable","","closed","","hgadre","2017-05-25T18:33:57Z","2019-01-18T23:51:06Z"
"","207","LUCENE-7841: Normalize ghe with upturn","","closed","","arysin","2017-05-22T16:02:46Z","2019-01-18T23:36:47Z"
"","206","LUCENE-7841: Normalize ghe with upturn","","closed","","arysin","2017-05-19T19:26:41Z","2019-01-18T23:36:28Z"
"","205","LUCENE-7841: Normalize ghe with upturn","","closed","","arysin","2017-05-19T19:26:08Z","2019-01-18T23:36:08Z"
"","203","Fix minor typo in docstring","","closed","","Chronial","2017-05-18T18:05:24Z","2019-01-22T02:51:08Z"
"","195","SOLR-10047 - Fix test: Use NoMergePolicy in testing","","closed","","kelaban","2017-04-24T16:09:10Z","2017-04-24T18:57:33Z"
"","194","LUCENE-7795 - illegal offsets in WordDelimiterFilter should prevent advancing start offset","","open","","michaelbraun","2017-04-20T21:36:21Z","2017-04-20T21:42:21Z"
"","192","LUCENE-7786 - add getter for field to TermInSetQuery","","open","","michaelbraun","2017-04-18T21:06:40Z","2019-06-27T11:33:34Z"
"","187","LUCENE-7785: Move dictionary for Ukrainan analyzer to external dependency","","closed","","arysin","2017-04-14T00:13:56Z","2017-10-09T13:40:34Z"
"","182","SOLR-10415 - improve debug logging to use parameterized logging","","closed","","michaelbraun","2017-04-08T14:49:32Z","2021-12-08T13:10:41Z"
"","180","SOLR-8138, added new SQL Qury UI.","","closed","","michaelsuzukisagi","2017-04-04T15:51:23Z","2021-02-17T19:36:11Z"
"","175","Skipping merger","","closed","","damianparus","2017-03-27T10:54:53Z","2021-08-26T21:33:09Z"
"","170","ReadTimeOut Exception occurred while building index","","closed","","ryandonglin","2017-03-20T10:01:24Z","2019-01-22T02:56:32Z"
"","163","Jira/solr 8593","","closed","","joel-bernstein","2017-03-01T15:51:53Z","2019-05-16T07:29:51Z"
"","161","Fix SOLR-9399, pass basic auth to update request","","closed","","Noodle05","2017-02-23T03:13:00Z","2019-11-26T20:41:56Z"
"","157","LUCENE-7691 - add explicit size to arraylist creation if known","","open","","michaelbraun","2017-02-11T21:10:27Z","2017-02-19T00:02:07Z"
"","155","SOLR-10082 : Add Variance and Standard Deviation aggregators","","closed","","rustamhsmv","2017-01-31T23:05:56Z","2019-01-18T23:21:28Z"
"","153","Fix issues reported by findbugs","","open","","praste","2017-01-31T21:17:12Z","2019-12-01T04:35:06Z"
"","150","[SOLR-10053] Ignore delegation token cancelation tests until HADOOP-14044 is fixed","","closed","","hgadre","2017-01-30T22:59:39Z","2017-02-03T23:11:12Z"
"","143","Rc","","closed","","yaoyaowd","2017-01-26T05:34:26Z","2019-01-18T22:39:53Z"
"","142","SOLR-10026 - JavaBinCodec should initialize maps and namedLists with known capacity","","closed","","johnthcall","2017-01-23T19:39:44Z","2017-01-24T23:23:59Z"
"","134","[SOLR-9926] Add an environment variable to zkcli to pass java system properties","","closed","","hgadre","2017-01-04T19:21:23Z","2019-01-18T22:36:36Z"
"","132","SOLR-9886","","closed","","praste","2016-12-29T22:48:47Z","2019-01-18T22:34:44Z"
"","131","Fix peer sync replcation test check","","open","","praste","2016-12-29T18:07:50Z","2017-02-19T00:02:02Z"
"","128","SOLR-9884 Adding version to segment handler","","closed","","stevenbower","2016-12-21T14:11:13Z","2019-01-18T22:35:56Z"
"","127","Sorted doc values for 5.5.1","","closed","","ealonsodb","2016-12-19T14:24:04Z","2016-12-19T14:24:27Z"
"","123","SOLR-9860 Enable configuring invariantParams via HttpSolrClient.Builder","","closed","","hgadre","2016-12-13T19:56:07Z","2016-12-19T17:16:07Z"
"","118","SOLR-9659: Add DataWatch API","","open","","romseygeek","2016-11-22T13:34:49Z","2017-02-19T00:02:01Z"
"","116","SOLR-9775 fixed NPEs","","open","","kagan770","2016-11-15T21:43:02Z","2019-11-27T08:28:07Z"
"","111","LUCENE-7544 - add UnifiedHighlighter extension points for custom queries","","closed","","michaelbraun","2016-11-07T20:49:33Z","2017-04-18T21:10:51Z"
"","94","SOLR-9617 - Add RemoteFileField FieldType","","open","","kelaban","2016-10-10T15:30:59Z","2017-02-19T00:01:58Z"
"","92","Replica choice","","closed","","fguery","2016-10-07T16:32:19Z","2016-10-07T16:32:42Z"
"","90","fixed some CSS syntax errors in Solr webapp","","closed","","saschaszott","2016-10-06T08:55:14Z","2019-01-22T17:06:38Z"
"","89","Branch 6 2","","closed","","selvarajy","2016-10-04T19:20:20Z","2016-10-04T19:21:17Z"
"","88","SOLR-9546 Refactored to use primitives instead of wrappers","","closed","","praste","2016-10-03T18:05:14Z","2019-01-18T22:24:28Z"
"","87","SOLR-9511, removed use of individual versions in PeerSync","","closed","","praste","2016-10-03T14:01:34Z","2021-09-22T01:57:18Z"
"","86","SOLR-9584 - use relative URL path instead of absolute path starting from /solr for angularjs services","","closed","","zyjibmcn","2016-09-30T15:22:00Z","2017-01-10T14:22:17Z"
"","85","Allow updating configs like port # on forced upgrade","","open","","jasondemorrow","2016-09-29T00:04:15Z","2017-02-19T00:01:56Z"
"","81","[SOLR-9536] Initialize timestamp field with Optional.empty() to avoid an NPE","","closed","","hgadre","2016-09-20T03:57:30Z","2019-01-18T22:17:06Z"
"","80","SOLR-9529 - Make multivalued dates dynamic field use dates field type","","closed","","treygrainger","2016-09-18T04:57:31Z","2022-01-02T19:19:24Z"
"","73","SOLR-9446 Do a fingerprint check before starting PeerSync","","closed","","praste","2016-08-26T21:36:41Z","2019-01-18T22:14:37Z"
"","65","[SOLR-9326] Ability to create/delete/list snapshots @ collection level.","","closed","","hgadre","2016-08-08T20:36:51Z","2019-01-18T22:04:47Z"
"","38","Restored 4.x codecs.","","closed","","mzasada","2016-05-11T08:31:33Z","2016-05-11T08:33:40Z"
"","37","Move to SolrCloudTestCase","","closed","","tomjon","2016-05-10T11:18:17Z","2019-01-22T16:53:27Z"
"","29","Fix typo in bin/solr zk help text","","closed","","cbeer","2016-04-13T00:09:32Z","2016-06-28T11:45:59Z"
"","27","Upgrade jackson to 2.7","","closed","","vdumitrescu","2016-04-07T15:43:27Z","2019-01-18T23:47:45Z"
"","26","SOLR-8939 Date millisecond resolution lost on distributed queries","","open","","bereng","2016-04-04T12:18:58Z","2017-02-19T00:01:52Z"
"","18","SOLR-8755 Add test cases for org.apache.solr.parser.TokenMgrError","","open","","bvanalderweireldt","2016-02-29T02:06:05Z","2017-02-19T00:01:51Z"
"","9","Switch Subversion for GIT mention in the README.txt","","closed","","arafalov","2016-02-22T00:03:21Z","2016-02-22T09:19:45Z"
"","7","some changes","","closed","","akanarsky","2016-02-12T23:42:05Z","2016-02-13T00:06:33Z"
"","3","[SOLR-8517] Implement minimal set of get* methods in ResultSetImpl for column names","","closed","","risdenk","2016-01-25T18:18:30Z","2016-01-25T19:03:32Z"
"","2","[SOLR-8519] Implement ResultSetMetaDataImpl.getColumnCount()","","closed","","risdenk","2016-01-25T18:10:29Z","2016-01-25T19:03:40Z"