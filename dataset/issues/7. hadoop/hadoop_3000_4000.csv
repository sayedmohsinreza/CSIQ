"#","No","Issue Title","Issue Details","State","Labels","User name","created","Updated"
"","903","HDDS-1490. Support configurable container placement policy through 'o…","…zone.scm.container.placement.classname'","closed","ozone,","ChenSammi","2019-06-04T12:31:36Z","2019-06-06T19:14:48Z"
"","1011","HDFS-14313. Get hdfs used space from FsDatasetImpl#volumeMap#ReplicaInfo in memor…","…y instead of df/du  Signed-off-by: sunlisheng","closed","","leosunli","2019-06-25T04:02:13Z","2019-08-08T13:46:23Z"
"","786","HDDS-1448 : RatisPipelineProvider should only consider open pipeline …","…while excluding dn for pipeline allocation.  While allocation pipelines, Ratis pipeline provider considers all the pipelines irrespective of the state of the pipeline. This can lead to case where all the datanodes are up but the pipelines are in closing state in SCM.","closed","ozone,","avijayanhwx","2019-04-30T06:29:52Z","2019-05-03T18:49:01Z"
"","1086","HADOOP-16341. ShutDownHookManager: Regressed performance on Hook removals after HADOOP-15679","…vals after HADOOP-15679  Continuation of #940. Taking it over from @t3rmin4t0r.","closed","","zeroflag","2019-07-12T14:44:59Z","2019-07-17T14:56:18Z"
"","940","HADOOP-16341. ShutDownHookManager: Regressed performance on Hook remo…","…vals after HADOOP-15679","open","","t3rmin4t0r","2019-06-10T22:11:35Z","2019-07-12T08:34:20Z"
"","896","HADOOP-16341. ShutDownHookManager: Regressed performance on Hook remo…","…vals after HADOOP-15679","open","","t3rmin4t0r","2019-06-03T18:42:56Z","2019-06-06T12:01:39Z"
"","1066","HDDS-1776. Fix image name in some ozone docker-compose files. Contrib…","…uted by Xiaoyu Yao.","closed","ozone,","xiaoyuyao","2019-07-09T21:06:30Z","2019-07-12T22:56:44Z"
"","698","HDDS-1390 - Remove hk2 dependency exclusions from ozone s3gateway mod…","…ule.  Some hk2 transitive dependencies were mistakenly excluded in HDDS-1358Link to solve maven enforcer plugin issues. This jira cleans that up.","closed","ozone,","avijayanhwx","2019-04-04T22:51:00Z","2019-04-05T19:36:01Z"
"","1026","HDDS-1730. Implement File CreateDirectory Request to use Cache and Do…","…ubleBuffer.","closed","ozone,","bharatviswa504","2019-06-27T23:39:48Z","2019-07-01T05:38:54Z"
"","1663","WIP: Better memory info parse patterns, so that only lines with memory slo…","…ts are parsed and others (like VmFlags) are ignored  ## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","open","","jvimr","2019-10-18T08:36:49Z","2020-07-31T16:20:08Z"
"","1317","HADOOP-16496. Apply HDDS-1870 (ConcurrentModification at PrometheusMe…","…tricsSink) to Hadoop common.  JIRA: https://issues.apache.org/jira/browse/HADOOP-16496 Ref: #1179","closed","","aajisaka","2019-08-20T07:15:39Z","2019-08-21T01:11:59Z"
"","1067","HDDS-1653. Add option to ""ozone scmcli printTopology"" to order the ou…","…tput acccording to topology layer. Contributed by Xiaoyu Yao.","closed","ozone,","xiaoyuyao","2019-07-10T04:47:29Z","2019-07-19T03:00:50Z"
"","1169","HDFS-14673 The console log is noisy when using DNSDomainNameResolver …","…to resolve NameNode.","closed","","pingsutw","2019-07-26T07:41:59Z","2019-07-26T18:08:47Z"
"","1134","HADOOP-16433. S3Guard: Filter expired entries and tombstones when lis…","…ting with MetadataStore#listChildren  integration tests are still running","closed","","bgaborg","2019-07-19T15:47:59Z","2019-07-24T17:12:30Z"
"","937","HDDS-1663. Add datanode to network topology cluster during node regis…","…ter.   https://issues.apache.org/jira/browse/HDDS-1663","closed","ozone,","ChenSammi","2019-06-10T14:52:09Z","2019-06-14T08:28:37Z"
"","941","HDDS-1587. Support dynamically adding delegated classes from to isola…","…ted class loader.","closed","","chenjunjiedada","2019-06-11T02:49:11Z","2019-06-11T04:38:11Z"
"","1556","HDDS-2213. Reduce key provider loading log level in OzoneFileSystem#ge…","…tAdditionalTokenIssuers  Updated Log level to debug.","closed","ozone,","shwetayakkali","2019-10-01T06:32:41Z","2019-10-11T17:23:20Z"
"","1469","HDDS-2034. Async RATIS pipeline creation and destroy through heartbea…","…t commands.  https://issues.apache.org/jira/browse/HDDS-2034?filter=-1  Change list, 1. remove gRPC channel RATIS pipeline create in RatisPipelineProvider 2. remove gRPC channel RATIS pipeline destroy in RatisPipelineUtils 3. add createPipelineCommand and closePipelineCommand command type in SCMCommandType 4. Refactor SCMPipelineManager to leverage createPipelineCommand and closePipelineCommand command to create and destroy pipeline asynchronously 5. Add  createPipelineCommandHandler and closePipelineCommandHandler in Datanode to handler request sent by SCM 6. Add createPipelineCommandStatus to carry the pipeline creation status back to SCM 7. Change PIPELINE_REPORT_PROCESS event to NEW_OPEN_PIPELINE event, trigger the event by SCMPipelineManager to inform SCMSafenodeManager about new healthy pipeline availability.  8. Update Pipeline related unit tests for the new asynchronous way.","closed","ozone,","ChenSammi","2019-09-18T15:25:00Z","2019-10-12T09:49:38Z"
"","730","HDDS-1426. Minor logging improvements for MiniOzoneChaosCluster. Cont…","…ributed by Arpit Agarwal.  Change-Id: I3459de58dd99e48a41b4408fd4a71b86bceeb329","closed","ozone,","arp7","2019-04-11T21:42:19Z","2019-04-12T09:43:22Z"
"","1080","HDDS-1752 Use concurrent set implementation for node to pipelines ma…","…pping","closed","ozone,","hgadre","2019-07-11T22:36:40Z","2019-07-12T08:45:49Z"
"","1552","HDDS-2210. ContainerStateMachine should not be marked unhealthy if ap…","…plyTransaction fails with closed container exception.  ## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","ozone,","bshashikant","2019-09-30T19:14:26Z","2019-10-02T04:41:12Z"
"","893","HDDS-1632. Make the hadoop home word readable and avoid sudo in hadoo…","…p-runner","closed","","elek","2019-06-03T09:13:54Z","2019-06-04T06:16:07Z"
"","890","HDDS-1632. Make the hadoop home word readable and avoid sudo in hadoo…","…p-runner","closed","","elek","2019-06-03T08:31:11Z","2019-06-03T08:47:23Z"
"","1631","HDDS-2188 : Implement LocatedFileStatus & getFileBlockLocations to pr…","…ovide node/localization information to Yarn/Mapreduce.  Note : This is a **PRELIMINARY PATCH** for getting some review comments. I am still doing some manual testing to iron out issues.  ## What changes were proposed in this pull request? For applications like Hive/MapReduce to take advantage of the data locality in Ozone, Ozone should return the location of the Ozone blocks. This is needed for better read performance for Hadoop Applications.  https://issues.apache.org/jira/browse/HDDS-2188  ## How was this patch tested? Added a few unit tests. Working on adding more. Currently doing manual testing by running MR jobs.","closed","","avijayanhwx","2019-10-09T18:14:10Z","2019-12-09T17:19:19Z"
"","899","HDFS-14535. The default 8KB buffer in requestFileDescriptors#Buffered…","…OutputStream is causing lots of heap allocation in HBase when using short-circut read","closed","","openinx","2019-06-04T02:55:37Z","2019-06-04T15:48:06Z"
"","1089","MAPREDUCE-7076 TestNNBench#testNNBenchCreateReadAndDelete failing in …","…our internal build","closed","","pingsutw","2019-07-13T16:29:38Z","2019-07-23T06:00:05Z"
"","1681","HADOOP-16672 : adding null check for ticket.doAs() while setting up I…","…OStreams","closed","","virajjasani","2019-10-28T09:35:05Z","2020-07-31T18:11:31Z"
"","1262","HDDS-1943. TestKeyManagerImpl.testLookupKeyWithLocation is failing. C…","…ontributed by Xiaoyu Yao.","closed","ozone,","xiaoyuyao","2019-08-09T18:22:34Z","2019-08-10T05:09:51Z"
"","1393","HDDS-2069. Default values of properties hdds.datanode.storage.utilization.{critical | warning}.threshold are not reasonable","…on.critical.threshold and hdds.datanode.storage.utilization.warning.threshold are not reasonable.   https://issues.apache.org/jira/browse/HDDS-2069?filter=-1","closed","ozone,","ChenSammi","2019-09-02T09:19:35Z","2019-09-04T02:26:44Z"
"","1222","HADOOP-16488 Deprecated JsonSerialization and move it out of hadoop-c…","…ommon","open","","Apache9","2019-08-04T07:42:32Z","2019-08-27T11:16:06Z"
"","1190","HDFS-14681: RBF: TestDisableRouterQuota failed because port 8888 was …","…occupied","closed","hdfs,","sunchao","2019-07-31T07:09:45Z","2019-07-31T17:24:49Z"
"","866","HDDS-1604. ContainerReader#initializeUsedBytes leaks DB reference. Co…","…ntributed by Xiaoyu Yao.","closed","ozone,","xiaoyuyao","2019-05-28T17:51:09Z","2019-05-29T01:44:57Z"
"","975","HDDS-1692. RDBTable#iterator should disabled caching of the keys duri…","…ng iterator.","closed","ozone,","bharatviswa504","2019-06-16T18:42:58Z","2019-06-17T05:00:40Z"
"","1163","HDDS-1786 : Datanodes takeSnapshot should delete previously created s…","…napshots.  Right now, after after taking a new snapshot, the previous snapshot file is left in the raft log directory. When a new snapshot is taken, the previous snapshot should be deleted.  Fixed the issue in the takeSnapshot method. Manually tested on docker and added unit test.","closed","ozone,","avijayanhwx","2019-07-25T21:59:41Z","2019-09-13T17:50:57Z"
"","1143","Ozone Read fails with StatusRunTimeExceptions after 2 datanode fail i…","…n Ratis pipeline  https://issues.apache.org/jira/browse/HDDS-1809  This issue is fixed by the code change in https://issues.apache.org/jira/browse/HDDS-1713.   Previously network topology use Ipaddress as the node key in topology cluster, which results that three sorted Datanodes are the same node.   Now datanode uuid is used as the node key in topology cluster, so sorted Datanodes will be three different nodes now.","closed","ozone,","ChenSammi","2019-07-23T07:15:41Z","2019-07-26T02:59:35Z"
"","966","HDDS-1686. Remove check to get from openKeyTable in acl implementatio…","…n for Keys.","closed","ozone,","bharatviswa504","2019-06-14T00:42:37Z","2019-07-22T22:11:11Z"
"","1570","HDDS-2216. Rename HADOOP_RUNNER_VERSION to OZONE_RUNNER_VERSION in co…","…mpose .env files.  ## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","ozone,","cxorm","2019-10-02T00:53:58Z","2019-10-04T16:27:31Z"
"","1009","HADOOP-16383. Pass ITtlTimeProvider instance in initialize method in …","…MetadataStore interface","closed","","bgaborg","2019-06-24T19:08:19Z","2019-07-17T14:27:47Z"
"","873","HADOOP-16337 Start the CLI MiniCluster failed because the default for…","…mat option is false","open","","infraio","2019-05-30T03:09:10Z","2019-05-30T03:09:10Z"
"","1328","HDDS-1998. TestSecureContainerServer#testClientServerRatisGrpc is fai…","…ling","closed","ozone,","pingsutw","2019-08-21T13:45:34Z","2019-08-27T06:36:14Z"
"","977","HDFS-14541. When evictableMmapped or evictable size is zero, do not throw NoSuchElementException","…lementException  Signed-off-by: sunlisheng","closed","","leosunli","2019-06-17T11:33:40Z","2019-06-25T16:25:19Z"
"","751","HDDS-1425. Ozone compose files are not compatible with the latest doc…","…ker-compose.","closed","","elek","2019-04-18T13:56:54Z","2019-04-22T15:12:07Z"
"","1034","HDDS-1721 : Client Metrics are not being pushed to the configured sin…","…k while running a hadoop command to write to Ozone.  Metrics system needs to be initialized for the sink configs to be picked up.   Manually tested the change. After this change, if the hadoop-metrics2.properties contains properties like such, client metrics will be pushed to sink.  xceiverclientmetrics.period=10 xceiverclientmetrics.sink..plugin.urls=/path/to/JAR xceiverclientmetrics.sink..interval=10","closed","ozone,","avijayanhwx","2019-06-28T22:19:50Z","2019-07-17T19:05:44Z"
"","1339","HDDS-2000. Don't depend on bootstrap/jquery versions from hadoop-trun…","…k snapshot  I have copied all the dependencies we need for OM and SCM web UI into hdds-framework static folder so that we need not depend on hadoop static resources. I have tested each of the UIs manually from invoking OM, SCM and Datanode in docker compose.   Also, included in this patch is the upgrade of bootstrap and jquery versions used in docs. I have also added ozone logo the navbar header of our docs and verified that the changes look good by both `hugo serve` and by clicking on `docs` link from OM and SCM web UIs.","closed","ozone,","vivekratnavel","2019-08-23T01:50:15Z","2019-08-23T20:28:12Z"
"","1411","HDDS-2098 : Ozone shell command prints out ERROR when the log4j file …","…is not present.   Manually tested change on cluster.","closed","ozone,","avijayanhwx","2019-09-06T18:56:01Z","2019-09-17T05:36:54Z"
"","1379","HDDS-2047. Datanodes fail to come up after 10 retries in a secure env…","…ironment.","closed","ozone,","xiaoyuyao","2019-08-29T19:05:50Z","2019-08-30T16:27:38Z"
"","1446","YARN-9834. Allow using a pool of local users to run Yarn Secure Conta…","…iner in secure mode  Signed-off-by: Shanyu Zhao   https://issues.apache.org/jira/browse/YARN-9834","open","","shanyu","2019-09-14T02:35:33Z","2022-01-27T19:38:36Z"
"","1363","HDDS-1783 : Latency metric for applyTransaction in ContainerStateMach…","…ine.  applyTransaction is invoked from the Ratis pipeline and the ContainerStateMachine uses a async executor to complete the task.  We require a latency metric to track the performance of log apply operations in the state machine. This will measure the end-to-end latency of apply which includes the queueing delay in the executor queues. Combined with the latency measurement in HddsDispatcher, this will be an indicator if the executors are overloaded.","closed","ozone,","avijayanhwx","2019-08-28T05:40:24Z","2019-09-03T09:49:35Z"
"","710","HADOOP-16237. Fix new findbugs issues after update guava to 27.0-jre …","…in hadoop-project trunk","closed","","bgaborg","2019-04-08T19:39:37Z","2019-04-15T16:59:48Z"
"","702","HADOOP-16237. Fix new findbugs issues after update guava to 27.0-jre …","…in hadoop-project trunk","closed","","bgaborg","2019-04-05T17:57:57Z","2019-04-09T12:45:24Z"
"","775","HADOOP-16184. S3Guard: Handle OOB deletions and creation of a file wh…","…ich has a tombstone marker  This first initial PR is to show what's happening. WIP, do not commit yet.  These tests will fail!","closed","","bgaborg","2019-04-26T15:00:17Z","2019-05-30T12:14:41Z"
"","927","HDDS-1543. Implement addAcl,removeAcl,setAcl,getAcl for Prefix. Contr…","…ibuted by Xiaoyu Yao.","closed","ozone,","xiaoyuyao","2019-06-07T22:29:39Z","2019-06-12T23:25:32Z"
"","865","HDDS-1536. testSCMSafeModeRestrictedOp is failing consistently. Contr…","…ibuted by Xiaoyu Yao.","closed","ozone,","xiaoyuyao","2019-05-28T16:33:01Z","2019-05-28T21:02:45Z"
"","722","HDDS-1421. Avoid unnecessary object allocations in TracingUtil. Contr…","…ibuted by Arpit Agarwal.  Change-Id: I3fd1b59447005cc62ae217c4def86a9df81944b1","closed","ozone,","arp7","2019-04-10T23:36:51Z","2019-04-12T09:57:46Z"
"","725","HDDS-1422. Exception during DataNode shutdown. Contributed by Arpit A…","…garwal.  Change-Id: I981fbd087baca80cc6b4ff58e91e63dcd9726c13","closed","ozone,","arp7","2019-04-11T01:11:14Z","2019-05-18T09:47:44Z"
"","850","HDDS-1551. Implement Bucket Write Requests to use Cache and DoubleBuf…","…fer.","closed","ozone,","bharatviswa504","2019-05-24T20:45:36Z","2019-05-30T22:31:19Z"
"","883","HDDS-1625 : ConcurrentModificationException when SCM has containers o…","…f different owners.  SCMBlockProtocolServer#allocateBlock throws ConcurrentModificationException when SCM has containers of different owners.  > 2019-05-31 13:53:16,808 WARN org.apache.hadoop.hdds.scm.container.SCMContainerManager: Container allocation failed for pipeline=Pipeline[ Id: 3e0eec4d-67d1-4582-a9e9-e68b0a340de6, Nodes: abaea3d2-a8c1-47de-8cdb-7cc5ed8f23a6{ip: 10.17.219.50, host: v  > c1340.halxg.cloudera.com, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN] requiredSize=268435456 {} > java.util.ConcurrentModificationException >         at java.util.TreeMap$PrivateEntryIterator.nextEntry(TreeMap.java:1211) >         at java.util.TreeMap$KeyIterator.next(TreeMap.java:1265) >         at org.apache.hadoop.hdds.scm.container.SCMContainerManager.getContainersForOwner(SCMContainerManager.java:473) >         at org.apache.hadoop.hdds.scm.container.SCMContainerManager.getMatchingContainer(SCMContainerManager.java:394) >         at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:203) >         at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:172)","closed","ozone,","avijayanhwx","2019-05-31T22:33:42Z","2019-06-03T19:45:05Z"
"","1664","HADOOP-16658 - S3A connector does not support including the token ren…","…ewer in the token identifier  Ran 'mvn verify' with endpoint s3.us-east-1.amazonaws.com Two tests failed, but passed when run individually: * ITestS3AConfiguration#testAutomaticProxyPortSelection * ITestS3AInconsistency#testGetFileStatus  ## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","pzampino","2019-10-18T17:31:13Z","2019-10-23T15:33:59Z"
"","1311","HDDS-1946. CertificateClient should not persist keys/certs to ozone.m…","…etadata.dir  The issue was that when OM and SCM are deployed on the same host with ozone.metadata.dir defined. SCM can start successfully but OM can not because the key/cert from OM will collide with SCM.  The solution implemented in this patch is to store certs in a sub directory inside ozone.metadata.dir based on the component. Ozone Manager will store its certs in `${ozone.metadata.dir}/om/certs` and Datanode will  store in `${ozone.metadata.dir}/dn/certs` to avoid conflicts. This solution was discussed with @anuengineer and I thank him for his guidance.  Testing done:  I tested the patch in docker containers and verified that certs are now stored in `${ozone.metadata.dir}/${component}/certs` path. I modified the unit tests and verified that all unit tests pass.","closed","ozone,","vivekratnavel","2019-08-17T22:36:30Z","2019-08-28T00:29:28Z"
"","1667","HDFS-14308. DFSStripedInputStream curStripeBuf is not freed by unbuff…","…er()  ## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","zhaoyim","2019-10-22T15:33:37Z","2019-10-25T20:09:15Z"
"","1496","HADOOP-16560. [YARN] use protobuf-maven-plugin to generat…","…e protobuf classes","closed","","Apache9","2019-09-22T07:11:46Z","2019-09-24T06:14:46Z"
"","1040","HDFS-13693: Remove unnecessary search in INodeDirectory.addChild during image loa…","…ding  Signed-off-by: sunlisheng","closed","","leosunli","2019-07-01T07:20:55Z","2019-07-26T22:37:25Z"
"","1107","HDDS-1813. Fix false warning from ozones3 acceptance test. Contribute…","…d by Xiaoyu Yao.","closed","ozone,","xiaoyuyao","2019-07-16T19:14:24Z","2019-07-16T20:51:12Z"
"","1101","HDDS-1544. Support default Acls for volume, bucket, keys and prefix. …","…Contributed by Ajay Kumar.  Delta from Ajay's latest PR: https://github.com/apache/hadoop/pull/1074  * Additional change to fix the unit tests and checkstyle issue.   * TestOzoneRpcClientWithRatis still has 3 test failing as expected. The root cause is the Ozone ACL work has not fully integrated with the OM-HA targeted for ozone 0.5. OM-HA support for HA is tracked separately by HDDS-1619.","closed","ozone,","xiaoyuyao","2019-07-16T00:44:50Z","2019-07-16T21:38:07Z"
"","1055","HDDS-1705. Recon: Add estimatedTotalCount to the response of ...","…containers and containers/{id} endpoints  This PR adds the following features to Recon  - Initialize Recon SQL Schemas while starting up Recon Server - Get TotalCount in containers and keys API Response - Move /api/containers/{containerId} --> /api/containers/{containerId}/keys  This patch was tested manually by bringing up ozone in a local dev environment and checking whether sqlite instance gets updated with total number of containers as expected. Also, the API responses of two endpoints were tested in a browser with different limits and prevKey combinations.","closed","ozone,","vivekratnavel","2019-07-03T23:24:09Z","2019-07-09T05:02:43Z"
"","1422","HDFS-14839: Use Java Concurrent BlockingQueue instead of Internal Blo…","…ckQueue","open","","belugabehr","2019-09-10T19:24:53Z","2021-06-28T16:58:48Z"
"","996","[HDFS-14585]Backport HDFS-8901 Use ByteBuffer in striping positional read to bran…","…ch-2.8.5  Signed-off-by: sunlisheng","closed","","leosunli","2019-06-21T02:05:29Z","2019-06-21T03:31:46Z"
"","995","[HDFS-14585]Backport HDFS-8901 Use ByteBuffer in striping positional read to bran…","…ch-2.8.5  Signed-off-by: sunlisheng","open","","leosunli","2019-06-20T11:24:00Z","2019-06-21T06:52:48Z"
"","997","[HDFS-14585]Backport HDFS-8901 Use ByteBuffer in DFSInputStream#read to bran…","…ch-2.8  Signed-off-by: sunlisheng","closed","","leosunli","2019-06-21T03:34:19Z","2019-07-26T23:04:54Z"
"","1121","YARN-9124. Resolve contradiction in ResourceUtils: addMandatoryResour…","…ces / checkMandatoryResources work differently","closed","","adamantal","2019-07-18T14:50:53Z","2019-08-02T11:04:39Z"
"","916","HDDS-1652. HddsDispatcher should not shutdown volumeSet. Contributed …","…by Xiaoyu Yao.","closed","ozone,","xiaoyuyao","2019-06-05T22:10:04Z","2019-06-06T18:18:00Z"
"","723","HDDS-1420. Tracing exception in DataNode HddsDispatcher. Contributed …","…by Arpit Agarwal.  Change-Id: I73394296b7de3b31b4d136fd5ed020a82bc063aa","closed","ozone,","arp7","2019-04-11T00:08:10Z","2019-04-12T11:19:06Z"
"","811","HDDS-1511. Space tracking for Open Containers in HDDS Volumes. Contri…","…buted by Supratim Deka","closed","ozone,","arp7","2019-05-10T03:01:36Z","2019-05-10T07:57:12Z"
"","1500","HADOOP-16561. [MAPREDUCE] use protobuf-maven-plugin to generate proto…","…buf classes","closed","","Apache9","2019-09-23T09:19:28Z","2019-09-24T00:52:13Z"
"","1373","HDDS-2053. Fix TestOzoneManagerRatisServer failure. Contributed by Xi…","…aoyu Yao.","closed","ozone,","xiaoyuyao","2019-08-28T23:32:56Z","2019-09-09T22:38:12Z"
"","1303","HDDS-1903 : Use dynamic ports for SCM in TestSCMClientProtocolServer …","…and TestSCMSecurityProtocolServer.   Add dynamic ports for a couple of unit tests failing due to the following error.  _java.net.BindException: Problem binding to [0.0.0.0:9961] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException     at_","closed","ozone,","avijayanhwx","2019-08-15T18:51:44Z","2019-08-18T17:08:39Z"
"","987","HDDS-1685. Recon: Add support for 'start' query param to containers…","…and containers/{id} endpoints  This PR adds support to ""start"" query param to seek to the given key in RocksDB for containers and containers/{id} endpoints.","closed","ozone,","vivekratnavel","2019-06-18T22:44:28Z","2019-07-01T19:45:15Z"
"","986","[HDDS-1690] ContainerController should provide a way to retrieve cont…","…ainers per volume  Added an API in ContainerSet (and ContainerController) which exposes an iterator of containers for a specified volume identifier.","closed","ozone,","hgadre","2019-06-18T19:13:10Z","2019-06-21T17:23:44Z"
"","1512","HADOOP-16598. Backport ""HADOOP-16558 [COMMON+HDFS] use protobuf-maven…","…-plugin to generate protobuf classes"" to all active branches","closed","","Apache9","2019-09-24T08:27:36Z","2019-09-30T22:14:09Z"
"","802","HADOOP-16279. S3Guard: Implement time-based (TTL) expiry for entries …","…(and tombstones)","closed","fs/s3,","bgaborg","2019-05-08T11:19:03Z","2019-06-19T18:52:15Z"
"","1509","HDDS-2168. TestOzoneManagerDoubleBufferWithOMResponse sometimes fails…","… with out of memory error  After debugging this issue with @avijayanhwx and @bharatviswa504 , found out that mockito was the culprit here by consuming lots of heap memory to store the invocations.  Thanks to @avijayanhwx and @bharatviswa504 for helping!","closed","ozone,","vivekratnavel","2019-09-23T22:22:27Z","2019-09-24T23:28:35Z"
"","1424","HDDS-2107. Datanodes should retry forever to connect to SCM in an…","… unsecure environment   In an unsecure environment, the datanodes try upto 10 times after waiting for 1000 milliseconds each time before throwing this error:  ``` Unable to communicate to SCM server at scm:9861 for past 0 seconds. java.net.ConnectException: Call From scm:9861 failed on connection exception: java.net.ConnectException: Connection refused; ```  This PR fixes that issue by having datanodes try forever to connect with SCM and not throw an error from the state machine.  I have also increased timeouts on a unit test to improve its stability.","closed","ozone,","vivekratnavel","2019-09-11T01:27:46Z","2019-09-16T19:58:16Z"
"","1528","HDDS-2181. Ozone Manager should send correct ACL type in ACL requests…","… to Authorizer  Currently, Ozone manager sends ""WRITE"" as ACLType for key create, key delete and bucket create operation. Fix the acl type in all requests to the authorizer.  This patch fixes these issues and sends correct ACL types to Authorizer.","closed","ozone,","vivekratnavel","2019-09-26T06:25:27Z","2021-03-22T23:45:59Z"
"","1638","HDDS-2280. HddsUtils#CheckForException should not return null in case…","… the ratis exception cause is not set.  ## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","ozone,","bshashikant","2019-10-10T12:23:19Z","2020-04-09T15:37:13Z"
"","1674","MAPREDUCE-7240.Exception 'Invalid event: TA_TOO_MANY_FETCH_FAILURE at…","… SUCCESS_FINISHING_CONTAINER' cause job error  https://github.com/apache/hadoop/pull/1618 PR for trunk","closed","","chimney-lee","2019-10-24T08:30:06Z","2020-08-03T01:34:07Z"
"","1616","MAPREDUCE-7240.Exception 'Invalid event: TA_TOO_MANY_FETCH_FAILURE at…","… SUCCESS_FINISHING_CONTAINER' cause job error  ## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","chimney-lee","2019-10-08T11:23:24Z","2019-10-08T12:08:27Z"
"","1618","MAPREDUCE-7240.Exception 'Invalid event: TA_TOO_MANY_FETCH_FAILURE at…","… SUCCESS_FINISHING_CONTAINER' cause job error","closed","","chimney-lee","2019-10-08T12:14:03Z","2020-08-18T01:35:10Z"
"","769","HDDS-1456. Stop the datanode, when any datanode statemachine state is…","… set to shutdown.","closed","ozone,","bharatviswa504","2019-04-24T18:51:47Z","2019-04-26T21:25:35Z"
"","1008","HDDS-1713. ReplicationManager fail to find proper node topology based…","… on Datanode details from heartbeat. Contributed by Xiaoyu Yao.","closed","ozone,","xiaoyuyao","2019-06-23T00:58:02Z","2019-07-25T17:25:50Z"
"","1333","HDDS-2008 : Wrong package for RatisHelper class in hadoop-hdds/common…","… module.  It is currently org.apache.ratis.RatisHelper.  It should be org.apache.hadoop.hdds.ratis.RatisHelper.","closed","ozone,","avijayanhwx","2019-08-22T05:24:28Z","2019-08-22T17:57:23Z"
"","1103","HDFS-14646. Standby NameNode should terminate the FsImage put process immediately if the peer NN is not in the appropriate state to receive an image.","… immediately if the peer NN is not in the appropriate state to receive an image.","closed","","iamcaoxudong","2019-07-16T06:39:01Z","2019-08-13T03:26:02Z"
"","1093","HDFS-14646. Standby NameNode should terminate the FsImage put process…","… immediately if the peer NN is not in the appropriate state to receive an image.","closed","","iamcaoxudong","2019-07-15T11:27:43Z","2019-07-16T06:31:33Z"
"","1650","HDDS-2034. Async RATIS pipeline creation and destroy through datanode…","… heartbeat commands.  Old PR link where all previous comments are hosted.  https://github.com/apache/hadoop/pull/1469","closed","","ChenSammi","2019-10-12T09:51:42Z","2019-11-16T11:10:20Z"
"","1112","HDDS-1713. ReplicationManager fail to find proper node topology based…","… Datanode details from heartbeat  https://github.com/apache/hadoop/pull/1008  1. support datanode UUID as datanode network location name in network topology cluster 2. send back datanode networkname/networklocation to datanode in its register command response, so that datanode heartbeat message will carry the correct networkname/networklocation information. 3. add  TestStorageContainerManager#testScmProcessDatanodeHeartbeat to verify the heartbeat change.","closed","ozone,","ChenSammi","2019-07-17T13:51:05Z","2019-07-19T22:45:27Z"
"","1527","HADOOP-16610. Upgrade to yetus 0.11.0 and use emoji vote on github pre…","… commit","closed","","Apache9","2019-09-26T03:07:16Z","2019-11-19T08:51:50Z"
"","915","HDDS-1650. Fix Ozone tests leaking volume checker thread. Contributed…","… by Xiaoyu Yao.","closed","ozone,","xiaoyuyao","2019-06-05T21:45:28Z","2019-06-06T18:20:05Z"
"","1463","HADOOP-16581. Revise ValueQueue to correctly replenish queues that go…","… below the watermark  In the existing implementation, the ValueQueue::getAtMost() method will only trigger a refill on a key queue if it has gone empty, instead of triggering a refill when it has gone below the watermark. Revised the test suite to correctly verify this behavior.","closed","","yuvaldeg","2019-09-17T20:53:10Z","2019-09-20T16:56:17Z"
"","1261","YARN-9676. Add DEBUG and TRACE level messages to AppLogAggregatorImpl…","… and connected classes  Also removed cleanupOldLogTimes and unused methods.  Looks to me that `AggregatedLogFormat` and `LogAggregationFileController` has proper logging.","closed","","adamantal","2019-08-09T13:45:13Z","2019-08-14T15:35:17Z"
"","1098","HDDS-1801. Make Topology Aware Replication/Read non-default for ozone…","… 0.4.1. Contributed by Xiaoyu Yao.","closed","ozone,","xiaoyuyao","2019-07-15T21:39:42Z","2019-07-17T17:39:41Z"
"","1079","HADOOP-16380: test to show that it is the root directory where the ""tombstone problem"" can be replicated","You don't get it on deeper paths because the full prefix is returned ""/test/dir/deleted"", which doesn't match the short name of a tombstone.     this helps explain why we only see it on the root dir tests.      Change-Id: I6e00b39684b7f3ff76eb84ee877128fa01c0f2bc  **This is not the fix**  This test replicates the problem as seen in the IDE when debugging root dir test failures","closed","fs/s3,","steveloughran","2019-07-11T14:49:14Z","2019-07-30T15:12:33Z"
"","699","Fix so dfs.client.failover.max.attempts is respected correctly","Without this change, you would get incorrect behavior in that you would always have to set `dfs.client.failover.max.attempts` to be +1 greater to have the desired behavior, e.g. if you want it to attempt failover exactly once, you would have to set `dfs.client.failover.max.attempts=2`.  Without this change, if you set `dfs.client.failover.max.attempts=1`, to attempt to failover just once time, instead it wouldn't try at all, and you see this log message: ``` org.apache.hadoop.io.retry.RetryInvocationHandler - Exception while invoking class org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo over hadoop-node-01.docker.infra.atscale.com/127.0.0.21:8020. Not retrying because failovers (1) exceeded maximum allowed (1) ```  Note that the non-failover retries just below this change is correct.","open","","jbarefoot","2019-04-05T00:09:23Z","2019-09-03T04:31:15Z"
"","1538","HDDS-1720 : Add ability to configure RocksDB logs for Ozone Manager.","With this patch, RocksDB logging can be configured for OM. If needed, we can write RocksDB logs to a separate file using a separate appender in log4j.properties.","closed","ozone,","avijayanhwx","2019-09-27T07:11:51Z","2019-10-03T22:25:13Z"
"","1466","HDDS-2144. MR job failing on secure Ozone cluster.","With this patch, able to run the map-reduce job on a secure cluster. This was caused by HDDS-2018, which has changed the return/computed value of delegationTokenService. Thank You @xiaoyuyao for helping in this issue.","closed","ozone,","bharatviswa504","2019-09-17T23:42:35Z","2019-09-18T20:27:28Z"
"","1583","HDDS-2071. Support filters in ozone insight point","With Ozone insight we can print out all the logs / metrics of one specific component s (eg. scm.node-manager or scm.node-manager).  It would be great to support additional filtering capabilities where the output is filtered based on specific keys.  For example to print out all of the logs related to one datanode or related to one type of RPC request.  Filter should be a key value map (eg. --filter datanode=sjdhfhf,rpc=createChunk) which can be defined in the ozone insight CLI.  As we have no option to add additional tags to the logs (it may be supported by log4j2 but not with slf4k), the first implementation can be implemented by pattern matching.  For example in SCMNodeManager.processNodeReport contains trace/debug logs which includes the "" [datanode={}]"" part. This formatting convention can be used to print out the only the related information.   See: https://issues.apache.org/jira/browse/HDDS-2071","closed","ozone,","elek","2019-10-03T15:08:36Z","2019-10-13T09:28:07Z"
"","1385","HDDS-2060. Create Ozone specific LICENSE file for the Ozone source package","With HDDS-2058 the Ozone (source) release package doesn't contains the hadoop sources any more. We need to create an adjusted LICENSE file for the Ozone source package (We already created a specific LICENSE file for the binary package which is not changed).  In the new LICENSE file we should include entries only for the sources which are part of the Ozone release.  See: https://issues.apache.org/jira/browse/HDDS-2060","closed","ozone,","elek","2019-08-30T14:30:14Z","2019-08-31T22:03:48Z"
"","1627","HADOOP-16644. Do a HEAD after a PUT to get the modtime.","WiP: no tests. What would a test look like? best to use some mock to fix the remote time to always be slightly different from the local. Or we make the clock of the S3A FS patchable, which is potentially the most flexible.  Its unfortunate we need to do this; inclusion of the result in the put response, or, if it is there, extraction of it, is what would work best -especially as that would guarantee consistent read on update, the way an unversioned HEAD does not  Change-Id: I2c99752647f522991b1f89dd9c43f3a2e9b98bf5","closed","work in progress,","steveloughran","2019-10-09T10:15:51Z","2021-10-15T19:45:19Z"
"","1060","HADOOP-13980. fsck - Work In Progress","WIP","closed","","bgaborg","2019-07-08T14:53:38Z","2019-07-29T13:33:36Z"
"","1004","HDDS-1718 : Increase Ratis Leader election timeout default to 10 seconds","While testing out ozone with long running clients which continuously write data, it was noted that whenever a 1 second GC pause occurs in the leader, it triggers a leader election thereby disturbing the steady state of the system for more time than the GC pause delay.","closed","ozone,","avijayanhwx","2019-06-21T19:17:41Z","2019-07-30T16:50:44Z"
"","1005","HDDS-1719 : Increase ratis log segment size to 1MB.","While testing out ozone with long running clients which continuously write data, it was noted ratis logs were rolled 1-2 times every second. This adds unnecessary overhead to the pipeline thereby affecting write throughput. Increasing the size of the log segment to 1MB will decrease the overhead.","closed","ozone,","avijayanhwx","2019-06-21T20:54:24Z","2019-06-24T15:57:42Z"
"","721","HDDS-1417. After successfully importing a container, datanode should delete the container tar.gz file from working directory.","Whenever we want to replicate or copy a container from one datanode to another, we compress the container data and create a tar.gz file. This tar file is then copied from source datanode to destination datanode. In destination, we use a temporary working directory where this tar file is copied. Once the copying is complete we import the container. After importing the container we no longer need the tar file in the working directory of destination datanode, this has to be deleted.","closed","ozone,","nandakumar131","2019-04-10T19:09:10Z","2019-04-11T09:19:47Z"
"","1614","HADOOP-16615. Add password check for credential provider","When we use hadoop credential provider to store password, we can not sure if the password is the same as what we remembered.  So, I think we need a check tool.","closed","","hddong","2019-10-08T07:27:50Z","2019-10-31T17:41:46Z"
"","1613","HADOOP-16615.Add password check for credential provider","When we use hadoop credential provider to store password, we can not sure if the password is the same as what we remembered.  So, I think we need a check tool.","closed","","hddong","2019-10-08T07:23:23Z","2019-10-08T07:24:19Z"
"","1654","YARN-9689: Support proxy user for Router to support kerberos","When we enable kerberos in YARN-Federation mode, we can not get new app since it will throw kerberos exception below.Which should be handled!  ` 2019-07-22,18:43:25,523 WARN org.apache.hadoop.ipc.Client: Exception encountered while connecting to the server : javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)] 2019-07-22,18:43:25,528 WARN org.apache.hadoop.yarn.server.router.clientrm.FederationClientInterceptor: Unable to create a new ApplicationId in SubCluster xxx java.io.IOException: DestHost:destPort xxx , LocalHost:localPort xxx. Failed on local exception: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]         at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)         at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)         at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)         at java.lang.reflect.Constructor.newInstance(Constructor.java:423)         at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831) `","closed","","caneGuy","2019-10-14T11:11:03Z","2019-11-05T11:07:28Z"
"","1356","HADOOP-16534. Exclude submarine from hadoop source build.","When we do source package of hadoop, it should not contain submarine project/code.","closed","","nandakumar131","2019-08-27T11:39:15Z","2019-09-06T09:05:06Z"
"","1670","HDFS-14925. Rename operation should check nest snapshot","When we do rename operation for directory, if the src directory or any of its descendant is snapshottable and the dst directory or its any of its ancestors is snapshottable, we consider this as nested snapshot, which should be denied.  V2:      1. reduce duplicate code      2. take `directory rename overwrite` into consideration  Signed-off-by: Zhao Junwang","closed","hdfs,","zhjwpku","2019-10-23T15:39:55Z","2019-11-01T23:38:23Z"
"","1020","YARN-9646 Use localhost when testing with the mini yarn cluster","When testing org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell#testDSShellWithoutDomain at home  The following error happened:  org.apache.hadoop.yarn.exceptions.YarnRuntimeException: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.net.BindException: Problem binding to [ruyang-mn3.linkedin.biz:0] java.net.BindException: Can't assign requested address; For more details see:  http://wiki.apache.org/hadoop/BindException  at org.apache.hadoop.yarn.server.MiniYARNCluster.startResourceManager(MiniYARNCluster.java:327)  ... Caused by: java.net.BindException: Can't assign requested address  at sun.nio.ch.Net.bind0(Native Method)  It's because the test uses  InetAddress.getLocalHost().getHostName();  to get the host name and tries to bind to it.  The machine is issued at work. At home, the FQDN of the hostname is either not resolvable or the cached ip address is not reachable. Even on VPN, somehow the same error happened from time to time. The exact cause of that behavior on VPN is unknown yet.  It makes WFH more difficult.  The test will be simpler and more reliable if it simply uses ""localhost"".  ===  The comment in  org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell#checkHostname    * NetUtils.getHostname() returns a string in the form ""hostname/ip"".    * Sometimes the hostname we get is the FQDN and sometimes the short name. In    * addition, on machines with multiple network interfaces, it runs any one of    * the ips.  suggests some complexities involved with this method of calling InetAddress.getLocalHost()  === This test specifically checks for hostname patterns. Not sure why. This change will remove the check, which simplifies the test quite a bit.  Testing: The failed test succeeds and all the distributed shell tests and mini cluster tests succeed","closed","","HappyRay","2019-06-26T17:30:33Z","2019-07-17T21:35:10Z"
"","817","HDFS-14303: branch-2 scan only meta file produce block dir structure check warn fix","when scan a only meta file but no block file block, will produce a block structure warn eg:  WARN DirectoryScanner:? - Block: 1101939874 has to be upgraded to block ID-based layout. Actual block file path: /data14/hadoop/data/current/BP-1461038173-10.8.48.152-1481686842620/current/finalized/subdir174/subdir68, expected block file path: /data14/hadoop/data/current/BP-1461038173-10.8.48.152-1481686842620/current/finalized/subdir174/subdir68/subdir68  the cause is added a .getParentFile() call mistakenly","closed","","iamgd67","2019-05-14T06:31:56Z","2019-06-20T03:02:08Z"
"","958","HDDS-1677. Auditparser robot test shold use a world writable working directory","When I tried to reproduce a problem which is reported by [~eyang], I found that the auditparser robot test uses the /opt/hadoop directory as a working directory to generate the audit.db export.  /opt/hadoop is may or may not be writable, it's better to use /tmp instead.  See: https://issues.apache.org/jira/browse/HDDS-1677","closed","ozone,","elek","2019-06-13T08:18:10Z","2019-06-13T23:04:15Z"
"","1324","Fix a typo in TextInputFormat.java","When I read source code about TextInputFormat, I found a typo.","closed","","XBaith","2019-08-21T03:49:00Z","2019-08-21T08:22:19Z"
"","707","HDDS-1402. Remove unused ScmBlockLocationProtocol from ObjectStoreHandler","When I analyzed the usages of the available RPC protocols in Ozone I found that the ScmBlockLocationProtocol is not used in ObjectStore at all.  I would propose to remove it...  See: https://issues.apache.org/jira/browse/HDDS-1402","closed","ozone,","elek","2019-04-08T16:28:38Z","2019-04-17T02:16:54Z"
"","1247","HDDS-1926. The new caching layer is used for old OM requests but not updated.","When I am trying to add a test with restart manager, and then try to create the same volume, I am getting some NetUtils EOF exception. Will try to see why it is causing, if I am able to solve this issue, will post an Integration test for the scenario mentioned in the Jira.","closed","ozone,","bharatviswa504","2019-08-07T17:26:47Z","2019-08-08T14:08:29Z"
"","760","Add order text SPACE in CLI command 'hdfs dfsrouteradmin'","when execute cli comand 'hdfs dfsrouteradmin' ,the text in -order donot contain SPACE","closed","","chimney-lee","2019-04-23T07:03:52Z","2019-10-24T08:17:46Z"
"","1159","HDDS-1850. ReplicationManager should consider inflight replication and deletion while picking datanode for re-replication.","When choosing the target datanode for re-replication ReplicationManager should consider the datanodes which are in inflight replication and deletion for the same container.","closed","ozone,","nandakumar131","2019-07-25T09:38:29Z","2019-07-26T05:30:22Z"
"","1383","In YARN ui2 applications tab, If finishTime is 0, 'NA' should be displayed at this time, indicating that the task is not finished yet","When a spark app is running, the finishTime returned by the server is always 0, so the Finished time of the Application on the page is always shown as :1970/01/01 08:00, which is very unfriendly.If finishTime is 0, 'NA' should be displayed at this time, indicating that the task is not finished yet","closed","","echohlne","2019-08-30T11:42:00Z","2019-09-05T10:16:38Z"
"","976","YARN-2695. Added support for reservation continue looking with node labels","When a resource deprived node is scheduled by resource manager, capacity scheduler will reserve a container on this node even though there are resources available on other nodes. Since reserved containers take up headroom, sometimes resources available on other nodes will never be utilized. After this change, headroom calculation will include resources that could be unreserved on other nodes in the same partition, and unreserve the container after allocation of another container on the scheduled node.","open","","dpvelasquez","2019-06-17T03:15:38Z","2019-12-02T17:45:56Z"
"","1263","HDDS-1927. Consolidate add/remove Acl into OzoneAclUtil class. Contri…","What have been changed: 1. Change OzoneKeyInfo to use OzoneAcl instead of OzoneAclInfo 2. Adding OzoneAclUtil#addAcl, removeAcl to consolidate the logic applies to both bucket and key. Will file a separate ticket to fix volume as it is currently using OzoneAclMap. 3. Adding TestOzoneAclUtil to cover misc add/remove cases 3. Fix the defaultAcl merge issue when inheriting by using the OzoneAclUtil#addAcl 5. Fix failures in TestOzoneRpcClientAbract and its subclasses.","closed","ozone,","xiaoyuyao","2019-08-09T20:43:32Z","2019-08-21T23:49:42Z"
"","813","HDDS-1503. Reduce garbage generated by non-netty threads in datanode ratis server","We use GRPC protocol for rpc communication in Ratis. By default thread caches are generated even for non-netty threads. This Jira aims to add a default JVM parameter for disabling thread caches for non-netty threads in datanode ratis server.","closed","","lokeshj1703","2019-05-13T09:16:52Z","2019-05-14T09:20:24Z"
"","950","HDDS-1659. Define the process to add proposal/design docs to the Ozone subproject","We think that it would be more effective to collect all the design docs in one place and make it easier to review them by the community.  We propose to follow an approach where the proposals are committed to the hadoop-hdds/docs project and the review can be the same as a review of a PR  See: https://issues.apache.org/jira/browse/HDDS-1659","closed","ozone,","elek","2019-06-12T07:39:48Z","2019-08-14T00:10:37Z"
"","922","HDDS-1659. Define the process to add proposal/design docs to the Ozone subproject","We think that it would be more effective to collect all the design docs in one place and make it easier to review them by the community.  We propose to follow an approach where the proposals are committed to the hadoop-hdds/docs project and the review can be the same as a review of a PR  See: https://issues.apache.org/jira/browse/HDDS-1659","closed","ozone,","elek","2019-06-07T09:27:55Z","2019-06-12T06:53:43Z"
"","1501","HDDS-2067. Create generic service facade with tracing/metrics/logging support","We started to use a message based GRPC approach. Wen have only one method and the requests are routed based on a ""type"" field in the proto message.   For example in OM protocol:  {code} /**  The OM service that takes care of Ozone namespace. */ service OzoneManagerService {     // A client-to-OM RPC to send client requests to OM Ratis server     rpc submitRequest(OMRequest)           returns(OMResponse); } {code}  And   {code}  message OMRequest {   required Type cmdType = 1; // Type of the command  ... {code}  This approach makes it possible to use the same code to process incoming messages in the server side.  ScmBlockLocationProtocolServerSideTranslatorPB.send method contains the logic of:   * Logging the request/response message (can be displayed with ozone insight)  * Updated metrics  * Handle open tracing context propagation.   These functions are generic. For example OzoneManagerProtocolServerSideTranslatorPB use the same (=similar) code.  The goal in this jira is to provide a generic utility and move the common code for tracing/request logging/response logging/metrics calculation to a common utility which can be used from all the ServerSide translators.  See: https://issues.apache.org/jira/browse/HDDS-2067","closed","ozone,","elek","2019-09-23T11:07:39Z","2019-09-26T10:24:15Z"
"","943","HDDS-1666. Issue in openKey when allocating block.","We set size as below  final long size = args.getDataSize() >= 0 ?  args.getDataSize() : scmBlockSize;    and create OmKeyInfo with below size set. But when allocating Block for openKey, we use as below.  allocateBlockInKey(keyInfo, args.getDataSize(), currentTime);     I feel here, we should use size which is set above so that we allocate at least a block when the openKey call happens.  Current Code also works fine, but for readability I believe this should be good.","closed","ozone,","bharatviswa504","2019-06-11T04:23:20Z","2019-07-16T00:54:42Z"
"","1452","HDDS-2121. Create a shaded ozone filesystem (client) jar","We need a shaded Ozonefs jar that does not include Hadoop ecosystem components (Hadoop, HDFS, Ratis, Zookeeper).  A common expected use case for Ozone is Hadoop clients (3.2.0 and later) wanting to access Ozone via the Ozone Filesystem interface. For these clients, we want to add Ozone file system jar to the classpath, however we want to use Hadoop ecosystem dependencies that are `provided` and already expected to be in the client classpath.  Note that this is different from the legacy jar which bundles a shaded Hadoop 3.2.0.  See: https://issues.apache.org/jira/browse/HDDS-2121","closed","ozone,","elek","2019-09-16T11:58:52Z","2019-09-18T20:25:16Z"
"","1434","HDDS-2120. Remove hadoop classes from ozonefs-current jar","We have two kind of ozone file system jars: current and legacy. current is designed to work only with exactly the same hadoop version which is used for compilation (3.2 as of now).  But as of now the hadoop classes are included in the current jar which is not necessary as the jar is expected to be used in an environment where  the hadoop classes (exactly the same hadoop classes) are already there. They can be excluded.  See: https://issues.apache.org/jira/browse/HDDS-2120","closed","ozone,","elek","2019-09-12T18:08:06Z","2019-09-17T17:18:15Z"
"","1409","HDDS-2087. Remove the hard coded config key in ChunkManager","We have a hard-coded config key in the ChunkManagerFactory.java.  ``` boolean scrubber = config.getBoolean(  ""hdds.containerscrub.enabled"",  false); ```  This patch fixes the hard coded config key by referring to it from a constant.","closed","ozone,","vivekratnavel","2019-09-06T00:53:26Z","2019-09-09T03:44:07Z"
"","869","HDDS-1607. Create smoketest for non-secure mapreduce example","We had multiple problems earlier with the classpath separation and the internal ozonefs classloader. Before fixing all the issues I propose to create a smoketest to detect if the classpath separation is broken again .  As a first step I created an smoketest/ozone-mr environment (based on the  work of [~xyao], which is secure) and a smoketest   Possible follow-up works:   * Adapt the test.sh for the ozonesecure-mr  * Include test runs with older hadoop versions   See: https://issues.apache.org/jira/browse/HDDS-1607","closed","ozone,","elek","2019-05-29T11:47:42Z","2019-06-04T06:18:03Z"
"","1447","HDDS-2111. XSS fragments can be injected to the S3g landing page","VULNERABILITY DETAILS There is a way to bypass anti-XSS filter for DOM XSS exploiting a ""window.location.href"".  Considering a typical URL:  scheme://domain:port/path?query_string#fragment_id  Browsers encode correctly both ""path"" and ""query_string"", but not the ""fragment_id"".   So if used ""fragment_id"" the vector is also not logged on Web Server.  VERSION Chrome Version: 10.0.648.134 (Official Build 77917) beta  REPRODUCTION CASE This is an index.html page:   {code:java} aws s3api --endpoint document.write(window.location.href.replace(""static/"", """")) create-bucket --bucket=wordcount {code}   The attack vector is: index.html?#alert('XSS');  * PoC: For your convenience, a minimalist PoC is located on: http://security.onofri.org/xss_location.html?#alert('XSS');  * References - DOM Based Cross-Site Scripting or XSS of the Third Kind - http://www.webappsec.org/projects/articles/071105.shtml   reference:-   https://bugs.chromium.org/p/chromium/issues/detail?id=76796  See: https://issues.apache.org/jira/browse/HDDS-2111","closed","ozone,","elek","2019-09-14T03:34:40Z","2019-09-16T22:49:21Z"
"","1255","HDDS-1935. Improve the visibility with Ozone Insight tool","Visibility is a key aspect for the operation of any Ozone cluster. We need better visibility to improve correctnes and performance. While the distributed tracing is a good tool for improving the visibility of performance we have no powerful tool which can be used to check the internal state of the Ozone cluster and debug certain correctness issues.  To improve the visibility of the internal components I propose to introduce a new command line application `ozone insight`.  The new tool will show the selected metrics / logs / configuration for any of the internal components (like replication-manager, pipeline, etc.).  For each insight points we can define the required logs and log levels, metrics and configuration and the tool can display only the component specific information during the debug.  h2. Usage  First we can check the available insight point:  {code} bash-4.2$ ozone insight list Available insight points:     scm.node-manager                     SCM Datanode management related information.   scm.replica-manager                  SCM closed container replication manager   scm.event-queue                      Information about the internal async event delivery   scm.protocol.block-location          SCM Block location protocol endpoint   scm.protocol.container-location      Planned insight point which is not yet implemented.   scm.protocol.datanode                Planned insight point which is not yet implemented.   scm.protocol.security                Planned insight point which is not yet implemented.   scm.http                             Planned insight point which is not yet implemented.   om.key-manager                       OM Key Manager   om.protocol.client                   Ozone Manager RPC endpoint   om.http                              Planned insight point which is not yet implemented.   datanode.pipeline[id]                More information about one ratis datanode ring.   datanode.rocksdb                     More information about one ratis datanode ring.   s3g.http                             Planned insight point which is not yet implemented. {code}  Insight points can define configuration, metrics and/or logs. Configuration can be displayed based on the configuration objects:  {code} ozone insight config scm.protocol.block-location Configuration for `scm.protocol.block-location` (SCM Block location protocol endpoint)  >>> ozone.scm.block.client.bind.host        default: 0.0.0.0        current: 0.0.0.0  The hostname or IP address used by the SCM block client  endpoint to bind   >>> ozone.scm.block.client.port        default: 9863        current: 9863  The port number of the Ozone SCM block client service.   >>> ozone.scm.block.client.address        default: ${ozone.scm.client.address}        current: scm  The address of the Ozone SCM block client service. If not defined value of ozone.scm.client.address is used  {code}  Metrics can be retrieved from the prometheus entrypoint:  {code} ozone insight metrics scm.protocol.block-location Metrics for `scm.protocol.block-location` (SCM Block location protocol endpoint)  RPC connections    Open connections: 0   Dropped connections: 0   Received bytes: 0   Sent bytes: 0   RPC queue    RPC average queue time: 0.0   RPC call queue length: 0   RPC performance    RPC processing time average: 0.0   Number of slow calls: 0   Message type counters    Number of AllocateScmBlock: 0   Number of DeleteScmKeyBlocks: 0   Number of GetScmInfo: 2   Number of SortDatanodes: 0 {code}  Log levels can be adjusted with the existing logLevel servlet and can be collected / streamd via a simple logstream servlet:  {code} ozone insight log scm.node-manager [SCM] 2019-08-08 12:42:37,392 [DEBUG|org.apache.hadoop.hdds.scm.node.SCMNodeManager|SCMNodeManager] Processing node report from [datanode=ozone_datanode_1.ozone_default] [SCM] 2019-08-08 12:43:37,392 [DEBUG|org.apache.hadoop.hdds.scm.node.SCMNodeManager|SCMNodeManager] Processing node report from [datanode=ozone_datanode_1.ozone_default] [SCM] 2019-08-08 12:44:37,392 [DEBUG|org.apache.hadoop.hdds.scm.node.SCMNodeManager|SCMNodeManager] Processing node report from [datanode=ozone_datanode_1.ozone_default] [SCM] 2019-08-08 12:45:37,393 [DEBUG|org.apache.hadoop.hdds.scm.node.SCMNodeManager|SCMNodeManager] Processing node report from [datanode=ozone_datanode_1.ozone_default] [SCM] 2019-08-08 12:46:37,392 [DEBUG|org.apache.hadoop.hdds.scm.node.SCMNodeManager|SCMNodeManager] Processing node report from [datanode=ozone_datanode_1.ozone_default] {code}  The verbose mode can display the raw messages as well:  {code} [SCM] 2019-08-08 13:16:37,398 [DEBUG|org.apache.hadoop.hdds.scm.node.SCMNodeManager|SCMNodeManager] Processing node report from [datanode=ozone_datanode_1.ozone_default] [SCM] 2019-08-08 13:16:37,400 [TRACE|org.apache.hadoop.hdds.scm.node.SCMNodeManager|SCMNodeManager] HB is received from [datanode=ozone_datanode_1.ozone_default]:  storageReport {   storageUuid: ""DS-bffe6bee-1166-4502-acf5-57fc16c5aa98""   storageLocation: ""/data/hdds""   capacity: 470282264576   scmUsed: 16384   remaining: 205695963136   storageType: DISK   failed: false }  {code}  h2. Use cases  Ozone insight can be used for any kind of debuging. Some problem examples from my yesterday   1. Due to a cache problem the volumes were created twice without any error at the second time. With this tool I can check the state of the internal cache, or check if the volume is added to the rocksdb itself.   2. After fixing this problem we found an DNS caching issue. The OM responded with an error but it was not clear where the error was propagated from (it was created in OzoneManagerProtocolClientSideTranslatorPB.handleError). With checking the traffic between SCM and OM it can be easy to track the origin of a specific error.    4. After fixing this problem we found some pipline problem (reported later at HDDS-1933). With this tool I could check the content of the reports and messages to the pipeline manager.      h2. Implementation  We can implement the tool without any significant code change as it uses existing features:   * Metrics can be downloaded from the `/prom` endpoint  * Log Level can be set with the existing `/logLevel` servlet endpoint (from hadoop-common)  * Log lines can be streamed with a very simple new servlet  * Configuration can be displayed based on configuration points  A new interface can be introduced for `InsightPoint`s where all the affected logs/levels, metrics and config classes can be defined for each components.  Prometheus servlet endpoint can be changed to be turned on by default.  See: https://issues.apache.org/jira/browse/HDDS-1935","closed","ozone,","elek","2019-08-08T13:38:59Z","2019-08-30T00:07:55Z"
"","1458","HDDS-2016. Add option to enforce gdpr in Bucket Create command.","Verified by running in a local cluster as the previous patches for this feature covers the tests.","closed","ozone,","dineshchitlangia","2019-09-17T05:43:57Z","2019-09-19T13:55:44Z"
"","1635","HADOOP-16596. [pb-upgrade] Use shaded protobuf classes from hadoop-thirdparty dependency","Use the shaded protobuf classes from ""hadoop-thirdparty"" in hadoop codebase.  Depends on https://github.com/apache/hadoop-thirdparty/pull/1 for the hadoop-thordparty dependency","closed","","vinayakumarb","2019-10-10T05:40:43Z","2020-02-07T09:21:54Z"
"","1589","HDDS-2244. Use new ReadWrite lock in OzoneManager.","Use new ReadWriteLock added in HDDS-2223.  Existing tests should cover this.  Ran a few Integration tests.   Not removed Old methods in OzoneManagerLock, as it is used in Old write requests in VolumeManagerImpl/BucketManagerImpl/KeyManagerImpl. Marked those methods as deprecated.","closed","ozone,","bharatviswa504","2019-10-04T05:00:48Z","2019-10-09T10:10:34Z"
"","1494","HADOOP-16558. [COMMON+HDFS] use protobuf-maven-plugin to generate protobuf classes","Use ""protoc-maven-plugin"" to dynamically download protobuf executable to generate protobuf classes from proto files.","closed","","vinayakumarb","2019-09-21T04:33:22Z","2019-09-23T07:08:24Z"
"","1279","HDDS-1942. Support copy during S3 multipart upload part creation","Uploads a part by copying data from an existing object as data source  Documented here:  https://docs.aws.amazon.com/AmazonS3/latest/API/mpUploadUploadPartCopy.html  See: https://issues.apache.org/jira/browse/HDDS-1942","closed","ozone,","elek","2019-08-11T12:45:10Z","2019-08-28T19:53:13Z"
"","1132","SUBMARINE-66. Improve TF config env JSON generator + tests","Uploaded SUBMARINE-66.003.patch from the [corresponding jira](https://issues.apache.org/jira/browse/SUBMARINE-66). I hope yetus will pick it up, and it won't fail.","closed","","adamantal","2019-07-19T09:49:56Z","2019-09-03T07:09:42Z"
"","1176","HADOOP-16460 : Upgrading wildfly-openssl to latest 1.0.7.Final release version","Upgrading wildfly-openssl to latest 1.0.7.Final release version","closed","","snvijaya","2019-07-27T00:45:14Z","2021-07-28T03:14:36Z"
"","1483","HDDS-2001. Update Ratis version to 0.4.0.","Updating Ratis version to 0.4.0","closed","ozone,","nandakumar131","2019-09-20T11:01:20Z","2019-09-22T10:13:39Z"
"","948","HDDS-1649. On installSnapshot notification from OM leader, download checkpoint and reload OM state","Unit tests pending.","closed","ozone,","hanishakoneru","2019-06-11T21:21:51Z","2019-07-22T19:06:56Z"
"","1475","HDDS-2154. Fix Checkstyle issues","Unfortunately checkstyle checks didn't work well from HDDS-2106 to HDDS-2119.   This patch fixes all the issues which are accidentally merged in the mean time.   See: https://issues.apache.org/jira/browse/HDDS-2154","closed","ozone,","elek","2019-09-19T10:10:47Z","2019-09-19T18:31:09Z"
"","1359","HADOOP-16430. S3AFilesystem.delete to incrementally update s3guard with deletions","This started off as a performance improvement on very large directory trees: update the metastore table as pages of files are deleted.  But while coding it I discovered that while delete() updated S3Guard with changes, *it never used it to get a consistency directory listing*  That means recursive directory tree deletes could be inconsistent. This is bad. This PR  * Moves the delete code into its own DeleteOperation alongside the rename one * Both of which now share the same callbacks for a limited set of methods they can invoke on the S3A FS * Uses the s3guard enabled list to scan the dir tree, skipping the use of tombstones to invalidate entries (so recovers from OOB changes) * in auth mode, does a final raw S3 scan and cleanup, so even if that is inconsistent, all is good  Test changes as appropriate for debugging things, working out why InconsistentClient wasn't being inconsistent, etc, etc","closed","fs/s3,","steveloughran","2019-08-27T22:15:01Z","2021-10-15T19:50:47Z"
"","876","HDDS-1613. Opening of rocksDB in datanode fails with No locks available. Contributed by Mukul Kumar Singh.","This problem occurs because in the current container cache, if an eviction is being requested on an entry with a reference, the entry is removed from the map while reference is still held onto the rocksdb. This reference also has acquired the lock as well.  When another consumer tries to fetch the rockdb from the cache, it does not find the entry and now tries to acquire the lock, this step will fail as the other reference is holding the lock.  Tested this on MiniOzoneChaosCluster after the fix.","closed","ozone,","mukul1987","2019-05-30T19:21:37Z","2019-06-03T20:44:30Z"
"","1266","HDDS-1948. S3 MPU can't be created with octet-stream content-type","This problem is reported offline by [~shanekumpf@gmail.com].  When aws-sdk-go is used to access to s3 gateway of Ozone it sends the Multi Part Upload initialize message with ""application/octet-stream"" Content-Type.   This Content-Type is missing from the aws-cli which is used to reimplement s3 endpoint.  The problem is that we use the same rest endpoint for initialize and complete Multipart Upload request. For the completion we need the CompleteMultipartUploadRequest parameter which is parsed from the body.  For initialize we have an empty body which can't be serialized to CompleteMultipartUploadRequest.  The workaround is to set a specific content type from a filter which help up to create two different REST method for initialize and completion message.  Here is an example to test (using bogus AWS credentials).  {code} curl -H 'Host:yourhost' -H 'User-Agent:aws-sdk-go/1.15.11 (go1.11.2; linux; amd64)' -H 'Content-Length:0' -H 'Authorization:AWS4-HMAC-SHA256 Credential=qwe/20190809/ozone/s3/aws4_request, SignedHeaders=content-type;host;x-amz-acl;x-amz-content-sha256;x-amz-date;x-amz-storage-class, Signature=7726ed63990ba3f4f1f796d4ab263f5d9c3374528840f5e49d106dbef491f22c' -H 'Content-Type:application/octet-stream' -H 'X-Amz-Acl:private' -H 'X-Amz-Content-Sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855' -H 'X-Amz-Date:20190809T070142Z' -H 'X-Amz-Storage-Class:STANDARD' -H 'Accept-Encoding:gzip' -X POST 'http://localhost:9999/docker/docker/registry/v2/repositories/apache/ozone-runner/_uploads/2173f019-09c3-466b-bb7d-c31ce749d826/data?uploads {code}  Without the patch it returns with HTTP 405 (Not supported Media Type).  See: https://issues.apache.org/jira/browse/HDDS-1948","closed","ozone,","elek","2019-08-10T07:09:14Z","2019-08-23T06:15:44Z"
"","1508","HADOOP-16548 : Disable Flush() over config","This PR renders OutputStream Flush() API to no-op in AbfsOutputStream over a config control.   Hflush() being the only documented API that can provide persistent data transfer, Flush() also executing actions to persist buffered data was causing perf issues.  OutputStreams of WASB and ADLS drivers already have the Flush() as a no-op too.  Option to enable OutputStream Flush() over config is provided incase there are any customers who have taken a dependency on this.","closed","","snvijaya","2019-09-23T18:25:51Z","2019-09-29T03:51:52Z"
"","1151","HDDS-1853. Fix failing blockade test-cases.","This PR is to fix and make sure that all the test-cases in blockade are working.","closed","ozone,","nandakumar131","2019-07-24T14:11:28Z","2019-07-24T18:46:24Z"
"","964","HDDS-1675. Cleanup Volume Request 2 phase old code.","This PR is to clean up the old 2 phase HA code for Volume requests. This PR consists of cleanup changes. It has not added any new code changes. https://issues.apache.org/jira/browse/HDDS-1379","closed","ozone,","bharatviswa504","2019-06-13T22:56:45Z","2019-08-01T02:13:52Z"
"","1097","HDDS-1795. Implement S3 Delete Bucket request to use Cache and DoubleBuffer.","This PR is dependent on HDDS-1689. To get Jenkins run posted this along with HDDS-1689 PR.","closed","ozone,","bharatviswa504","2019-07-15T19:06:20Z","2019-07-20T00:43:24Z"
"","984","HDDS-1674 Make ScmBlockLocationProtocol message type based","This PR is a first attempt at refactoring the ScmBlockLocationProtocol using a single message type as is used in the OzoneManagerProtocol. In this change, the new message wraps the existing messages and the translator classes simply wrap or unwrap it.  Only TraceID has been moved to the wrapper message - Moving error handling and error codes to the wrapper will be done in a separate change.  Before this can be merged we still need to determine if the clientId should be present in the  ScmBlockLocationProtocol. It is in OzoneManagerProtocol and has been replicated here for now, but it can be removed if needed.","closed","ozone,","sodonnel","2019-06-18T10:56:39Z","2019-06-21T09:39:40Z"
"","1117","HADOOP-16437 documentation typo fix: fs.s3a.experimental.fadvise -> fs.s3a.experimental.input.fadvise","This PR fixes a typo in the Hadoop documentation: `fs.s3a.experimental.fadvise` should be `fs.s3a.experimental.input.fadvise` (the `.input` was missing previously).","closed","","JoshRosen","2019-07-18T00:25:42Z","2019-07-18T22:19:39Z"
"","954","HDDS-1670. Add limit support to /api/containers and /api/containers/{id} endpoints","This PR adds support for limit query param to limit the results of /api/containers and /api/containers/{id} endpoints. This will help the UI to load and show results faster with infinite scrolling.","closed","ozone,","vivekratnavel","2019-06-12T23:20:07Z","2019-06-18T18:56:10Z"
"","1064","HDDS-1585. Add LICENSE.txt and NOTICE.txt to Ozone Recon Web","This PR adds all copyright notices and licenses of third party dependencies of recon web to LICENSE file.","closed","ozone,","vivekratnavel","2019-07-09T03:45:09Z","2019-07-22T22:39:29Z"
"","1297","HDFS-14729. Upgrade Bootstrap and jQuery versions used in HDFS UIs","This patch updates the Bootstrap and jQuery versions used by different HDFS UIs like Namenode web UI, Datanode web UI etc.  Bootstrap 3.3.7 -> 3.4.1 jQuery 3.3.1 -> 3.4.1  Testing done: I tested the patch locally by bringing up HDFS in a [pseudo distributed mode](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html#Standalone_Operation) and manually browsing through UI components in localhost and made sure that there are no compatibility issues or errors thrown in the browser console. And I did not see any major change in the UI presentation as well.","closed","","vivekratnavel","2019-08-14T23:53:29Z","2019-08-20T16:10:43Z"
"","991","HADOOP-16382: clock skew can cause S3Guard to think object metadata is out of date","This patch sets the PathMetadata lastUpdated value from the lastModified value of the S3AFileStatus used in the constructor -the one later used to determine if a metastore entry is out of date.  In putWithTTL the time of the TTL provider is compared with the status value and whichever is highest sets the TTL.  Change-Id: I0ed2871df0b29a17c4df03a4b474c777290f2672","closed","","steveloughran","2019-06-19T16:12:53Z","2021-10-15T19:45:56Z"
"","1510","HDDS-2170. Add Object IDs and Update ID to Volume Object","This patch proposes to add object ID and update ID when a volume is created.","closed","ozone,","anuengineer","2019-09-23T23:26:08Z","2019-09-24T18:01:50Z"
"","1115","HADOOP-16207 testMR failures","This patch is the preamble to any fix: working out what is wrong. With a side benefit of running the tests much faster.  * Replaces the subclasses of the various committers with a paramterization of a single test. This is done via subclasses wihch define the specific test parameters and validate the output. * Which allows the tests to share the same cluster setup, rather than doing it once for each test * Makes the creation of an HDFS FS optional. As well as massively speeding up test setup, this means the logs of the test runs get collected.  Oh, and did I say it's faster? Not by much; it's still ~3 minutes, but I've cut the file size down on a scale test run (leave that for other testers).   Now all the logs from test runs go into target/yarn-${timestamp}; once you can find the relevant stdouts from the MR App master then you can see what's gone on. Added some details to the log messages to make it more meaningful  Testing: S3 Ireland with/without s3guard (dynamo)","closed","fs/s3,","steveloughran","2019-07-17T22:04:15Z","2021-10-15T19:47:55Z"
"","1230","HDDS-1895. Support Key ACL operations for OM HA.","This patch is dependent on HDDS-1884. Posted this PR on top of HDDS-1884. 2nd commit is the actual changes for this PR.","closed","ozone,","bharatviswa504","2019-08-05T23:06:12Z","2019-08-21T13:53:04Z"
"","1547","HDDS-1615. ManagedChannel references are being leaked in ReplicationS…","This patch fixes the leaks by closing the stream observers cleanly.","closed","ozone,","mukul1987","2019-09-30T07:32:18Z","2019-10-01T09:01:16Z"
"","1312","HDDS-1979. Fix checkstyle errors","This patch fixes checkstyle errors in ListPipelinesSubcommand.java","closed","ozone,","vivekratnavel","2019-08-17T22:49:41Z","2019-08-18T04:53:13Z"
"","784","HADOOP-16050: s3a SSL connections should use OpenSSL","This patch does the following: * Introduces a new S3A configuration parameter called `fs.s3a.ssl.channel.mode` (name was chosen to be consistent with the ABFS version `fs.azure.ssl.channel.mode`)     * By default, this config sets OpenSSL as the `SSLSocketFactory` for secure S3 connections; if OpenSSL is not available at runtime, then the default JSEE implementation is used * Moves `SSLSocketFactoryEx` from the azure module to hadoop-common and renames it to `OpenSSLSocketFactory`; this way it can be used by both ABFS and S3 * Adds a few unit tests for the new S3A logic + a few unit tests for `OpenSSLSocketFactory`  All core S3A itests were run against us-east-1 and they all passed (`ITestS3AContractDistCp` failed once, but worked on retry).  Right now this feature is enabled by default, but I'm opening to turning it off by default / marking it as experimental if we want to let it bake for a while.","closed","","sahilTakiar","2019-04-29T14:53:00Z","2019-05-31T21:30:12Z"
"","1407","HADOOP-16490. Avoid/handle cached 404s during S3A file creation","This patch avoids issuing any HEAD path request when creating a file with overwrite=true, so 404s will not end up in the S3 load balancers unless someone calls getFileStatus/exists in their own code   Special S3Guard FNFE retry policy independently configurable from other retry policies, * and use a setting with exponential backoff * new config names * copy raises a RemoteFileChangedException which is *not* caught in rename() and downgraded to false. Thus: when a rename is unrecoverable, this fact is propagated * tests for this * More logging @ debug in change policies as to policy type and when options are not set, as well as being set. Currently to work out the policy involves looking for the absence of messages, not the presence. It makes the file more verbose, but will aid with debugging these problems.   Also: tests turning auth mode on/off have to handle the auth state being set through an authoritative path, rather than a single flag. Caught me out as of course the first test I saw with this was the ITestS3ARemoteFileChanged rename ones, and I assumed that it was my new code. It was actually due to me setting an auth path last week.  This is a rebased successor to #1229  Change-Id: I7bb468aca0f4019537d82bc083f0a9887eaa282b","closed","","steveloughran","2019-09-05T17:52:57Z","2019-09-12T09:43:11Z"
"","1493","HDDS-2163. Add 'Replication factor' to the output of list keys","This patch adds replication factor to the output of list keys.  ``` bash-4.2$ ozone sh key list /vol1/bucket1 {   ""volumeName"" : ""vol1"",   ""bucketName"" : ""bucket1"",   ""name"" : ""dockerfile"",   ""dataSize"" : 876,   ""creationTime"" : 1569022651963,   ""modificationTime"" : 1569022654752,   ""replicationType"" : ""RATIS"",   ""replicationFactor"" : 1 } ```","closed","ozone,","vivekratnavel","2019-09-21T02:02:05Z","2019-09-21T05:59:46Z"
"","1049","HDDS-1758. Add replication and key deletion tests to MiniOzoneChaosCluster. Contributed by Mukul Kumar Singh.","This patch adds key deletion and replication manager capability to MiniOzoneChaosCluster.","closed","","mukul1987","2019-07-03T04:18:43Z","2019-07-05T11:34:41Z"
"","1442","HADOOP-16570. S3A committers encounter scale issues","This patch addresses scale issues  ## Thread pool leakage  explicitly shuts down the thread pool in job cleanup and after task commit, abort, job abort and job commit.  The alternative strategy would to be to always destroy the threads in the same method they were used, but as two operations are normally parallelized back-to-back: listing pending .files and then committing or aborting them, retaining the pool is useful. And there isn't any close() method or similar in the OutputCommitter interface to place it.  To test this, a probe for the committer having a thread pool was added, and the AbstractITCommitProtocol test extended to verify that there was no thread pool after the various commit and abort lifecycle operations.  To verify that the tests themselves were valid, the destroyThreadPool() initially *did not* actually destroy the pool; the fact that the modified tests then all failed providesd evidence that all paths followed in those tests successfully cleaned up. Once the method did close the thread pool, all these failing tests passed.  Note: I also switched to the HadoopExecutors thread pool factory; I considered moving to one of the caching thread pools but decided that I'd make this change simpler for ease of backport. For a trunk-only fix I'd consider asking the target S3A FS for its store context and creating a thread pool of it, which would just be a restricted fraction of the store's own pool.  ## OOM on job commit for jobs with many thousands of tasks, each generating tens of files.  Instead of loading all pending commits into memory as a single list, the list of files to load is the sole list which is passed around; .pendingset files are loaded and processed in isolation -and reloaded if necessary for any abort/rollback operation.  The parallel commit/abort/revert operations now work at the .pendingset level, rather than that of individual pending commit files. The existing parallelized Tasks API is still used to commit those files, but with a null thread pool, so as to serialize the operations.  This could slow down the commit operation in the following situations:-  * There is a significant skew in the number of files different tasks have created. The job will be blocked waiting for the largest tasks to complete. * There are very few tasks (less the size of the thread pool) but they each created many many files.  I am not going to worry about these.","closed","fs/s3,","steveloughran","2019-09-13T17:56:50Z","2021-10-15T19:47:56Z"
"","992","HADOOP-16357 TeraSort Job failing on S3 DirectoryStagingCommitter: destination path exists","This patch  * changes the default for the staging committer to append, as we get for the classic FOF committer * adds a check for the dest path being a file not a dir * adds tests for this * Changes `AbstractCommitTerasortIT.` to *not* use the simple parser, so fails if the file is present.  Testing: S3A Ireland w/ S3Guard. the Staging test failed, which makes me think that the settings weren't getting through","closed","fs/s3,","steveloughran","2019-06-19T21:44:28Z","2019-07-30T15:12:18Z"
"","1277","HDDS-1054. List Multipart uploads in a bucket","This Jira is to implement in ozone to list of in-progress multipart uploads in a bucket.  [https://docs.aws.amazon.com/AmazonS3/latest/API/mpUploadListMPUpload.html]     See: https://issues.apache.org/jira/browse/HDDS-1054","closed","ozone,","elek","2019-08-11T12:21:31Z","2019-09-19T18:06:02Z"
"","718","HDDS-1301. Optimize recursive ozone filesystem apis","This Jira aims to optimise recursive apis in ozone file system. These are the apis which have a recursive flag which requires an operation to be performed on all the children of the directory. The Jira would add support for recursive apis in Ozone manager in order to reduce the number of rpc calls to Ozone Manager. Also currently these operations are not atomic. This Jira would make all the operations in ozone filesystem atomic.","closed","","lokeshj1703","2019-04-10T10:52:23Z","2020-04-30T13:46:08Z"
"","1047","HDDS-1750. Add block allocation metrics for pipelines in SCM","This Jira aims to add block allocation metrics for pipelines in SCM. This would help in determining the distribution of block allocations among various pipelines in SCM.","closed","","lokeshj1703","2019-07-02T09:55:49Z","2019-07-09T03:12:56Z"
"","1022","HDDS-1728. Add metrics for leader's latency in ContainerStateMachine. Contributed by Mukul Kumar Singh.","This jira adds metrics around leaders latency for pipeline operations.","closed","ozone,","mukul1987","2019-06-27T08:09:51Z","2019-07-08T06:49:17Z"
"","709","HDDS-1388. Add a shell script to run MiniOzoneChaosCluster using mvn exec. Contributed by Mukul Kumar Singh.","This jira adds a shell script to run MiniOzoneChaosCluster.","closed","ozone,","mukul1987","2019-04-08T18:41:16Z","2019-04-10T01:15:09Z"
"","1332","HADOOP-16445. Allow separate custom signing algorithms for S3 and DDB","This is very similar to the original patch. In terms of testing - have run tests against a bucket in us-east-1 (including with the patch posted on HADOOP-16477). Struggling a bit with failures though, which seem completely unrelated to the patch. Still trying to get my test configuration file to a state where tests pass.","closed","","sidseth","2019-08-21T18:31:41Z","2019-09-21T06:20:46Z"
"","1353","HDDS-1927. Consolidate add/remove Acl into OzoneAclUtil class. Contri…","This is to verify cherry-pick HDDS-1927 from trunk to ozone-0.4.1  …buted by Xiaoyu Yao.  Signed-off-by: Anu Engineer  (cherry picked from commit d58eba867234eaac0e229feb990e9dab3912e063)","closed","ozone,","xiaoyuyao","2019-08-26T19:22:00Z","2019-08-28T00:40:17Z"
"","1518","HDFS-14678. Allow triggerBlockReport to a specific namenode (Backport from trunk)","This is to backport the patch from trunk to branch-2","closed","hdfs,","LeonGao91","2019-09-25T00:30:55Z","2019-12-09T19:40:13Z"
"","731","HADOOP-16118. S3Guard to support on-demand DDB tables (branch-3.2).","This is the first step for on-demand operations: things recognize when they are using on-demand tables, as do the tests.  Branch-3.2 patch; test run failing for unrelated changes to the AbstractS3GuardToolTestBase test suite, which highlight that we have enough S3Guard changes in trunk it's time to backport one by one.  Contributed by Steve Loughran.  Change-Id: I44cf87a2bd253b78c2d0414e4be20e920027c980","closed","","steveloughran","2019-04-12T01:05:51Z","2021-10-15T19:46:08Z"
"","1655","HADOOP-16629: support copyFile in s3afilesystem","This is subtask of HADOOP-16604 which aims to provide copy functionality for cloud native applications. Intent of this PR is to provide copyFile(URI src, URI dst) functionality for S3AFileSystem (HADOOP-16629).  Creating new PR due to a merge mess up in https://github.com/apache/hadoop/pull/1591.  Changes w.r.t PR:1591:  1. Fixed doc (filesystem.md) 2. Fixed AbstractContractCopyTest. 3. If file already exists in destination, it would overwrite dest file. 4. Added CompletableFuture support. `public CompletableFuture copyFile(URI srcFile, URI dstFile)`  CompletableFuture makes the API nicer. However, `CompletableFuture::get --> waitingAndGet` invokes `Runtime.getAvailableProcessors` frequently. This can turn out to be expensive native call depending on workload. We can optimise this later, if it turns out to be an issue.  If the destination bucket is different, relevant persmissions/policies have to be already setup, without which it would throw exceptions. Providing URI instead of path, makes it easier to mention different buckets on need basis. Since this is yet to stabilize in implemetation, we can make relevant changes in the store.   Testing was done in region=us-west-2 on my local laptop. Contract tests and huge file tests passed . Other tests are still running and I will post the results. (ITestS3AContractRename failed, but not related to this patch)","open","","rbalamohan","2019-10-14T13:56:41Z","2019-10-29T17:50:20Z"
"","1581","HADOOP-15870. S3AInputStream.remainingInFile should use nextReadPos","This is PR #433 in sync with trunk and with my tuning of the seek tests.  tested: s3 ireland *and* abfs and hdfs implementations of the contract seek tests also rerun.  If this is happy, I am going to merge","closed","","steveloughran","2019-10-03T10:10:05Z","2019-10-10T21:00:18Z"
"","1161","HADOOP-16461. Regression: FileSystem cache lock parses XML within the lock","This is PR #1157 submitted by me to kick yetus off.","closed","","steveloughran","2019-07-25T13:27:38Z","2021-10-15T19:45:46Z"
"","1679","HDFS-13934. Multipart uploaders to be created through FileSystem/FileContext.","This is my proposal for an API for multipart uploads through the FS, rather than via service loading.  It builds on the work done in createFile() and openFile() for builders and futures.  * a builder API for configuring the uploader, including specifying the permissions of uploaded files. * MultipartUploader is now interface; org.apache.hadoop.fs.impl.AbstractMultipartUploader is the base class for implementations to extend. * all the operations in the interface now return FutureCompletable; implementations can perform the operations synchronously or asynchronously. * there is a new common path capability for the hasPathCapabilities() probe.  FileSystemMultipartUploader and its builder moved to fs.impl; I needed a class org.apache.hadoop.fs.InternalOperations to get at rename/3 from the new package. It really is time to make the good rename method public.  S3AMultipartUploader moved to fs.s3a.impl, alongside its builder. The uploader does not get a reference to the base FS; it gets a StoreContext and WriteOperationHelper and has to work with them. All operations and now async and executed in the executor offered by the StoreContext.  Tests are all fixed up to cope with the changed API.  The builders can be created from the file system; we can also extend file context and the filter classes... Though I would not pass the operation through checksum FS as the uploads will not be checksummed.  One thing I am unsure about is viewFS: even though we can do with the remapping when the builder is created, the actual uploads need the full path in the store. That is unless, this and the WiP copy operation both take a path remapper in the builder which is then used to map from View FS paths to ones in their store. Suggestions here are welcome.  No changes into the specification; yet. Let's get feedback first.  Change-Id: Ib526fe6db8e9282c634181be231d4124ea6c78fc","closed","hdfs,","steveloughran","2019-10-25T17:22:17Z","2020-07-13T18:16:29Z"
"","952","HADOOP-16729 out of band deletes","This is Gabor's #802 PR rebased to trunk and with some extra changes on top","closed","","steveloughran","2019-06-12T16:05:37Z","2019-07-22T14:50:45Z"
"","1181","HDDS-1849. Implement S3 Complete MPU request to use Cache and DoubleBuffer.","This is dependent on HDDS-1856.  To get CI run, posted HDDS-1856 changes + HDDS-1849  in this PR.","closed","ozone,","bharatviswa504","2019-07-29T22:03:21Z","2019-07-31T16:18:40Z"
"","794","HADOOP-16085: use object version or etags to protect against inconsistent read after replace/overwrite","This is a new PR to replace #675 .  The only difference vs what is on #675 is a merge of the latest code from trunk, resolution of minor merge conflicts when doing so, and squash down to a single commit.  #675 is being closed as-is to preserve the discussion there.  I have performed a full test run on this (against us-west-2 with a bucket with versioning enabled) which passed without any failing tests:  ``` mvn -T 1C verify -Dparallel-tests -DtestsThreadCount=8 -Ds3guard -Ddynamo ``` ``` Tests run: 860, Failures: 0, Errors: 0, Skipped: 145 ```","closed","","ben-roling","2019-05-02T17:38:20Z","2019-05-21T21:14:48Z"
"","843","HADOOP-15183 S3Guard store becomes inconsistent after partial failure of rename","This is a major patch which has grown to become a ""fix up the final issues with Auth mode"" patch, built according to my proposed [refactoring S3A](https://github.com/steveloughran/engineering-proposals/blob/master/refactoring-s3a.md) design.  * new stuff goes into an o.a.h.fs.s3a.impl class to make clear its for implementation  ## Multi-object delete: *  `o.a.h.fs.s3a.impl.MultiObjectDeleteSupport` handles partial delete failures by parsing the response and updating the metastore with those deleted entries  ## rename (i.e. copy + delete), plus scale and perf of commits  Each metastore has the notion of * `BulkOperationState`; this can be used by a store to track entries which have been added/found during a set of operations (sequential or in parallel) * and a `RenameTracker` which implements the algorithm for updating the store on rename. The `DelayedUpdateTracker` implements the classic ""do it at the end"" algorithm, while the `ProgressiveRenameTracker` does it incrementally.  * and their own `addAncestors()` call which can update the bulk state based on examining the store and the current state of the `BulkOperationState`. This has been pushed down from `S3Guard.addAncestors()` to allow them to do their own thing with the bulk state.  `S3AFilesystem.innerRename` now copies in parallel; hard coded at 10 for now (having it a factor of the delete page size makes sense). each parallel copy operation notifies the current `RenameTracker` of its completion, so letting them choose what to do (`DelayedUpdate`: saves the change; `ProgressiveRenameTracker`: updates the store immediately).   The RenameTracker also has the homework of updating the store state on the case of a partial rename failure. `DelayedUpdateTracker`: update the metastore; ProgressiveUpdate: no-op.  Local and DDB metastores now only use the `ProgressiveRenameTracker`; this was done after I'd move the classic design into its own tracker (i.e out of S3AFileSystem). Oh, and theres a `NullRenameTracker` for the null metastore.  The BulkOperationState ends up being passed all the way to the committers; to avoid them explicitly having to understand this, the `CommitOperations` class now has an inner (non-static) `CommitContext` class which contains this and exports the commit/abort/revert operations for the committers to call. Internally it then invokes WriteOperationHelper calls with the context, which then gets all the way through to `S3AFileSystem.finishedWrite()` for the updates there to decide what entries to put into the store.  With this design * Renames are progressive and parallelized. So faster as well as keeping the the metastore consistent. * Bulk delete failures are handled * Commit operations don't generate excessive load on the store: if you are committing 500 files, then each parent dir will be checked ~once. (I say ~once as the get() is done out of a sync block, so multiple parallel entries may duplicate the work, but I'd rather that than lock during a remote RPC call).  Note that for both the parallelized commit and copy ops, we can also shuffle the source data so that we aren't doing it on the same lowest-level directory (what I'd expect today). That should reduce load on the S3 Store. With a move to parallel copy operations that will make a difference: the list comes in sequentially so the initial set of 10 renames will be adjacent. Actually I could be even cleverer there and sort by size. Why so? ensures that a large file doesn't become the straggler in the copy.","closed","","steveloughran","2019-05-22T10:45:34Z","2019-06-12T21:03:36Z"
"","1480","HDFS-14857. FS operations fail in HA mode: DataNode fails to connect to NameNode","This is a fix for HDFS-14857 where the datanode fails to reconnect to the namenode when the namenodes IP address(es) change in an HA environment.","open","hdfs,","jeffsaremi","2019-09-20T02:02:16Z","2022-01-28T02:29:14Z"
"","803","HADOOP-16085: S3Guard to use object version or etags (interim PR)","This is #794 with my edits added.","closed","","steveloughran","2019-05-08T17:58:55Z","2019-05-09T13:51:56Z"
"","1642","HDDS-2282. scmcli pipeline list command throws NullPointerException. …","This fix the scm cli that does not have a ca certificate by creating a scm security protocol client to retrieve the ca certificate before instantiate the xceiverclientmanger when security is enabled.  Note the ozone insight cli will have similar issue when security is enabled. We will fix that in a separate JIRA.","closed","ozone,","xiaoyuyao","2019-10-10T22:54:58Z","2019-10-11T05:33:59Z"
"","1012","HADOOP-16393. S3Guard init command uses global settings, not those of target bucket","This does the bucket propagation, and patches `ITestS3GuardToolDynamoDB.testDynamoTableTagging`  Tested: S3 ireland.  This has not added any new tests: IMO it should, so as to verify propagation. We could actually add it to the tagging test, maybe, though the real one I want to verify is that bucket ref","closed","fs/s3,","steveloughran","2019-06-25T18:03:57Z","2019-07-10T19:57:41Z"
"","849","HADOOP-16328: ClassCastException in S3GuardTool.checkMetadataStoreUri","This does not fix the problem; all it does is provide better diagnostics on a failure (and let someone with a debugger set a breakpoint)  Change-Id: Ife1da9135567fed60f69d7c628a8214e98064243","closed","","steveloughran","2019-05-24T15:24:17Z","2021-10-15T19:46:04Z"
"","1095","HDDS-1756. DeleteContainerCommandHandler fails with NPE.","This change will make delete container an idempotent operation in datanode.","closed","ozone,","nandakumar131","2019-07-15T13:54:51Z","2019-07-16T14:13:05Z"
"","918","HDDS-1622 Use picocli for StorageContainerManager","This change requires HDDS-1645 (increase Pico CLI verison to 3.9.6) before it can be committed, but it also contains the change to the POM so the build does not fail and the full test suit can run.  This chance is to change the CLI code used to start the SCM to use Pico CLI to make it consistent with the S3 gateway.","closed","ozone,","sodonnel","2019-06-06T13:27:21Z","2019-06-07T15:57:57Z"
"","1615","HDDS-2196 Add CLI Commands and Protobuf messages to trigger decom states","This change provides 3 new CLI commands:  ``` scmcli dnadmin decommission hostname1 hostname2 hostname3 scmcli dnadmin maintenance hostname1 hostname2 hostname3 < --end time from now to end maintenance in hours> scmcli dnadmin recommission hostname1 hostname2 hostname3 ```  To allow for cases where many DNs are on the same host, the hostname can also have a port appended, eg:  ``` scmcli dnadmin decommission hostname1:5678 hostname1:6789 hostname1:7890 ```  These commands make use of 3 new protobuf messages, defined in StorageContainerLocationProtocol:  ``` DecommissionNodesRequestProto + DecommissionNodesResponseProto RecommissionNodesRequestProto + RecommissionNodesResponseProto StartMaintenanceNodesRequestProto + StartMaintenanceNodesResponseProto ```  All 3 accept a list of strings (for hostnames) and the maintenance message also allows an int to specify the end time in hours.  These 3 commands make a call to a new class NodeDecommissionManager which takes the list of hosts and validates them. If any host is invalid or not part of the cluster, the entire command is failed and the CLI will show an error. Assuming the validation passes OK, the list of nodes will be switch into DECOMMISSIONING, ENTERING_MAINTENANCE or back into IN_SERVICE.  At this point in time, there is no decommission logic present, the nodes will simply remain in the interm state forever. The actual decommissioning logic will be added in a further Jira.","closed","ozone,","sodonnel","2019-10-08T09:28:53Z","2019-10-14T09:43:21Z"
"","1546","HADOOP-16614. [COMMON] Add aarch64 support of the dependent leveldbjni","This change add a `aarch64` profile for switching to using the `org.openlabtesting:leveldbjni` which can support aarch64 platform.","closed","","liusheng","2019-09-30T03:35:34Z","2019-10-25T01:08:44Z"
"","1545","HADOOP-16614. Add aarch64 support of the dependent leveldbjni","This change add a `aarch64` profile for switching to using the `org.openlabtesting:leveldbjni` which can support aarch64 platform.","closed","","liusheng","2019-09-30T03:29:09Z","2019-09-30T03:34:48Z"
"","924","HADOOP-16353. Backport ABFS changes from trunk to branch-3.2","This chain of cherrypicked patches from trunk fills out branch-3.2 with those changes which aren't there. It doesn't (yet) include the delegation token work because that change also does some POM changes to import bouncy-castle which would create build problems unless I changed it.  As these patches are already in trunk, this PR doesn't need voting on, it's a due diligence to make sure yetus is happy, and to give people who care an opportunity to suggest changes.","closed","","steveloughran","2019-06-07T13:52:57Z","2019-06-07T17:36:31Z"
"","1198","HDFS-14034: Support getQuotaUsage API in WebHDFS","This backports HDFS-14034 to branch-2.","closed","hdfs,","sunchao","2019-07-31T17:21:27Z","2019-08-01T17:44:41Z"
"","742","HADOOP-16252 add prefix to dynamo tables in tests","This adds a configurable prefix to the table names used in the dynamo tests so that they can be run by a user given dynamo permissions only on tables with the configured prefix.  I have successfully executed the full test suite with this change, my own prefix defined in auth-keys.xml, and a user with dynamo permissions only to tables with the configured prefix.  I executed the tests with: ``` mvn -T 1C verify -Dparallel-tests -DtestsThreadCount=8 -Ds3guard -Ddynamo ```  I did have to re-execute 3 of the tests individually due to transient failures:  ``` mvn -T 1C verify -Dtest=skip -Dit.test=ITestS3AFileSystemContract -Ds3guard -Ddynamo mvn -T 1C verify -Dtest=skip -Dit.test=ITestS3AEmptyDirectory -Ds3guard -Ddynamo mvn -T 1C verify -Dtest=skip -Dit.test=ITestS3AContractGetFileStatusV1List -Ds3guard -Ddynamo ```","closed","","ben-roling","2019-04-15T18:33:37Z","2019-04-24T13:57:29Z"
"","1054","HADOOP-16409. Allow authoritative mode on non-qualified paths.","This addresses whitespace nits from Gabor's review of https://github.com/apache/hadoop/pull/1043, and allows non-qualified paths to be specified in the config.","closed","","mackrorysd","2019-07-03T21:17:13Z","2019-07-08T17:27:08Z"
"","835","HADOOP-15183 S3Guard store becomes inconsistent after partial failure of rename","This addresses  * HADOOP-15183: S3Guard store becomes inconsistent after partial failure of rename * HADOOP-13936 S3Guard: DynamoDB can go out of sync with S3AFileSystem::delete operation * HADOOP-15604 Bulk commits of S3A MPUs place needless excessive load on S3 & S3Guard","closed","","steveloughran","2019-05-20T19:18:57Z","2021-10-15T19:46:06Z"
"","1488","HDDS-2159. Fix Race condition in ProfileServlet#pid.","There is a race condition in ProfileServlet. The Servlet member field pid should not be used for local assignment. It could lead to race condition.","closed","ozone,","hanishakoneru","2019-09-20T20:07:38Z","2019-09-24T00:32:08Z"
"","1476","HDDS-2127. Detailed Tools doc not reachable","There are two doc pages for tools:  * docs/beyond/tools.html  * docs/tools.html  The latter is more detailed (has subpages for several tools), but it is not reachable (even indirectly) from the start page.  Not sure if this is intentional.  On a related note, it has two ""Testing tools"" sub-pages. One of them is empty and should be removed.  See: https://issues.apache.org/jira/browse/HDDS-2127","closed","ozone,","elek","2019-09-19T12:42:09Z","2019-09-19T16:54:53Z"
"","1042","YARN-9661. Fix typos in LocalityMulticastAMRMProxyPolicy and AbstractConfigurableFederationPolicy","There are some typo in LocalityMulticastAMRMProxyPolicy.java and AbstractConfigurableFederationPolicy.java","closed","","hunshenshi","2019-07-01T13:08:51Z","2019-07-01T17:46:34Z"
"","764","HDFS-14455:Fix typo in HAState.java","There are some typo in HAState  destructuve -> destructive  Aleady -> Already  Transtion -> Transition","closed","","hunshenshi","2019-04-24T09:31:28Z","2019-08-08T11:26:13Z"
"","1540","HDDS-2198. SCM should not consider containers in CLOSING state to come out of safemode.","There are cases where SCM can be stuck in safemode for ever if it considers containers in CLOSING state for coming out of safemode  * If there are 5 containers in OPEN state inside SCM * Out of 5, 3 containers are created in datanodes by the client. * 2 containers are yet to be created in datanodes * Due to some pipeline issue, pipeline close action is sent. * All 5 container's state are changed from OPEN to CLOSING in SCM. * Eventually , 3 container's state moves from CLOSING to CLOSED in SCM as the datanodes closes those containers. * 2 of the containers are still in CLOSING state. * SCM is restarted. * SCM will never gets container reports for the containers which were in CLOSING state as those containers were never created in datanodes. * SCM will remain in safemode.","closed","ozone,","nandakumar131","2019-09-27T18:44:14Z","2019-10-04T02:51:03Z"
"","882","HDDS-1624 : Refactor operations inside the bucket lock in OM key write.","There are a few steps that are done inside the OM bucket lock that are lock invariant and can be done outside the lock. This patch refactors those steps. It also adds an isExist API in the metadata store so that we dont need to deserialize the byte[] to Object while doing a simple table.get(key) != null check.  On applying the patch, the OM + SCM (With dummy datanodes) write performance improves by around 3x.  Thanks to @nandakumar131  who helped with this patch.","closed","ozone,","avijayanhwx","2019-05-31T20:26:17Z","2019-06-04T22:41:38Z"
"","1596","HDDS-2233 - Remove ByteStringHelper and refactor the code to the place where it used","There are a couple of things in this pull request. ByteStringHelper was used in two general places, once in BlockOutputStream, and once in ChunkUtils. ChunkUtils was an easy one, as in that case the method was used directly from KeyValueHandler only, where the configuration is present. I moved the logic back to the KeyValueHandler class, and at initialization time, I created the proper converter based on the config. At this point I realized that we use byte[] type in readChunk like methods here and there, but at the end most of the usage outside is via a ByteBuffer after a ByteBuffer.wrap(byte[]) call, so I changed the readChunk logic to return a ByteBuffer instead, and used that one, with this I eliminated the need of a conversion from byte[] to ByteString.  BlockOutputStream was a bit harder, as in that case, RPCClient initialized the old class with the config. The decision became the following: based on the Configuration, RPCClient already created an XCeiverClientManager that preserved a reference to the configuration, and which was already available in the BlockOutputStreamEntryPool class, that uses a BufferPool to create the buffers in BlockOutputStream, so that BlockOutputStream when does the conversion can reach it via its BufferPool.  I have cleaned up one code path, that came into my way during implementation, and I removed two declared exception from ChunkUtils.readData, and with that eliminated the need for a try-catch block in the place where it is called.","closed","ozone,","fapifta","2019-10-04T12:40:04Z","2019-10-09T05:59:10Z"
"","1082","HDDS-1790. Fix checkstyle issues in TestDataScrubber.","There are 4 Checkstyle issues in TestDataScrubber that has to be fixed ``` [ERROR] src/test/java/org/apache/hadoop/ozone/dn/scrubber/TestDataScrubber.java:[157] (sizes) LineLength: Line is longer than 80 characters (found 81). [ERROR] src/test/java/org/apache/hadoop/ozone/dn/scrubber/TestDataScrubber.java:[161] (sizes) LineLength: Line is longer than 80 characters (found 82). [ERROR] src/test/java/org/apache/hadoop/ozone/dn/scrubber/TestDataScrubber.java:[167] (sizes) LineLength: Line is longer than 80 characters (found 85). [ERROR] src/test/java/org/apache/hadoop/ozone/dn/scrubber/TestDataScrubber.java:[187] (sizes) LineLength: Line is longer than 80 characters (found 104). ```","closed","ozone,","nandakumar131","2019-07-12T09:39:07Z","2019-07-12T14:53:20Z"
"","1649","YARN-9881. Change Cluster_Scheduler_API's Item memory‘s datatype from int to long.","The Yarn Rest http://rm-http-address:port/ws/v1/cluster/scheduler document, In hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html#Cluster_Scheduler_API, change Item memory‘s datatype from int to long. 1.change Capacity Scheduler API's item [memory]'s dataType from int to long. 2. change Fair Scheduler API's item [memory]'s dataType from int to long.","open","","cjn082030","2019-10-12T09:43:37Z","2020-11-05T06:49:42Z"
"","1645","YARN-9881. Change Cluster_Scheduler_API's Item memory‘s datatype from int to long.","The Yarn Rest http://rm-http-address:port/ws/v1/cluster/scheduler document, In hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html#Cluster_Scheduler_API, change Item memory‘s datatype from int to long. 1.change Capacity Scheduler API's item [memory]'s dataType from int to long. 2. change Fair Scheduler API's item [memory]'s dataType from int to long.","closed","","cjn082030","2019-10-11T12:19:16Z","2019-10-12T09:46:34Z"
"","1398","HDDS-2064. OzoneManagerRatisServer#newOMRatisServer throws NPE when OM HA is configured incorrectly","The WIP patch can prevent NPE in `TestOzoneManagerConfiguration` unit test `testWrongConfigurationNoOMNodes` and `testWrongConfigurationNoOMAddrs`.  Before the second commit, it fails `testWrongConfiguration` and `testMultipleOMServiceIds`. - The reasons of the failures are that there is another logic checking `isOMAddressSet` right after my patch in `OzoneManager`. And those unit tests are expecting a different exception.  The second commit has addressed the unit test failures. Please review.","closed","ozone,","smengcl","2019-09-03T19:58:08Z","2019-11-05T15:57:44Z"
"","909","HDDS-1645 Change the version of Pico CLI to the latest 3.x release - 3.9.6","The version of Pico CLI used in the project is 3.5.2. The current stable release is 3.9.6 and it supports some good new features, such as being able to create sub-commands as methods rather than standalone classes.  We should increase the Pico CLI version in the project pom.xml to 3.9.6 to take advantage of these new features as the CLI code is refactored to use Pico CLI, such as in HDDS-1622.","closed","ozone,","sodonnel","2019-06-05T09:42:47Z","2019-06-06T14:20:24Z"
"","862","HDDS-1341. TestContainerReplication#testContainerReplication fails intermittently","The test fails intermittently. The link to the test report can be found below.  https://builds.apache.org/job/PreCommit-HDDS-Build/2582/testReport/  ``` java.lang.AssertionError: Container is not replicated to the destination datanode 	at org.junit.Assert.fail(Assert.java:88) 	at org.junit.Assert.assertTrue(Assert.java:41) 	at org.junit.Assert.assertNotNull(Assert.java:621) 	at org.apache.hadoop.ozone.container.TestContainerReplication.testContainerReplication(TestContainerReplication.java:139) 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) 	at java.lang.reflect.Method.invoke(Method.java:498) 	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47) 	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) 	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44) 	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) 	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74) ```  See: https://issues.apache.org/jira/browse/HDDS-1341","closed","ozone,","elek","2019-05-28T09:02:05Z","2019-05-28T21:40:46Z"
"","715","HDDS-1370. Command Execution in Datanode fails becaue of NPE","The reason for this can be if we take more time in executing a task, and in taskAwait we will return state as RUNNING and continue, and now when we execute task again internally endPoint state can be shutdown. Below code can return null. So, we need a null check over there.  Callable endpointTask           = getEndPointTask(endpoint);","closed","ozone,","bharatviswa504","2019-04-10T01:51:15Z","2019-04-10T17:25:29Z"
"","1032","[HDDS-1201] Reporting corrupted containers info to SCM","The previous patch for this jira did not implement the logic completely. Also there was no integration test to verify end-to-end functionality. Both these issues have been fixed as part of this change.","closed","ozone,","hgadre","2019-06-28T20:37:31Z","2019-07-12T15:14:10Z"
"","1207","Hadoop 16479","The pattern to parse the timezone was wrong. Corrected the same.","closed","","bilaharith","2019-08-01T11:26:49Z","2019-08-08T18:09:23Z"
"","1330","HDDS-2000. Don't depend on bootstrap/jquery versions from hadoop-trunk snapshot","The OM/SCM web pages are broken due to the upgrade in HDFS-14729 (which is a great patch on the Hadoop side). To have more stability I propose to use our own instance from jquery/bootstrap instead of copying the actual version from hadoop trunk which is a SNAPSHOT build.  See: https://issues.apache.org/jira/browse/HDDS-2000","closed","ozone,","elek","2019-08-21T14:42:28Z","2019-08-22T19:01:51Z"
"","1142","YARN-9692. ContainerAllocationExpirer is missspelled","The old fully name is org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer. I changed to  org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpired.","open","","wuyinxian124","2019-07-23T03:26:10Z","2019-09-03T03:25:17Z"
"","822","HDDS-1527. HDDS Datanode start fails due to datanode.id file read error","The modification here is to load id file as yaml and if that fails, log the exception and load as protobuf. The case where yaml file is corrupted, we would still throw an exception after trying to load protobuf with the error in the log file.","closed","","swagle","2019-05-15T19:45:26Z","2019-05-16T22:13:10Z"
"","1448","HDDS-2110. Arbitrary file can be downloaded with the help of ProfilerServlet","The LOC 324 in the file [ProfileServlet.java|https://github.com/apache/hadoop/blob/217bdbd940a96986df3b96899b43caae2b5a9ed2/hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/server/ProfileServlet.java] is prone to an arbitrary file download:- {code:java} protected void doGetDownload(String fileName, final HttpServletRequest req,      final HttpServletResponse resp) throws IOException {  File requestedFile = ProfileServlet.OUTPUT_DIR.resolve(fileName).toAbsolutePath().toFile();{code} As the String fileName is directly considered as the requested file.     Which is called at LOC 180 with HTTP request directly passed:- {code:java} if (req.getParameter(""file"") != null) {      doGetDownload(req.getParameter(""file""), req, resp);       return;     } {code}    See: https://issues.apache.org/jira/browse/HDDS-2110","closed","ozone,","elek","2019-09-14T04:19:29Z","2019-09-19T16:43:20Z"
"","1072","HDDS-1766. ContainerStateMachine is unable to increment lastAppliedTermIndex. Contributed by  Mukul Kumar Singh.","The last applied term index wasn't updated as the method is called by multiple executors and the method was not synchronized.","closed","ozone,","mukul1987","2019-07-10T12:34:53Z","2019-07-14T05:23:51Z"
"","1684","MAPREDUCE-7247. Modify HistoryServerRest.html content,change The job attempt id‘s datatype from string to int","The Job Attempts API http://history-server-http-address:port/ws/v1/history/mapreduce/jobs/{jobid}/jobattempts document, In http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/HistoryServerRest.html#Job_Attempts_API, change The job attempt id‘s datatype from string to int.","closed","","kevinzhao1661","2019-10-30T00:52:41Z","2020-01-16T03:57:33Z"
"","1138","HADOOP-16443 Improve help text for setfacl --set option","The help text associated with the command ""setfacl --set"" states:  ``` --set     Fully replace the ACL, discarding all existing entries. The                       must include entries for user, group, and others for                  compatibility with permission bits.                ``` However the actual behaviour is a bit more subtle:  >    If the ACL spec contains only access entries, then the existing default entries are retained. If the ACL spec contains only default entries, then the existing access entries are retained. If the ACL spec contains both access and default entries, then both are replaced.  This PR will improve the help text to more align with the expected behaviour.","closed","","sodonnel","2019-07-22T16:57:53Z","2019-07-23T09:26:46Z"
"","799","HDDS-1451 : SCMBlockManager findPipeline and createPipeline are not lock protected.","The getPipelines() and createPipeline() already seem to have a lock in their implementation. However, the problem described here involves a race condition between the call to getPipelines and createPipelines in BlockManagerImpl#allocateBlock. The fix is to add another getPipelines check after a failed createPipeline call to get any newly created pipelines.","closed","ozone,","avijayanhwx","2019-05-07T20:40:01Z","2019-05-20T20:02:57Z"
"","1576","HADOOP-16520 dynamodb ms version race refactor.","The following should be included: HADOOP-16349. DynamoDBMetadataStore.getVersionMarkerItem() to log at info/warn on retry.   Notes:  - Why there's no ITestDynamoDBMetadataStoreTableHandler if there's ITestDynamoDBMetadataStore, and why do I added the tests there? For readability and to avoid duplication. DynamoDBMetadataStoreTableHandler is just basically parts factored out from DynamoDBMetadataStore, and some helper methods.  - Why there's only testTableVersioning->checkVerifyVersionMarkerCompatibility to cover the full functionality of the version marker checking and recovery with dynamo, and not 6 different methods? Creating and deleting tables takes a *lot* of time. Minutes. I use the same table during the test and add/remove the version tag and item to cover all combinations.  - Why there's log on info level at DynamoDBMetadataStoreTableHandler#verifyVersionCompatibility? I think it's useful for know what's going on with the versions. It's not a lot logging at that level, but I find it useful.   Things to add: - md docs about version handling - I'll add once we settled with the implementation - maybe more tests: imho the test coverage is good enough, and adding more test will take more and more testing time. But I can try to add some _non_-integration (so simple junit, surefire) tests if asked.  Tested against ireland. Some tables won't be deleted for me so I get a timeout. I don't think that's related, maybe I'm just over the limit of creating and deleting tables now.","closed","","bgaborg","2019-10-02T15:00:19Z","2019-10-11T10:08:57Z"
"","1456","HDDS-2139. Update BeanUtils and Jackson Databind dependency versions.","The following Ozone dependencies have known security vulnerabilities. We should update them to newer/ latest versions. - Apache Common BeanUtils version 1.9.3 - Fasterxml Jackson version 2.9.5","closed","ozone,","hanishakoneru","2019-09-17T01:22:18Z","2019-09-18T00:39:49Z"
"","1374","HDDS-2050. Error while compiling ozone-recon-web","The following error was seen while compiling ozone-recon-web  ``` [INFO] Running 'yarn install' in /Users/nvadivelu/codebase/apache/hadoop/hadoop-ozone/ozone-recon/src/main/resources/webapps/recon/ozone-recon-web [INFO] yarn install v1.9.2 [INFO] [1/4] Resolving packages... [INFO] [2/4] Fetching packages... [ERROR] (node:31190) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead. [INFO] [3/4] Linking dependencies... [ERROR] warning "" > less-loader@5.0.0"" has unmet peer dependency ""webpack@^2.0.0 || ^3.0.0 || ^4.0.0"". [INFO] [4/4] Building fresh packages... [ERROR] warning Error running install script for optional dependency: ""/Users/nvadivelu/codebase/apache/hadoop/hadoop-ozone/ozone-recon/src/main/resources/webapps/recon/ozone-recon-web/node_modules/fsevents: Command failed. [ERROR] Exit code: 1 [ERROR] Command: node install [ERROR] Arguments: [ERROR] Directory: /Users/nvadivelu/codebase/apache/hadoop/hadoop-ozone/ozone-recon/src/main/resources/webapps/recon/ozone-recon-web/node_modules/fsevents [ERROR] Output: [ERROR] node-pre-gyp info it worked if it ends with ok [INFO] info This module is OPTIONAL, you can safely ignore this error [ERROR] node-pre-gyp info using node-pre-gyp@0.12.0 [ERROR] node-pre-gyp info using node@12.1.0 | darwin | x64 [ERROR] node-pre-gyp WARN Using request for node-pre-gyp https download [ERROR] node-pre-gyp info check checked for \""/Users/nvadivelu/codebase/apache/hadoop/hadoop-ozone/ozone-recon/src/main/resources/webapps/recon/ozone-recon-web/node_modules/fsevents/lib/binding/Release/node-v72-darwin-x64/fse.node\"" (not found) [ERROR] node-pre-gyp http GET https://fsevents-binaries.s3-us-west-2.amazonaws.com/v1.2.8/fse-v1.2.8-node-v72-darwin-x64.tar.gz [ERROR] node-pre-gyp http 404 https://fsevents-binaries.s3-us-west-2.amazonaws.com/v1.2.8/fse-v1.2.8-node-v72-darwin-x64.tar.gz [ERROR] node-pre-gyp WARN Tried to download(404): https://fsevents-binaries.s3-us-west-2.amazonaws.com/v1.2.8/fse-v1.2.8-node-v72-darwin-x64.tar.gz [ERROR] node-pre-gyp WARN Pre-built binaries not found for fsevents@1.2.8 and node@12.1.0 (node-v72 ABI, unknown) (falling back to source compile with node-gyp) [ERROR] node-pre-gyp http 404 status code downloading tarball https://fsevents-binaries.s3-us-west-2.amazonaws.com/v1.2.8/fse-v1.2.8-node-v72-darwin-x64.tar.gz [ERROR] node-pre-gyp ERR! build error [ERROR] node-pre-gyp ERR! stack Error: Failed to execute 'node-gyp clean' (Error: spawn node-gyp ENOENT) [ERROR] node-pre-gyp ERR! stack     at ChildProcess. (/Users/nvadivelu/codebase/apache/hadoop/hadoop-ozone/ozone-recon/src/main/resources/webapps/recon/ozone-recon-web/node_modules/fsevents/node_modules/node-pre-gyp/lib/util/compile.js:77:29) [ERROR] node-pre-gyp ERR! stack     at ChildProcess.emit (events.js:196:13) [ERROR] node-pre-gyp ERR! stack     at Process.ChildProcess._handle.onexit (internal/child_process.js:254:12) [ERROR] node-pre-gyp ERR! stack     at onErrorNT (internal/child_process.js:431:16) [ERROR] node-pre-gyp ERR! stack     at processTicksAndRejections (internal/process/task_queues.js:84:17) [ERROR] node-pre-gyp ERR! System Darwin 18.5.0 [ERROR] node-pre-gyp ERR! command \""/Users/nvadivelu/codebase/apache/hadoop/hadoop-ozone/ozone-recon/target/node/node\"" \""/Users/nvadivelu/codebase/apache/hadoop/hadoop-ozone/ozone-recon/src/main/resources/webapps/recon/ozone-recon-web/node_modules/fsevents/node_modules/node-pre-gyp/bin/node-pre-gyp\"" \""install\"" \""--fallback-to-build\"" [ERROR] node-pre-gyp ERR! cwd /Users/nvadivelu/codebase/apache/hadoop/hadoop-ozone/ozone-recon/src/main/resources/webapps/recon/ozone-recon-web/node_modules/fsevents [ERROR] node-pre-gyp ERR! node -v v12.1.0 [ERROR] node-pre-gyp ERR! node-pre-gyp -v v0.12.0 [ERROR] node-pre-gyp ERR! not ok [ERROR] Failed to execute 'node-gyp clean' (Error: spawn node-gyp ENOENT)"" [INFO] Done in 102.54s. ```  I fixed these node-pre-gyp and fsevents install errors by rebuilding yarn cache and yarn lock file and updating the dependencies to latest versions.  Tested in both ozone-0.4.1 and trunk branches and verified that these errors are not thrown during ozone-recon-web compilation.","closed","ozone,","vivekratnavel","2019-08-29T00:23:32Z","2019-08-29T23:57:03Z"
"","1472","HDDS-2150. Update dependency versions to avoid security vulnerabilities.","The following dependency versions have known security vulnerabilities. We should update them to recent/ later versions. - Apache Thrift 0.11.0 (dependency of JaegerTracing) - Apache Zookeeper 3.4.13 - Jetty Servlet 9.3.24","closed","ozone,","hanishakoneru","2019-09-18T21:45:44Z","2019-09-21T06:21:54Z"
"","844","HDDS-1582. Fix BindException due to address already in use in unit tests. Contributed by Mukul Kumar Singh.","The fix is to use Socket.bind in place of server sockets. The biggest difference is that ServerSocket will do accept and listen after binding to the socket and this will keep the sockets in TIME_WAIT state after close. Please refer, https://docs.oracle.com/javase/tutorial/networking/sockets/definition.html","closed","","mukul1987","2019-05-22T15:59:54Z","2019-08-28T22:28:07Z"
"","1030","ArrayList is not thread safe. Field timedOutItems is typically protected by synchronization on itself. However, in one place, the field is inside a synchronized on a different object, which does not ensure protection","The field ```timedOutItems```  (an ```ArrayList```, i.e., not thread safe):  https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/PendingReconstructionBlocks.java#L70  is protected by synchronization on itself (```timedOutItems```):  https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/PendingReconstructionBlocks.java#L167-L168  https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/PendingReconstructionBlocks.java#L267-L268  https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/PendingReconstructionBlocks.java#L178  However, in one place:  https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/PendingReconstructionBlocks.java#L133-L135  it is (trying to be) protected by synchronized using ```pendingReconstructions``` --- but this cannot protect ```timedOutItems```.  Synchronized on different objects does not ensure mutual exclusion with the other locations.  I.e., 2 code locations, one synchronized by ```pendingReconstructions``` and the other by ```timedOutItems``` can still executed concurrently.   This CR adds the synchronized on ```timedOutItems```.  Note that this CR keeps the synchronized on ```pendingReconstructions```, which is needed for a different purpose (protect ```pendingReconstructions```)","closed","","paulward24","2019-06-28T18:41:57Z","2019-06-28T23:06:44Z"
"","1015","HashMap is not thread safe. Field storageMap is typically synchronized by storageMap. However, in one place, field storageMap is not protected with synchronized.","The field ```storageMap```  (a ```HashMap```)  https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java#L155  is typically protected by synchronization on ```storageMap```, e.g.,   https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java#L294  https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java#L443  https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java#L484  For a total of 9 locations.  The reason is because ```HashMap``` is not thread safe.  However, here:  https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java#L455  ``` DatanodeStorageInfo storage =   storageMap.get(report.getStorage().getStorageID()); ```  It is not synchronized.  Note that in the same method (about 30 lines below):  https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java#L484  ```storageMap``` is again protected by synchronization:  ``` synchronized (storageMap) {   storageMapSize = storageMap.size(); } ```  This CR protected the above instance (line 455 ) with synchronization like in line 484 and in all other occurrences.","closed","","paulward24","2019-06-25T23:49:45Z","2019-07-01T20:54:50Z"
"","1644","YARN-9511. [YARN] Set the default permissions of test jar file(WIP)","The default permissions of created file will due to the `umask` of system. that may cause some tests of TestAuxServices failure, because the tests need to check the permissions. This change will do:  - Set the default permissions of test jar file to *owner read write* - Set the default permissions of test manifest file to *owner read write*","closed","","liusheng","2019-10-11T01:47:03Z","2019-11-25T01:43:42Z"
"","708","HDDS-1401. Static ContainerCache in Datanodes can result in overwrite of container db. Contributed by Mukul Kumar Singh.","The datanodes use a static Container cache, and this container cache is key'd using the container ID. In a MiniOzoneCluster environment, this can lead to multiple container on different datanodes to use the same rocksdb leading to inconsistency.","closed","ozone,","mukul1987","2019-04-08T17:56:44Z","2019-04-10T12:30:10Z"
"","1232","HDDS-1914. Ozonescript example docker-compose cluster can't be started","the compose/ozonescripts cluster provides an example environment to test the start-ozone.sh and stop-ozone.sh scripts.  It starts containers with sshd daemon but witout starting the ozone which makes it possible to start those scripts.  Unfortunately the docker files are broken since:  * we switched from debian to centos with the base image  * we started to use /etc/hadoop instead of /opt/hadoop/etc/hadoop for configuring the hadoop (workers file should be copied there)  * we started to use jdk11 to execute ozone (instead of java8)  The configuration files should be updated according to these changes.   # How to test this patch?  (1) Do a full build and try to start the ./compose/ozonescripts cluster (check the related README file in the directory):  ``` docker-compose up -d ```  (2) start the ozone processes with ./start.sh (from compose/ozonescripts)  (3) wait and check if om/scm webui are working and you have 1 healthy datanode    See: https://issues.apache.org/jira/browse/HDDS-1914","closed","ozone,","elek","2019-08-06T08:06:21Z","2019-08-14T06:42:04Z"
"","1449","HDDS-2129. Using dist profile fails with pom.ozone.xml as parent pom","The build fails with the {{dist}} profile. Details in a comment below.  See: https://issues.apache.org/jira/browse/HDDS-2129","closed","ozone,","elek","2019-09-14T11:14:51Z","2019-09-15T15:22:17Z"
"","726","HDDS-1424. Support multi-container robot test execution","The ./smoketest folder in the distribution package contains robotframework based test scripts to test the main behaviour of Ozone.  The tests have two layers:  1. robot test definitions to execute commands and assert the results (on a given host machine) 2. ./smoketest/test.sh which starts/stops the docker-compose based environments AND execute the selected robot tests inside the right hosts  The second one (test.sh) has some serious limitations:  1. all the tests are executed inside the same container (om):  https://github.com/apache/hadoop/blob/5f951ea2e39ae4dfe554942baeec05849cd7d3c2/hadoop-ozone/dist/src/main/smoketest/test.sh#L89  Some of the tests (ozonesecure-mr, ozonefs) may require the flexibility to execute different robot tests in different containers.  2. The definition of the global test set is complex and hard to understood.   The current code is: {code}    TESTS=(""basic"")    execute_tests ozone ""${TESTS[@]}""    TESTS=(""auditparser"")    execute_tests ozone ""${TESTS[@]}""    TESTS=(""ozonefs"")    execute_tests ozonefs ""${TESTS[@]}""    TESTS=(""basic"")    execute_tests ozone-hdfs ""${TESTS[@]}""    TESTS=(""s3"")    execute_tests ozones3 ""${TESTS[@]}""    TESTS=(""security"")    execute_tests ozonesecure . {code}   For example for ozonesecure the TESTS is not used. And the usage of bash lists require additional complexity in the execute_tests function.  I propose here a very lightweight refactor. Instead of including both the test definitions AND the helper methods in test.sh I would separate them.  Let's put a test.sh to each of the compose directories. The separated test.sh can include common methods from a main shell script. For example:  {code}  source ""$COMPOSE_DIR/../testlib.sh""  start_docker_env  execute_robot_test scm basic/basic.robot  execute_robot_test scm s3  stop_docker_env  generate_report  {code}  This is a more clean and more flexible definition. It's easy to execute just this test (as it's saved to the compose/ozones3 directory. And it's more flexible.  Other example, where multiple containers are used to execute tests:  {code}  source ""$COMPOSE_DIR/../testlib.sh""  start_docker_env  execute_robot_test scm ozonefs/ozonefs.robot    export OZONE_HOME=/opt/ozone  execute_robot_test hadoop32 ozonefs/hadoopo3fs.robot  execute_robot_test hadoop31 ozonefs/hadoopo3fs.robot  stop_docker_env  generate_report {code}  With this separation the definition of the helper methods (eg. execute_robot_test or stop_docker_env) would also be simplified.  See: https://issues.apache.org/jira/browse/HDDS-1424","closed","ozone,","elek","2019-04-11T13:53:34Z","2019-05-07T15:56:41Z"
"","1006","HDDS-1723. Create new OzoneManagerLock class.","Thank You @anuengineer for offline discussion and help during the code of using Short and bit manipulation, instead of BitSet.   If someone is interested in how the code looks like with BitSet, refer below link. https://github.com/bharatviswa504/hadoop-1/blob/bhcode-anucode/hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/om/lock/OzoneManagerLock1.java","closed","ozone,","bharatviswa504","2019-06-22T00:10:55Z","2019-06-25T15:48:04Z"
"","732","HDDS-1387. ConcurrentModificationException in TestMiniChaosOzoneCluster","TestMiniChaosOzoneCluster is failing with the below exception {noformat} [ERROR] org.apache.hadoop.ozone.TestMiniChaosOzoneCluster  Time elapsed: 265.679 s","closed","ozone,","elek","2019-04-12T12:07:53Z","2019-04-12T22:19:51Z"
"","962","HDDS-1682. TestEventWatcher.testMetrics is flaky","TestEventWatcher is intermittent. (Failed twice out of 44 executions).  Error is:  {code} Tests run: 3, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 7.764 s","closed","ozone,","elek","2019-06-13T14:27:38Z","2019-07-29T09:54:55Z"
"","1542","HDDS-2140. Add robot test for GDPR feature","Tested using test-single script.  ``` $ ../test-single.sh om gdpr/gdpr.robot ================================================ ozone-gdpr :: Smoketest Ozone GDPR Feature ================================================ Test GDPR(disabled) without explicit options                       | PASS | ------------------------------------------------------------------------------ Test GDPR with --enforcegdpr=true                                     | PASS | ------------------------------------------------------------------------------ Test GDPR with -g=true                                                         | PASS | ------------------------------------------------------------------------------ Test GDPR with -g=false                                                       | PASS | ------------------------------------------------------------------------------ ozone-gdpr :: Smoketest Ozone GDPR Feature                   | PASS | 4 critical tests, 4 passed, 0 failed 4 tests total, 4 passed, 0 failed ============================================================ Output:  /tmp/smoketest/ozone/result/robot-ozone-ozone-gdpr-om.xml Log:     ~/apache/hadoop/hadoop-ozone/dist/target/ozone-0.5.0-SNAPSHOT/compose/ozone/result/log.html Report:  ~/apache/hadoop/hadoop-ozone/dist/target/ozone-0.5.0-SNAPSHOT/compose/ozone/result/report.html ```","closed","ozone,","dineshchitlangia","2019-09-28T05:17:44Z","2019-10-04T21:29:58Z"
"","1218","HDDS-1891. Ozone fs shell command should work with default port when port number is not specified","Tested manually with ozone fs:  ```bash bash-4.2$ ozone fs -ls o3fs://bucket.volume.om:9862/ Found 1 items -rw-rw-rw-   1 hadoop hadoop       1485 1970-01-01 00:03 o3fs://bucket.volume.om:9862/README.txt  bash-4.2$ ozone fs -ls o3fs://bucket.volume.om/ Found 1 items -rw-rw-rw-   1 hadoop hadoop       1485 1970-01-01 00:03 o3fs://bucket.volume.om/README.txt ```  ```bash $ ozone fs -ls o3fs://bucket.volume.localhost/ 2019-08-02 12:57:13,223 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:9862. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS) ...  $ ozone fs -ls o3fs://bucket.volume.localhost:9861/ 2019-08-02 12:57:21,604 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS) ... ```  Do we want to add a unit test for this? If yes, existing `TestOzoneShell` won't suit the need since `getOmAddress()` always returns the full address with port number. And the port number is almost always not default OM port 9862 when the running the test. So I might need to come up with a new unit test suite. e.g. test the parser only.","closed","ozone,","smengcl","2019-08-02T20:02:33Z","2019-08-13T22:44:44Z"
"","1304","HDDS-1972. Provide example ha proxy with multiple s3 servers back end.","Tested it on my laptop: ``` $ docker-compose up Creating network ""ozones3-haproxy_default"" with the default driver Creating ozones3-haproxy_s3-proxy_1 ... done Creating ozones3-haproxy_s3g3_1     ... done Creating ozones3-haproxy_scm_1      ... done Creating ozones3-haproxy_s3g1_1     ... done Creating ozones3-haproxy_om_1       ... done Creating ozones3-haproxy_s3g2_1     ... done Creating ozones3-haproxy_datanode_1 ... done Attaching to ozones3-haproxy_s3-proxy_1, ozones3-haproxy_om_1, ozones3-haproxy_datanode_1, ozones3-haproxy_s3g3_1, ozones3-haproxy_s3g1_1, ozones3-haproxy_scm_1, ozones3-haproxy_s3g2_1 s3-proxy_1  | [NOTICE] 226/212303 (1) : New worker #1 (6) forked ```  ``` $ aws s3api --endpoint http://localhost:8081 create-bucket --bucket b12346 {     ""Location"": ""http://localhost:8081/b12346"" } HW13865:ozones3-haproxy bviswanadham$ aws s3api --endpoint http://localhost:8081 create-bucket --bucket b1234 {     ""Location"": ""http://localhost:8081/b1234"" } HW13865:ozones3-haproxy bviswanadham$ aws s3api --endpoint http://localhost:8081 create-bucket --bucket b123 {     ""Location"": ""http://localhost:8081/b123"" } HW13865:ozones3-haproxy bviswanadham$ aws s3api --endpoint http://localhost:8081 list-buckets {     ""Buckets"": [         {             ""CreationDate"": ""2019-08-15T21:23:49.643Z"",              ""Name"": ""b123""         },          {             ""CreationDate"": ""2019-08-15T21:23:45.330Z"",              ""Name"": ""b1234""         },          {             ""CreationDate"": ""2019-08-15T21:23:42.629Z"",              ""Name"": ""b12346""         }     ] } ```  docker logs:  ``` s3g1_1      | 2019-08-15 21:23:42 INFO  BucketEndpoint:206 - Location is /b12346 s3g2_1      | 2019-08-15 21:23:45 INFO  BucketEndpoint:206 - Location is /b1234 s3g3_1      | 2019-08-15 21:23:49 INFO  BucketEndpoint:206 - Location is /b123 ```","closed","ozone,","bharatviswa504","2019-08-15T21:25:09Z","2019-08-19T21:01:06Z"
"","1029","HDDS-1384. TestBlockOutputStreamWithFailures is failing","TestBlockOutputStreamWithFailures is failing with the following error  {noformat} 2019-04-04 18:52:43,240 INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@1f6c0e8a 2019-04-04 18:52:43,240 INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@1f6c0e8a 2019-04-04 18:52:43,241 ERROR server.GrpcService (ExitUtils.java:terminate(133)) - Terminating with exit status 1: Failed to start Grpc server java.io.IOException: Failed to bind   at org.apache.ratis.thirdparty.io.grpc.netty.NettyServer.start(NettyServer.java:253)   at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl.start(ServerImpl.java:166)   at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl.start(ServerImpl.java:81)   at org.apache.ratis.grpc.server.GrpcService.startImpl(GrpcService.java:144)   at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:202)   at org.apache.ratis.server.impl.RaftServerRpcWithProxy.start(RaftServerRpcWithProxy.java:69)   at org.apache.ratis.server.impl.RaftServerProxy.lambda$start$3(RaftServerProxy.java:300)   at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:202)   at org.apache.ratis.server.impl.RaftServerProxy.start(RaftServerProxy.java:298)   at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:419)   at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:186)   at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:169)   at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:338)   at java.lang.Thread.run(Thread.java:748) Caused by: java.net.BindException: Address already in use   at sun.nio.ch.Net.bind0(Native Method)   at sun.nio.ch.Net.bind(Net.java:433)   at sun.nio.ch.Net.bind(Net.java:425)   at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)   at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:130)   at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:558)   at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1358)   at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeBind(AbstractChannelHandlerContext.java:501)   at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:486)   at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1019)   at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel.bind(AbstractChannel.java:254)   at org.apache.ratis.thirdparty.io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:366)   at org.apache.ratis.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)   at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)   at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462)   at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)   at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)   ... 1 more {noformat}  See: https://issues.apache.org/jira/browse/HDDS-1384","closed","ozone,","elek","2019-06-28T16:53:46Z","2019-07-12T09:27:30Z"
"","750","HDDS-1384. TestBlockOutputStreamWithFailures is failing","TestBlockOutputStreamWithFailures is failing with the following error  {noformat} 2019-04-04 18:52:43,240 INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@1f6c0e8a 2019-04-04 18:52:43,240 INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@1f6c0e8a 2019-04-04 18:52:43,241 ERROR server.GrpcService (ExitUtils.java:terminate(133)) - Terminating with exit status 1: Failed to start Grpc server java.io.IOException: Failed to bind   at org.apache.ratis.thirdparty.io.grpc.netty.NettyServer.start(NettyServer.java:253)   at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl.start(ServerImpl.java:166)   at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl.start(ServerImpl.java:81)   at org.apache.ratis.grpc.server.GrpcService.startImpl(GrpcService.java:144)   at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:202)   at org.apache.ratis.server.impl.RaftServerRpcWithProxy.start(RaftServerRpcWithProxy.java:69)   at org.apache.ratis.server.impl.RaftServerProxy.lambda$start$3(RaftServerProxy.java:300)   at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:202)   at org.apache.ratis.server.impl.RaftServerProxy.start(RaftServerProxy.java:298)   at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.start(XceiverServerRatis.java:419)   at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.start(OzoneContainer.java:186)   at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:169)   at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:338)   at java.lang.Thread.run(Thread.java:748) Caused by: java.net.BindException: Address already in use   at sun.nio.ch.Net.bind0(Native Method)   at sun.nio.ch.Net.bind(Net.java:433)   at sun.nio.ch.Net.bind(Net.java:425)   at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)   at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:130)   at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:558)   at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1358)   at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeBind(AbstractChannelHandlerContext.java:501)   at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:486)   at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1019)   at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel.bind(AbstractChannel.java:254)   at org.apache.ratis.thirdparty.io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:366)   at org.apache.ratis.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)   at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)   at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462)   at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)   at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)   ... 1 more {noformat}  See: https://issues.apache.org/jira/browse/HDDS-1384","closed","ozone,","elek","2019-04-18T09:51:50Z","2019-04-30T12:41:25Z"
"","1003","HADOOP-16384: Avoid inconsistencies between DDB and S3","Step one: a new root test to execute prune against the live store and DDB table.  To follow: debug the conditions leading to prune fail on my store :)  Change-Id: I25d138ed7b42f2b5eda12c2cd736f8c054b69820","closed","fs/s3,","steveloughran","2019-06-21T12:37:09Z","2019-07-30T15:13:24Z"
"","815","HDDS-1522. Provide intellij runConfiguration for Ozone components","Sometimes I need to start ozone cluster from intellij to debug issues. It's possible but it requires to create many runConfiguration object inside my IDE.  I propose here to share the intellij specific runtimeConfigs to make it easy for anybody (who uses intellij) to run full ozone cluster from the IDE (1 datanode only).  See: https://issues.apache.org/jira/browse/HDDS-1522","closed","ozone,","elek","2019-05-13T16:26:00Z","2019-05-16T14:38:51Z"
"","854","HDDS-1598. Fix Ozone checkstyle issues on trunk","Some small checkstyle issues are accidentally committed with HDDS-700.  Trivial fixes are coming here...   See: https://issues.apache.org/jira/browse/HDDS-1598","closed","ozone,","elek","2019-05-27T16:59:01Z","2019-05-27T21:40:52Z"
"","765","HDDS-1460: Add the optmizations of HDDS-1300 to BasicOzoneFileSystem","Some of the optimizations made in HDDS-1300 were reverted in HDDS-1333. This Jira aims to bring back those optimizations.","closed","","lokeshj1703","2019-04-24T11:50:13Z","2019-04-26T12:01:44Z"
"","800","HDDS-1458. Create a maven profile to run fault injection tests","Some fault injection tests have been written using blockade.  It would be nice to have ability to start docker compose and exercise the blockade test cases against Ozone docker containers, and generate reports.  This is optional integration tests to catch race conditions and fault tolerance defects.   We can introduce a profile with id: it (short for integration tests).  This will launch docker compose via maven-exec-plugin and run blockade to simulate container failures and timeout.  Usage command: {code} mvn clean verify -Pit {code}  See: https://issues.apache.org/jira/browse/HDDS-1458","closed","ozone,","elek","2019-05-08T06:41:02Z","2019-07-02T03:41:24Z"
"","1329","HDDS-738. Removing REST protocol support from OzoneClient","Since we have functional {{S3Gateway}} for Ozone which works on REST protocol, having REST protocol support in OzoneClient feels redundant and it will take a lot of effort to maintain it up to date. As S3Gateway is in a functional state now, I propose to remove REST protocol support from OzoneClient.  Once we remove REST support from OzoneClient, the following will be the interface to access Ozone cluster  * OzoneClient (RPC Protocol)  * OzoneFS (RPC Protocol)  * S3Gateway (REST Protocol)  See: https://issues.apache.org/jira/browse/HDDS-738","closed","ozone,","elek","2019-08-21T14:12:09Z","2019-08-28T16:58:28Z"
"","979","HDDS-1698. Switch to use apache/ozone-runner in the compose/Dockerfile","Since HDDS-1634 we have an ozone specific runner image to run ozone with docker-compose based pseudo clusters.  As the new apache/ozone-runner image is uploaded to the dockerhub we can switch our scripts and use the new image.  See: https://issues.apache.org/jira/browse/HDDS-1698","closed","ozone,","elek","2019-06-17T17:47:14Z","2019-07-02T18:12:58Z"
"","783","HDDS-1478. Provide k8s resources files for prometheus and performance tests","Similar to HDDS-1412 we can further improve the available k8s resources with providing example resources to:  1) install prometheus 2) execute freon test and check the results.  See: https://issues.apache.org/jira/browse/HDDS-1478","closed","ozone,","elek","2019-04-29T13:47:17Z","2019-05-02T09:33:50Z"
"","1314","HDFS-14748. Make DataNodePeerMetrics#minOutlierDetectionSamples configurable","Signed-off-by: sunlisheng","closed","","leosunli","2019-08-19T15:05:30Z","2019-08-30T01:45:17Z"
"","1309","HDFS-14648. DeadNodeDetector state machine model","Signed-off-by: sunlisheng","open","","leosunli","2019-08-17T13:20:50Z","2019-09-03T02:04:44Z"
"","1231","HADOOP-16453. Update how exceptions are handled in NetUtils.java","Signed-off-by: sunlisheng","closed","","leosunli","2019-08-06T02:06:50Z","2019-09-03T17:28:55Z"
"","1223","HADOOP-16112. Delete the baseTrashPath's subDir leads to don't modify baseTrashPath","Signed-off-by: sunlisheng","open","","leosunli","2019-08-04T08:47:33Z","2020-07-31T19:52:21Z"
"","1149","HADOOP-16453. Remove useless trace log in NetUtils.java","Signed-off-by: sunlisheng","closed","","leosunli","2019-07-24T02:09:37Z","2019-08-08T11:53:17Z"
"","1091","HADOOP-16431. Change Log Level to trace in IOUtils.java and ExceptionDiags.java","Signed-off-by: sunlisheng","closed","","leosunli","2019-07-15T07:30:15Z","2019-07-24T01:07:16Z"
"","1046","HDFS-14483. Backport HDFS-14111,HDFS-3246 ByteBuffer pread interface to branch-2.9","Signed-off-by: sunlisheng","open","","leosunli","2019-07-02T05:08:54Z","2019-07-02T05:10:33Z"
"","1010","HDFS-13694. Making md5 computing being in parallel with image loading.","Signed-off-by: sunlisheng","closed","","leosunli","2019-06-25T01:46:18Z","2019-07-05T17:24:01Z"
"","999","HDFS-14585.  Backport HDFS-8901 Use ByteBuffer in DFSInputStream#read to branch-2.9","Signed-off-by: sunlisheng","closed","","leosunli","2019-06-21T08:39:51Z","2019-07-02T05:06:14Z"
"","998","Backport HDFS-8901 Use ByteBuffer in DFSInputStream#read to branch-2","Signed-off-by: sunlisheng","closed","","leosunli","2019-06-21T08:16:49Z","2019-07-26T23:03:18Z"
"","747","HDFS-14433. Remove the extra empty space in the DataStreamer logging.","Signed-off-by: Eason Lu","closed","","lys0716","2019-04-17T05:08:02Z","2019-04-17T17:38:48Z"
"","1524","HDDS-2020. Remove mTLS from Ozone GRPC. Contributed by Xiaoyu Yao.","Signed-off-by: Anu Engineer  (cherry picked from commit d072d3304ce3fe33e22bb703839b41ab5107ad42)  ## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","ozone,","xiaoyuyao","2019-09-25T15:23:17Z","2019-10-03T17:51:38Z"
"","1273","HDDS-1951. Wrong symbolic release name on 0.4.1 branch","See: https://issues.apache.org/jira/browse/HDDS-1951","closed","","elek","2019-08-10T13:40:12Z","2019-08-13T09:58:47Z"
"","695","HDDS-1385. Make the ozonesecure-mr environment definition version","see: https://issues.apache.org/jira/browse/HDDS-1385  This is a PR on top of  HDDS-1333","closed","","elek","2019-04-04T14:57:40Z","2019-04-05T15:52:29Z"
"","773","HDDS-1469. Generate default configuration fragments based on annotations","See the design doc in the parent jira for more details.  In this jira I introduce a new annotation processor which can generate ozone-default.xml fragments based on the annotations which are introduced by HDDS-1468.  The ozone-default-generated.xml fragments can be used directly by the OzoneConfiguration as I added a small code to the constructor to check ALL the available ozone-default-generated.xml files and add them to the available resources.  With this approach we don't need to edit ozone-default.xml as all the configuration can be defined in java code.  As a side effect each service will see only the available configuration keys and values based on the classpath. (If the ozone-default-generated.xml file of OzoneManager is not on the classpath of the SCM, SCM doesn't see the available configs.)     See: https://issues.apache.org/jira/browse/HDDS-1469","closed","ozone,","elek","2019-04-25T13:27:45Z","2019-05-02T12:24:23Z"
"","1625","HDDS-2271. Avoid buffer copying in KeyValueHandler.","See https://issues.apache.org/jira/browse/HDDS-2271","closed","ozone,","szetszwo","2019-10-09T09:04:35Z","2019-10-17T04:06:17Z"
"","1595","HDDS-2222. Add a method to update ByteBuffer in PureJavaCrc32/PureJavaCrc32C","See https://issues.apache.org/jira/browse/HDDS-2222","closed","ozone,","szetszwo","2019-10-04T11:42:53Z","2019-10-05T01:21:14Z"
"","1578","HDDS-2222 Add a method to update ByteBuffer in PureJavaCrc32/PureJavaCrc32C","See https://issues.apache.org/jira/browse/HDDS-2222","closed","ozone,","szetszwo","2019-10-02T22:40:50Z","2019-10-04T11:18:48Z"
"","1593","HDDS-2204. Avoid buffer coping in checksum verification.","See https://issues.apache.org/jira/browse/HDDS-2204","closed","ozone,","szetszwo","2019-10-04T10:02:00Z","2019-10-15T04:00:57Z"
"","814","HDDS-1518. Use /etc/ozone for configuration inside docker-compose","See https://issues.apache.org/jira/browse/HDDS-1518 for more details.","closed","","elek","2019-05-13T09:17:06Z","2019-05-16T16:27:36Z"
"","1229","HADOOP-16490. Improve S3Guard handling of FNFEs in copy","S3Guard retry policy independently configurable from other retry policies,  * and use a setting with exponential backoff * new config names * copy raises a RemoteFileChangedException which is *not* caught in rename() and downgraded to false. Thus: when a rename is unrecoverable, this fact is propagated * tests for this * More logging @ debug in change policies as to policy type and when options are not set, as well as being set. Currently to work out the policy involves looking for the absence of messages, not the presence. It makes the file more verbose, but will aid with debugging these problems.  Also: tests turning auth mode on/off have to handle the auth state being set through an authoritative path, rather than a single flag. Caught me out as of course the first test I saw with this was the ITestS3ARemoteFileChanged rename ones, and I assumed that it was my new code. It was actually due to me setting an auth path last week.  I'm unsure about the use of ""RemoteFileChangedException"", but it could be a remote file change, especially for an etag, where the file has been deleted since being recorded.I don't know if/how we should adapt to that in S3Guard if the problem persists. The file is either *no longer there* or *changes not yet visible*. Maybe consider marking parent dir as nonauth?   Also, how about we log the RemoteFileChangedException error message before we throw it, so that there's more details in the log of the problem, irrespective of the action in the app calling it (i.e. fsshell discarding it, possibly)  Change-Id: I7bb468aca0f4019537d82bc083f0a9887eaa282b","closed","fs/s3,","steveloughran","2019-08-05T22:15:14Z","2019-09-05T17:44:58Z"
"","868","HDDS-1568 : Add RocksDB metrics to OM.","RocksDB statistics need to sinked to hadoop-metrics2 for Ozone Manager to understand how OM behaves under heavy load. Example: ""rocksdb.bytes.written""","closed","ozone,","avijayanhwx","2019-05-29T06:53:01Z","2019-05-30T15:48:15Z"
"","1401","HDDS-1561: Mark OPEN containers as QUASI_CLOSED as part of Ratis groupRemove","Right now, if a pipeline is destroyed by SCM, all the container on the pipeline are marked as quasi closed when datanode received close container command. SCM while processing these containers reports, marks these containers as closed once majority of the nodes are available.  This is however not a sufficient condition in cases where the raft log directory is missing or corrupted. As the containers will not have all the applied transaction.  To solve this problem, we should QUASI_CLOSE the containers in datanode as part of ratis groupRemove. If a container is in OPEN state in datanode without any active pipeline, it will be marked as Unhealthy while processing close container command.","closed","ozone,","lokeshj1703","2019-09-04T16:36:36Z","2019-09-06T08:04:45Z"
"","808","Revert ""HDDS-1474. ozone.scm.datanode.id config should take path for a dir ""","Reverts apache/hadoop#792","closed","","hanishakoneru","2019-05-09T18:17:51Z","2019-08-21T18:24:14Z"
"","1594","Revert ""HDDS-2222 Add a method to update ByteBuffer in PureJavaCrc32/PureJavaCrc32C""","Reverts apache/hadoop#1578","closed","","szetszwo","2019-10-04T11:19:19Z","2019-10-04T11:19:46Z"
"","1215","HDDS-1832 : Improve logging for PipelineActions handling in SCM and datanode.","Reverts apache/hadoop#1200  Changing to ERROR.","closed","","avijayanhwx","2019-08-02T17:58:16Z","2019-08-02T20:09:52Z"
"","1183","Revert ""HDDS-1829 On OM reload/restart OmMetrics#numKeys should be updated""","Reverts apache/hadoop#1164","closed","","bharatviswa504","2019-07-29T23:44:07Z","2019-08-21T18:23:03Z"
"","925","HDDS-1660 Use Picocli for Ozone Manager","Replicate the changes made in HDDS-1622 for the StorageContainerManager to the Ozone Manager, so it also uses Picocli for the command line interface.","closed","ozone,","sodonnel","2019-06-07T15:35:58Z","2019-06-17T12:20:56Z"
"","1484","[HADOOP-16590] - LoginModule Classes and Principal Classes deprecated in IBM Java.","Replace deprecated classes in IBM Java with their replacements.","closed","","n-marion","2019-09-20T18:03:12Z","2020-01-10T21:44:07Z"
"","1543","HDDS-2202. Remove unused import in OmUtils","Removed unused import.","closed","ozone,","dineshchitlangia","2019-09-28T05:38:37Z","2019-09-30T14:12:05Z"
"","1471","HDDS-2148. Remove redundant code in CreateBucketHandler.java","Removed redundant code, so no tests modified/added.","closed","ozone,","dineshchitlangia","2019-09-18T18:31:51Z","2019-09-19T13:48:27Z"
"","1579","HDDS-2217 : Remove log4j and audit configuration from the docker-config files","Removed redundant and potentially confusing LOG4J entries.","closed","ozone,","christeoh","2019-10-02T23:49:31Z","2019-10-03T13:34:45Z"
"","1582","HDDS-2217. Removed redundant LOG4J lines from docker configurations","Removed potentially confusing LOG4J lines from docker configuration","closed","ozone,","christeoh","2019-10-03T13:36:42Z","2019-10-09T21:12:22Z"
"","1344","HDDS-1982 Extend SCMNodeManager to support decommission and maintenance states","Remove the existing decommission states from the protobuf definition.  At this stage, this PR is really a test to see if the build passes with these states removed.","closed","ozone,","sodonnel","2019-08-23T16:18:51Z","2019-09-20T18:52:52Z"
"","877","HDDS-1618. Merge code for HA and Non-HA OM write type requests for bucket","Removal of old code is not done in this jira.   For that we need  1. OzoneManager.java, to not implement OzoneManagerProtocol. 2. Still, HA code path which is newly added, we need CheckAcl, Audit logging to be implemented. These will be taken care in HDDS-1600 and HDDS-1605. Once these are implemented we can completely remove the old code. 3. S3 Bucket logic needs to be modified.","closed","ozone,","bharatviswa504","2019-05-30T22:14:23Z","2019-07-31T16:14:03Z"
"","1129","HDFS-14509 DN throws InvalidToken due to inequality of password when upgrade NN 2.x to 3.x","reference to jira","closed","hdfs,","Cosss7","2019-07-19T05:13:41Z","2019-10-08T03:18:07Z"
"","1128","HDFS-14551 NN throws NPE if downgrade it during rolling upgrade from 3.x to 2.x","reference jira.","closed","","Cosss7","2019-07-19T03:51:55Z","2019-08-19T05:59:32Z"
"","1056","HDDS-1717. Remove OMFailoverProxyProvider's dependency on hadoop-3.2","Refactors OMProxyInfo to not extend FailoverProxyProvider.ProxyInfo (which is a final class before hadoop-3.2).","closed","ozone,","hanishakoneru","2019-07-04T00:51:53Z","2019-07-09T11:42:06Z"
"","1678","HDDS-1847: Datanode Kerberos principal and keytab config key looks inconsistent","Refactored out the following configurations out of ScmConfigKeys to Java based configuration classes:-  - HDDS_SCM_KERBEROS_KEYTAB_FILE_KEY - HDDS_SCM_KERBEROS_PRINCIPAL_KEY - HDDS_SCM_HTTP_KERBEROS_PRINCIPAL_KEY - HDDS_SCM_HTTP_KERBEROS_KEYTAB_FILE_KEY","closed","","christeoh","2019-10-25T09:40:16Z","2019-10-31T23:45:38Z"
"","1178","YARN-9680 Code cleanup in ResourcePluginManager init methods","Refactor ResourcePluginManager.java and TestResourcePluginManager.java","open","","pingsutw","2019-07-27T18:46:27Z","2019-08-08T16:16:59Z"
"","1131","YARN-9375. Use Configured in GpuDiscoverer and FpgaDiscoverer","Recreated a PR, hope this time yetus will pick it up.  The change is straightforward, check [upstream jira](https://issues.apache.org/jira/browse/YARN-9375).","closed","","adamantal","2019-07-19T09:25:48Z","2019-08-05T09:04:55Z"
"","914","HDDS-1647 : Recon config tag does not show up on Ozone UI.","Recon tag does not show up on the list of tags on /conf page.","closed","ozone,","avijayanhwx","2019-06-05T21:30:08Z","2019-06-06T18:13:30Z"
"","913","HDDS-1647 : Recon config tag does not show up on Ozone UI","Recon tag does not show up on the list of tags on /conf page.","closed","","avijayanhwx","2019-06-05T21:26:56Z","2019-06-05T21:27:06Z"
"","1201","HDDS-1788. Fix kerberos principal error in Ozone Recon","Recon fails to come up in a secure cluster with the following error: ``` Failed startup of context o.e.j.w.WebAppContext@2009f9b0{/,file:///tmp/jetty-0.0.0.0-9888-recon-_-any-2565178148822292652.dir/webapp/,UNAVAILABLE}{/recon} javax.servlet.ServletException: javax.servlet.ServletException: Principal not defined in configuration at org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:188) at ```  This patch addresses this issue and enables Recon to come up in clusters secured by kerberos. I have manually tested the patch by creating the recon jar and replacing an old jar in a live secure CM deployed cluster and verified that Recon starts successfully and is able to login successfully with the kerberos ticket. Also updated ozonesecure docker-compose file to add recon and verified that recon is able to come up successfully. This patch also fixes various typos found in other parts of the source code not related to the title of this JIRA.","closed","ozone,","vivekratnavel","2019-08-01T00:08:09Z","2019-08-03T17:49:27Z"
"","895","HDDS-1636. Tracing id is not propagated via async datanode grpc call","Recently a new exception become visible in the datanode logs, using standard freon (STANDLAONE)  {code} datanode_2  | 2019-06-03 12:18:21 WARN  PropagationRegistry$ExceptionCatchingExtractorDecorator:60 - Error when extracting SpanContext from carrier. Handling gracefully. datanode_2  | io.jaegertracing.internal.exceptions.MalformedTracerStateStringException: String does not match tracer state format: 7576cabf-37a4-4232-9729-939a3fdb68c4WriteChunk150a8a848a951784256ca0801f7d9cf8b_stream_ed583cee-9552-4f1a-8c77-63f7d07b755f_chunk_1 datanode_2  | 	at org.apache.hadoop.hdds.tracing.StringCodec.extract(StringCodec.java:49) datanode_2  | 	at org.apache.hadoop.hdds.tracing.StringCodec.extract(StringCodec.java:34) datanode_2  | 	at io.jaegertracing.internal.PropagationRegistry$ExceptionCatchingExtractorDecorator.extract(PropagationRegistry.java:57) datanode_2  | 	at io.jaegertracing.internal.JaegerTracer.extract(JaegerTracer.java:208) datanode_2  | 	at io.jaegertracing.internal.JaegerTracer.extract(JaegerTracer.java:61) datanode_2  | 	at io.opentracing.util.GlobalTracer.extract(GlobalTracer.java:143) datanode_2  | 	at org.apache.hadoop.hdds.tracing.TracingUtil.importAndCreateScope(TracingUtil.java:102) datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:73) datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:61) datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:248) datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33) datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.Contexts$ContextualizedServerCallListener.onMessage(Contexts.java:76) datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33) datanode_2  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:46) datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:263) datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:686) datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123) datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) {code}  It turned out that the tracingId propagation between XCeiverClient and Server doesn't work very well (in case of Standalone and async commands)   1. there are many places (on the client side) where the traceId filled with  UUID.randomUUID().toString();    2. This random id is propagated between the Output/InputStream and different part of the clients  3. It is unnecessary, because in the XceiverClientGrpc and XceiverClientGrpc the traceId field is overridden with the real opentracing id anyway (sendCommand/sendCommandAsync)  4. Except in the XceiverClientGrpc.sendCommandAsync where this part is accidentally missing.  Things to fix:   1. fix XceiverClientGrpc.sendCommandAsync (replace any existing traceId with the good one)  2. remove the usage of the UUID based traceId (it's not used)  3. Improve the error logging in case of an invalid traceId on the server side.  See: https://issues.apache.org/jira/browse/HDDS-1636","closed","ozone,","elek","2019-06-03T12:58:05Z","2019-06-08T03:40:34Z"
"","1291","HDFS-14665. HttpFS: LISTSTATUS response is missing HDFS-specific fields","Rebased on branch-3.1","closed","","smengcl","2019-08-14T07:01:48Z","2019-08-20T17:49:51Z"
"","1013","HDDS-1691 : RDBTable#isExist should use Rocksdb#keyMayExist","RDBTable#isExist can use Rocksdb#keyMayExist, this avoids the cost of reading the value for the key.  Please refer,  https://github.com/facebook/rocksdb/blob/7a8d7358bb40b13a06c2c6adc62e80295d89ed05/java/src/main/java/org/rocksdb/RocksDB.java#L2184","closed","ozone,","avijayanhwx","2019-06-25T19:12:39Z","2019-06-26T18:44:50Z"
"","1039","HDDS-1616. ManagedChannel references are being leaked in while removing RaftGroup. Contributed by Mukul Kumar Singh.","RaftClient references are being leaked while removing pipeline.","closed","ozone,","mukul1987","2019-07-01T02:22:35Z","2019-07-02T21:35:16Z"
"","1495","HADOOP-16559 Use protobuf-maven-plugin to generate protobuf classes","Purged all the protoc execution in hadoop-maven-plugin.  I think we can do this quickly to make sure we do not need developpers to install protoc manually first, and then file follow-on issues to do the cleanups, for example, purge the syntax warnings for proto file, remove the unused properties in pom, etc.","closed","","Apache9","2019-09-21T14:58:34Z","2019-09-22T03:42:40Z"
"","902","HDDS-1628. Fix the execution and return code of smoketest executor shell script","Problem: Some of the smoketest executions were reported to green even if they contained failed tests.  Root cause: the legacy test executor (hadoop-ozone/dist/src/main/smoketest/test.sh) which just calls the new executor script (hadoop-ozone/dist/src/main/compose/test-all.sh) didn't handle the return code well (the failure of the smoketests should be signalled by the bash return code)  This patch:  * Fixes the error code handling in smoketest/test.sh  * Fixes the test execution in compose/test-all.sh (should work from any other directories)  * Updates hadoop-ozone/dev-support/checks/acceptance.sh to use the newer test-all.sh executor instead of the old one.  See: https://issues.apache.org/jira/browse/HDDS-1628","closed","ozone,","elek","2019-06-04T11:36:25Z","2019-06-05T12:06:14Z"
"","770","HDFS-14456:HAState#prepareToEnterState neednt a lock","prepareToEnterState in HAState is called without the context being locked.  But in NameNode#NameNode, prepareToEnterState is after haContext.writeLock()    ``` java try {   haContext.writeLock();   state.prepareToEnterState(haContext);   state.enterState(haContext); } finally {   haContext.writeUnlock(); } ```  Is it OK?  I move `state.prepareToEnterState(haContext);` out","closed","","hunshenshi","2019-04-25T03:41:33Z","2019-08-16T21:53:07Z"
"","743","HADOOP-11452 make rename/3 public","PR with the previous patches.  This is a WiP but ready for some iniital review; lacks tests & spec.  Also, because the base FileSystem.rename/3 does its own src/dest checks, it's less efficient against object stores. They need their own high-perf subclass.  Change-Id: I1586ef2290d7a3d2d33b1a32e2f0999b07c26143","closed","fs/s3,","steveloughran","2019-04-15T19:02:21Z","2021-03-02T15:24:45Z"
"","711","HDDS-1368. Cleanup old ReplicationManager code from SCM.","PR #620 brings in new ReplicationManager and PR #662 plugs in the new code, this is for removing the old ReplicationManager and related code.","closed","ozone,","nandakumar131","2019-04-09T09:37:42Z","2019-04-23T12:07:28Z"
"","908","YARN-9601:Potential NPE in ZookeeperFederationStateStore#getPoliciesC…","Potential NPE in ZookeeperFederationStateStore#getPoliciesConfigurations  The code of ZookeeperFederationStateStore#getPoliciesConfigurations ``` java for (String child : zkManager.getChildren(policiesZNode)) {   SubClusterPolicyConfiguration policy = getPolicy(child);   result.add(policy); } ``` The result of `getPolicy` may be null, so policy should be checked   The new code  ``` java for (String child : zkManager.getChildren(policiesZNode)) {   SubClusterPolicyConfiguration policy = getPolicy(child);   // policy maybe null, should check   if (policy == null) {     LOG.warn(""Policy for queue: {} does not exist."", child);     continue;   }   result.add(policy); } ```","closed","","hunshenshi","2019-06-05T06:56:46Z","2019-08-08T11:04:56Z"
"","1413","HADOOP-16255. Add ChecksumFs.rename(path, path, boolean) to rename crc file as well when FileContext.rename(path, path, options) is called. [BRANCH-2]","Please refer https://issues.apache.org/jira/browse/HADOOP-16255 for more details.  FYI, FileContext.rename(path, path, options) leaks crc file for source of rename when CheckFs or its descendant is used as underlying filesystem. https://issues.apache.org/jira/browse/SPARK-28025 took a workaround via removing crc file manually, and we hope to get rid of workaround eventually.  This PR is ported version of #1388 for branch-2.","closed","","HeartSaVioR","2019-09-06T21:58:19Z","2019-09-11T02:41:52Z"
"","1388","HADOOP-16255. Add ChecksumFs.rename(path, path, boolean) to rename crc file as well when FileContext.rename(path, path, options) is called.","Please refer https://issues.apache.org/jira/browse/HADOOP-16255 for more details.  FYI, `FileContext.rename(path, path, options)` leaks crc file for source of rename when CheckFs or its descendant is used as underlying filesystem. https://issues.apache.org/jira/browse/SPARK-28025 took a workaround via removing crc file manually, and we hope to get rid of workaround eventually.","closed","","HeartSaVioR","2019-08-31T04:28:32Z","2019-09-09T16:20:59Z"
"","1646","HADOOP-15430. hadoop fs -mkdir -p path-ending-with-slash/ fails with s3guard","path qualification in s3a fs strips any trailing / ; with tests","closed","","steveloughran","2019-10-11T13:32:47Z","2021-10-15T19:42:10Z"
"","1671","HADOOP-16665. Filesystems to be closed if they failed during initialize().","Patches FileSystem to do this, and for S3A have it stop services during init exception handling.  Also reviewed the mockFS subclass to make sure it gets close() right and remove all uses of the obsolete S3AUtils.closeAll with IOUtils.cleanupWithLogger  Change-Id: I0b9fd1aafc902a151a8cacb614058e00d475cd45","closed","fs/s3,","steveloughran","2019-10-23T18:38:35Z","2019-11-13T14:39:19Z"
"","1516","HADOOP-16599. Allow a SignerInitializer to be specified along with a","Patch is missing some unit tests, which will get added soon. Posting early to solicit feedback on the interface additions - @steveloughran","closed","","sidseth","2019-09-24T17:53:15Z","2019-10-02T23:03:49Z"
"","804","HDDS-1496. Support partial chunk reads and checksum verification","Partial chunk reads and checksum verifications","closed","ozone,","hanishakoneru","2019-05-08T22:32:20Z","2019-06-07T02:45:11Z"
"","1563","HDDS-2221. Monitor datanodes in ozoneperf compose cluster","ozoneperf compose cluster contains a prometheus but as of now it collects the data only from scm and om.  We don't know the exact number of datanodes (can be scaled up and down) therefor it's harder to configure the datanode host names. I would suggest to configure the first 10 datanodes (which covers most of the use cases)  How to test?  ``` cd hadoop-ozone/dist/target/ozone-0.5.0-SNAPSHOT/compose/ozoneperf docker-compose up -d firefox http://localhost:9090/targets ```  ","closed","ozone,","elek","2019-10-01T14:25:27Z","2019-10-13T09:34:29Z"
"","1423","HDDS-2106. Avoid usage of hadoop projects as parent of hdds/ozone","Ozone uses hadoop as a dependency. The dependency defined on multiple level:   1. the hadoop artifacts are defined in the  sections  2. both hadoop-ozone and hadoop-hdds projects uses ""hadoop-project"" as the parent  As we already have a slightly different assembly process it could be more resilient to use a dedicated parent project instead of the hadoop one. With this approach it will be easier to upgrade the versions as we don't need to be careful about the pom contents only about the used dependencies.  See: https://issues.apache.org/jira/browse/HDDS-2106","closed","ozone,","elek","2019-09-10T21:15:27Z","2019-09-12T01:23:06Z"
"","887","HDDS-1629. Tar file creation can be optional for non-dist builds","Ozone tar file creation is a very time consuming step. I propose to make it optional and create the tar file only if the dist profile is enabled (-Pdist)  The tar file is not required to test ozone as the same content is available from hadoop-ozone/dist/target/ozone-0.5.0-SNAPSHOT which is enough to run docker-compose pseudo clusters, smoketests.   If it's required, the tar file creation can be requested by the dist profile.   On my machine (ssd based) it can cause 5-10% time improvements as the tar size is ~500MB and it requires a lot of IO.  See: https://issues.apache.org/jira/browse/HDDS-1629","closed","ozone,","elek","2019-06-03T06:33:25Z","2019-06-04T06:20:46Z"
"","945","HDDS-1646. Support real persistence in the k8s example files","Ozone release contains example k8s deployment files to make it easier to deploy Ozone to kubernetes. As of now we use emptyDir everywhere, we should support the configuration of host volumes (hostPath or Local Persistent volumes).  The big question here is the default:  * Make the examples easy to start and ephemeral * Make the examples more safe, by default (but couldn't be started without additional administration).  (Note this conversation is started in the review of HDDS-1508)  Xiaoyu:  Can we support mount hostVolume for datanode daemons?  Marton: Yes, we can.  AFAIK there are two options:  * using [hostPath](https://kubernetes.io/docs/concepts/storage/volumes/#hostpath)  * or with [Local PersistentVolumes](https://kubernetes.io/blog/2018/04/13/local-persistent-volumes-beta/)  The first one requires the knowledge of directory names on the host. The second one is recommended but it requires the creation of PersistentVolumes or install a PersistentVolume provider  I am not sure what is the best approach, my current proposal is:   * Use empty dir everywhere to make it easier to start simple ozone cluster  * Provide simple option to turn on any of theses persistence (the kubernetes files are generated and the generation can be parametrized)  * Document how to customize the kubernetes resources files  Summary: it's question of the defaults:     1. Use a complex, but persistent solution, which may not work out of the box      2. Use a simple, but ephemeral solution (as default)  I started to use (2) but I am open to change.    See: https://issues.apache.org/jira/browse/HDDS-1646","closed","ozone,","elek","2019-06-11T12:43:17Z","2019-06-24T19:02:36Z"
"","1610","HDDS-1868. Ozone pipelines should be marked as ready only after the leader election is complete.","Ozone pipeline on restart or when first created, start in allocated state. They are moved into open state after all the pipeline have reported to it. However, this potentially can lead into an issue where the pipeline is still not ready to accept any incoming IO operations.  The pipelines should be marked as ready only after the leader election is complete and leader is ready to accept incoming IO.","closed","ozone,","swagle","2019-10-07T17:58:14Z","2019-10-21T19:32:38Z"
"","694","HDDS-1383. [Ozone Upgrade] Create the project skeleton with CLI interface","Ozone In-Place upgrade tool is a tool to upgrade hdfs data to ozone data without data movement.  In this jira I will create a skeleton project with the cli interface without any business logic.  See: https://issues.apache.org/jira/browse/HDDS-1383","closed","ozone,","elek","2019-04-04T13:24:35Z","2019-04-09T15:43:15Z"
"","1360","HDDS-2007. Make ozone fs shell command work with OM HA service ids","ozone fs command should work with service ids now.  ozone sh command doesn't work with service ids for now. Will improve in another jira.","closed","ozone,","smengcl","2019-08-27T22:45:34Z","2019-09-13T19:14:33Z"
"","1473","HDDS-2101. Ozone filesystem provider doesn't exist","Ozone did not have a filesystem provider in META-INF and this PR adds a filesystem provider for both ozonefs-lib-legacy and ozonefs-lib-current.  Testing done:  I tested the map reduce robot tests for Hadoop27 and Hadoop32 after removing `fs.o3fs.impl=org.apache.hadoop.fs.ozone.OzoneFileSystem` and `fs.o3fs.impl=org.apache.hadoop.fs.ozone.BasicOzoneFileSystem` from the docker configs and verified that the tests pass.","closed","ozone,","vivekratnavel","2019-09-19T07:22:22Z","2019-09-19T23:28:30Z"
"","928","Hdds 1651","Ozone currently uses dfs.http.policy for HTTP policy. Ozone should have its own ozone.http.policy configuration","closed","","shwetayakkali","2019-06-07T23:02:23Z","2019-06-08T02:55:40Z"
"","1652","HDDS-2220. HddsVolume needs a toString method.","Override toString to show the path of HddsVolume.  ## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","cxorm","2019-10-12T14:09:45Z","2019-10-16T14:16:46Z"
"","993","HDDS-1709. TestScmSafeNode is flaky","org.apache.hadoop.ozone.om.TestScmSafeMode.testSCMSafeMode is failed at last night with the following error: {code:java} java.lang.AssertionError at org.junit.Assert.fail(Assert.java:86) at org.junit.Assert.assertTrue(Assert.java:41) at org.junit.Assert.assertTrue(Assert.java:52) at org.apache.hadoop.ozone.om.TestScmSafeMode.testSCMSafeMode(TestScmSafeMode.java:285) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74){code} Locally it can be tested but it's very easy to reproduce by adding an additional sleep DataNodeSafeModeRule: {code:java} +++ b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/safemode/DataNodeSafeModeRule.java @@ -63,7 +63,11 @@ protected boolean validate() {      @Override    protected void process(NodeRegistrationContainerReport reportsProto) { - +    try { +      Thread.sleep(3000); +    } catch (InterruptedException e) { +      e.printStackTrace(); +    }{code} This is a clear race condition:  DatanodeSafeModeRule and ContainerSafeModeRule are processing the same events but it can be possible (in case of an accidental sleep) that the container safe mode rule is done, but DatanodeSafeModeRule didn't process the new event (yet).  As a result the test execution will continue: {code:java} GenericTestUtils     .waitFor(() -> scm.getCurrentContainerThreshold() == 1.0, 100, 20000); {code} (This line is waiting ONLY for the ContainerSafeModeRule).  The fix is easy, let's wait for the processing of all the async events: {code:java} EventQueue eventQueue =     (EventQueue) cluster.getStorageContainerManager().getEventQueue(); eventQueue.processAll(5000L);{code} As we are sure that the events are already sent to the EventQueue (because we have the previous waitFor), it should be enough.  See: https://issues.apache.org/jira/browse/HDDS-1709","closed","ozone,","elek","2019-06-20T08:18:51Z","2019-06-25T21:06:19Z"
"","1285","Fix syntax error in conftest.py","Old style exceptions are syntax errors on Python 3 while new style exceptions work as expected on both Python 2 and Python 3.","closed","","cclauss","2019-08-12T22:49:49Z","2019-08-27T09:18:26Z"
"","1551","HDDS-2199 In SCMNodeManager dnsToUuidMap cannot track multiple DNs on the same host","Often in test clusters and tests, we start multiple datanodes on the same host.  In SCMNodeManager.register() there is a map of hostname -> datanode UUID called dnsToUuidMap.  If several DNs register from the same host, the entry in the map will be overwritten and the last DN to register will 'win'.  This means that the method getNodeByAddress() does not return the correct DatanodeDetails object when many hosts are registered from the same address.  This method is only used in SCMBlockProtocolServer.sortDatanodes() to allow it to see if one of the nodes matches the client, but it need to be used by the Decommission code.  Perhaps we could change the getNodeByAddress() method to returns a list of DNs? In normal production clusters, there should only be one returned, but in test clusters, there may be many. Any code looking for a specific DN entry would need to iterate the list and match on the port number too, as host:port would be the unique definition of a datanode.","closed","ozone,","sodonnel","2019-09-30T14:53:51Z","2019-10-04T12:15:30Z"
"","1397","MAPREDUCE-7237. Supports config the shuffle's path cache related parameters","Nowadays the ShuffleHandler#Shuffle#pathCache's related parameters is hard coding. We should support config these.","closed","","jiwq","2019-09-03T13:42:53Z","2020-03-16T02:28:37Z"
"","1504","HDDS-2068. Make StorageContainerDatanodeProtocolService message based","Note: this change requires HDDS-2067 to be merged first.","closed","","elek","2019-09-23T14:44:08Z","2019-10-02T18:54:10Z"
"","1658","Merge pull request #1 from apache/trunk","new pull  ## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","xiaoxiaopan118","2019-10-15T06:57:23Z","2020-03-10T09:22:47Z"
"","946","HDDS-1669. SCM startup is failing if network-topology-default.xml is part of a jar","network-topology-default.xml can be loaded from file or classpath. But the NodeSchemaLoader assumes that the files on the classpath can be opened as a file. It's true if the file is in etc/hadoop (which is part of the classpath) but not true if the file is packaged to a jajr file:  {code} scm_1         | 2019-06-11 13:18:03 INFO  NodeSchemaLoader:118 - Loading file from jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar!/network-topology-default.xml scm_1         | 2019-06-11 13:18:03 ERROR NodeSchemaManager:74 - Failed to load schema file:network-topology-default.xml, error: scm_1         | java.lang.IllegalArgumentException: URI is not hierarchical scm_1         | 	at java.io.File.(File.java:418) scm_1         | 	at org.apache.hadoop.hdds.scm.net.NodeSchemaLoader.loadSchemaFromFile(NodeSchemaLoader.java:119) scm_1         | 	at org.apache.hadoop.hdds.scm.net.NodeSchemaManager.init(NodeSchemaManager.java:67) scm_1         | 	at org.apache.hadoop.hdds.scm.net.NetworkTopologyImpl.(NetworkTopologyImpl.java:63) scm_1         | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.initializeSystemManagers(StorageContainerManager.java:382) scm_1         | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.(StorageContainerManager.java:275) scm_1         | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.(StorageContainerManager.java:208) scm_1         | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.createSCM(StorageContainerManager.java:586) scm_1         | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter$SCMStarterHelper.start(StorageContainerManagerStarter.java:139) scm_1         | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter.startScm(StorageContainerManagerStarter.java:115) scm_1         | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter.call(StorageContainerManagerStarter.java:67) scm_1         | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter.call(StorageContainerManagerStarter.java:42) scm_1         | 	at picocli.CommandLine.execute(CommandLine.java:1173) scm_1         | 	at picocli.CommandLine.access$800(CommandLine.java:141) scm_1         | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1367) scm_1         | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1335) scm_1         | 	at picocli.CommandLine$AbstractParseResultHandler.handleParseResult(CommandLine.java:1243) scm_1         | 	at picocli.CommandLine.parseWithHandlers(CommandLine.java:1526) scm_1         | 	at picocli.CommandLine.parseWithHandler(CommandLine.java:1465) scm_1         | 	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:65) scm_1         | 	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:56) scm_1         | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter.main(StorageContainerManagerStarter.java:56) scm_1         | Failed to load schema file:network-topology-default.xml, error: {code}  The quick fix is to keep the current behaviour but read the file from classloader.getResourceAsStream() instead of classloader.getResource().toURI()  See: https://issues.apache.org/jira/browse/HDDS-1669","closed","ozone,","elek","2019-06-11T13:48:19Z","2019-06-11T17:37:03Z"
"","1489","HDDS-2019. Handle Set DtService of token in S3Gateway for OM HA.","Need some work on server-side for adding secure-om-s3-ha docker-compose cluster, as some fields like keytab are still not supporting parameter with serviceid and node id.","closed","ozone,","bharatviswa504","2019-09-20T21:34:48Z","2019-10-02T22:41:55Z"
"","1186","HADOOP-16472. findbugs warning on LocalMetadataStore.ttlTimeProvider sync","Moved the setter and addAncestors to synchronized  Untested! Let's see what findbugs says first","closed","","steveloughran","2019-07-30T14:19:58Z","2021-10-15T19:45:39Z"
"","1441","HADOOP-16568. S3A FullCredentialsTokenBinding fails if local credentials are unset","Move the local loading to deployUnbonded() (where they are required) and add a safety check when a new DT is requested  Change-Id: I516368c2c4a558a2a86e8cf107f77f1e40338261","closed","fs/s3,","steveloughran","2019-09-13T17:54:25Z","2020-07-13T19:29:06Z"
"","1499","HDDS-1738. Add nullable annotation for OMResponse classes.","Modify classes under  hadoop/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/  ## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","cxorm","2019-09-23T04:47:03Z","2019-09-28T04:54:09Z"
"","1192","HDFS-14686. HttpFS: HttpFSFileSystem#getErasureCodingPolicy always returns null","Modified existing unit test to verify the validity of the fix. Without the fix, the modified unit test WILL fail. Tested locally.","closed","hdfs,","smengcl","2019-07-31T08:08:31Z","2019-08-02T00:15:23Z"
"","801","HDDS-1500 : Allocate block failures in client should print exception trace.","Minor change.","closed","ozone,","avijayanhwx","2019-05-08T06:48:54Z","2019-05-09T10:08:50Z"
"","829","HDDS-1550. MiniOzoneCluster is not shutting down all the threads during shutdown. Contributed by Mukul Kumar Singh.","MiniOzoneCluster is not shutting down all the threads during shutdown. this patch tries to fix that issue.","closed","ozone,","mukul1987","2019-05-17T03:49:40Z","2019-08-28T22:26:28Z"
"","1041","HADOOP-15844. Tag S3GuardTool entry points as LimitedPrivate/Evolving","Marking `S3GuardTool` as LimitedPrivate(""management-tools"")/Evolving to reassure people using it as an API that we intend to retain it as an API for creating/destroying/maintaining S3Guard tables  Tested S3 Ireland (as part of a HADOOP-16384 test run)  Change-Id: Ic58bbd917da901a1bd2322ae0f41ca00e60dcc06","closed","fs/s3,","steveloughran","2019-07-01T12:40:03Z","2021-10-15T19:50:22Z"
"","1482","HADOOP-16589. [pb-upgrade] Update docker image to make 3.7.1 protoc as default","Make protoc 3.7.1 as default in Dockerfile.","closed","","vinayakumarb","2019-09-20T10:51:26Z","2019-09-21T04:40:30Z"
"","1403","HADOOP-16548 Made flush operation configurable in ABFS","Made flush operation configurable in ABFS driver for performance improvements.  Driver test results using a Namespace enabled account in Central India:  fs.azure.enable.abfs.flush = false  mvn -T 1C -Dparallel-tests=abfs -Dscale -DtestsThreadCount=8 clean verify Tests run: 42, Failures: 0, Errors: 0, Skipped: 0 Tests run: 394, Failures: 1, Errors: 1, Skipped: 21 Tests run: 190, Failures: 0, Errors: 0, Skipped: 15   fs.azure.enable.abfs.flush = true  mvn -T 1C -Dparallel-tests=abfs -Dscale -DtestsThreadCount=8 clean verify Tests run: 42, Failures: 0, Errors: 0, Skipped: 0 Tests run: 394, Failures: 0, Errors: 1, Skipped: 21 Tests run: 190, Failures: 0, Errors: 0, Skipped: 15","closed","","bilaharith","2019-09-05T05:58:09Z","2019-10-24T16:08:32Z"
"","1633","HDDS-2266. Avoid evaluation of LOG.trace and LOG.debug statement in the read/write path.","LOG.trace and LOG.debug with logging information will be evaluated even when debug/trace logging is disabled. This jira proposes to wrap all the trace/debug logging with LOG.isDebugEnabled and LOG.isTraceEnabled to prevent the logging.  Fixed all the places where the parameter would need evaluation, left only the string literals and pre-evaluated variables intact. Addressed LOG.debug, LOGGER.debug, LOG.trace and LOGGER.trace by search and edit.","closed","ozone,","swagle","2019-10-09T23:00:53Z","2019-10-10T10:00:12Z"
"","1486","HDDS-2158. Fixing Json Injection Issue in JsonUtils.","JsonUtils#toJsonStringWithDefaultPrettyPrinter() does not validate the Json String  before serializing it which could result in Json Injection. This method is mostly used along with JsonUtils#toJsonString() by first converting to String and then back to object. This can be avoided by directly writing the object through PrettyPrinter.","closed","ozone,","hanishakoneru","2019-09-20T19:06:59Z","2019-10-04T19:52:30Z"
"","1392","[WIP] HDFS-14801. PrometheusMetricsSink: Better support for NNTop.","JIRA: https://issues.apache.org/jira/browse/HDFS-14801","closed","","aajisaka","2019-09-02T05:35:33Z","2021-09-21T01:51:50Z"
"","1355","HDFS-14770. Erasure Coding: reconstructed internal block is error","JIRA: https://issues.apache.org/jira/browse/HDFS-14770","closed","","runitao","2019-08-27T09:36:40Z","2019-08-27T12:19:21Z"
"","1558","HADOOP-16620. [pb-upgrade] Remove protocol buffers 3.7.1 from requirements in BUILDING.txt","JIRA: https://issues.apache.org/jira/browse/HADOOP-16620","closed","","aajisaka","2019-10-01T07:13:10Z","2019-10-03T06:25:16Z"
"","1557","HADOOP-16609. Add Jenkinsfile for all active branches (branch-3.2)","JIRA: https://issues.apache.org/jira/browse/HADOOP-16609","closed","","aajisaka","2019-10-01T06:50:00Z","2019-10-10T01:47:45Z"
"","1354","HADOOP-16533. Upgrade jackson-databind to 2.9.9.3.","JIRA: https://issues.apache.org/jira/browse/HADOOP-16533","closed","","aajisaka","2019-08-27T07:11:08Z","2019-08-27T22:54:36Z"
"","1336","HADOOP-16527. Add a whitelist of endpoints to skip Kerberos authentication","JIRA: https://issues.apache.org/jira/browse/HADOOP-16527","closed","","aajisaka","2019-08-22T08:47:00Z","2019-09-02T02:10:32Z"
"","1244","HADOOP-16495. Fix invalid metric types in PrometheusMetricsSink","JIRA: https://issues.apache.org/jira/browse/HADOOP-16495","closed","","aajisaka","2019-08-07T07:13:33Z","2019-08-14T03:24:20Z"
"","1243","HADOOP-16494. Add SHA-512 checksum to release artifact to comply with the release distribution policy","JIRA: https://issues.apache.org/jira/browse/HADOOP-16494","closed","","aajisaka","2019-08-07T04:33:34Z","2019-08-22T02:03:02Z"
"","1170","HADOOP-16398. Exports Hadoop metrics to Prometheus","JIRA: https://issues.apache.org/jira/browse/HADOOP-16398","closed","ozone,","aajisaka","2019-07-26T07:42:47Z","2019-07-31T17:12:13Z"
"","1298","HADOOP-16061. Upgrade Yetus to 0.10.0","JIRA: https://issues.apache.org/jira/browse/HADOOP-16061","closed","","aajisaka","2019-08-15T02:30:48Z","2019-08-22T04:07:27Z"
"","763","[WIP] HADOOP-15984. Update jersey from 1.19 to 2.x","JIRA: https://issues.apache.org/jira/browse/HADOOP-15984  TODO list - [x] hadoop-common - [x] hadoop-hdfs - [ ] hadoop-mapreduce - [ ] hadoop-yarn - [ ] others","open","","aajisaka","2019-04-24T03:13:15Z","2022-06-20T20:32:04Z"
"","1307","HADOOP-15958. Revisiting LICENSE and NOTICE files","JIRA: https://issues.apache.org/jira/browse/HADOOP-15958","closed","","aajisaka","2019-08-16T11:10:40Z","2019-08-27T04:50:19Z"
"","1419","HADOOP-15184. Add GitHub pull request template.","JIRA: https://issues.apache.org/jira/browse/HADOOP-15184  * Updated the URL of the wiki page.","closed","","aajisaka","2019-09-10T06:38:00Z","2019-09-11T04:13:01Z"
"","910","HDDS-1612. Add 'scmcli printTopology' shell command to print datanode…","JIRA https://issues.apache.org/jira/browse/HDDS-1612","closed","ozone,","ChenSammi","2019-06-05T10:13:09Z","2019-06-06T03:13:40Z"
"","712","HDDS-1405. ITestOzoneContractCreate is failing.","ITestOzoneContractCreate and ITestOzoneContractMkdir are failing with FileAlreadyExistsException. The issue is around the file imported in BasicOzoneClientAdapterImpl. The class needs to import org.apache.hadoop.fs.FileAlreadyExistsException but currently imports java.nio.file.FileAlreadyExistsException.","closed","ozone,","lokeshj1703","2019-04-09T13:22:35Z","2019-04-09T17:39:43Z"
"","1224","HDDS-1810. SCM command to Activate and Deactivate pipelines.","It will be useful to have scm command to temporarily deactivate and re-activate a pipeline. This will help us a lot in debugging a pipeline.","closed","ozone,","nandakumar131","2019-08-04T14:09:00Z","2019-09-03T11:21:59Z"
"","1609","HDDS-2070. Create insight point to debug one specific pipeline","It depends on HDDS-2071","closed","","elek","2019-10-07T15:21:10Z","2019-12-04T14:18:05Z"
"","1514","HDDS-2072. Make StorageContainerLocationProtocolService message based","It depends on HDDS-2067","closed","ozone,","elek","2019-09-24T14:37:26Z","2019-10-03T00:01:45Z"
"","905","HDDS-1508. Provide example k8s deployment files for the new CSI server","Issue HDDS-1382 introduced a new internal CSI server. We should provide example deployment files to make it easy to deploy it to any kubernetes cluster.  See: https://issues.apache.org/jira/browse/HDDS-1508","closed","ozone,","elek","2019-06-04T13:12:25Z","2019-06-20T14:38:02Z"
"","1065","HDDS-1525. Mapreduce failure when using Hadoop 2.7.5","Integrate Ozone(0.4 branch) with Hadoop 2.7.5, ""hdfs dfs -ls /"" can pass, while teragen  failed.   When add  -verbose:class to java options, it shows that class KeyProvider is loaded twice by different classloader while it is only loaded once when execute  ""hdfs dfs -ls /""   All jars under share/ozone/lib are added into hadoop classpath except ozone file system current lib jar.   See: https://issues.apache.org/jira/browse/HDDS-1525","closed","ozone,","elek","2019-07-09T12:36:50Z","2019-07-10T13:36:24Z"
"","1157","HADOOP-16461. Regression: FileSystem cache lock parses XML within the lock","Instead of parsing a new configuration, rely on existing conf object within FileSystem","closed","","t3rmin4t0r","2019-07-24T23:41:00Z","2019-07-26T10:33:21Z"
"","1653","HADOOP-16653. S3Guard DDB overreacts to no tag access.","Initial PR just creates the test to demonstrate the issue.  Change-Id: I8ab98acbdf3d854491571ee98627f96a98cbde48","closed","","steveloughran","2019-10-14T10:46:31Z","2021-10-15T19:42:19Z"
"","1402","HADOOP-16547. make sure that s3guard prune sets up the FS","initial patch; not done the full testing yet  Change-Id: Iaf71561cef6c797a3c66fed110faf08da6cac361","closed","fs/s3,","steveloughran","2019-09-04T18:07:14Z","2021-10-15T19:50:42Z"
"","1061","HADOOP-16380 S3Guard tombstones can mislead about directory empty status","Initial patch changes ITestS3GuardEmptyDirs to replicate tombstone problem.   Moved the access to the innerGetFileStatus call into S3ATestUtils so that tests in the s3guard package can also get at it  Change-Id: I5e0aecea008ea281c12ca2ff16388effef45956c  Tested: s3 ireland. Now successfully fails :)","closed","fs/s3,","steveloughran","2019-07-08T15:53:20Z","2021-10-15T19:45:52Z"
"","1028","HDFS-14617 - Improve fsimage load time by writing sub-sections to the fsimage index","Initial code I used to perform my benchmarks for the above change. There are two parts to the change:  1) The code used to write the sub-sections to the image, which is fairly simple.  2) The code used to process the sub-sections in parallel. As much as possible this reuses the original code in multiple threads, but the inodeDirectory code needed to be moved around a bit to avoid synchronization issues.  The only sections with parallel loading so far are inode and inodeDirectory.  So far, there are no new tests for this feature. That is something I need to look into further if we agree this is a good change to move forward with.","closed","","sodonnel","2019-06-28T15:17:30Z","2019-08-30T03:39:36Z"
"","753","HDDS-1403. KeyOutputStream writes fails after max retries while writing to a closed container","Increasing the number of client retries to 100 and adding sleep of 500ms between retries","closed","ozone,","hanishakoneru","2019-04-18T23:07:46Z","2019-04-26T17:39:04Z"
"","1062","HDDS-1718. Increase Ratis Leader election timeout default.","Increased default to 5s. Fixed failing unit test.","closed","ozone,","swagle","2019-07-08T18:59:27Z","2019-07-09T17:59:23Z"
"","1023","YARN-9655:AllocateResponse in FederationInterceptor lost applicationPriority","In YARN Federation mode using FederationInterceptor, when submitting application, am will report an error. ``` java 2019-06-25 11:44:00,977 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: ERROR IN CONTACTING RM. java.lang.NullPointerException  at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.handleJobPriorityChange(RMContainerAllocator.java:1025)  at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getResources(RMContainerAllocator.java:880)  at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:286)  at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$AllocatorRunnable.run(RMCommunicator.java:280)  at java.lang.Thread.run(Thread.java:748) ``` The reason is that applicationPriority is lost.","closed","","hunshenshi","2019-06-27T12:41:42Z","2019-06-28T16:18:40Z"
"","1656","HADOOP-16579. Upgrade to Curator 4.2.0 and ZooKeeper 3.5.5","In this PR we upgraded the Apache Curator to 4.0.2 and Apache ZooKeeper to ~~3.5.5~~ 3.5.6.  While the new Curator and ZooKeeper versions are mostly backward-compatible with the old ones, we encountered a few minor issues still. So far the following changes have been made: - I added a static initializer for the unit tests using ZooKeeper to enable the four-letter-words diagnostic telnet commands. This is an interface that become disabled by default due to security concerns. (see https://issues.apache.org/jira/browse/ZOOKEEPER-2693) To keep the ZooKeeper 3.4.x behaviour, we enabled it for the tests. Some tests in Hadoop (or other projects using Hadoop-Common) might actually use this feature e.g. to verify the status of ZooKeeper. - I also fixed `ZKFailoverController` to look for relevant fail-over ActiveAttempt records. The new ZooKeeper seems to respond quicker during the fail-over tests than the old ZooKeeper, so we made sure to catch all the relevant records by adding a new parameter to `ZKFailoverontroller.waitForActiveAttempt()`.  Update 1: - On the new curator some of the API calls we use in Hadoop become deprecated, I updated that part in hadoop to not have compile time warnings - I changed the way how some tests are starting ZooKeeper server (the old server could be started with port 0 and bound to a random open port, but this feature is not working in ZooKeeper ~~3.5.5~~ 3.5.6, so I choose a random open port before starting the ZooKeeper server in the Hadoop code)  Update 2: - ZooKeeper 3.5.6 just got released, so I updated the version","closed","","symat","2019-10-14T14:20:14Z","2019-10-28T10:33:54Z"
"","1202","HDDS-1884. Support Bucket ACL operations for OM HA.","In this PR implemented add/set/remove ACL for the bucket.","closed","ozone,","bharatviswa504","2019-08-01T00:58:39Z","2019-08-09T04:29:01Z"
"","1014","HDDS-1727. Use generation of resourceName for locks in OzoneManagerLock.","In this Jira, we shall use generate Resourcename from actual resource names like volume/bucket/user/key inside OzoneManagerLock. In this way, users using these locking API's no need to worry of calling these additional API of generateResourceName in OzoneManagerLockUtil. And this also reduces code during acquiring locks in OM operations.","closed","ozone,","bharatviswa504","2019-06-25T19:22:12Z","2019-06-26T00:12:46Z"
"","867","HDDS-1605. Implement AuditLogging for OM HA Bucket write requests.","In this Jira, we shall implement audit logging for OM HA Bucket write requests.  As now we cannot use userName,  IpAddress from Server API's as these will be null, because the requests are executed under GRPC context. So, in our AuditLogger API's we need to pass username and remoteAddress which we can get from request after HDDS-1600 and use these during audit logging.","closed","ozone,","bharatviswa504","2019-05-28T20:16:38Z","2019-06-06T17:13:38Z"
"","980","Update RocksDB version to 6.0.1","In RocksDb 6.0.1, some useful tuning features were brought into the JNI API. We need to upgrade the version in ozone to pick those up.  https://github.com/facebook/rocksdb/pull/4833","closed","ozone,","avijayanhwx","2019-06-17T18:20:16Z","2019-06-18T18:14:09Z"
"","788","HDDS-1475 : Fix OzoneContainer start method.","In OzoneContainer start() we have   startContainerScrub(); writeChannel.start(); readChannel.start(); hddsDispatcher.init(); hddsDispatcher.setScmId(scmId);   Suppose here if the readChannel.start() failed due to some reason, from VersionEndPointTask, we try to start OzoneContainer again. This can cause an issue for writeChannel.start() if it is already started.   Fix the logic such a way that if service is started, don't attempt to start the service again. Similar changes needed to be done for stop().","closed","ozone,","avijayanhwx","2019-04-30T20:16:24Z","2019-05-07T21:09:41Z"
"","994","HDDS-1710. Publish JVM metrics via Hadoop metrics","In ozone metrics can be published with the help of hadoop metrics (for example via PrometheusMetricsSink)  The basic jvm metrics are not published by the metrics system (just with JMX)  I am very interested about the basic JVM metrics (gc count, heap memory usage) to identify possible problems in the test environment.  Fortunately it's very easy to turn it on with the help of org.apache.hadoop.metrics2.source.JvmMetrics.  See: https://issues.apache.org/jira/browse/HDDS-1710","closed","ozone,","elek","2019-06-20T10:06:18Z","2019-07-22T23:48:54Z"
"","857","HDDS-1600. Add userName and IPAddress as part of OMRequest.","In OM HA, the actual execution of request happens under GRPC context, so UGI object which we retrieve from ProtobufRpcEngine.Server.getRemoteUser(); will not be available.  In similar manner ProtobufRpcEngine.Server.getRemoteIp().     So, during preExecute(which happens under RPC context) extract userName and IPAddress and add it to the OMRequest, and then send the request to ratis server.","closed","ozone,","bharatviswa504","2019-05-27T21:22:25Z","2019-06-04T19:31:45Z"
"","1018","YARN-9643. Federation: Add subClusterID in nodes page of Router web","In nodes page of router web, there only are node info, No cluster id corresponding to the node.","open","","hunshenshi","2019-06-26T11:29:30Z","2021-06-28T03:29:25Z"
"","944","HDDS-1668. Add liveness probe to the example k8s resources files","In kubernetes resources we can define livebess probes which can help to detect any failure. If the define port is not available the pod will be rescheduled.  We need to add the liveness probes to our k8s resource files.  Note: We shouldn't add readiness probes. Readiness probe is about the service availability. The service/dns can be available only after the service is restarted. This is not good for us as:   * We need DNS resolution during the startup (See OzoneManager.loadOMHAConfigs)  * We already implemented retry in case of missing DNS entries  See: https://issues.apache.org/jira/browse/HDDS-1668","closed","ozone,","elek","2019-06-11T09:39:22Z","2019-07-15T20:19:33Z"
"","719","HDDS-1412. Provide example k8s deployment files as part of the release package","In HDDS-872 we added Dockerfile and skaffold definition to run dev builds on kubernetes. But it would be great to include example k8s resource definitions helping the deployment of ozone to any kubernetes cluster.  In this patch I will  1. Add k8s resources files to the release tar file to deploy basic ozone cluster 2. Add Dockerfile to the release tar file to create custom ozone image any time 3. Add additional maven profiles to build and push development docker images. 4. We don't need skaffold any more as the maven based approach is more flexible (we can support multiple k8s definitions)  To easily support multiple type of configuration (simple ozone, minikube, csi) we need a basic set of k8s resources files and additional transformations to generate the ready-to-use files for each specific use-cases.  The easiest way to do this is adopting the existing structure from https://github.com/flokkr/k8s and use https://github.com/elek/flekszible tool. But the tool itself is not required at runtime as we generate all the required k8s resources files during the development and add the results to the version control.   See: https://issues.apache.org/jira/browse/HDDS-1412","closed","ozone,","elek","2019-04-10T16:09:01Z","2019-05-02T10:11:49Z"
"","1058","HDDS-1763. Use vendor neutral s3 logo in ozone doc","In HDDS-1639 we restructured the ozone documentation and a new overview page is added to the main page.  This page contains an official aws logo, As [~bharatviswa] reported we are not sure about the exact condition to use logos / trademarks from Amazon. It's better to remain on the safe side and use a neutral S3 label.  In this patch the aws logo is replaced with an orange cloud + s3 text.  See: https://issues.apache.org/jira/browse/HDDS-1763","closed","ozone,","elek","2019-07-04T15:14:40Z","2019-07-15T20:17:22Z"
"","892","HDDS-1631. Fix auditparser smoketests","In HDDS-1518 we modified the location of the var and config files inside the container.  There are three problems with the current auditparser smokest:   1. The default audit log4j files are not part of the new config directory (fixed with HDDS-1630)  2. The smoketest is executed in scm container instead of om  3. The log directory is hard coded  The 2 and 3 will be fined in this patch.   See: https://issues.apache.org/jira/browse/HDDS-1631","closed","ozone,","elek","2019-06-03T09:11:16Z","2019-06-04T06:30:44Z"
"","1505","HDDS-2166. Some RPC metrics are missing from SCM prometheus endpoint","In Hadoop metrics it's possible to register multiple metrics with the same name but with different tags. For example each RpcServere has an own metrics instance in SCM.  {code}     ""name"" : ""Hadoop:service=StorageContainerManager,name=RpcActivityForPort9860"",     ""name"" : ""Hadoop:service=StorageContainerManager,name=RpcActivityForPort9863"", {code}  They are converted by PrometheusSink to a prometheus metric line with proper name and tags. For example:  {code} rpc_rpc_queue_time60s_num_ops{port=""9860"",servername=""StorageContainerLocationProtocolService"",context=""rpc"",hostname=""72736061cbc5""} 0 {code}  The PrometheusSink uses a Map to cache all the recent values but unfortunately the key contains only the name (rpc_rpc_queue_time60s_num_ops in our example) but not the tags (port=...)  For this reason if there are multiple metrics with the same name, only the first one will be displayed.  As a result in SCM only the metrics of the first RPC server can be exported to the prometheus endpoint.    See: https://issues.apache.org/jira/browse/HDDS-2166","closed","ozone,","elek","2019-09-23T14:46:15Z","2019-10-01T16:01:21Z"
"","1160","HADOOP-16458 LocatedFileStatusFetcher.getFileStatuses failing intermittently with s3","Improving diagnostics of scanning  * stack traces don't get lost as failures get wrapped/aggregated * debug level logging of what is up in Globber * Preparation for a test of LocatedFileStatus in S3A, though I've got some better ideas there (i.e. make it a scale test) * Contains HADOOP-13373. Add S3A implementation of FSMainOperationsBaseTest.","closed","fs/s3,","steveloughran","2019-07-25T13:21:36Z","2019-10-01T17:11:57Z"
"","1213","Hadoop 16455","Implemented FileSystem.access() method for ABFS. A new configuration has been added to switch on/off the functionality.","closed","","bilaharith","2019-08-02T08:34:26Z","2019-11-12T10:05:40Z"
"","884","HDDS-1620. Implement Volume Write Requests to use Cache and DoubleBuffer.","Implement Volume write requests to use OM Cache, double buffer.   In this Jira will add the changes to implement volume operations, and HA/Non-HA will have a different code path, but once all requests are implemented will have a single code path.","closed","ozone,","bharatviswa504","2019-06-01T01:04:46Z","2019-06-13T00:45:43Z"
"","1588","HDDS-1986. Fix listkeys API.","Implement listKeys API.","closed","ozone,","bharatviswa504","2019-10-03T22:54:41Z","2019-10-10T23:49:26Z"
"","947","HDDS-1638. Implement Key Write Requests to use Cache and DoubleBuffer","Implement Key write requests to use OM Cache, double buffer.   In this Jira will add the changes to implement key operations, and HA/Non-HA will have a different code path, but once all requests are implemented will have a single code path.    This PR is dependent on HDDS-1620. Submitted to get CI run. First commit is change from HDDS-1620, the 2nd commit is actual changes of this PR.  In further commits will add UT's for the new classes.","closed","ozone,","bharatviswa504","2019-06-11T21:10:30Z","2019-06-13T01:02:41Z"
"","956","HDDS-1638.  Implement Key Write Requests to use Cache and DoubleBuffer.","Implement Key write requests to use OM Cache, double buffer.   In this Jira will add the changes to implement key operations, and HA/Non-HA will have a different code path, but once all requests are implemented will have a single code path.","closed","ozone,","bharatviswa504","2019-06-13T01:03:44Z","2019-06-27T02:41:14Z"
"","1300","HDFS-14738：Reading and writing HDFS data through HDFS nfs3 server often getting stuck","If the user group does not exist, there will be a lot of invoking the updateMapIncr . And it is the synchronized methods，it really affects performance.","open","hdfs,","alexkingli","2019-08-15T06:55:13Z","2020-07-31T19:01:12Z"
"","1278","HDDS-1950. S3 MPU part-list call fails if there are no parts","If an S3 multipart upload is created but no part is upload the part list can't be called because it throws HTTP 500:  Create an MPU:  {code} aws s3api --endpoint http://localhost:9999 create-multipart-upload --bucket=docker --key=testkeu                                          {     ""Bucket"": ""docker"",     ""Key"": ""testkeu"",     ""UploadId"": ""85343e71-4c16-4a75-bb55-01f56a9339b2-102592678478217234"" } {code}  List the parts:  {code} aws s3api --endpoint http://localhost:9999 list-parts  --bucket=docker --key=testkeu --upload-id=85343e71-4c16-4a75-bb55-01f56a9339b2-102592678478217234 {code}  It throws an exception on the server side, because in the KeyManagerImpl.listParts the  ReplicationType is retrieved from the first part:  {code}         HddsProtos.ReplicationType replicationType =             partKeyInfoMap.firstEntry().getValue().getPartKeyInfo().getType(); {code}  Which is not yet available in this use case.  See: https://issues.apache.org/jira/browse/HDDS-1950","closed","ozone,","elek","2019-08-11T12:32:24Z","2019-08-28T19:14:35Z"
"","1688","HADOOP-16742. Possible NPE in S3A MultiObjectDeleteSupport error handling.","I've hit an issue where a DeleteObjects request using LocalStack causes a NullPointerException in the translateDeleteException function. `error.getCode()` can return `null`, and if there is more than one error returned by `deleteException.getErrors()`, this will cause the NPE.","closed","","torarvid","2019-11-01T12:05:11Z","2022-02-18T18:04:51Z"
"","706","YARN-9433. Remove unused constants in YARN resource manager","I've checked that these constants are not used in the project at all.","closed","","hextriclosan","2019-04-08T15:12:47Z","2019-04-10T09:39:59Z"
"","1017","how to get block in mr","i want to know block Before  mr task to do something","closed","","q1007239205","2019-06-26T03:16:59Z","2019-08-11T15:36:32Z"
"","727","HDDS-1425. Ozone compose files are not compatible with the latest docker-compose","I upgraded my docker-compose to the latest available one (1.24.0)  But after the upgrade I can't start the docker-compose based cluster any more:  ``` ./test.sh  ------------------------------------------------- Executing test(s): [basic]    Cluster type:      ozone   Compose file:      /home/elek/projects/hadoop-review/hadoop-ozone/dist/target/ozone-0.4.0-SNAPSHOT/smoketest/../compose/ozone/docker-compose.yaml   Output dir:        /home/elek/projects/hadoop-review/hadoop-ozone/dist/target/ozone-0.4.0-SNAPSHOT/smoketest/result   Command to rerun:  ./test.sh --keep --env ozone basic ------------------------------------------------- ERROR: In file /home/elek/projects/hadoop-review/hadoop-ozone/dist/target/ozone-0.4.0-SNAPSHOT/compose/ozone/docker-config: environment variable name 'LOG4J2.PROPERTIES_appender.rolling.file  ```  It turned out that the line of LOG4J2.PROPERTIES_appender.rolling.file contains an unnecessary space which is not accepted by the latest docker-compose any more.  See: https://issues.apache.org/jira/browse/HDDS-1425","closed","ozone,","elek","2019-04-11T14:06:20Z","2019-04-12T16:45:36Z"
"","961","HDDS-1680. Create missing parent directories during the creation of HddsVolume dirs","I started to execute all the unit tests continuously (in kubernetes with argo workflow).  Until now I got the following failures (number of failures / unit test name):  ```       1 org.apache.hadoop.fs.ozone.contract.ITestOzoneContractMkdir       1 org.apache.hadoop.fs.ozone.contract.ITestOzoneContractRename       3 org.apache.hadoop.hdds.scm.container.placement.algorithms.TestSCMContainerPlacementRackAware      31 org.apache.hadoop.ozone.container.common.TestDatanodeStateMachine      31 org.apache.hadoop.ozone.container.common.volume.TestVolumeSet       1 org.apache.hadoop.ozone.freon.TestDataValidateWithSafeByteOperations ```  TestVolumeSet is also failed locally:  {code} 2019-06-13 14:23:18,637 ERROR volume.VolumeSet (VolumeSet.java:initializeVolumeSet(184)) - Failed to parse the storage location: /home/elek/projects/hadoop/hadoop-hdds/container-service/target/test-dir/dfs java.io.IOException: Cannot create directory /home/elek/projects/hadoop/hadoop-hdds/container-service/target/test-dir/dfs/hdds 	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.initialize(HddsVolume.java:208) 	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.(HddsVolume.java:179) 	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.(HddsVolume.java:72) 	at org.apache.hadoop.ozone.container.common.volume.HddsVolume$Builder.build(HddsVolume.java:156) 	at org.apache.hadoop.ozone.container.common.volume.VolumeSet.createVolume(VolumeSet.java:311) 	at org.apache.hadoop.ozone.container.common.volume.VolumeSet.initializeVolumeSet(VolumeSet.java:165) 	at org.apache.hadoop.ozone.container.common.volume.VolumeSet.(VolumeSet.java:130) 	at org.apache.hadoop.ozone.container.common.volume.VolumeSet.(VolumeSet.java:109) 	at org.apache.hadoop.ozone.container.common.volume.TestVolumeSet.testFailVolumes(TestVolumeSet.java:232) 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) 	at java.lang.reflect.Method.invoke(Method.java:498) 	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47) 	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) 	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44) 	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) 	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) 	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) 	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74) {code}  The problem here is that the parent directory of the volume dir is missing. I propose to use hddsRootDir.mkdirs() instead of hddsRootDir.mkdir() which creates the missing parent directories.   See: https://issues.apache.org/jira/browse/HDDS-1680","closed","ozone,","elek","2019-06-13T12:28:56Z","2019-06-13T23:18:16Z"
"","1271","HADOOP-16082. FsShell ls: Add option -i to print inode id","I put the helper function at `CommandUtils#getValueFromFileStatusString` since I'm not sure where to put it, though it seems nobody uses `CommandUtils` anymore. Please advice.","open","","smengcl","2019-08-10T11:30:39Z","2021-10-18T13:26:08Z"
"","1325","Fix a typo in TextInputFormat.java","I pushed wrong base last time.sorry","closed","","XBaith","2019-08-21T08:34:51Z","2019-08-21T15:56:41Z"
"","969","HDDS-1597. Remove hdds-server-scm dependency from ozone-common","I noticed that the hadoop-ozone/common project depends on hadoop-hdds-server-scm project.  The common projects are designed to be a shared artifacts between client and server side. Adding additional dependency to the common pom means that the dependency will be available for all the clients as well.  (See the attached artifact about the current, desired structure).  We definitely don't need scm server dependency on the client side.  The code dependency is just one class (ScmUtils) and the shared code can be easily moved to the common.  See: https://issues.apache.org/jira/browse/HDDS-1597","closed","ozone,","elek","2019-06-14T14:05:41Z","2019-06-24T18:56:18Z"
"","860","HDDS-1597. Remove hdds-server-scm dependency from ozone-common","I noticed that the hadoop-ozone/common project depends on hadoop-hdds-server-scm project.  The common projects are designed to be a shared artifacts between client and server side. Adding additional dependency to the common pom means that the dependency will be available for all the clients as well.  (See the attached artifact about the current, desired structure).  We definitely don't need scm server dependency on the client side.  The code dependency is just one class (ScmUtils) and the shared code can be easily moved to the common.  See: https://issues.apache.org/jira/browse/HDDS-1597","closed","ozone,","elek","2019-05-28T08:08:24Z","2019-06-03T06:36:40Z"
"","1412","Avoiding logging Sasl message","I have created a tool (as my Master's thesis project) to analyze the evolution of function callgraphs of a software project through its commit history. I use the results of my tool to find problems in the most recent version of a project based on the problems in the older versions. I have used Hadoop as my dataset. One category of problems that I have focused on is an inconsistent change which is a change that is applied to a part of the code and should be applied to other parts of code that have the same situation.   In this case, the issue that my tool detected is that logging Sasl message should be avoided based on the issue HADOOP-11962. All of the instances of logging functions, that have Sasl message as their argument, have been removed except this one. So I am creating an issue and a pull request to suggest this change and assess the accuracy of my results.","open","","anaeimian","2019-09-06T20:35:44Z","2022-01-30T12:58:22Z"
"","1651","YARN-9880. In YARN ui2 attempts tab, The running Application Attempt's ElapsedTime is incorrect.","I found this problem where hadoop3.1.1 was used, want to upgrade to the latest version of hadoop, but found the running Application Attempt's ElapsedTime is also incorrect.  In UI1, get ElapsedTime from yarn server. In UI2, get currentTime from brower. Therefore, when the brower and the yarn server are not in the same time zones, the ElapsedTime is incorrect. While the Application‘s ElapsedTime is 29 Secs, the Application Attempt's ElapsedTime is 10 Hrs : 49 Mins : 55 Secs.  I think, in UI2, ElapsedTime should also come from the yarn server too.","open","","cjn082030","2019-10-12T10:05:02Z","2020-07-31T18:40:07Z"
"","1626","YARN-9880. In YARN ui2 attempts tab, The running Application Attempt's ElapsedTime is incorrect.","I found this problem where hadoop3.1.1 was used,  want to upgrade to the latest version of hadoop,  but found the running Application Attempt's ElapsedTime is also incorrect.  In UI1, get ElapsedTime from yarn server. In UI2, get currentTime from brower. Therefore, when the brower and the yarn server are not in the same time zones, the ElapsedTime is incorrect. While the Application‘s ElapsedTime is 29 Secs, the Application Attempt's ElapsedTime is 10 Hrs : 49 Mins : 55 Secs.   I think, in UI2, ElapsedTime should also come from the yarn server too.","closed","","cjn082030","2019-10-09T09:15:26Z","2019-10-12T10:06:15Z"
"","1021","huowang","I encountered a problem when I converted edits files from XML to binary using the HDFS oev command    Usually this conversion operation will not be a problem, but my XML culture contains an OP_TRUNCATE operation node, in this case, the error is reported, the specific error is as follows. (sorry, I can only take a screenshot because the company environment does not allow copying code, the name of the file is not NameNode's default name because I backed up the edits file for testing). ![image](https://user-images.githubusercontent.com/20262356/60243523-016a7000-98eb-11e9-84c1-05b4ef2c96e6.png)  The contents of the XML file are as follows ![image](https://user-images.githubusercontent.com/20262356/60243723-73db5000-98eb-11e9-977e-4f9ffea068ba.png) I found the error-reporting code and found that the blockFromXml method passed the entire data node instead of the subordinate BLOCK node. I think this was the reason. So I modified the code and recompiled it. Then I installed a single node Hadoop cluster and tested the HDFS oev command conversion file successfully. This is my first time to submit a patch. My English is not particularly good, I am not sure. Should the modified code be submitted in this way?  I hope I can contribute to the community.","open","","arthas-171","2019-06-27T07:11:04Z","2019-09-11T02:46:40Z"
"","1036","YARN-9655: add a UT for lost applicationPriority in FederationInterceptor","I add a UT in TestFederationInterceptor#testAllocateResponse。","open","","hunshenshi","2019-06-29T02:28:14Z","2020-07-31T19:38:40Z"
"","1648","HDFS-12478. Command line tools for managing Provided Storage Backup m…","https://issues.apache.org/jira/browse/HDFS-12478   This is a task for implementing the command line interface for attaching a PROVIDED storage backup system (see HDFS-9806, HDFS-12090).  The administrator should be able to mount a PROVIDED storage volume from the command line. ``` hdfs attach -create [-name ]   ``` Whitelist of users who are able to manage mounts (create, attach, detach). Be able to interrogate the status of the attached storage (last time a snapshot was taken, files being backed up).  The administrator should be able to remove an attached PROVIDED storage volume from the command line. This simply means that the synchronization process no longer runs. If the administrator has configured their setup to no longer have local copies of the data, the blocks in the subtree are simply no longer accessible as the external file store system is currently inaccessible. ``` hdfs attach -remove  [-force | -flush] ```  FYI @virajith.  Note that this will have overlap with HDFS-14805 but this is going to the HDFS-12090 branch and was carved out to make other patches smaller for review.","open","","ehiggs","2019-10-11T15:10:59Z","2019-12-02T17:12:00Z"
"","1623","HDDS-2269. Provide config for fair/non-fair for OM RW Lock.","https://issues.apache.org/jira/browse/HDDS-2269  Provide config in OzoneManager Lock for fair/non-fair for OM RW Lock.","closed","ozone,","bharatviswa504","2019-10-09T05:14:15Z","2019-10-10T17:59:24Z"
"","1574","HDDS-2227. GDPR key generation could benefit from secureRandom.","https://issues.apache.org/jira/browse/HDDS-2227 The SecureRandom can be used for the symetric key for GDPR. While GDPR is not a security feature, this is a good to have optional feature.  I want to thank Jonathan Leitschuh, for originally noticing this issue and reporting it.  How tested: ran unit.sh, had one failure in TestSCMContainerPlacementRackAware","closed","ozone,","anuengineer","2019-10-02T06:37:08Z","2019-10-02T19:35:20Z"
"","1572","HDDS-2226. S3 Secrets should use a strong RNG.","https://issues.apache.org/jira/browse/HDDS-2226  The S3 token generation under ozone should use a strong RNG.  I want to thank Jonathan Leitschuh, for originally noticing this issue and reporting it.  How tested: Ran Unit.sh","closed","ozone,","anuengineer","2019-10-02T05:26:40Z","2019-10-03T16:33:11Z"
"","1637","HDDS-2206. Separate handling for OMException and IOException in the Ozone Manager. Contributed by Supratim Deka","https://issues.apache.org/jira/browse/HDDS-2206  Introduced a boolean config parameter to control exception propagation from OM to Clients. If set to true, all system exceptions (IOException) are thrown as ServiceException to RPC client - this also propagates the complete server-side stack trace to the client. If false, system exception stack trace is logged locally on the server, not sent to client. The default value is set to true for now. For Ozone GA, we can revisit this choice.  Business Exception (OMException) handling is not changed.  This change does not include propagation of exceptions from within Ratis server.","open","ozone,","supratimdeka","2019-10-10T10:06:41Z","2019-10-15T10:04:57Z"
"","1566","HDDS-2201. Rename VolumeList to UserVolumeInfo.","https://issues.apache.org/jira/browse/HDDS-2201  Under Ozone Manager, The volume points to a structure called volumeInfo, Bucket points to BucketInfo, Key points to KeyInfo. However, User points to VolumeList. duh?  This JIRA proposes to refactor the VolumeList as UserVolumeInfo. Why not, UserInfo, because that structure is already taken by the security work of Ozone Manager.  How tested: Ran unit.sh","closed","ozone,","anuengineer","2019-10-01T17:20:31Z","2019-10-02T16:26:34Z"
"","1565","Hdds 2201","https://issues.apache.org/jira/browse/HDDS-2201  Under Ozone Manager, The volume points to a structure called volumeInfo, Bucket points to BucketInfo, Key points to KeyInfo. However, User points to VolumeList. duh?  This JIRA proposes to refactor the VolumeList as UserVolumeInfo. Why not  UserInfo, because that structure is already taken by the security work of Ozone Manager.","closed","ozone,","anuengineer","2019-10-01T16:48:38Z","2019-10-01T17:29:31Z"
"","1632","HDDS-2194. Replication of Container fails with Only closed containers…","https://issues.apache.org/jira/browse/HDDS-2194  The issue is because when the Replication Manager is considering to replicate containers which are under replicated, it considers replicas in QuasiClosed/Closed. Whereas in Datanode we have a check of Closed. This has caused the issue. So, that is why we see IllegealStateException in the logs.","closed","ozone,","bharatviswa504","2019-10-09T22:18:29Z","2019-10-15T02:38:57Z"
"","1526","HDDS-2180. Add Object ID and update ID on VolumeList Object.","https://issues.apache.org/jira/browse/HDDS-2180 Adds Object ID and Update ID to VolumeList object.","closed","ozone,","anuengineer","2019-09-25T21:47:10Z","2019-09-26T21:01:56Z"
"","1520","HDDS-2175. Propagate stack trace for OM Exceptions to the Client. Contributed by Supratim Deka","https://issues.apache.org/jira/browse/HDDS-2175  complete stack trace added into the message field of OM response. SCM exceptions(allocate block) are wrapped into an IOException on the OM and propagated to the client.  Intent is to make debugging more convenient.","closed","ozone,","supratimdeka","2019-09-25T06:25:19Z","2019-09-30T10:33:14Z"
"","1517","HDDS-2169. Avoid buffer copies while submitting client requests in Ratis","https://issues.apache.org/jira/browse/HDDS-2169","closed","ozone,","szetszwo","2019-09-24T23:06:44Z","2019-10-07T10:19:14Z"
"","1377","HDDS-2057. Incorrect Default OM Port in Ozone FS URI Error Message. Contributed by Supratim Deka","https://issues.apache.org/jira/browse/HDDS-2057  fixed the URI exception message to pull in OM port value from the Configuration. The web documentation in ozonefs.md shows the correct default OM port and does not need to be fixed.","closed","ozone,","supratimdeka","2019-08-29T15:57:44Z","2019-09-13T18:42:29Z"
"","1197","HDDS-1882. TestReplicationManager failed with NPE in ReplicationManager","https://issues.apache.org/jira/browse/HDDS-1882","closed","ozone,","ChenSammi","2019-07-31T12:20:32Z","2019-08-02T03:10:16Z"
"","1194","HDDS-1879.  Support multiple excluded scopes when choosing datanodes in NetworkTopology","https://issues.apache.org/jira/browse/HDDS-1879","closed","ozone,","ChenSammi","2019-07-31T11:38:31Z","2019-09-19T07:52:03Z"
"","1184","HDDS-1865. Use ""ozone.network.topology.aware.read"" to control both RPC client and server side logic","https://issues.apache.org/jira/browse/HDDS-1865  Change log, 1. change property name from dfs.network.topology.aware.read.enable to ozone.network.topology.aware.read 2. add  ""optional bool sortDatanodes = 14;"" in KeyArgs definition in OzoneManagerProtocol.proto 3. refine unit tests  4. add more logs for future debug","closed","ozone,","ChenSammi","2019-07-30T03:32:24Z","2019-08-12T02:24:56Z"
"","1168","HDDS-1864. Turn on topology aware read in TestFailureHandlingByClient.","https://issues.apache.org/jira/browse/HDDS-1864.","closed","ozone,","ChenSammi","2019-07-26T03:29:17Z","2019-07-26T17:42:15Z"
"","1113","HDDS-1798. Propagate failure in writeStateMachineData to Ratis. Contributed by Supratim Deka","https://issues.apache.org/jira/browse/HDDS-1798  unit test is pending. Will add the infra required for testing this change as part of https://issues.apache.org/jira/browse/HDDS-1818  writeStateMachineData() currently returns a future to Ratis. The scope of this jira is to signal any errors or failures encountered as part of the operation - WriteChunk / handleWriteChunk() to Ratis via this future. As of now, the future does not track failures.  This change is required to complete the failure handling done in HDDS-1603.","closed","ozone,","supratimdeka","2019-07-17T15:55:40Z","2019-08-05T08:14:35Z"
"","1094","HDDS-1787. NPE thrown while trying to find DN closest to client.","https://issues.apache.org/jira/browse/HDDS-1787?filter=-1","closed","ozone,","ChenSammi","2019-07-15T12:55:24Z","2019-07-16T19:52:30Z"
"","1081","HDDS-1754. getContainerWithPipeline fails with PipelineNotFoundException. Contributed by Supratim Deka","https://issues.apache.org/jira/browse/HDDS-1754  DeadNodeHandler can clean up the pipeline while containers are still in CLOSING state. modified getContainerWithPipeline() to refer the pipeline only if the container is in OPEN state. In CLOSING state, the read pipeline will be constructed from the Replicas known to SCM - this is already existing behavior for CLOSED state.","closed","","supratimdeka","2019-07-12T04:13:04Z","2019-07-12T05:01:49Z"
"","1051","HDDS-1748. Error message for 3 way commit failure is not verbose. Contributed by Supratim Deka","https://issues.apache.org/jira/browse/HDDS-1748  Added logs to print pipeline id, block id and datanode addresses when 3 way commit failure is encountered in watchForCommit.","closed","ozone,","supratimdeka","2019-07-03T11:05:47Z","2019-07-10T11:15:56Z"
"","933","HDDS-1662.Missing test resources of integrataion-test project in targ…","https://issues.apache.org/jira/browse/HDDS-1662","closed","ozone,","ChenSammi","2019-06-09T14:51:11Z","2019-06-12T05:04:38Z"
"","904","HDDS-1637. Fix random test failure TestSCMContainerPlacementRackAware.","https://issues.apache.org/jira/browse/HDDS-1637","closed","ozone,","ChenSammi","2019-06-04T12:41:02Z","2019-06-05T16:09:37Z"
"","917","HDDS-1621. writeData in ChunkUtils should not use AsynchronousFileChannel. Contributed by Supratim Deka","https://issues.apache.org/jira/browse/HDDS-1621  2 changes: 1. invoking a force+close on the channel inside writeData if dfs.container.chunk.write.sync is true. The force is triggered outside of the file lock, to avoid unnecessary lock contention. 2. change AsynchronousFileChannel to FileChannel for writing the file. This is the right thing to do because writeStateMachineData is already scheduling the write chunk requests asynchronously on threads from XceiverServerRatis.chunkExecutor.","closed","","supratimdeka","2019-06-06T06:02:09Z","2019-06-06T13:24:10Z"
"","1019","HDDS-1603. Handle Ratis Append Failure in Container State Machine. Contributed by Supratim Deka","https://issues.apache.org/jira/browse/HDDS-1603  The scope of this jira is to build on https://issues.apache.org/jira/browse/RATIS-573 and define the handling for Ratis log append failure in Ozone Container State Machine. 1. Enqueue pipeline unhealthy action to SCM, add a reason code to the message. 2. Trigger immediate heartbeat to SCM  Ratis-573 is not available in trunk. So this patch starts with an entry point in XceiverServerRatis which will be hooked up to notifyLogFailed() callback defined in StateMachine as part of RATIS-573.  Notify Ratis volume unhealthy to the Datanode is not implemented in this patch","closed","","supratimdeka","2019-06-26T16:39:55Z","2019-07-10T02:20:27Z"
"","931","HDDS-1586. Allow Ozone RPC client to read with topology awareness.","https://issues.apache.org/jira/browse/HDDS-1586","closed","ozone,","ChenSammi","2019-06-08T17:03:13Z","2019-07-25T17:26:42Z"
"","841","HDDS-1559. Include committedBytes to determine Out of Space in VolumeChoosingPolicy. Contributed by Supratim Deka","https://issues.apache.org/jira/browse/HDDS-1559  This patch improves the space availability check in chooseVolume by inclusion of committed space(committedBytes in HddsVolume) in the equation. Container create fails with Exception if there isn't sufficient available space.  The handling/management of the exception in Ratis is not modified in this patch. That will be scoped separately as part of Datanode IO Failure handling work.","closed","ozone,","supratimdeka","2019-05-21T17:46:25Z","2019-05-29T03:48:15Z"
"","1361","HDDS-1553. Add metrics in rack aware container placement policy.","https://issues.apache.org/jira/browse/HDDS-1553.  Initial patch","closed","ozone,","ChenSammi","2019-08-28T02:51:29Z","2019-09-07T08:04:17Z"
"","832","HDDS-1535. Space tracking for Open Containers : Handle Node Startup. Contributed by Supratim Deka","https://issues.apache.org/jira/browse/HDDS-1535  Follow up from HDDS-1511. Space tracking for Open Containers (committed space in the volume) relies on usedBytes in the Container state. usedBytes is not persisted for every update (chunkWrite). So on a node restart the value is stale.  The fix iterates the block DB for Open containers when building the container set (during startup).","closed","ozone,","supratimdeka","2019-05-18T10:54:08Z","2019-05-23T17:42:30Z"
"","957","HDDS-1532. Improve the concurrent testing framework of Freon.","https://issues.apache.org/jira/browse/HDDS-1532","closed","ozone,","iamcaoxudong","2019-06-13T06:45:12Z","2019-06-18T07:16:58Z"
"","830","HDDS-1530. Freon support big files larger than 2GB and add --bufferSize and --validateWrites options.","https://issues.apache.org/jira/browse/HDDS-1530 Ozone: Freon: Support big files larger than 2GB and add ""--bufferSize"" and ""--validateWrites"" options.","closed","ozone,","iamcaoxudong","2019-05-17T06:55:35Z","2019-06-11T09:43:06Z"
"","852","HDDS-1454. GC other system pause events can trigger pipeline destroy for all the nodes in the cluster. Contributed by Supratim Deka","https://issues.apache.org/jira/browse/HDDS-1454  Problem: In a MiniOzoneChaosCluster run it was observed that events like GC pauses or any other pauses in SCM can mark all the datanodes as stale in SCM. This will trigger multiple pipeline destroy and will render the system unusable.  Solution: Added a timestamp check in NodeStateManager. If the heartbeat task detects a long scheduling delay since the last time it ran, then the task skips doing health checks and node state transitions in the current iteration.  Test: The unit test simulates a JVM pause by simply pausing the iterations of the health check task. Once the health check task is ""unpaused"", the system condition will be similar to a JVM pause. The test asserts that any node with heartbeats should not transition to Stale or Dead after such a long delay in scheduling.","closed","ozone,","supratimdeka","2019-05-27T05:32:05Z","2019-06-19T14:41:17Z"
"","825","HDDS-1449. JVM Exit in datanode while committing a key. Contributed by Mukul Kumar Singh.","https://issues.apache.org/jira/browse/HDDS-1449  The JVM exit was happening because the db instance was being closed while the other thread was adding a key to the db.","closed","ozone,","mukul1987","2019-05-16T12:35:24Z","2019-05-22T11:50:01Z"
"","1323","HDDS-1094. Performance test infrastructure : skip writing user data on Datanode. Contributed by Supratim Deka","https://issues.apache.org/jira/browse/HDDS-1094  Added an alternate ChunkManager implementation which drops all chunk writes without writing to disk. Chunk Reads are cooked up zero-filled buffers. The goal of this infrastructure is to enable high-throughput tests and stress the pipeline (including the Ozone metadata components) without using faster storage devices like flash drives.  Added an extension to TestDataValidate (with the RandomKeyGenerator) to test the alternate ChunkManager.","closed","ozone,","supratimdeka","2019-08-21T03:43:08Z","2019-08-28T17:05:21Z"
"","738","[YARN-9479] Use Objects.equals(String,String) to avoid possible NullPointerException","Hello, I found that the String ""queueName"" may cause potential risk of  NullPointerException since it is immediately used after initialization and there is no null checker. One recommended API is Objects.equals(String,String) which can avoid this exception.","open","","bd2019us","2019-04-14T02:10:25Z","2019-09-03T02:39:38Z"
"","1416","HDDS-2102. HddsVolumeChecker should use java optional in place of Guava optional. Contributed by Mukul Kumar Singh.","HddsVolumeChecker should use java optional in place of Guava optional as Guava Optional is marked as unstable.","closed","ozone,","mukul1987","2019-09-09T17:18:43Z","2019-09-09T21:17:52Z"
"","791","HDDS-1479. Update S3.md documentation","HDDS-791 implemented range get operation.  But, S3.md documentation still has the below line:   GET Object | implemented | Range headers are not supported  This PR deletes the ""Range headers are not supported"" from the doc.","closed","ozone,","vivekratnavel","2019-05-02T07:08:12Z","2019-05-02T09:50:55Z"
"","1180","HDDS-1871. Remove anti-affinity rules from k8s minkube example","HDDS-1646 introduced real persistence for k8s example deployment files which means that we need anti-affinity scheduling rules: Even if we use statefulset instead of daemonset we would like to start one datanode per real nodes.  With minikube we have only one node therefore the scheduling rule should be removed to enable at least 3 datanodes on the same physical nodes.  How to test:  {code}  mvn clean install -DskipTests -f pom.ozone.xml cd hadoop-ozone/dist/target/ozone-0.5.0-SNAPSHOT/kubernetes/examples/minikube minikube start kubectl apply -f . kc get pod {code}  You should see 3 datanode instances.   See: https://issues.apache.org/jira/browse/HDDS-1871","closed","ozone,","elek","2019-07-29T12:45:20Z","2019-08-21T19:50:41Z"
"","1000","HDDS-1715 - Update the Intellij runner definitition of SCM to use the new class name","HDDS-1622 changed the CLI framework of SCM and with a new additional class (StorageContainerMangerStarter) it made it more testable.  But the intellij runner definitions are not (yet) updated to use the new class name for SCM/SCM-init (they are updated for OM in HDDS-1660).  We need to adjust the main class names in:  hadoop-ozone/dev-support/intellij/runConfigurations/StorageContainerManager.xml hadoop-ozone/dev-support/intellij/runConfigurations/StorageContainerManagerInit.xml","closed","","sodonnel","2019-06-21T10:49:41Z","2019-06-21T14:26:41Z"
"","1598","HDDS-2251. Add an option to customize unit.sh and integration.sh parameters","hadoop-ozone/dev-support/checks/unit.sh (and same with integration) provides an easy entrypoint to execute all the unit/integration test. But in same cases it would be great to use the script but further specify the scope of the test.  With this simple patch it will be possible to adjust the surefire parameters.  See: https://issues.apache.org/jira/browse/HDDS-2251","closed","ozone,","elek","2019-10-04T17:05:00Z","2019-10-05T11:40:01Z"
"","1348","HDDS-2030. Generate simplifed reports by the dev-support/checks/*.sh scripts","hadoop-ozone/dev-support/checks directory contains shell scripts to execute different type of code checks (findbugs, checkstyle, etc.)  Currently the contract is very simple. Every shell script executes one (and only one) check and the shell response code is set according to the result (non-zero code if failed).  To have better reporting in the github pr build, it would be great to improve the scripts to generate simple summary files and save the relevant files for archiving.  See: https://issues.apache.org/jira/browse/HDDS-2030","closed","ozone,","elek","2019-08-24T21:58:36Z","2019-09-16T19:30:47Z"
"","1035","HDDS-1735. Create separate unit and integration test executor dev-support script","hadoop-ozone/dev-support/checks directory contains multiple helper script to execute different type of testing (findbugs, rat, unit, build).  They easily define how tests should be executed, with the following contract:   * The problems should be printed out to the console   * in case of test failure a non zero exit code should be used     The tests are working well (in fact I have some experiments with executing these scripts on k8s and argo where all the shell scripts are executed parallel) but we need some update:   1. Most important: the unit tests and integration tests can be separated. Integration tests are more flaky and it's better to have a way to run only the normal unit tests   2. As HDDS-1115 introduced a pom.ozone.xml it's better to use them instead of the magical ""am pl hadoop-ozone-dist"" trick--   3. To make it possible to run blockade test in containers we should use - T flag with docker-compose   4. checkstyle violations are printed out to the console  See: https://issues.apache.org/jira/browse/HDDS-1735","closed","ozone,","elek","2019-06-29T00:00:07Z","2019-07-12T16:25:01Z"
"","907","HDDS-1640. Reduce the size of recon jar file","hadoop-ozone-recon-0.5.0-SNAPSHOT.jar is 73 MB, mainly because the node_modules are included (full typescript source, eslint, babel, etc.)  This PR reduces the size of recon jar file to 1.7MB after excluding node_modules.","closed","ozone,","vivekratnavel","2019-06-04T21:28:37Z","2019-06-05T05:54:01Z"
"","824","HADOOP-16085: S3Guard versioning: get ITestS3ARemoteFileChanged to work consistently","HADOOP-16085: S3Guard versioning: get ITestS3ARemoteFileChanged to work consistently  this is #794 with 1+ extra patch on to be merged in  * clear auth mode flag from FS config, so there is a metastore check before rename(file), ensuring that the values passed to the mock are consistent everywhere * change error in ChangeDetectionPolicy to make clear when an error is coming on the client for a getObjectMetadata call even when the copy policy is ""server"" * and fix up ITestS3ARemoteFileChanged to use the constant string defined in ChangeDetectionPolicy precisely to stop tests being brittle against changes in the text. * new tests in ITestS3ARemoteFileChanged to not lose stack traces when examining causes/inner causes of exceptions, just to throw new assertions with nested causes. * deleted a couple of unused imports * moved from two spaces after a ""."" to one. Sorry.","closed","","steveloughran","2019-05-16T12:03:02Z","2019-06-13T09:47:07Z"
"","879","HADOOP-15563 S3Guard to create on-demand DDB tables","HADOOP-15563 Full S3Guard Support for on-demand DDB tables  * If you create a table with read capacity == write capacity == 0, you get an on-demand table. * change the defaults in Constants and core-defaults to be zero. You get an on-demand table by default. * S3Guard docs reworked to cover the topic, including the updated defaults and why you should go to on-demand; also mentioned in the troubleshooting section.  It'd be nice if set-capacity could switch a table to on-demand, but the latest AWS SDK doesn't let you do that, even though the low level REST API does.  ITestS3GuardToolDynamoDB l * ifecycle test creates an on-demand table and skips changing its capacity. * Fix HADOOP-16187 ITestS3GuardToolDynamoDB test failures: test wasn't clearing enough per-bucket options.  ITestDynamoDBMetadataStore: review of every test case in so that * Capacity is always set to on-demand before table creation * Every test always cleans up its tables, even on assert failures.  Those tests have tended to leak tables in the past; these changes should eliminate it on uninterrupted test runs, and with on-demand capacity you don't get billed much until the next time you do an audit and delete of tables.  Also:  - removed @Unstable attribute from those Constants which I consider having been shipping too long to be changed. - moved test-only S3GUARD_DDB_TEST_TABLE_NAME_KEY key to S3ATestConstants. It was tagged Unstable, and should be in the right file.  Change-Id: Ia44559354666db8027e574eab97983167ed930bf  Note: this patch includes HADOOP-16117 as precursor; that's a separate PR, (#818); its needed to be able to create on-demand tables","closed","","steveloughran","2019-05-31T15:45:12Z","2021-10-15T19:45:57Z"
"","1105","HDDS-1799. Add goofyfs to the ozone-runner docker image","Goofys is a s3 fuse driver which is required for the ozone csi setup.  As of now it's installed in hadoop-ozone/dist/src/main/docker/Dockerfile from a non-standard location (because it couldn't be part of hadoop-runner earlier as it's ozone specific).  It should be installed to the ozone-runner from a canonical goffys release URL.  See: https://issues.apache.org/jira/browse/HDDS-1799","closed","ozone,","elek","2019-07-16T13:06:08Z","2019-07-22T23:13:39Z"
"","1123","HADOOP-16380 S3Guard to determine empty directory status for all non-root directories","Gabor's PR #1106 merged with the test of mine in #1079 with that test modified to show that yes, the tombstone problem goes all the way down  Fix: pass down the needEmptyDirectory flag all the way down from S3AFileSystem to metastore.get","closed","fs/s3,","steveloughran","2019-07-18T16:51:09Z","2019-07-30T15:12:51Z"
"","1647","HDFS-13310. The DatanodeProtocol should be have DNA_BACKUP to backup blocks.","FYI @virajith.","closed","","ehiggs","2019-10-11T14:15:53Z","2019-10-11T14:16:29Z"
"","1507","HDDS-2167. Hadoop31-mr acceptance test is failing due to the shading","From the daily build:  {code}  	Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/ozone/shaded/org/apache/http/client/utils/URIBuilder 	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.initialize(BasicOzoneFileSystem.java:138) 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3303) 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124) 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3352) 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3320) 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:479) 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:361) 	at org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:325) 	at org.apache.hadoop.fs.shell.CommandWithDestination.getRemoteDestination(CommandWithDestination.java:195) 	at org.apache.hadoop.fs.shell.CopyCommands$Put.processOptions(CopyCommands.java:259) 	at org.apache.hadoop.fs.shell.Command.run(Command.java:175) 	at org.apache.hadoop.fs.FsShell.run(FsShell.java:328) 	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76) 	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90) 	at org.apache.hadoop.fs.FsShell.main(FsShell.java:391) Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.ozone.shaded.org.apache.http.client.utils.URIBuilder 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381) 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424) 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349) 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357) 	... 15 more {code}  It can be reproduced locally with executing the tests:  {code} cd hadoop-ozone/dist/target/ozone-0.5.0-SNAPSHOT/compose/ozone-mr/hadoop31 ./test.sh {code}  See: https://issues.apache.org/jira/browse/HDDS-2167","closed","ozone,","elek","2019-09-23T15:49:28Z","2019-09-24T15:52:04Z"
"","1341","HDDS-2022. Add additional freon tests","Freon is a generic load generator tool for ozone (ozone freon) which supports multiple generation pattern.  As of now only the random-key-generator is implemented which uses ozone rpc client.  It would be great to add additional tests:   * Test key generation via s3 interface  * Test key generation via the hadoop fs interface  * Test key reads (validation)  * Test OM with direct RPC calls   See: https://issues.apache.org/jira/browse/HDDS-2022","closed","ozone,","elek","2019-08-23T08:11:27Z","2019-09-18T11:50:24Z"
"","1265","HDFS-12125. Document the missing EC removePolicy command","Forked PR 1258 to trigger precommit build.","closed","","jojochuang","2019-08-09T23:55:10Z","2019-08-10T01:01:05Z"
"","1264","HDFS-12125. Document the missing EC removePolicy command","Forked Hadoop PR 1258, to trigger precommit.","closed","","jojochuang","2019-08-09T23:48:43Z","2019-08-10T02:48:11Z"
"","1294","HDFS-14665. HttpFS: LISTSTATUS response is missing HDFS-specific fields","Forked from PR #1291","closed","","jojochuang","2019-08-14T12:14:48Z","2019-08-20T16:01:20Z"
"","1276","HDFS-14148. HDFS OIV ReverseXML SnapshotSection parser throws exception when there are more than one snapshottable directory","Fork the PR 1274","closed","","jojochuang","2019-08-11T05:00:56Z","2019-08-13T00:25:36Z"
"","1289","HDFS-14665. HttpFS: LISTSTATUS response is missing HDFS-specific fields","Fork from PR #1267","closed","","jojochuang","2019-08-13T20:17:36Z","2019-08-13T23:21:45Z"
"","756","[HDFS-14437]Fix BUG mentionted in HDFS-14437","For the bug of EditLog rolling mentioned in  https://issues.apache.org/jira/browse/HDFS-10943  I have tell the root cause of it in jira's comment. https://issues.apache.org/jira/browse/HDFS-14437  In the code of #logSync() this #wait  ``` while (mytxid > synctxid && isSyncRunning) {   try {     wait(1000);   } catch (InterruptedException ie) {   } } ``` when #endCurrentLogSegment call  #logSync() if  #isSyncRunning == true and mytxid > synctxid,  Current thread  will call #wait, other thread will run.  if other thread can't run , #isSyncRunning will always be true.  current thread can't run out of the while loop  this will become a dead lock.  If other thread get lock to run, They can do many things in 1000ms.  Then  other thread call logSync will end the flush process.  synctxid may be bigger than mytxid, then it will just return in the code : ``` if (mytxid","open","","AngersZhuuuu","2019-04-19T15:03:48Z","2019-04-24T01:54:17Z"
"","1560","HDDS-2214. TestSCMContainerPlacementRackAware has an intermittent failure","For example from the nightly build:  ```                java.lang.AssertionError         	at org.junit.Assert.fail(Assert.java:86)         	at org.junit.Assert.assertTrue(Assert.java:41)         	at org.junit.Assert.assertTrue(Assert.java:52)         	at org.apache.hadoop.hdds.scm.container.placement.algorithms.TestSCMContainerPlacementRackAware.testNoFallback(TestSCMContainerPlacementRackAware.java:276)         	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)         	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)         	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)         	at java.lang.reflect.Method.invoke(Method.java:498)         	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47) ```  The problem is in the testNoFallback:  Let's say we have 11 nodes (from parameter) and we would like to choose 5 nodes (hard coded in the test).  As the first two replicas are chosen from the same rack an all the other from different racks it's not possible, so we except a failure.  But we have an assertion that the success count is at least 3. But this is true only if the first two replicas are placed to the rack1 (5 nodes) or rack2 (5nodes). If the replica is placed to the rack3 (one node) it will fail immediately:  Lucky case when we have success count > 3  ```  rack1 -- node1   rack1 -- node2 -- FIRST replica  rack1 -- node3 -- SECOND replica  rack1 -- node4  rack1 -- node5   rack2 -- node6  rack2 -- node7 -- THIRD replica  rack2 -- node8  rack2 -- node9   rack2 -- node10  rack3 -- node11 -- FOURTH replica{code} ```   The specific case when we have success count == 1, as we can't choose the second replica on rack3 (This is when the test is failing)  ```  rack1 -- node1   rack1 -- node2  rack1 -- node3  rack1 -- node4  rack1 -- node5   rack2 -- node6  rack2 -- node7  rack2 -- node8  rack2 -- node9   rack2 -- node10  rack3 -- node11 -- FIRST replica{code}  ```","closed","ozone,","elek","2019-10-01T09:56:51Z","2019-10-13T09:27:29Z"
"","1001","HDDS-1258 - Fix error propagation for SCM protocol","Following on from HDDS-1674, which changed the SCMBlockLocationProtocol to use a single wrapper message for all child messages, this change ensures that any known SCMException's are caught and the correct code and message written to the wrapper.  Note that the client does not see the benifit of the new error handling, as the generally the client calls CLIENT -> OM -> SCM, and even with this change the OM cannot translate the SCM response codes into a more meaningful error message for the client.","closed","ozone,","sodonnel","2019-06-21T10:59:02Z","2019-07-01T18:20:22Z"
"","1549","HADOOP-16605: Fix testcase testSSLChannelModeConfig","Fixing testcase testSSLChannelModeConfig, which is supposed to be skipped when no test creds are provided.   Without test creds set:  INFO] Results: [INFO]  [WARNING] Tests run: 788, Failures: 0, Errors: 0, Skipped: 767   With test creds set: [INFO] Results: [INFO]  [WARNING] Tests run: 882, Failures: 0, Errors: 0, Skipped: 3","closed","","snvijaya","2019-09-30T10:45:06Z","2019-10-03T10:13:56Z"
"","816","HDFS-14482: Crash when using libhdfs with bad classpath","Fixes a bug in `jni_helper.c` `getJNIEnv` introduced by HDFS-14304. After HDFS-14304, the `getJNIEnv` would call `getGlobalJNIEnv` and pass the result to `jclasses.c` without first checking if the result of `getGlobalJNIEnv` is `NULL`.  Testing: * Ran all libhdfs tests locally, they all pass.","closed","","sahilTakiar","2019-05-13T19:22:55Z","2019-05-15T01:33:39Z"
"","812","HDDS-1511. Space tracking for Open Containers in HDDS Volumes. Contributed by Supratim Deka","Fixed junit failures. Addressed comment from Arpit Agarwal.","closed","ozone,","supratimdeka","2019-05-10T07:54:30Z","2019-05-25T02:46:35Z"
"","823","HADOOP-16315. ABFS: transform full UPN for named user in AclStatus","Fixed identity conversion for AclEntry when calling getAclStatus()  All tests passed my US-west account: xns account: Tests run: 41, Failures: 0, Errors: 0, Skipped: 0 Tests run: 393, Failures: 0, Errors: 0, Skipped: 25 Tests run: 190, Failures: 0, Errors: 0, Skipped: 23  non-xns account: Tests run: 41, Failures: 0, Errors: 0, Skipped: 0 Tests run: 393, Failures: 0, Errors: 0, Skipped: 207 Tests run: 190, Failures: 0, Errors: 0, Skipped: 15","closed","fs/azure,","DadanielZ","2019-05-15T20:35:30Z","2019-08-12T01:28:43Z"
"","1612","HDDS-2260. Avoid evaluation of LOG.trace and LOG.debug statement in the read/write path (HDDS).","Fixed all the places where the parameter would need evaluation, left only the string literals and pre-evaluated variables intact. Addressed LOG.debug, LOGGER.debug, LOG.trace and LOGGER.trace by search and edit.","closed","ozone,","swagle","2019-10-08T06:04:23Z","2019-10-08T18:14:41Z"
"","1587","HADOOP-16626. S3A ITestRestrictedReadAccess fails","Fix up test setup for the restricted access. -Force load the filesystems early on -And only add the contract resource if needed. -Only run the guarded tests if S3Guard is on according to the build.  I had a predecessor which always used the Local store, but it was hard to set up -you need to share across FS instances-, and you could never guarantee that it worked the same way with DDB. That patching is still there -it's just not needed/used for the DDB test runs  Change-Id: I79644ac264f74005775ff194d48f08fe951df0f1","closed","","steveloughran","2019-10-03T20:16:28Z","2021-10-15T19:45:23Z"
"","1390","Fix typos","fix typos","open","","KangZhiDong","2019-08-31T22:57:28Z","2019-09-04T15:55:25Z"
"","1603","HDDS-2257. Fix checkstyle issues in ChecksumByteBuffer","Fix these checkstyle issues  ``` hadoop-hdds/common/src/main/java/org/apache/hadoop/ozone/common/ChecksumByteBuffer.java 84: Inner assignments should be avoided. 85: Inner assignments should be avoided. 101: 'case' child has incorrect indentation level 8, expected level should be 6. 102: 'case' child has incorrect indentation level 8, expected level should be 6. 103: 'case' child has incorrect indentation level 8, expected level should be 6. 104: 'case' child has incorrect indentation level 8, expected level should be 6. 105: 'case' child has incorrect indentation level 8, expected level should be 6. 106: 'case' child has incorrect indentation level 8, expected level should be 6. 107: 'case' child has incorrect indentation level 8, expected level should be 6. 108: 'case' child has incorrect indentation level 8, expected level should be 6. ```","closed","ozone,","vivekratnavel","2019-10-04T22:31:25Z","2019-10-04T23:36:32Z"
"","1571","HDDS-2228. Fix NPE in OzoneDelegationTokenManager#addPersistedDelegat…","Fix the issue when OzoneDelegationTokenManager tries to load tokens without a valid certificate client.  Add a unit test that repro the issue and verify the fix.","closed","ozone,","xiaoyuyao","2019-10-02T05:06:20Z","2019-10-03T06:09:07Z"
"","1428","HADOOP-16556. Fix some alerts raised by LGTM","Fix the following alerts:  - `Array index out of bounds` in KerberosName.java  - `Contradictory type checks` in GenericExceptionHandler  - `Missing format argument` in RegistrySecurity and HttpFSExceptionProvider  These alerts are shown in https://lgtm.com/projects/g/apache/hadoop/?mode=tree","closed","","malcolmtaylor","2019-09-12T07:54:08Z","2019-12-17T08:45:04Z"
"","859","HDDS-1533. JVM exit on TestHddsDatanodeService. Contributed by Mukul Kumar Singh.","Fix TestHddsDatanodeService exiting because of JVM exit.","closed","ozone,","mukul1987","2019-05-28T06:50:48Z","2019-05-28T12:19:43Z"
"","989","Yarn 9314.Fair Scheduler: Queue Info mistake when configured same queue name at same level","fix same queue problem.","closed","","asagjj","2019-06-19T09:09:34Z","2019-06-19T09:45:46Z"
"","1539","HADOOP-16511: Fix order of actual and expected expression in HDFS","Fix order of actual and expected expression in HDFS by using AssertJ as recommanded in JIRA and other fixes in the series.","open","","ZhengZhenyu","2019-09-27T09:01:23Z","2019-09-30T11:55:00Z"
"","1286","HDDS-1894. Add filter to scmcli listPipelines.","Fix issue #[HDDS-1894](https://issues.apache.org/jira/browse/HDDS-1894?focusedCommentId=16902551&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel)","closed","ozone,","timmylicheng","2019-08-13T01:49:07Z","2019-08-16T06:58:02Z"
"","1193","HDDS-1877. hadoop31-mapreduce fails due to wrong HADOOP_VERSION","Fix https://issues.apache.org/jira/browse/HDDS-1877","closed","ozone,","adoroszlai","2019-07-31T11:09:16Z","2019-07-31T14:08:36Z"
"","1337","HDFS-14699.Erasure Coding: Can NOT trigger the reconstruction when ha…","Fix HDFS-14699 Erasure Coding: Can NOT trigger the reconstruction when have the dup internal blocks and missing one internal block","closed","","zhaoyim","2019-08-22T09:40:21Z","2019-08-24T13:30:09Z"
"","819","HDDS-1501 : Create a Recon task interface to update internal DB on updates from OM.","First of 3 JIRAs (HDDS-1105 and HDDS-1391 are the other 2). Adds a task interface and controller implementation in Recon such that updates from OM are passed on to the tasks.","closed","ozone,","avijayanhwx","2019-05-14T23:15:06Z","2019-05-23T22:34:56Z"
"","1108","HDDS-1805. Implement S3 Initiate MPU request to use Cache and DoubleBuffer.","First commit is S3 DeleteBucket request. Posted for initial CI, once HDDS-1795 gets in, will rebase this.","closed","ozone,","bharatviswa504","2019-07-16T21:27:34Z","2019-07-20T15:11:37Z"
"","1492","MAPREDUCE-7241. FileInputFormat listStatus with less memory footprint","FileInputFormat may cause oom problem when scanning lots of files during listing status, as described in https://issues.apache.org/jira/browse/MAPREDUCE-7241. This patch can reduce the memory usage, allowing MR scanning more files with less memory footprint.","closed","","dengzhhu653","2019-09-21T00:52:53Z","2020-03-28T04:52:02Z"
"","1498","HADOOP-16578 : Avoid FileSystem API calls when FileSystem already exists","Even when FileSystem already exists, if the config ""fs.azure.createRemoteFileSystemDuringInitialization"" is true, a GetFileSystemProperties call is made which enforces container Read RBAC role. This blocks users who have necessary ACLs to proceed using the ABFS Driver.   In this PR, RBAC enforcement for GetFileSystemProperties call is avoided in the above flow.","closed","","snvijaya","2019-09-22T18:33:35Z","2019-10-02T00:44:20Z"
"","836","HADOOP-16319 skip invalid tests when default encryption enabled","ETag values are unpredictable with some encryption algorithms. Skip tests asserting ETags when default encryption is enabled.","closed","","ben-roling","2019-05-20T19:42:24Z","2020-03-17T13:32:25Z"
"","1290","Hadoop 16438","Enabling config option to control the SSL channel mode. Possible channel modes being - (a) OpenSSL (b) Default_JSSE (c) Default - This is the default choice if the config is not present or is invalid. When set to this, connection creation is attempted in OpenSSL mode and will fallback to Default_JSSE mode on any failure.","open","","snvijaya","2019-08-14T04:29:59Z","2019-09-03T01:31:29Z"
"","1394","Hadoop-16438 ADLS Gen1 OpenSSL config control","Enabling config option to control the SSL channel mode. Possible channel modes being - (a) OpenSSL (b) Default_JSE (c) Default - This is the default choice if the config is not present or is invalid. When set to this, connection creation is attempted in OpenSSL mode and will fallback to Default_JSE mode on any failure.","closed","","snvijaya","2019-09-02T20:27:10Z","2019-09-09T16:13:47Z"
"","1502","YARN-9851: Make execution type check compatiable","During upgrade from 2.6 to 3.1, we encountered a problem:  ` 2019-09-23,19:29:05,303 WARN org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Lost container container_e35_1568719110875_6460_08_000001, status: RUNNING, execution type: null 2019-09-23,19:29:05,303 WARN org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Lost container container_e35_1568886618758_11172_01_000062, status: RUNNING, execution type: null 2019-09-23,19:29:05,303 WARN org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Lost container container_e35_1568886618758_11172_01_000063, status: RUNNING, execution type: null 2019-09-23,19:29:05,303 WARN org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Lost container container_e35_1568886618758_11172_01_000064, status: RUNNING, execution type: null 2019-09-23,19:29:05,303 WARN org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Lost container container_e35_1568886618758_30617_01_000006, status: RUNNING, execution type: null ` ``` for (ContainerStatus remoteContainer : containerStatuses) {   if (remoteContainer.getState() == ContainerState.RUNNING       && remoteContainer.getExecutionType() == ExecutionType.GUARANTEED) {     nodeContainers.add(remoteContainer.getContainerId());   } else {     LOG.warn(""Lost container "" + remoteContainer.getContainerId()             + "", status: "" + remoteContainer.getState()             + "", execution type: "" + remoteContainer.getExecutionType());   } }​ ```  The cause is that we has nm with version 2.6, which do not have executionType for container status. We should make the check more compatiable.","closed","","caneGuy","2019-09-23T12:40:27Z","2019-11-13T11:38:01Z"
"","767","HDDS-1462. Fix content and format of Ozone documentation","During the review of HDDS-1457 I realized that the current documentation contains many outdated information regarding the usage of docker, build commands or s3 usage.  The security information is also rendered in an incorrect way.  The png files for the prometheus page are missing (were included in the patch of HDDS-846 but missing from the commit).  See: https://issues.apache.org/jira/browse/HDDS-1462","closed","ozone,","elek","2019-04-24T15:18:34Z","2019-04-29T20:39:05Z"
"","959","HDDS-1678. Default image name for kubernetes examples should be ozone and not hadoop","During the build the kubernetes example files are adjusted to use a specific docker image name.  By default it should be the apache/ozone:${VERSION} to make it possible to use the examples without any build from the release artifact. With the examples of the release artifact the user can use the latest released apache/ozone:${VERSION} from docker hub.  For development build the image can be set with -Ddocker.image (or -Dozone.docker.image with HDDS-1667).  Unfortunately -- due to a small typo -- apace/hadoop image is used by default instead of apache/ozone.    See: https://issues.apache.org/jira/browse/HDDS-1678","closed","ozone,","elek","2019-06-13T08:50:06Z","2019-06-21T12:37:29Z"
"","894","HDDS-1635. Maintain docker entrypoint and envtoconf inside ozone project","During an offline discussion with [~eyang] and [~arp], Eric suggested to maintain the source of the docker specific start images inside the main ozone branch (trunk) instead of the branch of the docker image.  With this approach the ozone-runner image can be a very lightweight image and the entrypoint logic can be versioned together with the ozone itself.  An other use case is a container creation script. Recently we [documented|https://cwiki.apache.org/confluence/display/HADOOP/Ozone+Docker+images] that hadoop-runner/ozone-runner/ozone images are not for production (for example because they contain development tools).  We can create a helper tool (similar what Spark provides) to create Ozone container images from any production ready base image. But this tool requires the existence of the scripts inside the distribution.  (ps: I think sooner or later the functionality of envtoconf.py can be added to the OzoneConfiguration java class and we can parse the configuration values directly from environment variables.  In this patch I copied the required scripts to the ozone source tree and the new ozone-runner image (HDDS-1634) is designed to use it from this specific location.   See: https://issues.apache.org/jira/browse/HDDS-1635","closed","ozone,","elek","2019-06-03T11:12:21Z","2019-06-11T18:12:06Z"
"","886","HDDS-1627. Make the version of the used hadoop-runner configurable","During an offline discussion with [~arp] and [~eyang] we agreed that it could be more safe to fix the tag of the used hadoop-runner images during the releases.  It also requires fix tags from hadoop-runner, but after that it's possible to use the fixed tags.  This patch makes it possible to define the required version/tag in pom.xml   1. the default hadoop-runner.version is added to all .env files  during the build  2. If a variable is added to the .env, it can be used from docker-compose files AND can be overridden by environment variables (it makes it possible to define custom version during a local run)   See: https://issues.apache.org/jira/browse/HDDS-1627","closed","ozone,","elek","2019-06-03T05:56:24Z","2019-06-11T18:18:13Z"
"","1599","HADOOP-16632. Speculating & Partitioned S3A magic committers can leave pending files under __magic","Downgrade the checks for leftover __magic entries from fail to warn now the parallel test runs make speculation more likely. That or we disable specex.  Change-Id: Ia4df2e90f82a06dbae69f3fdaadcbb0e0d713b38","closed","test,","steveloughran","2019-10-04T18:03:09Z","2019-11-19T13:54:34Z"
"","1467","HADOOP-16583. Minor fixes to S3 testing instructions","Documentation update only. No tests erquired. ## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","sidseth","2019-09-18T06:26:18Z","2019-09-20T18:42:11Z"
"","901","HDDS-1639. Restructure documentation pages for better understanding","Documentation page should be updated according to the recent changes:  In the uploaded PR I modified the following:    *  Pages are restructured to use a similar structure what is intruced on the wiki by [~anu]. (Getting started guides are separated for different environments)   * The width of the menu is increased (to make it more readable)   * The logo is moved from the main page from the menu (to get more space for the menu items)   * 'Requirements' section is added to each 'Getting started' page   * Test tools / docker image / kubernetes pages are imported from the wiki.   See: https://issues.apache.org/jira/browse/HDDS-1639","closed","ozone,","elek","2019-06-04T08:46:48Z","2019-06-28T17:53:29Z"
"","1104","HDFS-14318:dn cannot be recognized and must be restarted to recognize the Repaired disk","dn detected that disk a has failed. After disk a is repaired, dn cannot be recognized and must be restarted to recognize  I make a patch to dn for recognize the repaired disk without restart dn","open","","hunshenshi","2019-07-16T11:33:24Z","2019-10-21T06:44:59Z"
"","1196","HDDS-1881. Design doc: decommissioning in Ozone","Design doc can be attached to the documentation. In this jira the design doc will be attached and merged to the documentation page.  See: https://issues.apache.org/jira/browse/HDDS-1881","closed","ozone,","elek","2019-07-31T12:15:08Z","2019-08-28T17:19:04Z"
"","1675","HADOOP-16654:Delete hadoop-ozone and hadoop-hdds subprojects from apa…","Deleting hadoop-ozone and hadoop-hdds subprojects.","closed","","snemuri","2019-10-24T14:45:54Z","2019-11-15T20:51:43Z"
"","1319","HDDS-1981: Datanode should sync db when container is moved to CLOSED or QUASI_CLOSED state","Datanode should sync db when container is moved to CLOSED or QUASI_CLOSED state. This will ensure that the metadata of a container is persisted.","closed","ozone,","lokeshj1703","2019-08-20T10:28:50Z","2019-08-27T04:53:12Z"
"","809","HDDS-1474. ""ozone.scm.datanode.id"" config should take path for a dir and not a file","Currently, the ozone config ""ozone.scm.datanode.id"" takes file path as its value. It should instead take dir path as its value and assume a standard filename ""datanode.id""","closed","ozone,","vivekratnavel","2019-05-09T19:06:46Z","2019-05-10T00:11:10Z"
"","1280","HADOOP-16505. Add ability to register custom signer with AWS SignerFactory","Currently, the AWS SignerFactory restricts the class of Signer algorithms that can be used.  We require an ability to register a custom Signer. The `SignerFactory` supports this functionality through its `registerSigner` method.  By providing a fully qualified classname to the existing parameter `fs.s3a.signing-algorithm`, the custom signer can be registered.","closed","","viczsaurav","2019-08-12T15:40:38Z","2019-10-03T09:22:03Z"
"","982","HDDS-1702. Optimize Ozone Recon build time","Currently, hadoop-ozone-recon node_modules folder is copied to target folder and this takes a lot of time while building hadoop-ozone project.   This PR reduces the build time by excluding node_modules folder. With this patch it only takes approximately ~10 seconds to compile Recon.","closed","ozone,","vivekratnavel","2019-06-17T20:58:23Z","2019-06-18T21:44:24Z"
"","1124","HDDS-1749 : Ozone Client should randomize the list of nodes in pipeline for reads","Currently the list of nodes returned by SCM are static and are returned in the same order to all the clients. Ideally these should be sorted by the network topology and then returned to client.  However even when network topology in not available, then SCM/client should randomly sort the nodes before choosing the replica's to connect.","closed","ozone,","avijayanhwx","2019-07-18T18:18:52Z","2019-07-25T14:56:11Z"
"","1350","YARN-9783. Remove low-level zookeeper test to be able to build Hadoop against zookeeper 3.5.5","Currently the Hadoop build (with ZooKeeper 3.5.5) fails because of a YARN test case: TestSecureRegistry.testLowlevelZKSaslLogin(). This test case seems to use low-level ZooKeeper internal code, which changed in the new ZooKeeper version.  Removing the testcase will enable us to build and test Hadoop with the latest ZooKeeper version.","closed","","symat","2019-08-26T14:34:49Z","2019-08-28T09:04:27Z"
"","1564","HDDS-2223. Support ReadWrite lock in LockManager.","Currently LockManager is using exclusive lock, instead we should support ReadWrite lock.","closed","ozone,","nandakumar131","2019-10-01T15:39:10Z","2019-10-04T03:15:34Z"
"","782","HDDS-1461. Optimize listStatus api in OzoneFileSystem","Currently in listStatus we make multiple getFileStatus calls. This can be optimized by converting to a single rpc call for listStatus.  Also currently listStatus has to traverse a directory recursively in order to list its immediate children. This happens because in OzoneManager all the metadata is stored in rocksdb sorted on keynames. The Jira also aims to fix this by using seek api provided by rocksdb.","closed","","lokeshj1703","2019-04-29T10:26:39Z","2019-05-21T09:20:16Z"
"","1087","HDDS-1767: ContainerStateMachine should have its own executors for executing applyTransaction calls","Currently ContainerStateMachine uses the executors provided by XceiverServerRatis for executing applyTransaction calls. This would result in two or more ContainerStateMachine to share the same set of executors. Delay or load in one ContainerStateMachine would adversely affect the performance of other state machines in such a case. It is better to have separate set of executors for each ContainerStateMachine.","closed","ozone,","lokeshj1703","2019-07-12T14:47:44Z","2019-07-18T09:18:42Z"
"","1375","HDDS-2048: State check during container state transition in datanode should be lock protected","Currently container state checks during state transition are not lock protected in KeyValueHandler. These can cause invalid state transitions.","closed","ozone,","lokeshj1703","2019-08-29T08:39:20Z","2019-09-10T08:45:32Z"
"","1114","HDDS-1481: Cleanup BasicOzoneFileSystem#mkdir","Currently BasicOzoneFileSystem#mkdir does not have the optimizations made in HDDS-1300. The changes for this function were missed in HDDS-1460.","closed","ozone,","lokeshj1703","2019-07-17T17:56:01Z","2019-07-18T09:14:46Z"
"","906","HDDS-1641. Csi server fails because transitive Netty dependencies","CSI server can't be started because an ClassNotFound exception.  It turned out that with using the new configuration api we got old netty jar files as transitive dependencies. (hdds-configuration depends on hadoop-common, hadoop-commons depends on the word)  We should exclude all the old netty version from the classpath of the CSI server.  See: https://issues.apache.org/jira/browse/HDDS-1641","closed","ozone,","elek","2019-06-04T13:22:26Z","2019-06-04T14:56:39Z"
"","1050","HDDS-1550. MiniOzoneCluster is not shutting down all the threads during shutdown. Contributed by Mukul Kumar Singh.","Creating a new pull request.","closed","ozone,","mukul1987","2019-07-03T05:29:50Z","2019-07-09T03:24:13Z"
"","1464","HDDS-730. Ozone fs cli prints hadoop fs in usage.","Create OzoneFsShell that extends hadoop FsShell  ## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","ozone,","cxorm","2019-09-17T21:00:39Z","2019-09-25T13:19:29Z"
"","839","YARN-9568. NPE in MiniYarnCluster during FileSystemNodeAttributeStore.recover","Contributed by Steve Loughran.  This places the FileSystemNodeAttributeStore into the cluster's test dir, so multiple parallel mini yarn clusters do not interfere with each other or leave the test filesystem in a state where all subsequent test runs fail.  Change-Id: I7da543de09f9eeedad08c81f6c7d82825010ecc3","closed","","steveloughran","2019-05-21T10:37:05Z","2019-07-19T13:42:30Z"
"","951","HADOOP-15183. S3Guard store becomes inconsistent after partial failure of rename","Contributed by Steve Loughran.  This is the squashed patch of PR #843 commit 115fb770  Contains  * HADOOP-13936. S3Guard: DynamoDB can go out of sync with S3AFileSystem.delete()  * HADOOP-15604. Bulk commits of S3A MPUs place needless excessive load on S3 & S3Guard  * HADOOP-15658. Memory leak in S3AOutputStream  * HADOOP-16364. S3Guard table destroy to map IllegalArgumentExceptions to IOEs]  This work adds to the S3Guard Metastore APIs  * the notion of a ""BulkOperation"" : A store-specific class which is requested before initiating bulk work (put, purge, rename) and which then can be used to cache table changes performed during the bulk operation. This allows for renames and commit operations to avoid duplicate creation of parent entries in the tree: the store can track what is already created/found.  * the notion of a ""RenameTracker"" which factors out the task of updating a metastore with changes to the filesystem during a rename, (files added + deleted) and after the completion of the operation, successful or not.  The original rename update -the one which failed to update the store until the end of the rename is implemented as the DelayedUpdateRenameTracker, while a new ProgressiveRenameTracker updates the sttore as individual files are copied and when bulk deletes complete. To avoid performance problems, stores mut provide a BulkOperation implementation which remembers ancestors added. The DynamoDBMetastore does this.  Some of the new features are implemented as part of a gradual refactoring of the S3AFileSystem itself: the handling of partial delete failures is in its own class org.apache.hadoop.fs.s3a.impl.MultiObjectDeleteSupport which, rather than being given a reference back to the owning S3AFileSystem, is handed a StoreContext which contains restriced attributes and callback. As this refactoring continues in future patches, and the different layers of a new store model factored out, this will be extended.  Change-Id: Ie0bd96ab861f0f30170b75f78e5503fc0e929524","closed","","steveloughran","2019-06-12T09:04:51Z","2021-10-15T19:45:54Z"
"","818","HADOOP-16117 Update AWS SDK to 1.11.563","Contributed by Steve Loughran.  Change-Id: Iff125bf3e2f409ae7fd0d05440f4f7ba38c24331","closed","","steveloughran","2019-05-14T11:52:29Z","2019-06-06T09:16:32Z"
"","1145","HADOOP-16450. ITestS3ACommitterFactory to not use useInconsistentClient.","Contributed by Steve Loughran.  Change-Id: Ifb9771a73a07f744e4ed5f5e6be72473179db439  Tested: S3 Ireland, in both a sequential and a parallel test run","closed","test,","steveloughran","2019-07-23T11:53:13Z","2021-10-15T19:45:43Z"
"","1269","HADOOP-16500 S3ADelegationTokens to only log at debug on startup","Contributed by steve loughran.  Change-Id: Ifafc15f32791911976d7ebc36fb6e8853f59ed41","closed","fs/s3,","steveloughran","2019-08-10T09:48:57Z","2019-08-28T17:38:53Z"
"","863","HADOOP-16332. Remove S3A dependency on http core.","Contributed by Steve Loughran.  Change-Id: I53209c993a405fefdb5e1b692d5a56d027d3b845","closed","","steveloughran","2019-05-28T11:05:25Z","2019-05-28T21:52:17Z"
"","988","HADOOP-16376. ABFS: Override access() to no-op.","Contributed by Da Zhou.  Change-Id: Ia0024bba32250189a87eb6247808b2473c331ed0","closed","","DadanielZ","2019-06-18T23:32:43Z","2020-03-05T07:07:16Z"
"","1657","HADOOP-16652: Backport of HADOOP-16587: Make ABFS AAD endpoints configurable","Contributed by Bilahari T H.  This also addresses HADOOP-16498: AzureADAuthenticator cannot authenticate in China.  Change-Id: I2441dd48b50b59b912b0242f7f5a4418cf94a87c  ## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","bilaharith","2019-10-14T17:09:00Z","2019-10-31T17:37:30Z"
"","1150","HDDS-1816: ContainerStateMachine should limit number of pending apply transactions","ContainerStateMachine should limit number of pending apply transactions in order to avoid excessive heap usage by the pending transactions.","closed","ozone,","lokeshj1703","2019-07-24T09:10:01Z","2019-07-31T13:55:27Z"
"","1554","HADOOP-16619. Upgrade jackson and jackson-databind to 2.9.10","Compiled locally on my Mac. Confirmed that it uses 2.9.10 jars for `jackson-core`, `jackson-annotations`, `jackson-databind`, etc.:  ``` $ cd hadoop-dist/target/hadoop-3.3.0-SNAPSHOT $ find . -name ""*jackson*"" ./share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar ./share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar ./share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar ./share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar ./share/hadoop/common/lib/jackson-xc-1.9.13.jar ./share/hadoop/common/lib/jackson-core-2.9.10.jar ./share/hadoop/common/lib/jackson-core-asl-1.9.13.jar ./share/hadoop/common/lib/jackson-annotations-2.9.10.jar ./share/hadoop/common/lib/jackson-databind-2.9.10.jar ./share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar ./share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar ./share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar ./share/hadoop/hdfs/lib/jackson-core-2.9.10.jar ./share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar ./share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar ./share/hadoop/hdfs/lib/jackson-databind-2.9.10.jar ./share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar ```","closed","","smengcl","2019-09-30T21:21:21Z","2019-10-01T19:46:41Z"
"","1110","HADOOP-16341. ShutDownHookManager: Regressed performance on Hook removals after HADOOP-15679","clone of #1086 but for 3.2","closed","","zeroflag","2019-07-17T12:55:15Z","2019-07-17T12:58:37Z"
"","1109","HADOOP-16341. ShutDownHookManager: Regressed performance on Hook removals after HADOOP-15679","clone of #1086 but for 3.1","closed","","zeroflag","2019-07-17T12:55:14Z","2019-07-17T16:13:33Z"
"","1591","HADOOP-16629: support copyFile in s3afilesystem","Changes: This is subtask of HADOOP-16604 which aims to provide copy functionality for cloud native applications. Intent of this PR is to provide `copyFile(URI src, URI dst)` functionality for S3AFileSystem (HADOOP-16629).  Testing was done in `region=us-west-2` on my local laptop. ``` [ERROR] Tests run: 1090, Failures: 5, Errors: 22, Skipped: 318 ```  I observed good number of tests timing out and few of them throwing NPE. e.g  ``` [ERROR] testPrefixVsDirectory(org.apache.hadoop.fs.s3a.ITestAuthoritativePath)  Time elapsed: 13.164 s","closed","","rbalamohan","2019-10-04T07:49:13Z","2019-10-23T16:02:39Z"
"","1016","HDDS-1672. Improve locking in OzoneManager.","Changes in this PR: 1. Used new class implemented in HDDS-1723. 2. Removed the old OzoneManagerLock.java code.","closed","ozone,","bharatviswa504","2019-06-26T00:16:51Z","2019-06-28T21:06:25Z"
"","1217","HDDS-1832 : Improve logging for PipelineActions handling in SCM and datanode.","Changed to ERROR logging.","closed","ozone,","avijayanhwx","2019-08-02T18:05:16Z","2019-08-14T05:24:50Z"
"","1381","HDDS-2044. Remove 'ozone' from the recon module names.","Changed ""ozone-recon"" to ""recon"" and ""ozone-recon-codegen"" to ""recon-codegen"".","closed","ozone,","shwetayakkali","2019-08-30T00:27:44Z","2019-09-17T09:56:44Z"
"","1433","HADOOP-16566. S3Guard fsck: Use org.apache.hadoop.util.StopWatch instead of com.google.common.base.Stopwatch","Change-Id: Ied43ef1522dfc6a1210d6fc58c38d8208824931b","closed","","bgaborg","2019-09-12T15:18:53Z","2019-09-12T17:04:58Z"
"","932","HDDS-1655. Redundant toString() call for metaDataPath in KeyValueContainerCheck","Change-Id: Idf91e6367cf1a6e27986034e13cf34f59e79fc25  Redundant toString() call for variable metadataPath at:  https://github.com/apache/hadoop/blob/trunk/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/keyvalue/KeyValueContainerCheck.java#L284","closed","","shwetayakkali","2019-06-08T23:33:21Z","2019-06-09T05:13:12Z"
"","1639","HADOOP-16650. ITestS3AClosedFS failing -junit test thread.","Change-Id: Ia58f5e1dd57588a28081f9c4092c010b3132856a  tested: s3 ireland. now going to CP and test on the specific backport branch where I encountered the problem","closed","","steveloughran","2019-10-10T13:00:29Z","2021-10-15T19:48:01Z"
"","930","HDDS-1651. Create a http.policy config for Ozone","Change-Id: Ia284f685f6d39a512124e6055537615d325ae96b","closed","ozone,","shwetayakkali","2019-06-07T23:14:36Z","2019-06-28T22:23:15Z"
"","1691","HADOOP-16424. S3Guard fsck: Check internal consistency of the MetadataStore","Change-Id: I9bf479170a21f47817144a778aa63fd309ea1ab9","closed","fs/s3,","bgaborg","2019-11-04T16:29:23Z","2019-12-10T14:51:55Z"
"","912","HDDS-1201. Reporting Corruptions in Containers to SCM","Change-Id: I767ecfe4f27729955ca41b5f634400742a49bbbd  Add protocol message and handling to report container corruptions to the SCM. Also add basic recovery handling in SCM.","closed","ozone,","shwetayakkali","2019-06-05T17:26:42Z","2019-06-06T19:44:31Z"
"","1522","HDFS-14874. Fix TestHDFSCLI and TestDFSShell test break because of logging change in mkdir","Change-Id: I5b0d0995cee48187aec40c06f4da1c9b3c97fcf8","closed","","bgaborg","2019-09-25T13:20:32Z","2019-09-26T04:45:14Z"
"","720","HDDS-1418. Move bang line to the start of the start-chaos.sh script.","Change-Id: I4fcf39d61a7d4c4ca79cb56a6958db0f691fe971","closed","ozone,","arp7","2019-04-10T19:07:29Z","2019-04-10T19:56:33Z"
"","1660","HADOOP-16653. S3Guard DDB overreacts to no tag access","Change-Id: I4990e61dcf1baa7ddb593ac9a2195e9338060539","closed","","bgaborg","2019-10-16T11:36:50Z","2019-10-28T10:22:51Z"
"","1661","HADOOP-16484. S3A to warn or fail if S3Guard is disabled","Change-Id: I368ec8d0395dd15272a8ed718823992d472028f3","closed","","bgaborg","2019-10-17T12:09:33Z","2019-11-04T11:55:42Z"
"","1302","HADOOP-16138. hadoop fs mkdir / of nonexistent abfs container raises NPE","Change-Id: I2f637865c871e400b95fe7ddaa24bf99fa192023","closed","","bgaborg","2019-08-15T13:09:22Z","2019-09-23T11:29:09Z"
"","1209","HADOOP-16481. ITestS3GuardDDBRootOperations.test_300_MetastorePrune needs to set region","Change-Id: I26f8e9bc441bd1cb7b0d9b37161984049df6bac4","closed","fs/s3,","steveloughran","2019-08-01T18:28:50Z","2019-08-20T18:13:24Z"
"","1620","HADOOP-16642. ITestDynamoDBMetadataStoreScale fails when throttled.","Change-Id: I1bbb4692c7fe345a0e5c3d3660eeb644ca9ced2d  tests against s3 ireland but its not my laptop seeing the failure -this was an in-EC2 test run.","closed","test,","steveloughran","2019-10-08T17:01:27Z","2021-10-15T19:42:00Z"
"","755","HDDS-1411. Add unit test to check if SCM correctly sends close commands for containers in closing state after a restart.","cc: @nandakumar131   I was able to get this work as expected by stopping the HB processing then closing the container, restarting SCM and making sure the close event is fired.   Some ugly reflection had to be used since in general, we do not use test friendly things like dependency injection etc. :)","closed","ozone,","swagle","2019-04-19T01:19:01Z","2019-04-23T15:34:15Z"
"","781","HDDS-1473. DataNode ID file should be human readable.","cc: @arp7 Human readable version of the dn details will now be written out like this::  `!!org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml {   certSerialId: '8689088562908158976',   hostName: localhost,   ipAddress: 155.217.19.151,   portDetails: {     RATIS: 0,     REST: 0,     STANDALONE: 1   },   uuid: 74737b50-7b2b-448b-8a72-f2c6c6c77e4a }`","closed","ozone,","swagle","2019-04-28T16:33:28Z","2019-05-02T20:59:16Z"
"","797","HDDS-1489. Unnecessary log messages on console with Ozone shell.","cc: @arp7","closed","","swagle","2019-05-06T22:56:44Z","2019-05-07T22:39:59Z"
"","985","HADOOP-16380. S3Guard Tombstones can get in the way","Cause: tombstones mislead about directory empty status  This is not the fix, though it provides diagnostics about the problem with more checks and more details in assertions.  Change-Id: I583071b254a89f64687b87e653afd01d65a8e8de","closed","fs/s3,","steveloughran","2019-06-18T13:59:32Z","2019-08-05T19:03:03Z"
"","1676","HADOOP-16669. TestRawLocalFileSystemContract.testPermission fails if no native library","Catches the first error and converts to a skip; stack traces retained for the curious.  Change-Id: Id2fed3cde6fa86acf36f0e78766f707b2b3c2c5b  ## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","steveloughran","2019-10-24T17:35:44Z","2019-11-06T19:30:01Z"
"","1682","Bump nimbus-jose-jwt from 4.41.1 to 7.9 in /hadoop-project","Bumps [nimbus-jose-jwt](https://bitbucket.org/connect2id/nimbus-jose-jwt) from 4.41.1 to 7.9.  Changelog  *Sourced from [nimbus-jose-jwt's changelog](https://bitbucket.org/connect2id/nimbus-jose-jwt/src/master/CHANGELOG.txt).*  > version 1.0 (2012-03-01) > 	* First version based on the OpenInfoCard JWT, JWS and JWE code base. >  > version 1.1 (2012-03-06) > 	* Introduces type-safe enumeration of the JSON Web Algorithms (JWA). > 	* Refactors the JWT class. >  > version 1.2 (2012-03-08) > 	* Moves JWS and JWE code into separate classes. >  > version 1.3 (2012-03-09) > 	* Switches to Apache Commons Codec for Base64URL encoding and decoding > 	* Consolidates the crypto utilities within the package. > 	* Introduces a JWT content serialiser class. >  > version 1.4 (2012-03-09) > 	* Refactoring of JWT class and JUnit tests. >  > version 1.5 (2012-03-18) > 	* Switches to JSON Smart for JSON serialisation and parsing. > 	* Introduces claims set class with JSON objects, string, Base64URL and > 	  byte array views. >  > version 1.6 (2012-03-20) > 	* Creates class for representing, serialising and parsing JSON Web Keys > 	  (JWK). > 	* Introduces separate class for representing JWT headers. >  > version 1.7 (2012-04-01) > 	* Introduces separate classes for plain, JWS and JWE headers. > 	* Introduces separate classes for plain, signed and encrypted JWTs. > 	* Removes the JWTContent class. > 	* Removes password-based (PE820) encryption support. >  > version 1.8 (2012-04-03) > 	* Adds support for the ZIP JWE header parameter. > 	* Removes unsupported algorithms from the JWA enumeration. >  > version 1.9 (2012-04-03) > 	* Renames JWEHeader.{get|set}EncryptionAlgorithm() to > 	  JWEHeader.{get|set}EncryptionMethod(). >  > version 1.9.1 (2012-04-03) > 	* Upgrades JSON Smart JAR to 1.1.1. >  > version 1.10 (2012-04-14) > 	* Introduces serialize() method to base abstract JWT class. >  > version 1.11 (2012-05-13) > 	* JWT.serialize() throws checked JWTException instead of > ... (truncated)   Commits  - [`10dce4f`](https://bitbucket.org/connect2id/nimbus-jose-jwt/commits/10dce4f52d13f515ed20d48b94447d00b6b8fd6f) b64 works with JWTClaimsSet - [`40b1fcf`](https://bitbucket.org/connect2id/nimbus-jose-jwt/commits/40b1fcfe368c6eb0eabd3ed61ba8e102e2a00d9c) Adds new static X509CertUtils.parseWithException methods - [`805fce1`](https://bitbucket.org/connect2id/nimbus-jose-jwt/commits/805fce19a78544524a316c7bbb6568e25b41b9f3) [maven-release-plugin] prepare release 7.6 - [`1a72c5f`](https://bitbucket.org/connect2id/nimbus-jose-jwt/commits/1a72c5fa8d2f0c44d39f7ad9d2418e6c7f3e5efa) [maven-release-plugin] prepare for next development iteration - [`af733f9`](https://bitbucket.org/connect2id/nimbus-jose-jwt/commits/af733f963cc1e98949604c6776d22ccfd2cd66b7) Changes JWSObject#serialize(boolean) method signature (iss [#320](https://bitbucket.org/connect2id/nimbus-jose-jwt/issues/320)) - [`d752e17`](https://bitbucket.org/connect2id/nimbus-jose-jwt/commits/d752e177482d0bf3c42325731c3588dfe5958c03) Merge branch 'fixB64' - [`3fa65f3`](https://bitbucket.org/connect2id/nimbus-jose-jwt/commits/3fa65f3e2c51d8158b0f63b789d031db0ebc7a9b) Change log for 7.7 - [`1abe7c2`](https://bitbucket.org/connect2id/nimbus-jose-jwt/commits/1abe7c2ac5addbbefb5b3a061ff7e9c6df40ffa1) [maven-release-plugin] prepare release 7.7 - [`dd19a71`](https://bitbucket.org/connect2id/nimbus-jose-jwt/commits/dd19a712b2b8c0f7c64cb6678cbf96f97d81553e) [maven-release-plugin] prepare for next development iteration - [`7f4dbc0`](https://bitbucket.org/connect2id/nimbus-jose-jwt/commits/7f4dbc02f30147806cda74fea5127346c2704523) Issue [#325](https://bitbucket.org/connect2id/nimbus-jose-jwt/issues/325) Enhancement: Add an optional proxy support to the DefaultResourceR... - Additional commits viewable in [compare view](https://bitbucket.org/connect2id/nimbus-jose-jwt/branches/compare/7.9..4.41.1)    [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.nimbusds:nimbus-jose-jwt&package-manager=maven&previous-version=4.41.1&new-version=7.9)](https://help.github.com/articles/configuring-automated-security-fixes)  Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.  [//]: # (dependabot-automerge-start) [//]: # (dependabot-automerge-end)  ---   Dependabot commands and options   You can trigger Dependabot actions by commenting on this PR: - `@dependabot rebase` will rebase this PR - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it - `@dependabot merge` will merge this PR after your CI passes on it - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it - `@dependabot cancel merge` will cancel a previously requested merge and block automerging - `@dependabot reopen` will reopen this PR if it is closed - `@dependabot ignore this [patch|minor|major] version` will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself) - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself) - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language  You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/hadoop/network/alerts).","closed","java,","dependabot[bot]","2019-10-29T20:38:49Z","2019-12-09T01:14:49Z"
"","1683","Bump bower from 1.7.7 to 1.8.8 in /hadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/src/main/webapp","Bumps [bower](https://github.com/bower/bower) from 1.7.7 to 1.8.8.  Release notes  *Sourced from [bower's releases](https://github.com/bower/bower/releases).*  > ## v1.8.8 > Fix security issue connected to extracting .tar.gz archives >  > **This bug allows to write arbitrary file on filesystem when Bower extracts malicious package** >  > Needlessly to say, please upgrade >  > ## v1.8.7 > Fixes side effect of fix from v1.8.6 that caused improper permissions for extracted folders >  > [bower/bower#2532](https://github-redirect.dependabot.com/bower/bower/issues/2532) >  > ## v1.8.6 > **Fix Zip Slip Vulnerability of decompress-zip package**: https://snyk.io/research/zip-slip-vulnerability >  > Note: v1.8.5 has been unpublished because of missing files >  > ## v1.8.4 > - Fixes release 1.8.3 by publishing with npm@3 instead of npm@5 (to include `lib/node_modules`) >  > ## v1.8.3 > - 451c60e Do not store resolutions if --save is not used, fixes [#2344](https://github-redirect.dependabot.com/bower/bower/issues/2344) ([#2508](https://github-redirect.dependabot.com/bower/bower/issues/2508)) > - 50ee729 Allow to disable shorthand resolver ([#2507](https://github-redirect.dependabot.com/bower/bower/issues/2507)) > - bb17839 Allow shallow cloning when source is a ssh protocol ([#2506](https://github-redirect.dependabot.com/bower/bower/issues/2506)) > - 5a6ae54 Add support for Arrays in Environment Variable replacement ([#2411](https://github-redirect.dependabot.com/bower/bower/issues/2411)) > - 74af42c Only replace last `@` after (if any) last `/` with `#` ([#2395](https://github-redirect.dependabot.com/bower/bower/issues/2395)) > - 💯Make tests work on Windows / Linux / OSX on node versions 0.10 / 0.12 / 4 / 6 / 8 / 9  > - 💅Format source code with [prettier](https://github.com/prettier/prettier) >  > ## v1.8.2 > Migrate registry url from http://bower.herokuapp.com to https://registry.bower.io >  > It is so we leverage CDN and offload Heroku instance reducing costs. >  > ## v1.8.0 > - Download tar archives from GitHub when possible ([#2263](https://github-redirect.dependabot.com/bower/bower/issues/2263)) >   - Change default shorthand resolver for github from `git://` to `https://` > - Fix ssl handling by not setting GIT_SSL_NO_VERIFY=false ([#2361](https://github-redirect.dependabot.com/bower/bower/issues/2361)) > - Allow for removing components with url instead of name ([#2368](https://github-redirect.dependabot.com/bower/bower/issues/2368)) > - Show in warning message location of malformed bower.json ([#2357](https://github-redirect.dependabot.com/bower/bower/issues/2357)) > - Improve handling of non-semver versions in git resolver ([#2316](https://github-redirect.dependabot.com/bower/bower/issues/2316)) > - Fix handling of cached releases pluginResolverFactory ([#2356](https://github-redirect.dependabot.com/bower/bower/issues/2356)) > - Allow to type the entire version when conflict occured ([#2243](https://github-redirect.dependabot.com/bower/bower/issues/2243)) > - Allow `owner/reponame` shorthand for registering components ([#2248](https://github-redirect.dependabot.com/bower/bower/issues/2248)) > - Allow single-char repo names and package names ([#2249](https://github-redirect.dependabot.com/bower/bower/issues/2249)) > - Make `bower version` no longer honor `version` in bower.json ([#2232](https://github-redirect.dependabot.com/bower/bower/issues/2232)) > - Add `postinstall` hook ([#2252](https://github-redirect.dependabot.com/bower/bower/issues/2252)) > - Allow for `@` instead of `#` for `install` and `info` commands ([#2322](https://github-redirect.dependabot.com/bower/bower/issues/2322)) > - Upgrade all bundled modules >  > ... (truncated)   Changelog  *Sourced from [bower's changelog](https://github.com/bower/bower/blob/master/CHANGELOG.md).*  > # Changelog >  > ## Newer releases >  > Please see: https://github.com/bower/bower/releases >  > ## 1.8.0 - 2016-11-07 >  > - Download tar archives from GitHub when possible ([#2263](https://github-redirect.dependabot.com/bower/bower/issues/2263)) >   - Change default shorthand resolver for github from `git://` to `https://` > - Fix ssl handling by not setting GIT_SSL_NO_VERIFY=false ([#2361](https://github-redirect.dependabot.com/bower/bower/issues/2361)) > - Allow for removing components with url instead of name ([#2368](https://github-redirect.dependabot.com/bower/bower/issues/2368)) > - Show in warning message location of malformed bower.json ([#2357](https://github-redirect.dependabot.com/bower/bower/issues/2357)) > - Improve handling of non-semver versions in git resolver ([#2316](https://github-redirect.dependabot.com/bower/bower/issues/2316)) > - Fix handling of cached releases pluginResolverFactory ([#2356](https://github-redirect.dependabot.com/bower/bower/issues/2356)) > - Allow to type the entire version when conflict occured ([#2243](https://github-redirect.dependabot.com/bower/bower/issues/2243)) > - Allow `owner/reponame` shorthand for registering components ([#2248](https://github-redirect.dependabot.com/bower/bower/issues/2248)) > - Allow single-char repo names and package names ([#2249](https://github-redirect.dependabot.com/bower/bower/issues/2249)) > - Make `bower version` no longer honor `version` in bower.json ([#2232](https://github-redirect.dependabot.com/bower/bower/issues/2232)) > - Add `postinstall` hook ([#2252](https://github-redirect.dependabot.com/bower/bower/issues/2252)) > - Allow for `@` instead of `#` for `install` and `info` commands ([#2322](https://github-redirect.dependabot.com/bower/bower/issues/2322)) > - Upgrade all bundled modules >  > ## 1.7.9 - 2016-04-05 >  > - Show warnings for invalid bower.json fields > - Update bower-json >   - Less strict validation on package name (allow spaces, slashes, and ""@"") >  > ## 1.7.8 - 2016-04-04 >  > - Don't ask for git credentials in non-interactive session, fixes [#956](https://github-redirect.dependabot.com/bower/bower/issues/956) [#1009](https://github-redirect.dependabot.com/bower/bower/issues/1009) > - Prevent swallowing exceptions with programmatic api, fixes [#2187](https://github-redirect.dependabot.com/bower/bower/issues/2187) > - Update graceful-fs to 4.x in all dependences, fixes [nodejs/node#5213](https://github-redirect.dependabot.com/nodejs/node/issues/5213) > - Resolve pluggable resolvers using cwd and fallback to global modules, fixes [#1919](https://github-redirect.dependabot.com/bower/bower/issues/1919) > - Upgrade handlebars to 4.0.5, closes [#2195](https://github-redirect.dependabot.com/bower/bower/issues/2195) > - Replace all % chatacters in defined scripts, instead of only first one, fixes [#2174](https://github-redirect.dependabot.com/bower/bower/issues/2174) > - Update opn package to fix issues with ""bower open"" command on Windows > - Update bower-config >   - Do not interpolate environment variables in script hooks, fixes [bower/config#47](https://github-redirect.dependabot.com/bower/config/issues/47) > - Update bower-json >   - Validate package name more strictly and allow only latin letters, dots, dashes and underscores > - Add support for ""save"" and ""save-exact"" in .bowerrc, [#2161](https://github-redirect.dependabot.com/bower/bower/issues/2161)   Commits  - [`67741b4`](https://github.com/bower/bower/commit/67741b4bfe465ef0b816f7f2811ce6ba6d065c1a) Bump to 1.8.8 - [`45c6bfa`](https://github.com/bower/bower/commit/45c6bfa86f6e57731b153baca9e0b41a1cc699e3) Fix .tar.gz extract vulnerability - [`4f68fc7`](https://github.com/bower/bower/commit/4f68fc7daa4d6f0a3dfd0da2afdbb8f0b87558af) Update decompress-zip and bump - [`206046b`](https://github.com/bower/bower/commit/206046b27120b8420a22b5c199479c103cb970f0) Bump to 1.8.6 - [`43894f5`](https://github.com/bower/bower/commit/43894f5149e43f246fa448012b95e2546003a821) Bump to 1.8.5 - [`6390815`](https://github.com/bower/bower/commit/6390815c5fb8766e527129cc5b63d1393d59ecd1) Update decompress-zip - [`e8b94ec`](https://github.com/bower/bower/commit/e8b94ecbd07376996eb0bea6cb30c20deb7e89b6) Mention parcel - [`51feb8f`](https://github.com/bower/bower/commit/51feb8f925d57d069de6a54bc56e4164ec7245ec) Fix release script - [`1c15dea`](https://github.com/bower/bower/commit/1c15deadc035714a8911a81807ec1e25d6e27683) Bump to 1.8.4 - [`2aa1f27`](https://github.com/bower/bower/commit/2aa1f27367f9f21c00b0ed1c8ddf8e1e12381abf) Update publish script - Additional commits viewable in [compare view](https://github.com/bower/bower/compare/v1.7.7...v1.8.8)    [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=bower&package-manager=npm_and_yarn&previous-version=1.7.7&new-version=1.8.8)](https://help.github.com/articles/configuring-automated-security-fixes)  Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.  [//]: # (dependabot-automerge-start) [//]: # (dependabot-automerge-end)  ---   Dependabot commands and options   You can trigger Dependabot actions by commenting on this PR: - `@dependabot rebase` will rebase this PR - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it - `@dependabot merge` will merge this PR after your CI passes on it - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it - `@dependabot cancel merge` will cancel a previously requested merge and block automerging - `@dependabot reopen` will reopen this PR if it is closed - `@dependabot ignore this [patch|minor|major] version` will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself) - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself) - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language  You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/hadoop/network/alerts).","closed","javascript,","dependabot[bot]","2019-10-29T20:39:21Z","2019-12-09T06:46:18Z"
"","780","HDFS-13677: Swap old replicas when reconfiguration Disk","BugFix for 13677[HDFS-13677](https://issues.apache.org/jira/browse/HDFS-13677)","closed","","ZanderXu","2019-04-28T04:11:55Z","2019-08-08T11:20:13Z"
"","758","HDDS-999. Make the DNS resolution in OzoneManager more resilient. (swagle)","Brought back change from HDDS-776 with the retriable task, OM will now wait for at least 50 seconds before giving up.","closed","ozone,","swagle","2019-04-22T23:51:00Z","2019-04-26T10:47:15Z"
"","1119","YARN-9375. Use Configured in GpuDiscoverer and FpgaDiscoverer","Both GpuDiscoverer and FpgaDiscoverer classes are now extending Configured.","closed","","adamantal","2019-07-18T09:18:38Z","2019-07-19T09:22:23Z"
"","831","HDDS-1487. Bootstrap React framework for Recon UI","Bootstrap React with Typescript, Ant, LESS and other necessary libraries for Recon UI.   This PR also adds necessary changes to recon pom.xml to bring React UI up when starting recon server","closed","ozone,","vivekratnavel","2019-05-17T09:05:39Z","2019-05-20T21:40:37Z"
"","1677","YARN-9934. avoid submitting aggregator when app dir creation fail","Before submiting a log aggreation runnable, LogAggregationService  will try to create the aggreated log dir.  In some case, it may fail(e.g dir num exceed max limit)   When it did failed and submitted to LogAggregationService, the runnable may run forever if some app statue flip misbehavior(e.g not handling application complete event rightfully,thus keeping appFinishing of AppLogAggregatorImpl be always true).    In our production(Version 2.7.3), this cause huge number of dangling aggregator(~400+ LogAggregationService threads alive for some node, in which nodemanager configured only 50+ vCPUs).   The patch try to early throw the creation exception, avoiding starting unnecessary log polling.   Jira:[YARN-9934](https://issues.apache.org/jira/browse/YARN-9934)","closed","","zizon","2019-10-25T02:58:38Z","2019-10-28T03:15:04Z"
"","878","MAPREDUCE-7210. Replace `mapreduce.job.counters.limit` with `mapreduce.job.counters.max` in mapred-default.xml","Because the `mapreduce.job.counters.limit` is deprecated, the new property name is `mapreduce.job.counter.max`, so we need update the `mapred-default.xml`.","closed","","jiwq","2019-05-31T13:08:54Z","2019-06-08T14:49:18Z"
"","840","HDDS-1565. Rename k8s-dev and k8s-dev-push profiles to docker and docker-push","Based on the feedback from [~eyang] I realized that the names of the k8s-dev and k8s-dev-push profile are not expressive enough as the created containers can be used not only for kubernetes but to use them in any other environments.  I propose to rename to docker/docker-push.  See: https://issues.apache.org/jira/browse/HDDS-1565","closed","ozone,","elek","2019-05-21T15:58:51Z","2019-06-06T06:08:08Z"
"","1521","HDDS-2073. Make SCMSecurityProtocol message based","Based on HDDS-2067","closed","","elek","2019-09-25T12:16:03Z","2019-10-02T19:31:36Z"
"","1634","YARN-7243. Moving logging APIs over to slf4j in hadoop-yarn-server-resourcemanager.","Backport https://issues.apache.org/jira/browse/YARN-7243 to branch-3.2 to fix compile failure caused by https://issues.apache.org/jira/browse/YARN-9873","closed","","aajisaka","2019-10-10T02:39:59Z","2019-10-10T06:27:58Z"
"","861","HDDS-1596. Create service endpoint to download configuration from SCM","As written in the design doc (see the parent issue) it was proposed to download the configuration from the scm by the other services.  I propose to create a separated endpoint to provide the ozone configuration. /conf can't be used as it contains *all* the configuration and we need only the modified configuration.  The easiest way to implement this feature is:   * Create a simple rest endpoint which publishes all the configuration  * Download the configurations to $HADOOP_CONF_DIR/ozone-global.xml during the service startup.  * Add ozone-global.xml as an additional config source (before ozone-site.xml but after ozone-default.xml)  * The download can be optional  With this approach we keep the support of the existing manual configuration (ozone-site.xml has higher priority) but we can download the configuration to a separated file during the startup, which will be loaded.  There is no magic: the configuration file is saved and it's easy to debug what's going on as the OzoneConfiguration is loaded from the $HADOOP_CONF_DIR as before.  Possible follow-up steps:   * Migrate all the other services (recon, s3g) to the new approach. (possible newbie jiras)  * Improve the CLI to define the SCM address. (As of now we use ozone.scm.names)  * Create a service/hostname registration mechanism and autofill some of the configuration based on the topology information.  See: https://issues.apache.org/jira/browse/HDDS-1596","closed","ozone,","elek","2019-05-28T08:41:06Z","2019-08-28T16:22:35Z"
"","1641","HDDS-2281. ContainerStateMachine#handleWriteChunk should ignore close container exception.","As write chunk happens in parallel over datanode, it might be possible that writeChunk happening as part of writeStateMachineData may fail with CloseContainerException. This leads to a log append failure in Ratis and as a result of which pipeline close action gets triggered on datanode resulting in frequent destruction of pipelines in the system.  Currently, ContainerStateMachine#applyTrannsaction ignores close container exception.Similarly,ContainerStateMachine#handleWriteChunk call also should ignore close container exception.  The patch was tested by adding a unit test where after allocating a container and doing writes over it with multiple threads in parallel with one thread closing the container randomly and verifying that because of close container , the stateMachine is not marked unhealthy and new snapshots can still be taken and pipeline functions does not halt.","closed","ozone,","bshashikant","2019-10-10T20:25:05Z","2020-04-30T13:48:20Z"
"","858","HDDS-1602. Fix TestContainerPersistence#testDeleteBlockTwice.","As rocksdb - db.delete(key) when the key does not exist does nothing, it does not throw an exception. First we should get and then call delete.   As now for every block delete, we do two 2 db operations. get and then delete. If we want to avoid get(), we can directly call delete, and remove this test. But with this approach, deleteBlock can be called with some randomBlockId's and the user will not know whether this block exists, and we deleted it. (As we don't throw an exception.) So, not taken this approach.","closed","ozone,","bharatviswa504","2019-05-27T23:04:25Z","2019-05-28T19:56:12Z"
"","771","HDDS-1466. Improve the configuration API with using Java classes instead of constants","As of now we use the API in Configuration api from hadoop-common. We propose to use additional wrapper to get configured Objects instead of constants to make the configuration more structured and type safe.  The ozone-default.xml can be generated with annotation processor.  Please see the attached design doc about more details.  See: https://issues.apache.org/jira/browse/HDDS-1466","closed","ozone,","elek","2019-04-25T09:24:41Z","2019-04-25T09:25:43Z"
"","733","HDDS-1284. Adjust default values of pipline recovery for more resilient service restart","As of now we have a following algorithm to handle node failures:  1. In case of a missing node the leader of the pipline or the scm can detected the missing heartbeats. 2. SCM will start to close the pipeline (CLOSING state) and try to close the containers with the remaining nodes in the pipeline 3. After 5 minutes the pipeline will be destroyed (CLOSED) and a new pipeline can be created from the healthy nodes (one node can be part only one pipwline in the same time).  While this algorithm can work well with a big cluster it doesn't provide very good usability on small clusters:  Use case1:  Given 3 nodes, in case of a service restart, if the restart takes more than 90s, the pipline will be moved to the CLOSING state. For the next 5 minutes (ozone.scm.pipeline.destroy.timeout) the container will remain in the CLOSING state. As there are no more nodes and we can't assign the same node to two different pipeline, the cluster will be unavailable for 5 minutes.  Use case2:  Given 90 nodes and 30 pipelines where all the pipelines are spread across 3 racks. Let's stop one rack. As all the pipelines are affected, all the pipelines will be moved to the CLOSING state. We have no free nodes, therefore we need to wait for 5 minutes to write any data to the cluster.  These problems can be solved in multiple ways:  1.) Instead of waiting 5 minutes, destroy the pipeline when all the containers are reported to be closed. (Most of the time it's enough, but some container report can be missing) 2.) Support multi-raft and open a pipeline as soon as we have enough nodes (even if the nodes already have a CLOSING pipelines).  Both the options require more work on the pipeline management side. For 0.4.0 we can adjust the following parameters to get better user experience:  {code}        ozone.scm.pipeline.destroy.timeout     60s     OZONE, SCM, PIPELINE            Once a pipeline is closed, SCM should wait for the above configured time       before destroying a pipeline.              ozone.scm.stale.node.interval     90s     OZONE, MANAGEMENT            The interval for stale node flagging. Please       see ozone.scm.heartbeat.thread.interval before changing this value.          {code}  First of all, we can be more optimistic and mark node to stale only after 5 mins instead of 90s. 5 mins should be enough most of the time to recover the nodes.  Second: we can decrease the time of ozone.scm.pipeline.destroy.timeout. Ideally the close command is sent by the scm to the datanode with a HB. Between two HB we have enough time to close all the containers via ratis. With the next HB, datanode can report the successful datanode. (If the containers can be closed the scm can manage the QUASI_CLOSED containers)  We need to wait 29 seconds (worst case) for the next HB, and 29+30 seconds for the confirmation. --> 66 seconds seems to be a safe choice (assuming that 6 seconds is enough to process the report about the successful closing)  See: https://issues.apache.org/jira/browse/HDDS-1284","closed","ozone,","elek","2019-04-12T12:10:13Z","2019-05-16T15:20:58Z"
"","1519","HDDS-2174. Delete GDPR Encryption Key from metadata when a Key is deleted","As advised, deleted GDPR related metadata from KeyInfo before moving it to deletedTable. Added/updated test.  P.S. The changes in KeyManagerImpl are not really needed but made them for sanity & it is no harm.","closed","ozone,","dineshchitlangia","2019-09-25T03:42:40Z","2019-09-27T04:33:44Z"
"","1007","HADOOP-16389: Bump Apache Avro to 1.9.0","Apache Avro 1.9.0 brings a lot of new features:  - Deprecate Joda-Time in favor of Java8 JSR310 and setting it as default - Remove support for Hadoop 1.x - Move from Jackson 1.x to 2.9 - Add ZStandard Codec - Lots of updates on the dependencies to fix CVE's - Remove Jackson classes from public API - Apache Avro is built by default with Java 8 - Apache Avro is compiled and tested with Java 11 to guarantee compatibility - Apache Avro MapReduce is compiled and tested with Hadoop 3 - Apache Avro is now leaner, multiple dependencies were removed: guava, paranamer, commons-codec, and commons-logging","open","","Fokko","2019-06-22T05:47:43Z","2019-07-26T06:10:05Z"
"","1322","[HDDS-1994] Rename ScmBlockLocationTestIngClient.java to ScmBlockLocationTestingClient.java","And revert HDDS-1965","closed","","hgadre","2019-08-20T23:54:19Z","2021-02-10T23:54:27Z"
"","792","HDDS-1474. ozone.scm.datanode.id config should take path for a dir","and not a file.  Currently, the ozone config ""ozone.scm.datanode.id"" takes file path as its value. It should instead take dir path as its value and assume a standard filename ""datanode.id""","closed","ozone,","vivekratnavel","2019-05-02T09:09:20Z","2019-05-09T18:16:59Z"
"","1531","HADOOP-16579 - Upgrade to Apache Curator 4.2.0 excluding ZK","An integration/smoke test with multiple components (HDFS, HBase, Spark etc) is in progress.  I will update the PR once done.","closed","","nkalmar","2019-09-26T13:39:04Z","2019-10-04T17:57:08Z"
"","1435","HDDS-2119. Use checkstyle.xml and suppressions.xml in hdds/ozone projects for checkstyle validation.","After #1423 hdds/ozone no more relies on hadoop parent pom, so we have to use separate checkstyle.xml and suppressions.xml in hdds/ozone projects for checkstyle validation.","closed","ozone,","nandakumar131","2019-09-12T20:45:56Z","2019-09-20T09:18:07Z"
"","1668","HADOOP-16645. S3A Delegation Token extension point to use StoreContext.","Adds a new interface DelegationOperations which S3A FS offers. This just exends AWSPolicyProvider, as that is the only callback outside of StoreContext which is currently used.  Having an explicit interface lets us add more callbacks in future, without breaking the signature of the API -hence any external implementations  supercedes #1630  -that also included the Marshalling  -> Marshaling change. this PR is only the first commit  Change-Id: I412ae78d6a806bea954ec5980faf2b7f8aac7bed","closed","fs/s3,","steveloughran","2019-10-22T17:15:09Z","2021-10-15T19:42:14Z"
"","1630","HADOOP-16645. S3A Delegation Token extension point to use StoreContext.","Adds a new interface DelegationOperations which S3A FS offers. This just exends AWSPolicyProvider, as that is the only callback outside of StoreContext which is currently used.  Having an explicit interface lets us add more callbacks in future, without breaking the signature of the API -hence any external implementations  Change-Id: I412ae78d6a806bea954ec5980faf2b7f8aac7bed","closed","fs/s3,","steveloughran","2019-10-09T15:24:38Z","2021-10-15T19:42:20Z"
"","1399","YARN-10210. Add a RMFailoverProxyProvider that does DNS resolution on failover","Addresses the following issue: https://issues.apache.org/jira/browse/HADOOP-16543","closed","","RogPodge","2019-09-04T00:19:09Z","2020-03-26T18:05:14Z"
"","1573","HDFS-14889. Ability to check if a block has a replica on provided storage.","Addresses https://issues.apache.org/jira/browse/HDFS-14889. Adding a method in `BlockInfo` to return true of the block has any replica on a Provided storage.","closed","","ashvina","2019-10-02T05:40:37Z","2019-10-04T04:48:24Z"
"","1478","HDFS-14856. Fetch file ACLs while mounting external store.","Addresses https://issues.apache.org/jira/browse/HDFS-14856.  If configuration `dfs.namenode.mount.acls.enabled` is set (true), `FsTreeWalk` will fetch ACLs of files on the external storage system provided at the time of mount.","closed","","ashvina","2019-09-19T17:19:08Z","2019-10-14T16:44:57Z"
"","1251","HDFS-14696. Backport HDFS-11273 to branch-2 (Move TransferFsImage#doGetUrl function to a Util class)","Addressed some of the checkstyle warning, see the second commit message for details.","closed","","smengcl","2019-08-07T22:36:25Z","2019-08-08T21:57:17Z"
"","837","Adding nodeId to Delimited File","Adding inodeId to delimited file as XML processor.","closed","","amommendes","2019-05-21T01:30:06Z","2020-11-12T22:07:59Z"
"","1175","Gcs connector","added shaded version of the connector instead","closed","","commanderchewbacca","2019-07-26T23:29:30Z","2019-07-27T00:25:15Z"
"","872","HDDS-1581. Atleast one of the metadata dir config property must be tagged as REQUIRED","Added REQUIRED tag on fallback property and updated description of other configs as needed.","closed","","dineshchitlangia","2019-05-30T03:01:18Z","2019-05-30T15:42:28Z"
"","1259","HDDS-1105 : Add mechanism in Recon to obtain DB snapshot 'delta' updates from Ozone Manager","Added mechanism in Recon to obtain DB snapshot 'delta' updates from Ozone Manager. Recon will make RPC calls to OM to get delta updates from the latest sequence number of its own OM snapshot DB. After applying the changes to its OM DB, the updates are passed on to the set of tasks that are ""listening"" on OM DB updates.   Other than the core logic for the above, the patch :  - Cleans up the unit test code - Fixes issues in OM DB updates sender - Removes the need for powermock in recon unit tests. - Adds guice injection to Task framework. - Cleans up contract of Recon task interface.   **Testing done** Added unit tests for all new methods added in OzoneManagerServiceProviderImpl. Manually tested on live cluster by adding keys on OM, and verifying if events are being picked up by Recon, and if the container DB is subsequently updated.   Sample logging from Recon on test cluster.","closed","ozone,","avijayanhwx","2019-08-09T05:43:09Z","2019-08-19T17:47:50Z"
"","1200","HDDS-1832 : Improve logging for PipelineActions handling in SCM and datanode.","Added logging.","closed","ozone,","avijayanhwx","2019-07-31T22:43:27Z","2019-08-02T17:59:22Z"
"","1126","Gcs connector","added gcs connector to images to allow for gcs use for operator-metering","closed","","commanderchewbacca","2019-07-19T01:07:57Z","2019-07-19T01:09:20Z"
"","1127","Gcs connector","added gcs connector for  operator-metering","closed","","commanderchewbacca","2019-07-19T01:11:09Z","2019-07-19T01:11:22Z"
"","871","HDDS-1579. Create OMDoubleBuffer metrics.","Added DoubleBuffer Metrics in OM: 1. totalNumOfFlushIterations 2. totalNumOfFlushedTransactions. 3. maxNumberOfTransactionsFlushedInOneIteration","closed","ozone,","bharatviswa504","2019-05-29T23:21:20Z","2019-06-20T16:56:18Z"
"","1033","HDDS-1391 : Add ability in OM to serve delta updates through an API.","Added an RPC end point to serve the set of updates in OM RocksDB from a given sequence number. This will be used by Recon (HDDS-1105) to push the data to all the tasks that will keep their aggregate data up to date.","closed","ozone,","avijayanhwx","2019-06-28T22:08:45Z","2019-07-29T16:39:41Z"
"","1189","HDFS-14683. WebHDFS: Add erasureCodingPolicy field to GETCONTENTSUMMARY response","Added a unit test for `JsonUtil#toJsonString(ContentSummary)`. Amended WebHDFS doc. Tested locally.  When the ecPolicy is empty, the request would just return empty string, i.e. `ecPolicy: """"`.","closed","hdfs,","smengcl","2019-07-31T06:52:16Z","2019-08-02T00:55:30Z"
"","838","HADOOP-16321: ITestS3ASSL+TestOpenSSLSocketFactory failing with java.lang.UnsatisfiedLinkErrors","Added a `NativeCodeLoader.isNativeCodeLoaded())` check before these tests so they get skipped if native libraries can't be loaded or are not present.  Tested on OSX after a `mvn clean install -DskipTests` and `mvn clean install -DskipTests -Pnative`. The test gets skipped in both cases.   Tested on the Hadoop dev Docker env; with `-Pnative` the test passes, without `-Pnative` the test is skipped.  `ITestS3ASSL` was tested against `us-east-1`.","closed","","sahilTakiar","2019-05-21T07:34:30Z","2019-05-22T10:01:15Z"
"","936","YARN-9605.Add ZkConfiguredFailoverProxyProvider for RM HA","Add ZkConfiguredFailoverProxyProvider for RM HA.Which can be useful when use ZK to handle RM failover","closed","","caneGuy","2019-06-10T09:28:48Z","2021-09-03T11:55:45Z"
"","1611","HADOOP-16612 Track Azure Blob File System client-perceived latency","Add instrumentation code to measure the ADLS Gen 2 API performance Add a feature switch to optionally enable this feature Add unit tests for correctness and performance","closed","fs/azure,","jeeteshm","2019-10-07T19:37:40Z","2019-11-19T17:24:51Z"
"","1569","[Abandoned] HADOOP-16612 Track Azure Blob File System client-perceived latency","Add instrumentation code to measure the ADLS Gen 2 API performance Add a feature switch to optionally enable this feature Add unit tests for correctness and performance","closed","","jeeteshm","2019-10-01T22:33:23Z","2019-11-05T01:49:38Z"
"","766","YARN-9509: Added a configuration for admins to be able to capped per-container cpu usage based on a multiplier","Add a multiplier configuration on strict resource usage to authorize container to use spare cpu up to a limit. Currently with strict resource usage you can't get more than what you request which is sometime not good for jobs that doesn't have a constant usage of cpu (for ex. spark jobs with multiple stages). But without strict resource usage we have seen some bad behaviour from our users that don't tune at all their needs and it leads to some containers requesting 2 vcore but constantly using 20. The idea here is to still authorize containers to get more cpu than what they request if some are free but also to avoid too big differencies so SLA on jobs is not breached if the cluster is full (at least increase of runtime is contain)","open","","ashangit","2019-04-24T13:03:15Z","2021-08-03T14:01:31Z"
"","1643","HDDS-2278. Run S3 test suite on OM HA cluster.","Add a docker compose OM HA cluster with S3. Run the S3 test suite on the OM HA cluster. https://issues.apache.org/jira/browse/HDDS-2278","closed","ozone,","bharatviswa504","2019-10-11T00:40:58Z","2019-10-15T02:38:31Z"
"","934","YARN-9537.Add configuration to disable AM preemption","Add a configuration to support disable AM preemption. Which can be useful for some case when we have a cluster do not want app to be preempted and restart.","closed","","caneGuy","2019-06-10T08:49:08Z","2022-06-24T12:00:30Z"
"","1621","HADOOP-16640. WASB: Override getCanonicalServiceName() to return URI","Add a configuration to override getCanonicalServiceName() to return URI of WASB FS.","closed","","DadanielZ","2019-10-08T19:44:21Z","2019-10-16T20:24:03Z"
"","848","YARN-9579:the property of sharedcache in mapred-default.xml","add ""enabled"" category to `mapreduce.job.sharedcache.mode` in mapred-default.xml.  Add the following content  `If ""enable"" is specified then the job submission code will use the shared cache with all resouce, include jobjar, libjars, files and archives.`","open","","hunshenshi","2019-05-24T03:52:26Z","2021-10-07T05:57:18Z"
"","772","HDDS-1468. Inject configuration values to Java objects","According to the design doc in the parent issue we would like to support java configuration objects which are simple POJO but the fields/setters are annotated. As a first step we can introduce the OzoneConfiguration.getConfigObject() api which can create the config object and inject configuration.  Later we can improve it with annotation processor which can generate the ozone-default.xml.  See: https://issues.apache.org/jira/browse/HDDS-1468","closed","ozone,","elek","2019-04-25T09:25:54Z","2019-05-02T09:45:12Z"
"","1256","HDDS-1937. Acceptance tests fail if scm webui shows invalid json","Acceptance test of a nightly build is failed with the following error:  {code} Creating ozonesecure_datanode_3 ...  [7A[2K Creating ozonesecure_kdc_1      ... [32mdone[0m [7B[6A[2K Creating ozonesecure_om_1       ... [32mdone[0m [6B[8A[2K Creating ozonesecure_scm_1      ... [32mdone[0m [8B[1A[2K Creating ozonesecure_datanode_3 ... [32mdone[0m [1B[5A[2K Creating ozonesecure_kms_1      ... [32mdone[0m [5B[4A[2K Creating ozonesecure_s3g_1      ... [32mdone[0m [4B[2A[2K Creating ozonesecure_datanode_2 ... [32mdone[0m [2B[3A[2K Creating ozonesecure_datanode_1 ... [32mdone[0m [3Bparse error: Invalid numeric literal at line 2, column 0 {code}  https://raw.githubusercontent.com/elek/ozone-ci/master/byscane/byscane-nightly-5b87q/acceptance/output.log  The problem is in the script which checks the number of available datanodes.  If the HTTP endpoint of the SCM is already started BUT not ready yet it may return with a simple HTML error message instead of json. Which can not be parsed by jq:  In testlib.sh:  {code}   37   │   if [[ ""${SECURITY_ENABLED}"" == 'true' ]]; then   38   │     docker-compose -f ""${compose_file}"" exec -T scm bash -c ""kinit -k HTTP/scm@EXAMPL        │ E.COM -t /etc/security/keytabs/HTTP.keytab && curl --negotiate -u : -s '${jmx_url}'""   39   │   else   40   │     docker-compose -f ""${compose_file}"" exec -T scm curl -s ""${jmx_url}""   41   │   fi \   42   │     | jq -r '.beans[0].NodeCount[] | select(.key==""HEALTHY"") | .value' {code}  One possible fix is to adjust the error handling (set +x / set -x) per method instead of using a generic set -x at the beginning. It would provide a more predictable behavior. In our case count_datanode should not fail evert (as the caller method: wait_for_datanodes can retry anyway).  See: https://issues.apache.org/jira/browse/HDDS-1937","closed","ozone,","elek","2019-08-08T15:55:41Z","2019-08-28T18:41:44Z"
"","939","HADOOP-16340. ABFS driver continues to retry on IOException responses from REST operations","ABFS driver continues to retry (until retry count is exhausted) upon IOException responses from REST operations.    In the exception hander for IOExceptions at https://github.com/apache/hadoop/blob/65f60e56b082faf92e1cd3daee2569d8fc669c67/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java#L174-L197, there is no way exit out of the retry loop by re-throwing an exception unless one of the following conditions have been met:  - The retry limit was hit - An HttpException was encountered  From an org.apache.hadoop.fs.azurebfs.extensions.CustomTokenProviderAdaptee or org.apache.hadoop.fs.azurebfs.extensions.CustomDelegationTokenManager implementation, there is no way to create an org.apache.hadoop.fs.azurebfs.oauth2.AzureADAuthenticator.HttpException since the constructor is package private.   To solve this issue, access to org.apache.hadoop.fs.azurebfs.oauth2.AzureADAuthenticator.HttpException needs to be set to that custom implementations can use it.     This patch changes the org.apache.hadoop.fs.azurebfs.oauth2.AzureADAuthenticator.HttpException constructor to private rather than package private.","closed","","rlevas","2019-06-10T16:46:18Z","2019-06-19T16:46:24Z"
"","1586","HDDS-2240. Command line tool for OM HA.","A command line tool (ozone omha) to get information related to OM HA.  This Jira proposes to add the getServiceState option for OM HA which lists all the OMs in the service and their corresponding Ratis server roles (LEADER/ FOLLOWER).  We can later add more options to this tool.","closed","ozone,","hanishakoneru","2019-10-03T18:58:17Z","2019-10-17T17:06:00Z"
"","1078","HDDS-1784. Missing HostName and IpAddress in the response of register command.","`SCMNodeManager` sets the HostName and IpAddress to the response of register command, but that is being ignored in `SCMDatanodeProtocolServer` while sending the response back to the datanode.","closed","ozone,","nandakumar131","2019-07-11T13:33:04Z","2019-07-12T04:58:08Z"
"","1439","HDDS-2125. maven-javadoc-plugin.version is missing in pom.ozone.xml.","`maven-javadoc-plugin.version` is missing from `pom.ozone.xml` which is causing build failure.","closed","ozone,","nandakumar131","2019-09-13T13:31:33Z","2019-09-14T06:19:17Z"
"","1083","HDDS-1791. Update network-tests/src/test/blockade/README.md file","`hadoop-ozone/fault-injection-test/network-tests/src/test/blockade/README.md` has to be updated after #1068","closed","ozone,","nandakumar131","2019-07-12T10:12:05Z","2019-07-12T14:55:07Z"
"","990","HDDS-1554. Create disk tests for fault injection test","``` The current plan for fault injection disk tests are:  # Scenario 1 - Read/Write test  ## Run docker-compose to bring up a cluster  ## Initialize scm and om  ## Upload data to Ozone cluster  ## Verify data is correct  ## Shutdown cluster  # Scenario 2 - Read/Only test  ## Repeat Scenario 1  ## Mount data disk as read only  ## Try to write data to Ozone cluster  ## Validate error message is correct  ## Shutdown cluster  # Scenario 3 - Corruption test  ## Repeat Scenario 2  ## Shutdown cluster  ## Modify data disk data  ## Restart cluster  ## Validate error message for read from corrupted data  ## Validate error message for write to corrupted volume  See: https://issues.apache.org/jira/browse/HDDS-1554 ```","closed","ozone,","elek","2019-06-19T09:43:56Z","2019-10-02T21:34:39Z"
"","978","HDDS-1694. TestNodeReportHandler is failing with NPE","``` FAILURE in ozone-unit-076618677d39x4h9/unit/hadoop-hdds/server-scm/org.apache.hadoop.hdds.scm.node.TestNodeReportHandler.txt ------------------------------------------------------------------------------- Test set: org.apache.hadoop.hdds.scm.node.TestNodeReportHandler ------------------------------------------------------------------------------- Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.43 s","closed","ozone,","elek","2019-06-17T15:36:04Z","2019-06-18T07:04:29Z"
"","1070","HDDS-1725. pv-test example to test csi is not working","[~rmaruthiyodan] reported two problems regarding to the pv-test example in csi examples folder.  pv-test folder contains an example nginx deployment which can use an ozone PVC/PV to publish content of a folder via http.  Two problems are identified:  * The label based matching filter of service doesn't point to the nginx deployment  * The configmap mounting is missing from nginx deployment  See: https://issues.apache.org/jira/browse/HDDS-1725","closed","ozone,","elek","2019-07-10T12:23:49Z","2019-08-21T07:48:44Z"
"","1002","HDDS-1716. Smoketest results are generated with an internal user","[~eyang] reported the problem in HDDS-1609 that the smoketest results are generated a user (the user inside the docker container) which can be different from the host user.  There is a minimal risk that the test results can be deleted/corrupted by an other users if the current user is different from uid=1000  I opened this issue because [~eyang] said me during an offline discussion that HDDS-1609 is a more complex issue and not only about the ownership of the test results.  I suggest to handle the two problems in different way. With this patch, the permission of the test result files can be fixed easily.  In HDDS-1609 we can discuss about general security problems and try to find generic solution for them.  Steps to reproduce _this_ the problem:   * Use a user which is different from uid=1000   * Create a new ozone build (mvn clean install -f pom.ozone.xml -DskipTests)   * Go to a compose directory (cd hadoop-ozone/dist/target/ozone-0.5.0-SNAPSHOT/compose/)   * Execute tests (./test.sh)   * check the ownership of the results (ls -lah ./results)  Current result: the owner of the result files are the user uid=1000  Expected result: the owner of the files should be always the current user (even if the current uid is different)     See: https://issues.apache.org/jira/browse/HDDS-1716","closed","ozone,","elek","2019-06-21T11:51:57Z","2019-07-02T20:53:32Z"
"","1059","HDDS-1764. Fix hidden errors in acceptance tests","[~bharatviswa] pinged me offline with the problem that in some cases the smoketest is failing even if the reports are green:  > All smoke tests are passed, but CI is showing as Failed. >  > https://ci.anzix.net/job/ozone/17284/RobotTests/log.html > https://github.com/apache/hadoop/pull/1048 >   The root cause is a few typo after HDDS-1698, which can be fixed with the uploaded PR.  ***What is the problem?***  In case of any error during the test execution the smoketest is failed. In this case because the typo in two docker-compose.yaml files two of the tests can't be started.  But there is no separated robot test report and the error is visible only in the console.  ***How did it happen?***  The ACL work improved some intermittency in the acceptance tests. HDDS-1698 is committed because the acceptance tests were failed with ACL errors which hide the real error (the test was red anyway).     See: https://issues.apache.org/jira/browse/HDDS-1764","closed","ozone,","elek","2019-07-04T15:26:29Z","2019-07-10T12:01:23Z"
"","701","HDDS-1397. Avoid the usage of signal handlers in datanodes of the MiniOzoneClusters","[~arpaga] showed me a problem that TestQueryNode.testHealthyNodesCount is failed in the CI check of HDDS-1339.  According to the logs the test is timed out because only 4 datanodes are started out of the 5.  The log also contained an exception from one datanode:  ``` 2019-04-04 00:26:33,583 WARN  ozone.HddsDatanodeService (LogAdapter.java:warn(59)) - failed to register any UNIX signal loggers:  java.lang.IllegalStateException: Can't re-install the signal handlers.     at org.apache.hadoop.util.SignalLogger.register(SignalLogger.java:77)     at org.apache.hadoop.util.StringUtils.startupShutdownMessage(StringUtils.java:718)     at org.apache.hadoop.util.StringUtils.startupShutdownMessage(StringUtils.java:707)     at org.apache.hadoop.ozone.HddsDatanodeService.createHddsDatanodeService(HddsDatanodeService.java:126)     at org.apache.hadoop.ozone.HddsDatanodeService.createHddsDatanodeService(HddsDatanodeService.java:108)     at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.createHddsDatanodes(MiniOzoneClusterImpl.java:552) ```  The code which requires the signal handler is the following (signal handler is registered in the startupShutdownMessage)  ``` /**    * Create an Datanode instance based on the supplied command-line arguments.    *     * This method is intended for unit tests only. It suppresses the    * startup/shutdown message and skips registering Unix signal handlers.    *    * @param args        command line arguments.    * @param conf        HDDS configuration    * @param printBanner if true, then log a verbose startup message.    * @return Datanode instance    */   private static HddsDatanodeService createHddsDatanodeService(       String[] args, Configuration conf, boolean printBanner) {     if (args.length == 0 && printBanner) {       StringUtils           .startupShutdownMessage(HddsDatanodeService.class, args, LOG);       return new HddsDatanodeService(conf);     } else {       new HddsDatanodeService().run(args);       return null;    } ```  As you can read from the comment it's expected to be called with printBanner=false to avoid the creation of the signal handler.   Note: In the startupShutdownMessage method a new signal handler is registered and signal handlers can be registered only once:  ``` //SignalLogger   void register(final LogAdapter LOG) {    if (registered) {       throw new IllegalStateException(""Can't re-install the signal handlers."");     }  .... ```  We have a dedicated method to create datanode service for the unit tests. The only thing what we need is to turn OFF the signal handler registration here. (The following code fragment shows the original state where the signal handler creation is requested with the true parameter value)  ```   @VisibleForTesting   public static HddsDatanodeService createHddsDatanodeService(       String[] args, Configuration conf) {     return createHddsDatanodeService(args, conf, true);   } ```  See: https://issues.apache.org/jira/browse/HDDS-1397","closed","ozone,","elek","2019-04-05T09:18:38Z","2019-04-10T16:40:42Z"
"","741","HDFS-14425:Native build fails on macos due to jlong in hdfs.c","[WARNING] /Users/xx/tmp/idea/hadoop-3.2.0-src/hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/libhdfs/hdfs.c:3033:/Users/xx/tmp/idea/hadoop-3.2.0-src/hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/libhdfs/hdfs.c:3033:4949::  warningwarning: : incompatible pointer types passing 'tOffset *' (aka 'long long *') to parameter of type 'jlong *' (aka 'long *') [-Wincompatible-pointer-types]incompatible pointer types passing 'tOffset *' (aka 'long long *') to parameter of type 'jlong *' (aka 'long *') [-Wincompatible-pointer-types]","closed","","hunshenshi","2019-04-15T09:45:17Z","2019-07-26T22:33:13Z"
"","821","MAPREDUCE-7205. Changed to the interpret container scheduler kill exit code as a task attempt killing event","[MAPREDUCE-7205](https://issues.apache.org/jira/browse/MAPREDUCE-7205)  MR needs to recognize the special exit code value of -108 and interpret it as a container being killed instead of a container failure.  -108: Container was terminated by the ContainerScheduler to make room for another container...","closed","","jiwq","2019-05-15T12:11:54Z","2019-05-22T05:47:53Z"
"","1436","HDFS-14846: libhdfs tests are failing on trunk due to jni usage bugs","[HDFS-14846](https://issues.apache.org/jira/browse/HDFS-14846): libhdfs tests are failing on trunk due to jni usage bugs  JIRA describes the issue. The fix is to remote any duplicate calls to `DeleteLocalRef`.","closed","","sahilTakiar","2019-09-12T22:53:15Z","2019-09-17T23:06:23Z"
"","963","HDFS-14564: Add libhdfs APIs for readFully; add readFully to ByteBufferPositionedReadable","[HDFS-14564](https://issues.apache.org/jira/browse/HDFS-14564): Add libhdfs APIs for readFully; add readFully to ByteBufferPositionedReadable  * Adds `readFully` to `ByteBufferPositionedReadable` and exposes it via libhdfs * Exposes `PositionedReadable#readFully` via libhdfs * Like `hdfsPread` and `hdfsRead` if the underlying stream supports `ByteBuffer` reads, the `ByteBuffer` APIs will be used * Add unit tests, and did a bit of javadoc / code cleanup","closed","","sahilTakiar","2019-06-13T19:18:58Z","2019-10-01T22:26:52Z"
"","955","HDFS-14478: Add libhdfs APIs for openFile","[HDFS-14478](https://issues.apache.org/jira/browse/HDFS-14478): Add libhdfs APIs for openFile  Exposes the openFile API via libhdfs, adds new tests to `test_libhdfs_ops.c`. For the most part, the libhdfs API mirrors the Java API (e.g. the async open file is modeled in a similar fashion to `java.util.concurrent.Future`).","open","hdfs,","sahilTakiar","2019-06-12T23:46:41Z","2022-02-02T01:13:30Z"
"","1368","HADOOP-16536. Backport HADOOP-15273 to branch-2","[HADOOP-16536](https://jira.apache.org/jira/browse/HADOOP-16536) [HADOOP-15273](https://jira.apache.org/jira/browse/HADOOP-15273)  this PR is to backport HADOOP-15273 first. Once it's merged, I'll submit another one for HADOOP-16158.","closed","","kai33","2019-08-28T15:56:49Z","2019-12-09T19:40:13Z"
"","983","HADOOP-16379: S3AInputStream#unbuffer should merge input stream stats into fs-wide stats","[HADOOP-16379: S3AInputStream#unbuffer should merge input stream stats into fs-wide stats](https://issues.apache.org/jira/browse/HADOOP-16379) * Adds a new method to `InputStreamStatistics` called `merge` which allows users to periodically merge the stats into the fs-wide stats * Added new unit tests to validate the calling `unbuffer` merges the stream stats into the fs-wide stats  Testing: * Ran S3A tests against US East (N. Virginia)","closed","","sahilTakiar","2019-06-18T03:27:47Z","2019-06-20T08:42:53Z"
"","970","HADOOP-16371: Option to disable GCM for SSL connections when running on Java 8","[HADOOP-16371: Option to disable GCM for SSL connections when running on Java 8](https://issues.apache.org/jira/browse/HADOOP-16371)  Changes: * Patch is based on the merged patch from HADOOP-16050 * Decided a better name for `SSLSocketFactoryEx` would be `DelegatingSSLSocketFactory` because the class is not OpenSSL specific (e.g. it is capable of just delegating to the JSSE) * Add a bunch of code comments to `DelegatingSSLSocketFactory` * Documented `fs.s3a.ssl.channel.mode` in `performance.md` and `core-default.xml` * If a user tries to configure OpenSSL as the mode via `fs.s3a.ssl.channel.mode` an `UnsupportedOperationException` is thrown.  Testing Done: * Ran all S3 tests `mvn verify` and S3 scale tests `mvn verify -Dparallel-tests -Dscale -DtestsThreadCount=16` (did not have S3Guard or kms tests setup) * Ran `TestDelegatingSSLSocketFactory` on Ubuntu and OSX with `-Pnative` and confirmed the test passes on both systems (on OSX it is skipped, on Ubuntu it actually runs) * Ran the ABFS tests against ""East US 2"" and the only failure was `ITestGetNameSpaceEnabled.testNonXNSAccount` (known issue) * Ran `mvn package -Pdist -DskipTests -Dmaven.javadoc.skip=true -DskipShade`, un-tarred `hadoop-dist/target/hadoop-3.3.0-SNAPSHOT.tar.gz` and ran `./bin/hadoop fs -ls s3a://[my-bucket-name]/` successfully and that I could upload and read a file to S3 using the CLI without the wildlfy jar on the classpath","closed","","sahilTakiar","2019-06-14T18:06:08Z","2019-09-17T10:33:40Z"
"","864","HADOOP-16334. Fix yetus-wrapper not working when HADOOP_YETUS_VERSION greater or equal than 0.9.0","[HADOOP-16334](https://issues.apache.org/jira/browse/HADOOP-16334)","closed","","jiwq","2019-05-28T14:30:10Z","2019-05-30T07:33:33Z"
"","796","HADOOP-16294: Enable access to input options by DistCp subclasses","[HADOOP-16294](https://issues.apache.org/jira/browse/HADOOP-16294)  Adding a protected-scope getter for the DistCpOptions, so that a subclass does not need to save its own copy of the inputOptions supplied to its constructor, if it wishes to override the createInputFileListing method with logic similar to the original implementation, i.e. calling CopyListing#buildListing with a path and input options.","closed","enhancement,","noslowerdna","2019-05-06T13:38:35Z","2019-05-16T14:14:01Z"
"","919","HADOOP-16158. DistCp to support checksum validation when copy blocks in parallel","[HADOOP-16158](https://issues.apache.org/jira/browse/HADOOP-16158)  Copying blocks in parallel (enabled when blocks per chunk > 0) is a great DistCp improvement that can hugely speed up copying big files.  But its checksum validation is skipped, e.g. in `RetriableFileCopyCommand.java`  ``` // isSplit() here is introduced by HADOOP-11794 and  // used to indicate if the source data to copy is only a chunk of it  // (consists of one or more blocks, not all). if (!source.isSplit()) {   compareCheckSums(sourceFS, source.getPath(), sourceChecksum,       targetFS, targetPath); } ```  and this could result in checksum/data mismatch without notifying developers/users (e.g. HADOOP-16049). I'd like to provide a patch to add the checksum validation.","closed","","kai33","2019-06-06T15:47:00Z","2019-08-19T01:46:32Z"
"","1204","HDDS-1768. Audit xxxAcl methods in OzoneManager","@xiaoyuyao , @ajayydv - Request you to please review this PR. Thank you.","closed","ozone,","dineshchitlangia","2019-08-01T05:54:46Z","2019-08-15T19:50:02Z"
"","1203","HDDS-1768. Audit xxxAcl methods in OzoneManager","@xiaoyuyao , @ajayydv - Request you to please review this PR. Thank you.","closed","","dchitlangia","2019-08-01T05:52:26Z","2019-08-01T05:53:19Z"
"","1146","HDDS-1366. Add ability in Recon to track the number of small files in an Ozone Cluster","@swagle @avijayanhwx","closed","ozone,","shwetayakkali","2019-07-23T19:25:56Z","2019-08-10T17:14:56Z"
"","1584","HDDS-2237. KeyDeletingService throws NPE if it's started too early","1. OzoneManager starts KeyManager  2. KeyManager starts KeyDeletingService  3. KeyDeletingService uses OzoneManager.isLeader()  4. OzoneManager.isLeader() uses omRatisServer  5. omRatisServer can be null (bumm)     Now the initialization order in OzoneManager:     new KeymanagerServer() *Includes start()!!!!*  omRatisServer initialization  start() (includes KeyManager.start())     The solution seems to be easy: start the key manager only from the OzoneManager.start() and not from the OzoneManager.instantiateServices()  See: https://issues.apache.org/jira/browse/HDDS-2237","closed","ozone,","elek","2019-10-03T15:19:03Z","2019-10-04T16:49:14Z"
"","1601","HADOOP-16635. S3A innerGetFileStatus scans for directories-only still does a HEAD.","1. Make sure the probe set is passed down. 2. check for Head probe wraps only HEAD request.  Change-Id: I7664a80da53f85c42c319cd6b56b3d6366e09fc6","closed","","steveloughran","2019-10-04T20:34:07Z","2021-10-15T19:48:03Z"
"","810","HDDS-1512. Implement DoubleBuffer in OzoneManager.","1. In this Jira added double buffer implementation. (Not integrated to OM, this will be done in further jira's) 2. Added a few response classes to give an idea, how this will be integrated with OM.","closed","ozone,","bharatviswa504","2019-05-09T20:44:25Z","2019-05-24T18:00:19Z"
"","900","HDDS-1510. Classpath files are deployed to the maven repository as pom/jar files","1. Classpath files are plain text files which are generatede for each ozone projects. Classpath files are used to defined the classpath of a module (om, scm, etc) based on the maven classpath.  Example classpath file:  {code} classpath=$HDDS_LIB_JARS_DIR/kerb-simplekdc-1.0.1.jar:$HDDS_LIB_JARS_DIR/hk2-utils-2.5.0.jar:$HDDS_LIB_JARS_DIR/jackson-core-2.9.5.jar:$HDDS_LIB_JARS_DIR/ratis-netty-0.4.0-fe2b15d-SNAPSHOT.jar:$HDDS_LIB_JARS_DIR/protobuf-java-2.5.0.jar:...  {code}  Classpath files are maven artifacts and copied to share/ozone/classpath in the distribution  2. 0.4.0 was the first release when we deployed the artifacts to the apache nexus. [~ajayydv] reported the problem that the staging repository can't be closed: INFRA-18344  It turned out that the classpath files are uploaded with jar extension to the repository. We deleted all the classpath files manually and the repository became closable.  To avoid similar issues we need to fix this problem and make sure that the classpath files are not uploaded to the repository during a 'mvn deploy' or uploaded but with a good extension.  ps: I don't know the exact solution yet, but I can imagine that bumping the version of maven deploy plugin can help. Seems to be a bug in the plugin.  ps2: This is blocker as we need to fix it before the next release  See: https://issues.apache.org/jira/browse/HDDS-1510","closed","ozone,","elek","2019-06-04T08:24:16Z","2019-06-04T17:38:38Z"
"","1491","HDDS-2161. Create RepeatedKeyInfo structure to be saved in deletedTable","/label ozone","closed","ozone,","dineshchitlangia","2019-09-20T22:07:08Z","2019-09-23T20:22:45Z"
"","1233","HDDS-1915. Remove hadoop script from ozone distribution","/bin/hadoop script is included in the ozone distribution even if we a dedicated /bin/ozone  [~arp] reported that it can be confusing, for example ""hadoop classpath"" returns with a bad classpath (ozone classpath ) should be used instead.  To avoid such confusions I suggest to remove the hadoop script from distribution as ozone script already provides all the functionalities.  It also helps as to reduce the dependencies between hadoop 3.2-SNAPSHOT and ozone as we use the snapshot hadoop script as of now.  See: https://issues.apache.org/jira/browse/HDDS-1915","closed","ozone,","elek","2019-08-06T08:11:04Z","2019-08-14T05:23:07Z"
"","806","HDDS-1224. Restructure code to validate the response from server in the Read path",".","closed","ozone,","bshashikant","2019-05-09T13:55:10Z","2019-06-04T17:37:03Z"
"","807","HADOOP-16085 S3Guard versioning (stevel patch 002)","-move CopyOutcome into fs.s3a.impl package -add new (failing) test for directory renaming where one of the files underneath is eventually consistent. -pull out commonanity from test methods (spyOnFilesystem(), expectReadFailure()) -intercept() calls provide details on failure, primarily just by returning the result of the operation expected to fail. -ChangeDetectionPolicy-raised exceptions on copy failures don't include position any more -cache/restore metastore so even on test failures mockito is involved on teardown","closed","","steveloughran","2019-05-09T16:59:42Z","2019-05-16T11:57:01Z"
"","1246","HADOOP-16499. S3A retry policy to be exponential","-exponential retry policy used -retry interval = 1s -retry attempts = 8 -docs updated  tested s3 ireland  Change-Id: I48b17af34a50b7291f2c360ee74dbce7540556b4","closed","fs/s3,","steveloughran","2019-08-07T16:16:03Z","2021-10-15T19:50:52Z"
"","1619","HADOOP-16478. S3Guard bucket-info fails if the caller lacks s3:GetBucketLocation","-Catch and downgrade to info -add to javadocs -review all other uses -test in ITestAssumeRole; needs to open up a bit more of the tool for this.  ----  Tested s3 ireland. initially tested without the downgrade, to verify the test created the failure mode.  It did:  ``` [ERROR] testBucketLocationForbidden(org.apache.hadoop.fs.s3a.auth.ITestAssumeRole)  Time elapsed: 3.957 s","closed","","steveloughran","2019-10-08T16:15:45Z","2021-10-15T19:42:16Z"
"","971","HADOOP-16376: Override access() to no-up","- Gen1 driver override` FileSystem.access()` and forward it to storage service, but ABFS doesn't have this and is having some hive permission issue. As a short term fix, ABFS could override this to be a no-op.","closed","","DadanielZ","2019-06-14T19:42:13Z","2019-07-10T17:23:21Z"
"","1577","HDDS-2200 : Recon does not handle the NULL snapshot from OM DB cleanly.","- Fix NULL OM snapshot handling in Recon. - Bootstrap Recon startup with last known OM snapshot DB and Recon container DB. - Add more useful log lines.","closed","ozone,","avijayanhwx","2019-10-02T19:52:15Z","2019-10-03T23:24:49Z"
"","700","HDDS-1396 : Recon start fails due to changes in Aggregate Schema definition.","- bin/ozone looks for hadoop-ozone-recon-*.jar as the main JAR for Recon Server. Since the codegen jar (hadoop-ozone-recon-codegen) also satisfies the above, it gets picked up as the main JAR and recon start fails due to CNF issue. To fix this, we have changed artifact name of codegen module such that it does not get picked up as Application JAR for recon.  - Fixed guice issue for DataSourceConfiguration which was due to double binding of the same class.  - Downgraded guice version to 4.0, to keep it compatible to dependencies.","closed","ozone,","avijayanhwx","2019-04-05T07:47:11Z","2019-04-15T19:58:07Z"
"","776","HADOOP-16242. ABFS: add bufferpool to AbfsOutputStream","- Added bufferpool to AbfsOutPutStream to improve memory usage. - Verified performance change, results are attached in HADOOP-16242 jira.","closed","","DadanielZ","2019-04-26T19:15:01Z","2019-04-29T12:28:29Z"
"","787","HADOOP-16251. ABFS: add FSMainOperationsBaseTest","- Addded tests which are extended from FSMainOperationsBaseTest","closed","fs/azure,","DadanielZ","2019-04-30T19:42:10Z","2019-06-03T08:32:35Z"
"","768","HADOOP-16269. ABFS: add listFileStatus with StartFrom.","- Add support to list entries in a path from an entry name in lexical order(Azure Storage Service returns the entries in lexical order) - This support is added to AzureBlobFileSystemStore and won't be exposed to FS level api.","closed","fs/azure,","DadanielZ","2019-04-24T16:59:26Z","2019-05-08T16:22:51Z"
"","785","HDDS-1464. Client should have different retry policies for different exceptions.","+ @hanishakoneru   KeyOutputStream correctly does the handleWrite() from inside the retry so only the correct setting for the fixed delay between retries needs to be set appropriately.","closed","ozone,","swagle","2019-04-29T21:24:35Z","2019-05-05T16:21:16Z"
"","1602","HDDS-2252. Enable gdpr robot test in daily build","**What changes were proposed in this pull request?** Updated test.sh script to include gdpr.robot test so that it gets triggered as part of daily build.  **Link to Apache JIRA** https://issues.apache.org/jira/browse/HDDS-2252  **How was this patch tested?** Started Docker cd ~/ozone-SNAPSHOT/compose/ozone ./test.sh","closed","ozone,","dineshchitlangia","2019-10-04T20:36:28Z","2019-10-07T14:32:38Z"
"","1481","HADOOP-16587: Made auth endpoints configurable for MSI and refresh token flows","**Driver test results using a Namespace enabled account in Central India:**  mvn -T 1C -Dparallel-tests=abfs -Dscale -DtestsThreadCount=8 clean verify  **With configs** ```   	fs.azure.account.oauth2.msi.endpoint 	http://169.254.169.254/metadata/identity/oauth2/token   	fs.azure.account.oauth2.refresh.token.endpoint 	https://login.microsoftonline.com/Common/oauth2/token  ```  Tests run: 42, Failures: 0, Errors: 0, Skipped: 0 Tests run: 393, Failures: 0, Errors: 1, Skipped: 21 Tests run: 190, Failures: 0, Errors: 0, Skipped: 15  **Without specifying the configs (with default values)**  Tests run: 42, Failures: 0, Errors: 0, Skipped: 0 Tests run: 392, Failures: 0, Errors: 1, Skipped: 21 Tests run: 190, Failures: 0, Errors: 0, Skipped: 15","closed","","bilaharith","2019-09-20T09:23:28Z","2019-10-07T12:09:32Z"
"","846","HDDS-1555. Disable install snapshot for ContainerStateMachine.","* pom change is needed to get the latest RATIS master and get RATIS-564 changes.  - The configuration installSnapshotEnabled = false actually controls whether only a notification is sent to the follower and not the snapshot chunk, I guess this flag is not correctly named and I can address that in a later version of the patch.  - The fact that the snapshot contents cannot be used to actually catch up the follower, it is the reason to initiate close pipeline and not install the snapshot. The follower will basically never be able to catch up.  - The Replication monitor after the close will take care of replication of closed containers.","closed","ozone,","swagle","2019-05-23T03:11:49Z","2019-08-21T07:49:18Z"
"","880","HDDS-1617. Restructure the code layout for Ozone Manager","* Move Volume Management to core.volume under Ozone Manager.     * Move Bucket Management to core.bucket package under Ozone Manager.     * Move Key Management functions to core.Keys package.     * Move S3 and FS to Ozone Manager core package.     * Move Metrics, discovery, persistence, security to its own package under ozone manager.     * Rename web to commandLine, since the Rest interface is not used any more since we have S3.","closed","ozone,","anuengineer","2019-05-31T17:45:42Z","2019-06-25T05:09:09Z"
"","1210","HADOOP-16477. S3 delegation token tests fail if fs.s3a.encryption.key set","* Delegation Token In FileSystem tests unset more options and compare propagation of entries * Added a spurious ITestRoleDelegationInFilesystem override so I can debug things better. * SSEC tests fail too...need to understand that  It looks like the AWS Permissions Policy created for the Role DT (and passed into AssumeRole) isn't asking for the right KMS permissions for a PUT request to work. At least, it's mkdirs that fails first...we should verify read of existing data too). I don't currently understand what is wrong with the permissions I am asking for.   *Or maybe it's actually the role which is blocked?* That would explain things -the code is valid, but the role is too restricted. Needs more investigation, and no doubt some more entries in the troubleshooting docs  Change-Id: Icbd418f9aa6c72312d39b4d94a1f2a2854fca059","closed","work in progress,","steveloughran","2019-08-01T18:33:46Z","2021-10-15T19:42:07Z"
"","1185","HADOOP-16470 IAMInstanceCredentialsProvider to use EC2ContainerCredentialsProviderWrapper","* contains HADOOP-16471 -restoration of SharedInstanceProfileCredentialsProvider  Change-Id: I6ec2c3585ad1966d6664465a2b3fbfa25fbda46f","closed","fs/s3,","steveloughran","2019-07-30T14:05:26Z","2019-08-28T14:21:28Z"
"","1257","HDDS-1913. Fix OzoneBucket and RpcClient APIS for acl.","(cherry picked from commit b60d93b8b500f0ba97c027125401368d22028822)","closed","ozone,","bharatviswa504","2019-08-08T20:08:26Z","2019-08-16T23:39:50Z"
"","834","HDDS-1065. OM and DN should persist SCM certificate as the trust root. Contributed by Ajay Kumar.","(cherry picked from commit 7254bf06e66deaf4dd9d00e65fc8894bd869a797)","closed","ozone,","ajayydv","2019-05-20T16:36:37Z","2019-05-22T18:47:33Z"
"","1275","HDDS-1911. Support Prefix ACL operations for OM HA.","(cherry picked from commit 3906b7d233cd276901fc86b24d7d26d676ff985b)","closed","ozone,","bharatviswa504","2019-08-11T03:16:29Z","2019-08-16T22:11:12Z"
"","1418","HDDS-2089: Add createPipeline CLI.","#HDDS-2089 Add createPipeline for ozone scmcli","closed","ozone,","timmylicheng","2019-09-10T03:43:43Z","2019-09-16T02:29:13Z"
"","1366","HDDS-1577. Add default pipeline placement policy implementation.","#HDDS-1577 Add pipeline placement policy","closed","ozone,","timmylicheng","2019-08-28T12:22:41Z","2019-09-05T08:51:04Z"
"","1395","HDDS-1571. Refactor ContainerPlacementPolicy.","#HDDS-1571 Refactor ContainerPlacementPolicy to Placement Policy for future exploit.","closed","ozone,","timmylicheng","2019-09-03T08:39:58Z","2019-09-11T07:14:43Z"
"","1431","HDDS-1569 Support creating multiple pipelines with same datanode","#HDDS-1569 Use PipelinePlacementPolicy to support creating multiple pipelines with same datanode","closed","ozone,","timmylicheng","2019-09-12T09:45:01Z","2019-11-04T03:58:49Z"
"","1662","YARN-9913. In YARN ui2 attempt container tab, The Container's ElapsedTime of  running Application is incorrect when the browser and the yarn server are in different timezons.","### what is the problem In YARN ui2 attempt container tab, The Container's ElapsedTime of running Application is incorrect when the browser and the yarn server are in different timezons.  ### how to fix Use the RestAPI's returnValue ElapsedTime as the container‘s ElapsedTime. ( Instead of using Date.now() of the browser)","open","","cjn082030","2019-10-18T08:16:08Z","2022-01-09T14:30:59Z"
"","1536","HDDS-2164 : om.db.checkpoints is getting filling up fast.","### What changes were proposed in this pull request?  - Fixed the underlying issue which was not causing the OM DB checkpoints to be cleaned up on OM host whenever recon or some other client requests DB checkpoint.  - Changed the 2 step process in the OM DB checkpoint servlet (Creating a tar file for OM DB + Writing to outputstream) to a single step process (Writing the compressed tar file as a stream directly to output stream).  ### How was this patch tested? Manually tested on live cluster with a Ozone Manager instance and Recon. Verified that the OM DB checkpoints that are being generated in OM host are being cleaned up irrespective of whether the download to Recon succeeds or not.   ### Apache JIRA https://issues.apache.org/jira/browse/HDDS-2164","closed","ozone,","avijayanhwx","2019-09-27T05:59:19Z","2019-10-04T19:44:22Z"
"","1604","HDDS-2254. Fix flaky unit test TestContainerStateMachine#testRatisSnapshotRetention","## What changes were proposed in this pull request? On locally trying out repeated runs of the unit test, the unit test failed intermittently while asserting ""Null"" value for CSM snapshot. This assertion is not valid when the other unit test in the class executes before and creates keys in the cluster/container. Removed the null check since it does not test the core functionality of snapshot retention.  https://issues.apache.org/jira/browse/HDDS-2254  ## How was this patch tested? Ran the unit tests a few hundred times in IDE in different order.","closed","ozone,","avijayanhwx","2019-10-05T15:56:33Z","2019-10-15T20:19:56Z"
"","1515","HDDS-2171. Dangling links in test report due to incompatible realpath","## What changes were proposed in this pull request?  Workaround for BusyBox's simplistic `realpath` command, which doesn't support `--relative-to` option.  https://issues.apache.org/jira/browse/HDDS-2171  ## How was this patch tested?  Created local `realpath` implementation with behavior similar to BusyBox's, and ran `_mvn_unit_report.sh`.  Also tried it with regular `realpath`.","closed","ozone,","adoroszlai","2019-09-24T17:28:04Z","2019-09-25T10:06:59Z"
"","1254","HDDS-1934. TestSecureOzoneCluster may fail due to port conflict","## What changes were proposed in this pull request?  Use random port for SCM for the test cases where it is started in `TestSecureOzoneCluster`.  https://issues.apache.org/jira/browse/HDDS-1934  ## How was this patch tested?  ``` $ cd hadoop-ozone/dist/target/ozone-0.5.0-SNAPSHOT/compose/ozone $ docker-compose up -d $ cd - $ mvn -Phdds -pl :hadoop-ozone-integration-test test -Dtest=TestSecureOzoneCluster ... [INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 37.32 s - in org.apache.hadoop.ozone.TestSecureOzoneCluster ```","closed","ozone,","adoroszlai","2019-08-08T10:10:31Z","2019-08-09T06:20:33Z"
"","1327","HDDS-1999. Basic acceptance test and SCM/OM web UI broken by Bootstrap upgrade","## What changes were proposed in this pull request?  Update bootstrap/jquery version references in SCM/OM/S3G and in acceptance test.  https://issues.apache.org/jira/browse/HDDS-1999  ## How was this patch tested?  Ran `basic.robot` in `ozones3` compose folder.  Checked SCM/OM/S3G web UI visually.","closed","ozone,","adoroszlai","2019-08-21T13:16:55Z","2019-08-21T19:20:07Z"
"","1293","HDDS-1965. Compile error due to leftover ScmBlockLocationTestIngClient file","## What changes were proposed in this pull request?  Typo in class name of `ScmBlockLocationTestingClient` was fixed in 5a248de5115, but the original file is still present in the repo, causing compile error.  https://issues.apache.org/jira/browse/HDDS-1965","closed","ozone,","adoroszlai","2019-08-14T11:13:53Z","2019-08-14T13:26:13Z"
"","1462","HDDS-2141. Missing total number of operations","## What changes were proposed in this pull request?  Sum request counts and use it as fallback in case explicit ""Ops"" metric is not available.  https://issues.apache.org/jira/browse/HDDS-2141  ## How was this patch tested?  Ran `ozonefs` robot test, checked OM metrics page.","closed","ozone,","adoroszlai","2019-09-17T14:44:13Z","2019-09-19T12:16:54Z"
"","1622","HDDS-1228. Chunk Scanner Checkpoints","## What changes were proposed in this pull request?  Save timestamp of last successful data scan for each container (in the `.container` file).  After a datanode restart, resume data scanning with the container that was least recently scanned.  Newly closed containers have no timestamp and are thus scanned first during the next iteration.  This will be changed in [HDDS-1369](https://issues.apache.org/jira/browse/HDDS-1369), which proposes to scan newly closed containers immediately.  https://issues.apache.org/jira/browse/HDDS-1228  ## How was this patch tested?  Created and closed containers.  Restarted datanode while scanning was in progress.  Verified that after the restart, scanner resumed from the container where it was interrupted.  ``` datanode_1  | STARTUP_MSG: Starting HddsDatanodeService datanode_1  | 2019-10-08 19:37:07 DEBUG ContainerDataScanner:148 - Scanning container 1, last scanned never datanode_1  | 2019-10-08 19:37:07 DEBUG ContainerDataScanner:155 - Completed scan of container 1 at 2019-10-08T19:37:07.570Z datanode_1  | 2019-10-08 19:37:07 INFO  ContainerDataScanner:122 - Completed an iteration of container data scrubber in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 0 datanode_1  | 2019-10-08 19:37:17 DEBUG ContainerDataScanner:148 - Scanning container 2, last scanned never datanode_1  | 2019-10-08 19:38:57 DEBUG ContainerDataScanner:155 - Completed scan of container 2 at 2019-10-08T19:38:57.402Z datanode_1  | 2019-10-08 19:38:57 DEBUG ContainerDataScanner:148 - Scanning container 1, last scanned at 2019-10-08T19:37:07.570Z datanode_1  | 2019-10-08 19:38:57 DEBUG ContainerDataScanner:155 - Completed scan of container 1 at 2019-10-08T19:38:57.443Z datanode_1  | 2019-10-08 19:38:57 INFO  ContainerDataScanner:122 - Completed an iteration of container data scrubber in 1 minutes. Number of iterations (since the data-node restart) : 2, Number of containers scanned in this iteration : 2, Number of unhealthy containers found in this iteration : 0 datanode_1  | 2019-10-08 19:38:57 DEBUG ContainerDataScanner:148 - Scanning container 3, last scanned never datanode_1  | 2019-10-08 19:39:02 DEBUG ContainerDataScanner:155 - Completed scan of container 3 at 2019-10-08T19:39:02.402Z datanode_1  | 2019-10-08 19:39:02 DEBUG ContainerDataScanner:148 - Scanning container 4, last scanned never datanode_1  | 2019-10-08 19:39:02 DEBUG ContainerDataScanner:155 - Completed scan of container 4 at 2019-10-08T19:39:02.430Z datanode_1  | 2019-10-08 19:39:02 DEBUG ContainerDataScanner:148 - Scanning container 5, last scanned never datanode_1  | 2019-10-08 19:39:11 ERROR HddsDatanodeService:75 - RECEIVED SIGNAL 15: SIGTERM datanode_1  | STARTUP_MSG: Starting HddsDatanodeService datanode_1  | 2019-10-08 19:39:22 DEBUG ContainerDataScanner:148 - Scanning container 5, last scanned never datanode_1  | 2019-10-08 19:40:18 DEBUG ContainerDataScanner:155 - Completed scan of container 5 at 2019-10-08T19:40:18.268Z datanode_1  | 2019-10-08 19:40:18 DEBUG ContainerDataScanner:148 - Scanning container 6, last scanned never datanode_1  | 2019-10-08 19:40:31 DEBUG ContainerDataScanner:155 - Completed scan of container 6 at 2019-10-08T19:40:31.735Z datanode_1  | 2019-10-08 19:40:31 DEBUG ContainerDataScanner:148 - Scanning container 2, last scanned at 2019-10-08T19:38:57.402Z datanode_1  | 2019-10-08 19:42:12 DEBUG ContainerDataScanner:155 - Completed scan of container 2 at 2019-10-08T19:42:12.128Z datanode_1  | 2019-10-08 19:42:12 DEBUG ContainerDataScanner:148 - Scanning container 1, last scanned at 2019-10-08T19:38:57.443Z datanode_1  | 2019-10-08 19:42:12 DEBUG ContainerDataScanner:155 - Completed scan of container 1 at 2019-10-08T19:42:12.140Z datanode_1  | 2019-10-08 19:42:12 DEBUG ContainerDataScanner:148 - Scanning container 3, last scanned at 2019-10-08T19:39:02.402Z datanode_1  | 2019-10-08 19:42:16 DEBUG ContainerDataScanner:155 - Completed scan of container 3 at 2019-10-08T19:42:16.629Z datanode_1  | 2019-10-08 19:42:16 DEBUG ContainerDataScanner:148 - Scanning container 4, last scanned at 2019-10-08T19:39:02.430Z datanode_1  | 2019-10-08 19:42:16 DEBUG ContainerDataScanner:155 - Completed scan of container 4 at 2019-10-08T19:42:16.669Z datanode_1  | 2019-10-08 19:42:16 INFO  ContainerDataScanner:122 - Completed an iteration of container data scrubber in 2 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 6, Number of unhealthy containers found in this iteration : 0 ```  Also tested upgrade from Ozone 0.4.0.  (Downgrade does not work, see [HDDS-2268](https://issues.apache.org/jira/browse/HDDS-2268).)","closed","ozone,","adoroszlai","2019-10-08T20:52:49Z","2019-10-14T19:32:26Z"
"","1357","HDDS-2042. Avoid log on console with Ozone shell","## What changes were proposed in this pull request?  Sample Docker Compose-based clusters are currently [configured](https://github.com/apache/hadoop/blob/3329257d99d2808e66ae6c2fe87a9c4f8877026f/hadoop-ozone/dist/src/main/compose/ozone/docker-config#L32-L33) to log almost everything to the console.  This is useful because logs can be accessed via `docker logs` or `docker-compose logs`.  Further, [default logs settings](https://github.com/apache/hadoop/blob/3329257d99d2808e66ae6c2fe87a9c4f8877026f/hadoop-ozone/dist/src/main/conf/log4j.properties#L137-L138) for non-Docker Compose clusters also direct INFO and higher level messages to the console.  However, it does not work well with interactive clients, eg. `ozone sh`, since regular console output and log messages are mixed.  Previously there [were](https://issues.apache.org/jira/browse/HDDS-1489) [attempts](https://issues.apache.org/jira/browse/HDDS-465) to work around this by setting specific class log levels to `WARN` or `ERROR`.  This approach has two problems: 1. it applies to Ozone server processes, too 2. new INFO or higher level messages may be introduced any time (eg. MetricsSystem startup)  This pull request proposes to collect logs for `ozone` subcommands `sh` and `freon` to files instead of the console.  It eliminates the need for per-class log level settings (though current ones are kept).  https://issues.apache.org/jira/browse/HDDS-2042  ## How was this patch tested?  Tested commands in sample docker cluster.  Output is clean (except pesky warning (omitted here) about illegal access for key operations).  ``` $ cd hadoop-ozone/dist/target/ozone-0.5.0-SNAPSHOT/compose/ozones3 $ docker-compose exec scm bash bash-4.2$ ozone sh volume create vol1 bash-4.2$ ozone sh bucket create vol1/buck1 bash-4.2$ ozone sh key put vol1/buck1/key1 /etc/passwd ```  Verified that log file contains the messages previously sent to console:  ``` bash-4.2$ tail /var/log/hadoop/ozone-shell.log 2019-08-27 14:45:02,695 [main] INFO  RpcClient:293 - Creating Volume: vol1, with hadoop as owner. 2019-08-27 14:45:13,099 [main] INFO  RpcClient:432 - Creating Bucket: vol1/buck1, with Versioning false and Storage Type set to DISK and Encryption set to false 2019-08-27 14:45:24,011 [main] INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties 2019-08-27 14:45:24,160 [main] INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s). 2019-08-27 14:45:24,160 [main] INFO  MetricsSystemImpl:191 - XceiverClientMetrics metrics system started ```  Verbose mode still works:  ``` bash-4.2$ ozone sh --verbose key put vol1/buck1/key2 /etc/passwd Volume Name : vol1 Bucket Name : buck1 Key Name : key2 File Hash : b01f053617ddfeb782a3e757d9c08912 ```  Freon:  ``` bash-4.2$ ozone freon rk --numOfVolumes=1 --numOfBuckets=1 --numOfKeys=20 --numOfThreads=1   100.00% |?????????????????????????????????????????????????????????????????????????????????????????????????????|  20/20 Time: 0:00:03  *************************************************** Status: Success Git Base Revision: e97acb3bd8f3befd27418996fa5d4b50bf2e17bf Number of Volumes created: 1 Number of Buckets created: 1 Number of Keys added: 20 Ratis replication factor: ONE Ratis replication type: STAND_ALONE Average Time spent in volume creation: 00:00:00,080 Average Time spent in bucket creation: 00:00:00,013 Average Time spent in key creation: 00:00:00,234 Average Time spent in key write: 00:00:02,310 Total bytes written: 204800 Total Execution time: 00:00:06,284 *************************************************** ```","closed","ozone,","adoroszlai","2019-08-27T16:36:31Z","2019-08-31T05:40:41Z"
"","1236","HDDS-1918. hadoop-ozone-tools has integration tests run as unit","## What changes were proposed in this pull request?  Run `hadoop-ozone-tools` tests as part of `integration.sh`, not `unit.sh`.  https://issues.apache.org/jira/browse/HDDS-1918  ## How was this patch tested?  ``` $ ./hadoop-ozone/dev-support/checks/unit.sh ... (no Ozone Tools here) ... $ ./hadoop-ozone/dev-support/checks/integration.sh ... [INFO] Reactor Build Order: [INFO] [INFO] Apache Hadoop Ozone Integration Tests                              [jar] [INFO] Apache Hadoop Ozone FileSystem                                     [jar] [INFO] Apache Hadoop Ozone Tools                                          [jar] ... ```","closed","ozone,","adoroszlai","2019-08-06T14:55:44Z","2019-08-07T06:26:40Z"
"","1575","HDDS-2231. test-single.sh cannot copy results","## What changes were proposed in this pull request?  Restore pre-[HDDS-2185](https://issues.apache.org/jira/browse/HDDS-2185) behavior of `test-single.sh` by explicitly creating `result` directory.  https://issues.apache.org/jira/browse/HDDS-2231  ## How was this patch tested?  ``` $ cd hadoop-ozone/dist/target/ozone-0.5.0-SNAPSHOT/compose/ozone $ docker-compose up -d --scale datanode=3 $ ../test-single.sh scm basic/basic.robot $ ls result robot-ozone-ozone-basic-scm.xml ```","closed","ozone,","adoroszlai","2019-10-02T10:39:58Z","2019-10-04T03:53:34Z"
"","1513","HDDS-2149. Replace FindBugs with SpotBugs","## What changes were proposed in this pull request?  Replace FindBugs with [SpotBugs](https://spotbugs.github.io), as FindBugs is no longer maintained.  https://issues.apache.org/jira/browse/HDDS-2149  ## How was this patch tested?  ``` $ mvn -f pom.ozone.xml clean $ hadoop-ozone/dev-support/checks/findbugs.sh ... [INFO] BUILD SUCCESS ```  Also verified that it catches violations introduced temporarily:  ``` ... [INFO] Build failures were ignored. H C Eq: org.apache.hadoop.hdds.HddsUtils.equals(Object) always returns false  At HddsUtils.java:[line 98] M D RV: Return value of Object.toString() ignored, but method has no side effect  At HddsUtils.java:[line 94] ```","closed","ozone,","adoroszlai","2019-09-24T11:16:22Z","2019-09-27T06:01:59Z"
"","1460","HDDS-2136. OM block allocation metric not paired with its failures","## What changes were proposed in this pull request?  Rename metric member variables for block allocation count and its failures to have the same prefix to ensure that they appear in the same chart.  I think `BlockAllocations` is both a bit simpler than `BlockAllocateCalls` and more consistent with other metrics.  https://issues.apache.org/jira/browse/HDDS-2136  ## How was this patch tested?  Ran acceptance tests, checked OM Metrics web page.","closed","ozone,","adoroszlai","2019-09-17T11:05:28Z","2019-09-18T08:25:12Z"
"","1191","HDDS-1876. hadoop27 acceptance test cannot be run","## What changes were proposed in this pull request?  Rename leftover file that was missed in cleanup (a42d4b1082c) after merge to `ozone-0.4.1` (fc3bfdc5352).  https://issues.apache.org/jira/browse/HDDS-1876  ## How was this patch tested?  ``` $ cd hadoop-ozone/dist/target/ozone-0.4.1-SNAPSHOT/compose/ozone-mr/hadoop27 $ ./test.sh ... hadoop27-createmrenv :: Create directories required for MR test       | PASS | ... hadoop27-hadoopo3fs :: Test ozone fs with hadoopfs                    | PASS | ... hadoop27-mapreduce :: Execute MR jobs                                 | PASS | ... ```","closed","ozone,","adoroszlai","2019-07-31T07:33:25Z","2019-07-31T14:10:02Z"
"","1367","HDDS-1941. Unused executor in SimpleContainerDownloader","## What changes were proposed in this pull request?  Remove unused executor from `SimpleContainerDownloader`.  https://issues.apache.org/jira/browse/HDDS-1941","closed","ozone,","adoroszlai","2019-08-28T15:10:13Z","2019-08-29T06:00:05Z"
"","1250","HDDS-1929. OM started on recon host in ozonesecure compose","## What changes were proposed in this pull request?  Remove unnecessary OM initialization for `recon` host.  https://issues.apache.org/jira/browse/HDDS-1929  ## How was this patch tested?  ``` $ cd hadoop-ozone/dist/target/ozone-0.5.0-SNAPSHOT/compose/ozonesecure $ docker-compose up -d --scale datanode=3 $ docker-compose logs -f recon ```","closed","ozone,","adoroszlai","2019-08-07T20:01:47Z","2019-08-14T07:12:53Z"
"","1568","HDDS-2225. SCM fails to start in most unsecure environments due to leftover secure config","## What changes were proposed in this pull request?  Remove unnecessary `spark` container from `ozonesecure-mr` test, since it generates configs into the wrong directory (a mounted one).  These configs are then picked up by other tests and cause failures.  https://issues.apache.org/jira/browse/HDDS-2225  ## How was this patch tested?  Ran `ozonesecure-mr` and `ozone-recon` tests in this order.","closed","ozone,","adoroszlai","2019-10-01T20:41:26Z","2019-10-04T06:58:34Z"
"","1485","HDDS-2157. checkstyle: print filenames relative to project root","## What changes were proposed in this pull request?  Remove project root from filenames in `checkstyle.sh` output.  Also, make script slightly more readable by breaking long sed command.  https://issues.apache.org/jira/browse/HDDS-2157  ## How was this patch tested?  Introduced some checkstyle errors, then ran check:  ```bash $ git revert --no-commit 126ef77a810 $ hadoop-ozone/dev-support/checks/checkstyle.sh ... hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/utils/db/cache/TableCache.java  88: Line is longer than 80 characters (found 91). hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/utils/RocksDBStoreIterator.java  29: Line is longer than 80 characters (found 90).  46: Line is longer than 80 characters (found 105). hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/utils/LevelDBStoreIterator.java  28: Line is longer than 80 characters (found 90). hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/utils/TestMetadataStore.java  124: Line is longer than 80 characters (found 87). hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/transport/server/ratis/ContainerStateMachine.java  451: '}' at column 11 should be alone on a line. hadoop-hdds/client/src/main/java/org/apache/hadoop/hdds/scm/client/HddsClientUtils.java  136: Line is longer than 80 characters (found 89).  144: Line is longer than 80 characters (found 81).  154: Line is longer than 80 characters (found 99). ... ```","closed","ozone,","adoroszlai","2019-09-20T18:52:40Z","2019-09-23T10:01:42Z"
"","1477","HDDS-2151. Ozone client logs the entire request payload at DEBUG level","## What changes were proposed in this pull request?  Remove byte data from container command request before logging it (applicable to `PutSmallFile` and `WriteChunk`).  https://issues.apache.org/jira/browse/HDDS-2151  ## How was this patch tested?  Set root log level to DEBUG in `ozone-shell-log4j.properties`.  Created small and large keys via `ozone sh`.  Verified that `ozone-shell.log` contains detailed request without actual `data`.","closed","ozone,","adoroszlai","2019-09-19T13:09:24Z","2019-09-19T18:02:26Z"
"","1349","HDDS-2026. Overlapping chunk region cannot be read concurrently","## What changes were proposed in this pull request?  Only allow a single read/write operation for the same path in `ChunkUtils`, to avoid `OverlappingFileLockException` due to concurrent reads.  This allows concurrent reads/writes of separate files (as opposed to simply synchronizing the methods).  It might be improved later by storing and reusing the file lock.  Use plain `FileChannel` instead of `AsynchronousFileChannel` for reading, too, since it was used in synchronous fashion (by calling `.get()`) anyway.  https://issues.apache.org/jira/browse/HDDS-2026  ## How was this patch tested?  Added unit test.  Used improved Freon tool from #1341 to perform read of same key from multiple threads (which revealed the bug in the first place).  ``` $ ozone freon ockg -n 1 -p asdf $ ozone sh key list vol1/bucket1 [ {   ""version"" : 0,   ""size"" : 10240,   ""keyName"" : ""asdf/0""   ... } ]  $ ozone freon ocokr -k 'asdf/0' ...          mean rate = 164.39 calls/second                   ...               mean = 53.75 milliseconds             stddev = 42.11 milliseconds             median = 44.05 milliseconds ... Total execution time (sec): 6 Failures: 0 Successful executions: 1000 ```","closed","ozone,","adoroszlai","2019-08-26T12:02:44Z","2019-08-28T04:19:41Z"
"","1248","HDDS-1925. ozonesecure acceptance test broken by HTTP auth requirement","## What changes were proposed in this pull request?  Obtain Kerberos ticket for HTTP before web requests and use it for `curl`.  (Unfortunately it works only on the same host, eg. `scm` cannot make request to `om` using its own HTTP keytab.)  https://issues.apache.org/jira/browse/HDDS-1925  ## How was this patch tested?  Ran both secure and unsecure acceptance tests.  (Some of them timed out locally...)","closed","ozone,","adoroszlai","2019-08-07T18:22:20Z","2019-08-08T05:10:42Z"
"","1120","HDDS-1822. NPE in SCMCommonPolicy.chooseDatanodes","## What changes were proposed in this pull request?  NPE is caused by base `chooseDatanodes` not checking for `excludedNodes` being `null`.  Default placement policy is now random (HDDS-1801), but `TestContainerPlacementFactory#testDefaultPolicy` still reflects rack-aware policy.  Adding the `null` check makes the test fail instead of erroring out with NPE.  Changed the test to only check default policy being returned, not its behavior (since that should be verified in the specific policy's unit test).  https://issues.apache.org/jira/browse/HDDS-1822  ## How was this patch tested?  Unit test.","closed","ozone,","adoroszlai","2019-07-18T13:32:40Z","2019-07-22T07:49:03Z"
"","1282","HDDS-1908. TestMultiBlockWritesWithDnFailures is failing","## What changes were proposed in this pull request?  Multi-block writes tests are failing most of the time because Ratis leader election timeout is about the same length as the client retry timeout (5 times 1 second).  This frequently caused an entire pipeline to be excluded (by `KeyOutputStream.handleException`) just because client gives up before leader is elected.  There are only 6 nodes in TestMultiBlockWritesWithDnFailures test, 2 of which is shut down as part of the test.  Thus, if this happens, subsequent write fails because new block cannot be allocated.  This change decreases leader election timeout and increases client retries.  It is basically an extension of [HDDS-1780](https://issues.apache.org/jira/browse/HDDS-1780).  Additional changes:   * move `testMultiBlockWritesWithIntermittentDnFailures` to `TestMultiBlockWritesWithDnFailures`  * remove unused `maxRetries` member  * call cluster `shutdown()` regardless of test success/failure (see also [HDDS-1949](https://issues.apache.org/jira/browse/HDDS-1949))  https://issues.apache.org/jira/browse/HDDS-1908  ## How was this patch tested?  Ran both test classes 10+ times, without any intermittent failure.  ``` [INFO] Running org.apache.hadoop.ozone.client.rpc.TestFailureHandlingByClient [INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 157.086 s - in org.apache.hadoop.ozone.client.rpc.TestFailureHandlingByClient [INFO] Running org.apache.hadoop.ozone.client.rpc.TestMultiBlockWritesWithDnFailures [INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 75.308 s - in org.apache.hadoop.ozone.client.rpc.TestMultiBlockWritesWithDnFailures ```","closed","ozone,","adoroszlai","2019-08-12T17:42:13Z","2019-08-13T10:30:53Z"
"","1537","HDDS-2187. ozone-mr test fails with No FileSystem for scheme o3fs","## What changes were proposed in this pull request?  MR acceptance tests are [failing](https://github.com/elek/ozone-ci/blob/2f2c99652af6b26a95f08eece9e545f0d72ccf45/trunk/trunk-nightly-20190925-htsvn/acceptance/output.log#L724) at the `Create user dir for hadoop` step of `Create directories required for MR test` suite.  This happens since [HDDS-2101](https://issues.apache.org/jira/browse/HDDS-2101) removed `fs.o3fs.impl` definition from `core-site.xml`, filesystem provider is defined in META-INF of `hadoop-ozone-filesystem-lib-*.jar`.  The problem is that the filesystem jars are not on the classpath for `ozone fs` commands used to create hadoop user dir in the `ozone-mr` env, so the explicit config is needed.  This change adds back the config, but only for scm, not for Hadoop.  It also applies both changes (this fix and the removal per HDDS-2101) to `ozonesecure-mr` env.  It is based on top of #1533 (which should be merged first).  https://issues.apache.org/jira/browse/HDDS-2187  ## How was this patch tested?  Ran all affected acceptance tests locally.  ``` 0 datanode is up and healthy (until now) 3 datanodes are up and registered to the scm ============================================================================== hadoop32-createmrenv :: Create directories required for MR test                ============================================================================== Create test volume, bucket and key                                    | PASS | ------------------------------------------------------------------------------ Create user dir for hadoop                                            | PASS | ------------------------------------------------------------------------------ hadoop32-createmrenv :: Create directories required for MR test       | PASS | 2 critical tests, 2 passed, 0 failed 2 tests total, 2 passed, 0 failed ============================================================================== Output:  /tmp/smoketest/hadoop32/result/robot-hadoop32-hadoop32-createmrenv-scm.xml ============================================================================== hadoop32-hadoopo3fs :: Test ozone fs with hadoopfs                             ============================================================================== Test hadoop dfs                                                       | PASS | ------------------------------------------------------------------------------ hadoop32-hadoopo3fs :: Test ozone fs with hadoopfs                    | PASS | 1 critical test, 1 passed, 0 failed 1 test total, 1 passed, 0 failed ============================================================================== Output:  /tmp/smoketest/hadoop32/result/robot-hadoop32-hadoop32-hadoopo3fs-rm.xml ============================================================================== hadoop32-mapreduce :: Execute MR jobs                                          ============================================================================== Execute PI calculation                                                | PASS | ------------------------------------------------------------------------------ Execute WordCount                                                     | PASS | ------------------------------------------------------------------------------ hadoop32-mapreduce :: Execute MR jobs                                 | PASS | 2 critical tests, 2 passed, 0 failed 2 tests total, 2 passed, 0 failed ============================================================================== Output:  /tmp/smoketest/hadoop32/result/robot-hadoop32-hadoop32-mapreduce-rm.xml Robot framework is not installed, the reports can be generated (sudo pip install robotframework). 0 datanode is up and healthy (until now) 3 datanodes are up and registered to the scm ============================================================================== hadoop31-createmrenv :: Create directories required for MR test                ============================================================================== Create test volume, bucket and key                                    | PASS | ------------------------------------------------------------------------------ Create user dir for hadoop                                            | PASS | ------------------------------------------------------------------------------ hadoop31-createmrenv :: Create directories required for MR test       | PASS | 2 critical tests, 2 passed, 0 failed 2 tests total, 2 passed, 0 failed ============================================================================== Output:  /tmp/smoketest/hadoop31/result/robot-hadoop31-hadoop31-createmrenv-scm.xml fetch http://dl-cdn.alpinelinux.org/alpine/v3.8/main/x86_64/APKINDEX.tar.gz fetch http://dl-cdn.alpinelinux.org/alpine/v3.8/community/x86_64/APKINDEX.tar.gz (1/7) Installing libbz2 (1.0.6-r7) (2/7) Installing libffi (3.2.1-r4) (3/7) Installing gdbm (1.13-r1) (4/7) Installing sqlite-libs (3.25.3-r1) (5/7) Installing python2 (2.7.15-r2) (6/7) Installing py-setuptools (39.1.0-r0) (7/7) Installing py2-pip (10.0.1-r0) Executing busybox-1.28.4-r0.trigger Executing glibc-bin-2.27-r0.trigger OK: 93 MiB in 45 packages Collecting robotframework   Downloading https://files.pythonhosted.org/packages/22/0f/1b9ffa0c4e59789b50e6034866e823b7d4a5c7eaedad7bfd0bba42f2aa9d/robotframework-3.1.2-py2.py3-none-any.whl (602kB) Installing collected packages: robotframework Successfully installed robotframework-3.1.2 ============================================================================== hadoop31-hadoopo3fs :: Test ozone fs with hadoopfs                             ============================================================================== Test hadoop dfs                                                       | PASS | ------------------------------------------------------------------------------ hadoop31-hadoopo3fs :: Test ozone fs with hadoopfs                    | PASS | 1 critical test, 1 passed, 0 failed 1 test total, 1 passed, 0 failed ============================================================================== Output:  /tmp/smoketest/hadoop31/result/robot-hadoop31-hadoop31-hadoopo3fs-rm.xml ============================================================================== hadoop31-mapreduce :: Execute MR jobs                                          ============================================================================== Execute PI calculation                                                | PASS | ------------------------------------------------------------------------------ Execute WordCount                                                     | PASS | ------------------------------------------------------------------------------ hadoop31-mapreduce :: Execute MR jobs                                 | PASS | 2 critical tests, 2 passed, 0 failed 2 tests total, 2 passed, 0 failed ============================================================================== Output:  /tmp/smoketest/hadoop31/result/robot-hadoop31-hadoop31-mapreduce-rm.xml Robot framework is not installed, the reports can be generated (sudo pip install robotframework). 2 datanode is up and healthy (until now) 3 datanodes are up and registered to the scm ============================================================================== hadoop27-createmrenv :: Create directories required for MR test                ============================================================================== Create test volume, bucket and key                                    | PASS | ------------------------------------------------------------------------------ Create user dir for hadoop                                            | PASS | ------------------------------------------------------------------------------ hadoop27-createmrenv :: Create directories required for MR test       | PASS | 2 critical tests, 2 passed, 0 failed 2 tests total, 2 passed, 0 failed ============================================================================== Output:  /tmp/smoketest/hadoop27/result/robot-hadoop27-hadoop27-createmrenv-scm.xml fetch http://dl-cdn.alpinelinux.org/alpine/v3.8/main/x86_64/APKINDEX.tar.gz fetch http://dl-cdn.alpinelinux.org/alpine/v3.8/community/x86_64/APKINDEX.tar.gz (1/7) Installing libbz2 (1.0.6-r7) (2/7) Installing libffi (3.2.1-r4) (3/7) Installing gdbm (1.13-r1) (4/7) Installing sqlite-libs (3.25.3-r1) (5/7) Installing python2 (2.7.15-r2) (6/7) Installing py-setuptools (39.1.0-r0) (7/7) Installing py2-pip (10.0.1-r0) Executing busybox-1.28.4-r0.trigger Executing glibc-bin-2.27-r0.trigger OK: 93 MiB in 45 packages Collecting robotframework   Downloading https://files.pythonhosted.org/packages/22/0f/1b9ffa0c4e59789b50e6034866e823b7d4a5c7eaedad7bfd0bba42f2aa9d/robotframework-3.1.2-py2.py3-none-any.whl (602kB) Installing collected packages: robotframework Successfully installed robotframework-3.1.2 ============================================================================== hadoop27-hadoopo3fs :: Test ozone fs with hadoopfs                             ============================================================================== Test hadoop dfs                                                       | PASS | ------------------------------------------------------------------------------ hadoop27-hadoopo3fs :: Test ozone fs with hadoopfs                    | PASS | 1 critical test, 1 passed, 0 failed 1 test total, 1 passed, 0 failed ============================================================================== Output:  /tmp/smoketest/hadoop27/result/robot-hadoop27-hadoop27-hadoopo3fs-rm.xml ============================================================================== hadoop27-mapreduce :: Execute MR jobs                                          ============================================================================== Execute PI calculation                                                | PASS | ------------------------------------------------------------------------------ Execute WordCount                                                     | PASS | ------------------------------------------------------------------------------ hadoop27-mapreduce :: Execute MR jobs                                 | PASS | 2 critical tests, 2 passed, 0 failed 2 tests total, 2 passed, 0 failed ============================================================================== Output:  /tmp/smoketest/hadoop27/result/robot-hadoop27-hadoop27-mapreduce-rm.xml Robot framework is not installed, the reports can be generated (sudo pip install robotframework). 0 datanode is up and healthy (until now) 0 datanode is up and healthy (until now) 0 datanode is up and healthy (until now) 3 datanodes are up and registered to the scm ============================================================================== ozonesecure-mr-kinit :: Kinit test user                                        ============================================================================== Kinit                                                                 | PASS | ------------------------------------------------------------------------------ ozonesecure-mr-kinit :: Kinit test user                               | PASS | 1 critical test, 1 passed, 0 failed 1 test total, 1 passed, 0 failed ============================================================================== Output:  /tmp/smoketest/ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-kinit-om.xml ============================================================================== ozonesecure-mr-createmrenv :: Create directories required for MR test          ============================================================================== Create test volume, bucket and key                                    | PASS | ------------------------------------------------------------------------------ Create user dir for hadoop                                            | PASS | ------------------------------------------------------------------------------ ozonesecure-mr-createmrenv :: Create directories required for MR test | PASS | 2 critical tests, 2 passed, 0 failed 2 tests total, 2 passed, 0 failed ============================================================================== Output:  /tmp/smoketest/ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-createmrenv-om.xml ============================================================================== ozonesecure-mr-kinit-hadoop :: Kinit test user                                 ============================================================================== Kinit                                                                 | PASS | ------------------------------------------------------------------------------ ozonesecure-mr-kinit-hadoop :: Kinit test user                        | PASS | 1 critical test, 1 passed, 0 failed 1 test total, 1 passed, 0 failed ============================================================================== Output:  /tmp/smoketest/ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-kinit-hadoop-rm.xml ============================================================================== ozonesecure-mr-mapreduce :: Execute MR jobs                                    ============================================================================== Execute PI calculation                                                | PASS | ------------------------------------------------------------------------------ Execute WordCount                                                     | PASS | ------------------------------------------------------------------------------ ozonesecure-mr-mapreduce :: Execute MR jobs                           | PASS | 2 critical tests, 2 passed, 0 failed 2 tests total, 2 passed, 0 failed ============================================================================== Output:  /tmp/smoketest/ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-mapreduce-rm.xml Robot framework is not installed, the reports can be generated (sudo pip install robotframework). ```","closed","ozone,","adoroszlai","2019-09-27T06:47:33Z","2019-10-02T11:06:58Z"
"","1600","HDDS-2239. Fix TestOzoneFsHAUrls","## What changes were proposed in this pull request?  Make sure context classloader is restored to avoid NPE during shutdown.  https://issues.apache.org/jira/browse/HDDS-2239  ## How was this patch tested?  Ran `TestOzoneFsHAUrls` in IDE.","closed","ozone,","adoroszlai","2019-10-04T18:37:26Z","2019-10-07T17:32:03Z"
"","1580","HDDS-2234. rat.sh fails due to ozone-recon-web/build files","## What changes were proposed in this pull request?  Make RAT check ignore `ozone-recon-web/build` directory.  During `ozone-recon` to `recon` rename ([HDDS-2044](https://issues.apache.org/jira/browse/HDDS-2044)) the directory ignored by RAT was [changed to `recon-web/build`](https://github.com/apache/hadoop/blob/0e026cb0cefcadcfe404cd5d542f081f3b8ab69b/hadoop-ozone/pom.xml#L294), but the real directory is still [`ozone-recon-web`](https://github.com/apache/hadoop/tree/trunk/hadoop-ozone/recon/src/main/resources/webapps/recon/ozone-recon-web).  The mismatch is not a problem for CI because it doesn't build anything before the RAT check, so the `build` directory is not present.  https://issues.apache.org/jira/browse/HDDS-2234  ## How was this patch tested?  ``` $ mvn -f pom.ozone.xml -Dmaven.javadoc.skip=true -DskipTests clean package ... [INFO] BUILD SUCCESS  $ ls hadoop-ozone/recon/src/main/resources/webapps/recon/ozone-recon-web/build asset-manifest.json favicon.ico index.html manifest.json precache-manifest.2d16a2d17952080aea9277dca13a2b39.js service-worker.js static  $ hadoop-ozone/dev-support/checks/rat.sh ... [INFO] BUILD SUCCESS  $ echo $? 0 ```","closed","ozone,","adoroszlai","2019-10-03T07:18:45Z","2019-10-04T03:54:29Z"
"","1437","HDDS-2122. Broken logo image on category sub-pages","## What changes were proposed in this pull request?  Make link to Ozone logo relative to current page to fix broken image on sub pages.  https://issues.apache.org/jira/browse/HDDS-2122  ## How was this patch tested?  Built docs from source, verified that logo is OK in both top-level and sub pages.  ``` $ mvn -Phdds -pl :hadoop-hdds-docs clean package $ grep '","closed","ozone,","adoroszlai","2019-09-13T10:13:49Z","2019-09-13T13:39:18Z"
"","1171","HDDS-1834. parent directories not found in secure setup due to ACL check","## What changes were proposed in this pull request?  Let ACL check allow access for non-existent parent key instead of failing with ""key not found"".  Since the key does not exist, no ACL can be associated.  Actual access right will be determined based on volume, bucket and prefix ACLs.  https://issues.apache.org/jira/browse/HDDS-1834  ## How was this patch tested?  Ran `ozonesecurity` and `ozonefs` smoketests in `ozonesecure` environment.","closed","ozone,","adoroszlai","2019-07-26T11:06:24Z","2019-07-30T20:46:49Z"
"","740","[HDDS-1434] TestDatanodeStateMachine is flaky","## What changes were proposed in this pull request?  Let `TestCloseContainerCommandHandler` and `TestDatanodeStateMachine` both use random port for Ozone container, to avoid port conflict in case of parallel test execution.  ## How was this patch tested?  First reproduced the issue using:  ``` $ mvn -Phdds -pl :hadoop-hdds-container-service -Pparallel-tests test ```  Then verified that `TestDatanodeStateMachine` can be made to pass by either setting the random port or by disabling `TestCloseContainerCommandHandler` completely (using `@Ignore`).","closed","","adoroszlai","2019-04-14T14:32:10Z","2019-04-17T07:24:06Z"
"","1283","HDDS-1954. StackOverflowError in OzoneClientInvocationHandler","## What changes were proposed in this pull request?  Including `proxy` in the trace message causes stack overflow, since it results in a call to `proxy.toString()`, which also wants to log, etc.  I would also argue that `target` is more interesting for logging than `proxy`: eg. `org.apache.hadoop.ozone.client.rpc.RpcClient@5c3d4f05` vs. `com.sun.proxy.$Proxy87`.  https://issues.apache.org/jira/browse/HDDS-1954  ## How was this patch tested?  Set root log level to TRACE and ran some integration tests via Maven (eg. `TestOzoneRpcClientWithRatis`).  Verified that `surefire-reports` has no `StackOverflowError`, but has messages like:  ``` TRACE client.OzoneClient (OzoneClientInvocationHandler.java:invoke(51)) - Invoking method public abstract org.apache.hadoop.ozone.client.OzoneVolume org.apache.hadoop.ozone.client.protocol.ClientProtocol.getVolumeDetails(java.lang.String) throws java.io.IOException on target org.apache.hadoop.ozone.client.rpc.RpcClient@5c3d4f05 ```","closed","","adoroszlai","2019-08-12T20:01:47Z","2019-08-15T18:11:48Z"
"","1358","HDDS-2045. Partially started compose cluster left running","## What changes were proposed in this pull request?  If any container in the sample cluster [fails to start](https://github.com/elek/ozone-ci/blob/5c64f77f3ab64aed0826d8f40991fe621f843efd/pr/pr-hdds-2026-p4f6m/acceptance/output.log#L24), all successfully started containers are left running.  This [prevents](https://github.com/elek/ozone-ci/blob/5c64f77f3ab64aed0826d8f40991fe621f843efd/pr/pr-hdds-2026-p4f6m/acceptance/output.log#L59) any further acceptance tests from normal completion.  This is only a minor inconvenience, since acceptance test as a whole fails either way.  This change makes sure the cluster is stopped if startup fails.  https://issues.apache.org/jira/browse/HDDS-2045  ## How was this patch tested?  Temporarily added fake failures in `start_docker_env` and `wait_for_datanodes`, and verified that the cluster is stopped:  ``` $ ./test.sh Removing network ozone_default WARNING: Network ozone_default not found. Creating network ""ozone_default"" with the default driver Creating ozone_scm_1      ... done Creating ozone_datanode_1 ... done Creating ozone_datanode_2 ... done Creating ozone_datanode_3 ... done Creating ozone_om_1       ... done 0 datanode is up and healthy (until now) Stopping ozone_datanode_1 ... done Stopping ozone_datanode_3 ... done Stopping ozone_om_1       ... done Stopping ozone_datanode_2 ... done Stopping ozone_scm_1      ... done Removing ozone_datanode_1 ... done Removing ozone_datanode_3 ... done Removing ozone_om_1       ... done Removing ozone_datanode_2 ... done Removing ozone_scm_1      ... done Removing network ozone_default ```  Verified that the test succeeds without the fake failure.  ``` $ ./test.sh Removing network ozone_default WARNING: Network ozone_default not found. Creating network ""ozone_default"" with the default driver Creating ozone_scm_1      ... done Creating ozone_om_1       ... done Creating ozone_datanode_1 ... done Creating ozone_datanode_2 ... done Creating ozone_datanode_3 ... done 0 datanode is up and healthy (until now) 3 datanodes are up and registered to the scm ============================================================================== ozone-auditparser ============================================================================== ozone-auditparser.Auditparser :: Smoketest ozone cluster startup ============================================================================== Initiating freon to generate data                                     | PASS | ------------------------------------------------------------------------------ Testing audit parser                                                  | PASS | ------------------------------------------------------------------------------ ozone-auditparser.Auditparser :: Smoketest ozone cluster startup      | PASS | 2 critical tests, 2 passed, 0 failed 2 tests total, 2 passed, 0 failed ============================================================================== ozone-auditparser                                                     | PASS | 2 critical tests, 2 passed, 0 failed 2 tests total, 2 passed, 0 failed ============================================================================== Output:  /tmp/smoketest/ozone/result/robot-ozone-ozone-auditparser-om.xml ============================================================================== ozone-basic :: Smoketest ozone cluster startup ============================================================================== Check webui static resources                                          | PASS | ------------------------------------------------------------------------------ Start freon testing                                                   | PASS | ------------------------------------------------------------------------------ ozone-basic :: Smoketest ozone cluster startup                        | PASS | 2 critical tests, 2 passed, 0 failed 2 tests total, 2 passed, 0 failed ============================================================================== Output:  /tmp/smoketest/ozone/result/robot-ozone-ozone-basic-scm.xml Stopping ozone_datanode_1 ... done Stopping ozone_datanode_3 ... done Stopping ozone_datanode_2 ... done Stopping ozone_om_1       ... done Stopping ozone_scm_1      ... done Removing ozone_datanode_1 ... done Removing ozone_datanode_3 ... done Removing ozone_datanode_2 ... done Removing ozone_om_1       ... done Removing ozone_scm_1      ... done Removing network ozone_default ```","closed","ozone,","adoroszlai","2019-08-27T18:09:50Z","2019-08-29T08:26:49Z"
"","1451","HDDS-2134. OM Metrics graphs include empty request type","## What changes were proposed in this pull request?  Handle `numVolumes`, `numBuckets`, and `numKeys` metrics as ""other"", instead of including them in the Volume, Bucket, and Key request graphs.  https://issues.apache.org/jira/browse/HDDS-2134  ## How was this patch tested?  Checked OM Metrics after running `freon`.  Verified that `NumVolumes`, etc. appear in the _Other JMX properties_ table, and that the number of volme/bucket/key requests in the graphs add up to the total shown above each graph.","closed","ozone,","adoroszlai","2019-09-16T11:40:03Z","2019-09-18T12:15:06Z"
"","1503","HDDS-2165. Freon fails if bucket does not exists","## What changes were proposed in this pull request?  Freon should not fail after creating missing bucket.  https://issues.apache.org/jira/browse/HDDS-2165  ## How was this patch tested?  ``` $ ozone freon ockg -n 1 -b bucket3 ... Failures: 0 Successful executions: 1 ```","closed","ozone,","adoroszlai","2019-09-23T13:31:52Z","2019-09-25T12:33:21Z"
"","1092","HDDS-1800. Result of author check is inverted","## What changes were proposed in this pull request?  Fix:   1. author check fails when no violations are found  2. author check violations are duplicated in the output  Eg. https://ci.anzix.net/job/ozone-nightly/173/consoleText says that:  ``` The following tests are FAILED:  [author]: author check is failed (https://ci.anzix.net/job/ozone-nightly/173//artifact/build/author.out/*view*/) ```  but no actual `@author` tags were found:  ``` $ curl -s 'https://ci.anzix.net/job/ozone-nightly/173//artifact/build/author.out/*view*/' | wc        0       0       0 ```  ## How was this patch tested?  ``` $ bash -o pipefail -c 'hadoop-ozone/dev-support/checks/author.sh | tee build/author.out'; echo $? 0  $ wc build/author.out        0       0       0 build/author.out  $ echo '// @author Tolkien' >> hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManager.java  $ bash -o pipefail -c 'hadoop-ozone/dev-support/checks/author.sh | tee build/author.out'; echo $? ./hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManager.java:// @author Tolkien 1  $ wc build/author.out        1       3     108 build/author.out ```","closed","ozone,","adoroszlai","2019-07-15T10:24:18Z","2019-07-25T16:16:16Z"
"","1457","HDDS-2132. TestKeyValueContainer is failing","## What changes were proposed in this pull request?  Fix unit tests recently broken by new `Preconditions.checkNotNull` in `KeyValueContainerUtil#parseKVContainerData` (added in fe8cdf0ab846df9c2f3f59d1d4875185633a27ea for [HDDS-2076](https://issues.apache.org/jira/browse/HDDS-2076)).  https://issues.apache.org/jira/browse/HDDS-2132 https://issues.apache.org/jira/browse/HDDS-2133  ## How was this patch tested?  ``` $ mvn -am -Phdds -pl :hadoop-hdds-container-service clean test ... [INFO] Apache Hadoop HDDS ................................. SUCCESS [  2.527 s] [INFO] Apache Hadoop HDDS Config .......................... SUCCESS [  3.223 s] [INFO] Apache Hadoop HDDS Common .......................... SUCCESS [01:53 min] [INFO] Apache Hadoop HDDS Server Framework ................ SUCCESS [ 18.258 s] [INFO] Apache Hadoop HDDS Container Service ............... SUCCESS [01:13 min] ```","closed","ozone,","adoroszlai","2019-09-17T04:48:30Z","2019-09-17T09:08:57Z"
"","1173","HDDS-1852. Fix typo in TestOmAcls","## What changes were proposed in this pull request?  Fix typo, remove unnecessary `throws`.  ## How was this patch tested?  Ran unit test.","closed","ozone,","adoroszlai","2019-07-26T17:08:54Z","2019-07-29T08:56:50Z"
"","1606","HDDS-2262. SLEEP_SECONDS: command not found","## What changes were proposed in this pull request?  Fix typo in `entrypoint.sh` to avoid the following message:  ``` datanode_1  | /opt/hadoop/bin/docker/entrypoint.sh: line 66: SLEEP_SECONDS: command not found datanode_1  | Sleeping for  seconds ```  https://issues.apache.org/jira/browse/HDDS-2262  ## How was this patch tested?  ``` $ cd hadoop-ozone/dist/target/ozone-0.5.0-SNAPSHOT/compose/ozonesecure-mr $ docker-compose up -d $ docker-compose logs datanode | grep -i sleep datanode_1  | Sleeping for 5 seconds datanode_1  | Sleeping for 5 seconds ```","closed","ozone,","adoroszlai","2019-10-07T10:15:31Z","2019-10-08T06:38:37Z"
"","1624","HDDS-2267. Container metadata scanner interval mismatch","## What changes were proposed in this pull request?  Fix time unit mismatch in container metadata scanner.  Elapsed time is measured in nanoseconds, needs to be converted to milliseconds.  https://issues.apache.org/jira/browse/HDDS-2267  ## How was this patch tested?  Tested on `ozone` docker-compose cluster.  ``` datanode_1  | 2019-10-09 06:18:00 INFO  ContainerMetadataScanner:60 - Background ContainerMetadataScanner starting up datanode_1  | 2019-10-09 06:18:00 INFO  ContainerMetadataScanner:88 - Completed an iteration of container metadata scrubber in 0 minutes. Number of  iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0 datanode_1  | 2019-10-09 06:19:00 INFO  ContainerMetadataScanner:88 - Completed an iteration of container metadata scrubber in 0 minutes. Number of  iterations (since the data-node restart) : 2, Number of containers scanned in this iteration : 2, Number of unhealthy containers found in this iteration : 0 ... datanode_1  | STARTUP_MSG: Starting HddsDatanodeService datanode_1  | 2019-10-09 06:23:52 INFO  ContainerMetadataScanner:60 - Background ContainerMetadataScanner starting up datanode_1  | 2019-10-09 06:23:52 INFO  ContainerMetadataScanner:88 - Completed an iteration of container metadata scrubber in 0 minutes. Number of  iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 2, Number of unhealthy containers found in this iteration : 0 datanode_1  | 2019-10-09 06:24:52 INFO  ContainerMetadataScanner:88 - Completed an iteration of container metadata scrubber in 0 minutes. Number of  iterations (since the data-node restart) : 2, Number of containers scanned in this iteration : 2, Number of unhealthy containers found in this iteration : 0 ```","closed","ozone,","adoroszlai","2019-10-09T06:32:02Z","2019-10-16T10:58:54Z"
"","1343","HDDS-2024. Fix rat.sh problems","## What changes were proposed in this pull request?  Fix problems in `rat.sh`:  1. `grep: warning: recursive search of stdin` due to missing search target (which works with GNU grep, but not with some others) 2. `cat: target/rat-aggregated.txt: No such file or directory` due mismatch of `REPORT_FILE` value vs. literal 3. typo in `REPORT_FILE` value  Also: use `-s` test instead of `cat` (probably cheaper and safer).  https://issues.apache.org/jira/browse/HDDS-2024  ## How was this patch tested?  ``` $ ./hadoop-ozone/dev-support/checks/rat.sh ... [INFO] Build failures were ignored. hadoop-hdds/common/target/rat.txt: !????? hadoop-hdds/common/src/main/java/org/apache/hadoop/utils/db/cache/CacheResult.java hadoop-ozone/dist/target/rat.txt: !????? hadoop-ozone/dist/src/main/compose/ozones3-haproxy/haproxy-conf/haproxy.cfg hadoop-ozone/integration-test/target/rat.txt: !????? hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneRpcClientForAclAuditLog.java hadoop-ozone/common/target/rat.txt: !????? hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/util/BooleanBiFunction.java hadoop-ozone/ozone-manager/target/rat.txt: !????? hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/response/s3/bucket/TestS3BucketDeleteResponse.java hadoop-ozone/ozone-manager/target/rat.txt: !????? hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/response/s3/multipart/TestS3MultipartUploadAbortResponse.java hadoop-ozone/ozone-manager/target/rat.txt: !????? hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/s3/multipart/TestS3MultipartUploadCompleteRequest.java hadoop-ozone/ozone-manager/target/rat.txt: !????? hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/s3/multipart/TestS3MultipartUploadAbortRequest.java hadoop-ozone/ozone-manager/target/rat.txt: !????? hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/s3/multipart/S3MultipartUploadCompleteResponse.java hadoop-ozone/ozone-manager/target/rat.txt: !????? hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/key/OMKeyPurgeResponse.java hadoop-ozone/ozone-manager/target/rat.txt: !????? hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/ratis/utils/OzoneManagerDoubleBufferHelper.java hadoop-ozone/ozone-manager/target/rat.txt: !????? hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3MultipartUploadCompleteRequest.java hadoop-ozone/ozone-manager/target/rat.txt: !????? hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyPurgeRequest.java hadoop-ozone/ozone-manager/target/rat.txt: !????? hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/bucket/acl/OMBucketSetAclRequest.java hadoop-ozone/ozone-manager/target/rat.txt: !????? hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/bucket/acl/OMBucketRemoveAclRequest.java hadoop-ozone/ozone-manager/target/rat.txt: !????? hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/volume/acl/OMVolumeAclRequest.java  $ echo $? 1 ```","closed","ozone,","adoroszlai","2019-08-23T10:02:04Z","2019-08-23T11:25:02Z"
"","1245","HDDS-1924. ozone sh bucket path command does not exist","## What changes were proposed in this pull request?  Fix leftover reference to `ozone sh bucket path`.  It was generally changed to `ozone s3 path` in [HDDS-761](https://issues.apache.org/jira/browse/HDDS-761).  https://issues.apache.org/jira/browse/HDDS-1924  ## How was this patch tested?  ``` $ aws s3api --endpoint http://localhost:9878/ create-bucket --bucket=wordcount {     ""Location"": ""http://localhost:9878/wordcount"" }  $ docker-compose exec om ozone s3 path wordcount Volume name for S3Bucket is : s3100b8cad7cf2a56f6df78f171f97a1ec Ozone FileSystem Uri is : o3fs://wordcount.s3100b8cad7cf2a56f6df78f171f ```","closed","","adoroszlai","2019-08-07T09:01:16Z","2019-08-07T18:02:55Z"
"","1118","HDDS-1811. Prometheus metrics are broken","## What changes were proposed in this pull request?  Fix invalid metric type errors:  ``` target=http://192.168.69.76:9882/prom err=""invalid metric type \""apache.hadoop.ozone.container.common.transport.server.ratis._csm_metrics_delete_container_avg_time gauge\"""" ```  and  ``` target=http://scm:9876/prom err=""invalid metric type \""_rati_s-_thre_e-d7116831-ac55-4bf2-a259-d85cfba0572d counter\"""" ```   1. datanode: avoid `.` in record name by using simple class name  2. SCM: replace `-` with `_`.  Also properly convert `ALL_CAPS` names, eg. `RATIS_THREE` to `ratis_three` instead of `_rati_s-_thre_e`.  https://issues.apache.org/jira/browse/HDDS-1811  ## How was this patch tested?  Updated unit test.  Checked metrics in `ozoneperf` pseudo-cluster.","closed","ozone,","adoroszlai","2019-07-18T06:40:40Z","2019-07-23T06:02:00Z"
"","1195","HDDS-1878. checkstyle error in ContainerStateMachine","## What changes were proposed in this pull request?  Fix checkstyle error due to too long line.  Unfortunately at 71 characters `DFS_CONTAINER_RATIS_STATEMACHINE_MAX_PENDING_APPLY_TRANSACTIONS_DEFAULT` is too long for the 80-char limit even with static imports, so it has to be shortened.  I figured that `RATIS` would be the least useful part, implied by `STATEMACHINE`, so I removed that.  https://issues.apache.org/jira/browse/HDDS-1878  ## How was this patch tested?  ``` $ mvn -Phdds -DskipTests -am -pl :hadoop-hdds-container-service clean package $ ./hadoop-ozone/dev-support/checks/checkstyle.sh ```","closed","ozone,","adoroszlai","2019-07-31T11:59:46Z","2019-08-02T17:00:38Z"
"","1172","HDDS-1867. Invalid Prometheus metric name from JvmMetrics","## What changes were proposed in this pull request?  Fix `invalid metric type` error introduced by using JVM Metrics.  Instead of adding replacement for space, replace all characters that cannot appear in [Prometheus metric names](https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels) with `_`.  https://issues.apache.org/jira/browse/HDDS-1867  ## How was this patch tested?  Verified in `ozoneperf` compose environment that `http://scm:9876/prom` endpoint is UP, and no `invalid metric type` error appears in the log.  Added unit test.","closed","ozone,","adoroszlai","2019-07-26T12:42:33Z","2019-07-29T08:57:49Z"
"","1144","HDDS-1710. Fix checkstyle errors","## What changes were proposed in this pull request?  Fix [checkstyle errors](https://ci.anzix.net/job/ozone-nightly/182/checkstyle/) related to [HDDS-1710](https://issues.apache.org/jira/browse/HDDS-1710).  ## How was this patch tested?  ``` $ mvn -Phdds -DskipTests -DskipShade -am -pl :hadoop-ozone-dist clean package $ hadoop-ozone/dev-support/checks/checkstyle.sh ... [INFO] BUILD SUCCESS ```","closed","ozone,","adoroszlai","2019-07-23T11:01:48Z","2019-07-23T19:48:56Z"
"","1426","HDDS-2109. Refactor scm.container.client config","## What changes were proposed in this pull request?  Extract typesafe config related to HDDS client with prefix `scm.container.client`.  https://issues.apache.org/jira/browse/HDDS-2109  ## How was this patch tested?   * affected unit test `TestXceiverClientManager` and `TestOzoneConfigurationFields`  * checkstyle  * acceptance test in `ozone` compose env","closed","ozone,","adoroszlai","2019-09-11T11:24:30Z","2019-09-16T13:34:23Z"
"","1468","HDDS-2138. OM bucket operations do not add up","## What changes were proposed in this pull request?  Display S3 bucket operations in the ""Bucket"" chart, since `numBucketOps` (counter for total bucket operations) is incremented for these.  https://issues.apache.org/jira/browse/HDDS-2138  ## How was this patch tested?  Ran `ozones3` acceptance test, verified that bucket graph shows S3Lists, S3Creates etc.  Operation count matches the sum of individual counts ignoring the fake ""s"" request type (being fixed in [HDDS-2134](https://issues.apache.org/jira/browse/HDDS-2134)).","closed","ozone,","adoroszlai","2019-09-18T09:31:59Z","2019-09-18T14:43:53Z"
"","1284","HDDS-1952. Disable TestMiniChaosOzoneCluster in integration.sh","## What changes were proposed in this pull request?  Disable `TestMiniChaosOzoneCluster` in integration test (`integration.sh`) run by CI and nightly builds, since it always crashes after running for a long time.  It can still be run manually.  https://issues.apache.org/jira/browse/HDDS-1952","closed","ozone,","adoroszlai","2019-08-12T21:23:57Z","2019-08-13T13:42:19Z"
"","1238","HDDS-1921. TestOzoneManagerDoubleBufferWithOMResponse is flaky","## What changes were proposed in this pull request?  Currently `testDoubleBuffer` waits for a specific transaction count and checks `lastAppliedIndex`, which is updated last in `flushTransactions` on another thread.  I guess this may be the cause of flakiness.  By swapping the order in the test, we ensure that when the wait is over, all operations (transaction count increase, etc.) are done.  https://issues.apache.org/jira/browse/HDDS-1921  ## How was this patch tested?  Ran `TestOzoneManagerDoubleBufferWithOMResponse` a few times.","closed","ozone,","adoroszlai","2019-08-06T21:55:34Z","2019-08-07T06:25:52Z"
"","1470","HDDS-2147. Include dumpstream in test report","## What changes were proposed in this pull request?  Copy `*.dumpstream` files to the unit test report dir.  It may help finding out the cause of `Corrupted STDOUT` warning of forked JVM.  http://maven.apache.org/surefire/maven-surefire-plugin/faq.html#dumpfiles  https://issues.apache.org/jira/browse/HDDS-2147","closed","ozone,","adoroszlai","2019-09-18T16:53:58Z","2019-09-19T08:48:02Z"
"","1597","HDDS-2250. Generated configs missing from ozone-filesystem-lib jars","## What changes were proposed in this pull request?  Concatenate `ozone-default-generated.xml` files using Maven Shade Plugin's built-in XML transformer.  https://issues.apache.org/jira/browse/HDDS-2250  ## How was this patch tested?  Ran Hadoop 3.1 and 3.2 acceptance tests:  ``` $ cd hadoop-ozone/dist/target/ozone-0.5.0-SNAPSHOT/compose/ozone-mr/hadoop32 $ ./test.sh ... hadoop32-hadoopo3fs :: Test ozone fs with hadoopfs                    | PASS | ... hadoop32-mapreduce :: Execute MR jobs                                 | PASS | ...  $ cd ../hadoop31 $ ./test.sh ... hadoop31-hadoopo3fs :: Test ozone fs with hadoopfs                    | PASS | ... hadoop31-mapreduce :: Execute MR jobs                                 | PASS | ... ```  Checked the concatenated XML:  ``` $ unzip hadoop-ozone/ozonefs-lib-current/target/hadoop-ozone-filesystem-lib-current-0.5.0-SNAPSHOT.jar ozone-default-generated.xml $ grep '' ozone-default-generated.xml| sort -u     hadoop.hdds.db.rocksdb.logging.enabled     hadoop.hdds.db.rocksdb.logging.level     hdds.containerscrub.enabled     hdds.containerscrub.metadata.scan.interval     hdds.containerscrub.volume.bytes.per.second     hdds.ratis.server.num.snapshots.retained     ozone.om.group.rights     ozone.om.user.rights     scm.container.client.idle.threshold     scm.container.client.max.outstanding.requests     scm.container.client.max.size ```  CSI and SCM configs are missing, but I think that's because Ozone FS does not depend on CSI and depends on SCM only with test scope.","closed","ozone,","adoroszlai","2019-10-04T12:48:00Z","2019-10-05T06:13:38Z"
"","1605","HDDS-2259. Container Data Scrubber computes wrong checksum","## What changes were proposed in this pull request?  Compute checksum in container scrubber only for the actual length of data read.  Otherwise, if the actual chunk size is not an integer multiple of the number of bytes per checksum (ie. buffer size), leftover data in the buffer results in wrong checksum and unhealthy containers.  ``` Corruption detected in container: [1] Exception: [Inconsistent read for chunk=102914246583189504_chunk_1 len=671 expected checksum [0, 0, 0, 0, -14, -102, -99, -51] actual checksum [0, 0, 0, 0, 23, -23, 53, -79] for block conID: 1 locID: 102914246583189504 bcsId: 3] ```  https://issues.apache.org/jira/browse/HDDS-2259  ## How was this patch tested?  1. Changed unit test to reproduce the problem by making sure that ""bytes per checksum"" and ""chunk size"" are different. 2. Tested manually    1. Created and closed containers with small (> /data/hdds/hdds/*/current/containerDir0/2/chunks/*_chunk_1  ```  Log:  ``` Completed an iteration of container data scrubber in 1 minutes. Number of iterations (since the data-node restart) : 16, Number of containers scanned in this iteration : 3, Number of unhealthy containers found in this iteration : 0 ... Corruption detected in container: [2] Exception: [Inconsistent read for chunk=102914295727980545_chunk_1 len=5023516 expected checksum [0, 0, 0, 0, 21, 105, -33, 7] actual checksum [0, 0, 0, 0, -103, -121, 23, -96] for block conID: 2 locID: 102914295727980545 bcsId: 9] Completed an iteration of container data scrubber in 1 minutes. Number of iterations (since the data-node restart) : 19, Number of containers scanned in this iteration : 3, Number of unhealthy containers found in this iteration : 1 ```  Note: tested on top of #1590 to avoid excess CPU usage.","closed","ozone,","adoroszlai","2019-10-06T08:20:35Z","2019-10-08T06:38:05Z"
"","1608","HDDS-2265. integration.sh may report false negative","## What changes were proposed in this pull request?  Check if Maven was killed during test run (observable in integration test runs).  If so, mention it in `summary.txt`.  Non-empty `summary.txt` is handled as ""failure"".  https://issues.apache.org/jira/browse/HDDS-2265  ## How was this patch tested?  Tested both positive and negative case:  1. successful run, `summary.txt` remains empty 2. manually killed `mvn` process, verified that `summary.txt` contains the expected line","closed","ozone,","adoroszlai","2019-10-07T11:47:05Z","2019-10-09T14:43:33Z"
"","1085","HDDS-1785. OOM error in Freon due to the concurrency handling","## What changes were proposed in this pull request?  Change concurrency in Freon `RandomKeyGenerator`:   * create a worker for each thread  * let each worker create volumes, buckets and keys, without limiting ""inner"" objects to specific ""outer"" ones (eg. create key for any bucket)  Workers coordinate the items they create using ""global"" counters.  https://issues.apache.org/jira/browse/HDDS-1785  ## How was this patch tested?  Tested with various number of volumes/buckets/threads.  ``` $ ozone freon rk --numOfVolumes 1 --numOfBuckets 100 --numOfKeys 5 --numOfThreads 1 --replicationType=RATIS --factor=THREE ... Number of Volumes created: 1 Number of Buckets created: 100 Number of Keys added: 500 Ratis replication factor: THREE Ratis replication type: RATIS Average Time spent in volume creation: 00:00:00,100 Average Time spent in bucket creation: 00:00:00,304 Average Time spent in key creation: 00:00:01,556 Average Time spent in key write: 00:00:53,509 Total bytes written: 5120000 Total Execution time: 00:01:01,537 ```  ``` $ ozone freon rk --numOfVolumes 1 --numOfBuckets 100 --numOfKeys 5 --numOfThreads 50 --replicationType=RATIS --factor=THREE ... Number of Volumes created: 1 Number of Buckets created: 100 Number of Keys added: 500 Ratis replication factor: THREE Ratis replication type: RATIS Average Time spent in volume creation: 00:00:00,003 Average Time spent in bucket creation: 00:00:00,229 Average Time spent in key creation: 00:00:00,273 Average Time spent in key write: 00:00:10,375 Total bytes written: 5120000 Total Execution time: 00:00:16,872 ```  ``` $ ozone freon rk --numOfVolumes 10 --numOfBuckets 10 --numOfKeys 500 --numOfThreads 50 --replicationType=RATIS --factor=THREE ... Number of Volumes created: 10 Number of Buckets created: 100 Number of Keys added: 50000 Ratis replication factor: THREE Ratis replication type: RATIS Average Time spent in volume creation: 00:00:00,052 Average Time spent in bucket creation: 00:00:00,240 Average Time spent in key creation: 00:00:30,742 Average Time spent in key write: 00:10:04,146 Total bytes written: 512000000 Total Execution time: 00:10:42,463 ```  ``` $ ozone freon rk --numOfVolumes 100 --numOfBuckets 100 --numOfKeys 2 --numOfThreads 50 --replicationType=RATIS --factor=THREE ... Number of Volumes created: 100 Number of Buckets created: 10000 Number of Keys added: 20000 Ratis replication factor: THREE Ratis replication type: RATIS Average Time spent in volume creation: 00:00:00,266 Average Time spent in bucket creation: 00:00:06,388 Average Time spent in key creation: 00:00:09,324 Average Time spent in key write: 00:03:44,925 Total bytes written: 204800000 Total Execution time: 00:04:11,735 ```","closed","ozone,","adoroszlai","2019-07-12T11:59:14Z","2019-07-25T16:16:13Z"
"","1421","HDDS-2103. TestContainerReplication fails due to unhealthy container","## What changes were proposed in this pull request?  Change `TestContainerReplication` to close the container directly via client.  https://issues.apache.org/jira/browse/HDDS-2103  ## How was this patch tested?  Ran the changed unit test - passes, no other code changed.  Checkstyle passes.","closed","ozone,","adoroszlai","2019-09-10T08:34:45Z","2019-09-11T14:29:36Z"
"","1533","HDDS-2185. createmrenv failure not reflected in acceptance test result","## What changes were proposed in this pull request?  Avoid purging results dir when `testlib.sh` is `source`d.  Explicitly do that during docker env startup.  https://issues.apache.org/jira/browse/HDDS-2185  ## How was this patch tested?  Ran `ozone-mr/hadoop31` test, verified that `robot-hadoop31-hadoop31-createmrenv-scm.xml` is present along with other results.  Note that with this change, acceptance tests are expected to be failing.  They should have been failing with [HDDS-2187](https://issues.apache.org/jira/browse/HDDS-2187) since [HDDS-2101](https://issues.apache.org/jira/browse/HDDS-2101) was merged.  They are being fixed in #1537.","closed","ozone,","adoroszlai","2019-09-26T14:32:28Z","2019-09-28T05:40:28Z"
"","1548","HDDS-2205. checkstyle.sh reports wrong failure count","## What changes were proposed in this pull request?  Avoid counting filenames as failures in `checkstyle.sh`.  https://issues.apache.org/jira/browse/HDDS-2205  ## How was this patch tested?  ``` $ hadoop-ozone/dev-support/checks/checkstyle.sh ... hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/OmUtils.java  49: Unused import - org.apache.hadoop.ozone.om.OMMetadataManager.  $ cat target/checkstyle/failures 1 ```","closed","ozone,","adoroszlai","2019-09-30T07:37:00Z","2019-10-01T07:59:23Z"
"","1443","HDDS-2124. Random next links","## What changes were proposed in this pull request?  Assign weights to pages to ensure correct order.  https://issues.apache.org/jira/browse/HDDS-2124  ## How was this patch tested?  Generated docs, verified order.","closed","ozone,","adoroszlai","2019-09-13T19:00:16Z","2019-09-16T13:52:03Z"
"","1415","HDDS-2075. Tracing in OzoneManager call is propagated with wrong parent","## What changes were proposed in this pull request?  Apply tracing to `OzoneManagerProtocol` instead of `OzoneManagerProtocolPB`.  The latter only has a single public method, and no other `*ProtocolPB` interface is traced.  https://issues.apache.org/jira/browse/HDDS-2075  ## How was this patch tested?  Verified operation hierarchy in Jaeger UI.","closed","ozone,","adoroszlai","2019-09-09T16:16:55Z","2019-09-11T19:06:12Z"
"","1525","HDDS-2179. ConfigFileGenerator fails with Java 10 or newer","## What changes were proposed in this pull request?  Allow building HDDS Config (and Ozone in general) with newer JDKs.  Also change the error message that's printed in case of an `IOException` to include a bit more info about the error (exception type).  Example:  ```diff -[ERROR] Can't generate the config file from annotation: hadoop-hdds/config/target/test-classes/ozone-default-generated.xml +[ERROR] Can't generate the config file from annotation: java.nio.file.NoSuchFileException: hadoop-hdds/config/target/test-classes/ozone-default-generated.xml ```  https://issues.apache.org/jira/browse/HDDS-2179  ## How was this patch tested?  Tested HDDS Config build with Java 8, 10, 11, 13.  ``` $ mvn -f pom.ozone.xml -DskipTests -am -pl :hadoop-hdds-config clean package ... [INFO] Apache Hadoop Ozone Main ........................... SUCCESS [  0.472 s] [INFO] Apache Hadoop HDDS ................................. SUCCESS [  1.718 s] [INFO] Apache Hadoop HDDS Config .......................... SUCCESS [  1.651 s] [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS  $ wc hadoop-hdds/config/target/test-classes/ozone-default-generated.xml       33      63    1060 hadoop-hdds/config/target/test-classes/ozone-default-generated.xml ```","closed","ozone,","adoroszlai","2019-09-25T20:08:22Z","2019-09-27T05:48:46Z"
"","1249","HDDS-1928. Cannot run ozone-recon compose due to syntax error","## What changes were proposed in this pull request?  Add missing version tag for `datanode` service in `ozone-recon` compose.  https://issues.apache.org/jira/browse/HDDS-1928  ## How was this patch tested?  ``` $ docker-compose up -d --scale datanode=3 Creating network ""ozone-recon_default"" with the default driver Creating ozone-recon_datanode_1 ... done Creating ozone-recon_datanode_2 ... done Creating ozone-recon_datanode_3 ... done Creating ozone-recon_recon_1    ... done Creating ozone-recon_scm_1      ... done Creating ozone-recon_om_1       ... done ```","closed","ozone,","adoroszlai","2019-08-07T18:50:25Z","2019-08-14T05:36:27Z"
"","1372","HDDS-2051. Rat check failure in decommissioning.md","## What changes were proposed in this pull request?  Add license header in new `decommissioning.md`.  https://issues.apache.org/jira/browse/HDDS-2051  ## How was this patch tested?  ``` $ hadoop-ozone/dev-support/checks/rat.sh ... [INFO] Apache Hadoop HDDS/Ozone Documentation ............. SUCCESS [  0.066 s] ... ```","closed","ozone,","adoroszlai","2019-08-28T19:47:35Z","2019-08-28T20:35:05Z"
"","1235","HDDS-1916. Only contract tests are run in ozonefs module","## What changes were proposed in this pull request?  Add default Surefire inclusion patterns in addition to the custom one for contract tests.  https://issues.apache.org/jira/browse/HDDS-1916  ## How was this patch tested?  Verified that the remaining 6 test classes are also run by Maven:  ``` [INFO] --- maven-surefire-plugin:3.0.0-M1:test (default-test) @ hadoop-ozone-filesystem --- [INFO] [INFO] ------------------------------------------------------- [INFO]  T E S T S [INFO] ------------------------------------------------------- [INFO] Running org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus [INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.763 s - in org.apache.hadoop.fs.ozone.contract.ITestOzoneContractGetFileStatus [INFO] Running org.apache.hadoop.fs.ozone.contract.ITestOzoneContractSeek [INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.517 s - in org.apache.hadoop.fs.ozone.contract.ITestOzoneContractSeek [INFO] Running org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDelete [INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.624 s - in org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDelete [INFO] Running org.apache.hadoop.fs.ozone.contract.ITestOzoneContractRootDir [INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.872 s - in org.apache.hadoop.fs.ozone.contract.ITestOzoneContractRootDir [INFO] Running org.apache.hadoop.fs.ozone.contract.ITestOzoneContractMkdir [INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.223 s - in org.apache.hadoop.fs.ozone.contract.ITestOzoneContractMkdir [INFO] Running org.apache.hadoop.fs.ozone.contract.ITestOzoneContractRename [INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.569 s - in org.apache.hadoop.fs.ozone.contract.ITestOzoneContractRename [INFO] Running org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp [INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 35.582 s - in org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp [INFO] Running org.apache.hadoop.fs.ozone.contract.ITestOzoneContractCreate [WARNING] Tests run: 11, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 21.074 s - in org.apache.hadoop.fs.ozone.contract.ITestOzoneContractCreate [INFO] Running org.apache.hadoop.fs.ozone.contract.ITestOzoneContractOpen [INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.094 s - in org.apache.hadoop.fs.ozone.contract.ITestOzoneContractOpen [INFO] Running org.apache.hadoop.fs.ozone.TestFilteredClassLoader [INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.21 s - in org.apache.hadoop.fs.ozone.TestFilteredClassLoader [INFO] Running org.apache.hadoop.fs.ozone.TestOzoneFileInterfaces [INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 140.386 s - in org.apache.hadoop.fs.ozone.TestOzoneFileInterfaces [INFO] Running org.apache.hadoop.fs.ozone.TestOzoneFileSystemWithMocks [INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.05 s - in org.apache.hadoop.fs.ozone.TestOzoneFileSystemWithMocks [INFO] Running org.apache.hadoop.fs.ozone.TestOzoneFsRenameDir [INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.711 s - in org.apache.hadoop.fs.ozone.TestOzoneFsRenameDir [INFO] Running org.apache.hadoop.fs.ozone.TestOzoneFileSystem [INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 77.904 s - in org.apache.hadoop.fs.ozone.TestOzoneFileSystem [INFO] Running org.apache.hadoop.fs.ozone.TestOzoneFSInputStream [INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 48.962 s - in org.apache.hadoop.fs.ozone.TestOzoneFSInputStream [INFO] [INFO] Results: [INFO] [WARNING] Tests run: 117, Failures: 0, Errors: 0, Skipped: 2 ```","closed","ozone,","adoroszlai","2019-08-06T09:08:33Z","2019-08-14T05:34:53Z"
"","1382","HDDS-2061. Add hdds.container.chunk.persistdata as exception to TestOzoneConfigurationFields","## What changes were proposed in this pull request?  Add `hdds.container.chunk.persistdata` as an exception in `TestOzoneConfigurationFields` to fix its [failure](https://github.com/elek/ozone-ci/blob/master/trunk/trunk-nightly-20190830-rr75b/integration/hadoop-ozone/integration-test/org.apache.hadoop.ozone.TestOzoneConfigurationFields.txt).  https://issues.apache.org/jira/browse/HDDS-2061  ## How was this patch tested?  ``` $ mvn -am -Phdds -pl :hadoop-ozone-integration-test -DfailIfNoTests=false clean test -Dtest=TestOzoneConfigurationFields ... [INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.36 s - in org.apache.hadoop.ozone.TestOzoneConfigurationFields ```","closed","ozone,","adoroszlai","2019-08-30T09:44:14Z","2019-08-31T05:36:28Z"
"","1295","HDDS-1966. Wrong expected key ACL in acceptance test","## What changes were proposed in this pull request?  Acceptance test [fails at ACL checks](https://elek.github.io/ozone-ci/trunk/trunk-nightly-wxhxr/acceptance/smokeresult/log.html#s1-s16-s2-t4-k2):  ``` [ {   ""type"" : ""USER"",   ""name"" : ""testuser/scm@EXAMPLE.COM"",   ""aclScope"" : ""ACCESS"",   ""aclList"" : [ ""ALL"" ] }, {   ""type"" : ""GROUP"",   ""name"" : ""root"",   ""aclScope"" : ""ACCESS"",   ""aclList"" : [ ""ALL"" ] }, {   ""type"" : ""GROUP"",   ""name"" : ""superuser1"",   ""aclScope"" : ""ACCESS"",   ""aclList"" : [ ""ALL"" ] }, {   ""type"" : ""USER"",   ""name"" : ""superuser1"",   ""aclScope"" : ""ACCESS"",   ""aclList"" : [ ""READ"", ""WRITE"", ""READ_ACL"", ""WRITE_ACL"" ] } ]' does not match '""type"" : ""GROUP"", .*""name"" : ""superuser1*"", .*""aclScope"" : ""ACCESS"", .*""aclList"" : . ""READ"", ""WRITE"", ""READ_ACL"", ""WRITE_ACL""' ```  The test [sets user ACL](https://github.com/apache/hadoop/blob/0e4b757955ae8da1651b870c12458e3344c0b613/hadoop-ozone/dist/src/main/smoketest/basic/ozone-shell.robot#L123), but [checks group ACL](https://github.com/apache/hadoop/blob/0e4b757955ae8da1651b870c12458e3344c0b613/hadoop-ozone/dist/src/main/smoketest/basic/ozone-shell.robot#L125).  I think this passed previously due to a bug that was [fixed](https://github.com/apache/hadoop/pull/1234/files#diff-2d061b57a9838854d07da9e0eca64f31) by [HDDS-1917](https://issues.apache.org/jira/browse/HDDS-1917).  https://issues.apache.org/jira/browse/HDDS-1966  ## How was this patch tested?  Ran `ozonesecure` acceptance test, verified that key ACL checks were passing.","closed","ozone,","adoroszlai","2019-08-14T13:45:26Z","2019-08-14T16:47:44Z"
"","697","HDDS-1398. Concurrency issue in SCMConnectionManager#getValues","## What changes were proposed in this pull request?  `testStartStopDatanodeStateMachine` is flaky, causing [occasional pre-commit build failures](https://builds.apache.org/job/hadoop-multibranch/job/PR-691/1/artifact/out/patch-unit-hadoop-hdds_container-service.txt).  [HDDS-1332](https://issues.apache.org/jira/browse/HDDS-1332) added some logging to find out more about the cause.  I think the problem is not test-specific, and is caused by the following: `SCMConnectionManager#scmMachines` is a plain `HashMap`, guarded by a `ReadWriteLock` in most places where it's used, except `getValues()`.  The method also returns the values collection without any write protection (though currently none of the callers modify it).  This is an attempt to fix the cause by acquiring the read lock and creating a read-only copy.  https://issues.apache.org/jira/browse/HDDS-1332  ## How was this patch tested?  Ran affected unit tests several times, plus tried `ozone` docker-compose cluster.","closed","","adoroszlai","2019-04-04T18:44:32Z","2019-04-05T20:23:18Z"
"","1292","HDDS-1964. TestOzoneClientProducer fails with ConnectException","## What changes were proposed in this pull request?  `TestOzoneClientProducer` verifies that `RpcClient` cannot be created because OM address is not configured.  The call to `producer.createClient()` is expected to fail with the message `Couldn't create protocol`, which is triggered by `IllegalArgumentException: Could not find any configured addresses for OM. Please configure the system with ozone.om.address`.  bf457797f607f3aeeb2292e63f440cb13e15a2d9 added the default address as explicitly configured value, so client creation now progresses further and fails when it cannot connect to OM (which is not started by the unit test).  This change simply sets the previous empty OM address for this test.  It also adds log4j config for `s3gateway` tests to produce better output next time, because [currently](https://raw.githubusercontent.com/elek/ozone-ci/master/trunk/trunk-nightly-wxhxr/unit/hadoop-ozone/s3gateway/org.apache.hadoop.ozone.s3.TestOzoneClientProducer-output.txt) it is not very helpful.  https://issues.apache.org/jira/browse/HDDS-1964  ## How was this patch tested?  ``` $ mvn -Phdds -pl :hadoop-ozone-s3gateway test ... [INFO] Tests run: 77, Failures: 0, Errors: 0, Skipped: 0 ... [INFO] BUILD SUCCESS ```","closed","ozone,","adoroszlai","2019-08-14T09:59:34Z","2019-08-14T17:27:00Z"
"","1378","HDDS-1413. TestCloseContainerCommandHandler is flaky","## What changes were proposed in this pull request?  `TestCloseContainerCommandHandler` is flaky, because it uses real  1. Ratis client; 3 seconds is not always enough for the `groupAdd` call, resulting in [timeout](https://github.com/elek/ozone-ci/blob/8012e10c950001b688f67d66875935e8fc449b23/pr/pr-hdds-1054-cqztt/unit/hadoop-hdds/container-service/org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestCloseContainerCommandHandler.txt#L5-L6) 2. `OzoneContainer`, which uses threads to collect container information, sometimes finishes only after the test is failed with [NPE](https://github.com/elek/ozone-ci/blob/8012e10c950001b688f67d66875935e8fc449b23/pr/pr-hdds-1054-cqztt/unit/hadoop-hdds/container-service/org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestCloseContainerCommandHandler.txt#L51-L53)  The first issue might be solved by increasing the timeout to eg. 5 seconds.  However, even 10+20 seconds is not always enough to avoid the second issue.  Therefore this change is a rewrite of the test cases to use mocks.  https://issues.apache.org/jira/browse/HDDS-1413  ## How was this patch tested?  Ran the unit test repeatedly.  No other code changed.","closed","ozone,","adoroszlai","2019-08-29T16:21:59Z","2019-08-31T05:38:28Z"
"","1268","HDDS-1910. Cannot build hadoop-hdds-config from scratch in IDEA","## What changes were proposed in this pull request?  `ConfigFileGenerator` is both defined (`.java` source) and configured to be used (by reference in `META-INF`) in `hadoop-hdds-config` module's `main` source.  Maven build is configured to work around this by explicit `-proc:none` compiler arg, applied only to `main` compilation, but not to `test` compilation.  Since the annotation processor is only used in tests in this module, this works fine.  It seems IDEA does not respect this compiler configuration (and cannot even be configured differently for `main` and `test` compilation).  This change configures the processor for use in `config/test` and `common/main`.  Thus dependent modules still inherit it for main source processing, while the `config` module can be properly compiled without the hack.  https://issues.apache.org/jira/browse/HDDS-1910  ## How was this patch tested?  1. Verified that `hadoop-hdds/config` can be compiled from scratch in IDEA.  To confirm, try to run eg. `TestConfigFileAppender` unit test. 2. Verified that full Maven build still generates the same Ozone config based on existing annotations: ```   926 hadoop-hdds/common/target/test-classes/ozone-default-generated.xml  1060 hadoop-hdds/config/target/test-classes/ozone-default-generated.xml  1192 hadoop-hdds/server-scm/target/classes/ozone-default-generated.xml   504 hadoop-ozone/common/target/classes/ozone-default-generated.xml  1194 hadoop-ozone/csi/target/classes/ozone-default-generated.xml   504 hadoop-ozone/ozonefs-lib-current/target/classes/ozone-default-generated.xml   504 hadoop-ozone/ozonefs-lib-legacy/target/classes/libs/ozone-default-generated.xml   504 hadoop-ozone/ozonefs-lib-legacy/target/classes/ozone-default-generated.xml ```","closed","ozone,","adoroszlai","2019-08-10T08:16:05Z","2019-08-15T18:12:20Z"
"","1384","HDDS-2063. Integration tests create untracked file audit.log","## What changes were proposed in this pull request?  `audit.log` is only tested by `TestOzoneRpcClientForAclAuditLog`, but its `log4j2.properties` is being picked up by other tests, too.  This change renames the test config file to some custom one to avoid that.  https://issues.apache.org/jira/browse/HDDS-2063  ## How was this patch tested?  ``` $ mvn -Phdds -pl :hadoop-ozone-integration-test test -Dtest=TestOzoneRpcClientForAclAuditLog ... [INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.81 s - in org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientForAclAuditLog ... $ git status On branch HDDS-2063 nothing to commit, working tree clean  $ mvn -Phdds -pl :hadoop-ozone-integration-test test -Dtest=Test2WayCommitInRatis ... $ git status On branch HDDS-2063 nothing to commit, working tree clean ```","closed","ozone,","adoroszlai","2019-08-30T12:34:03Z","2019-08-31T05:35:01Z"
"","1096","HDDS-1793. Acceptance test of ozone-topology cluster is failing","## What changes were proposed in this pull request?  1. Remove explicit container names from `ozone-topology`, since they are not handled by `execute_robot_test`    (`must specify at least one container source`) 2. Allow more than 3 datanodes (`ozone-topology` has 4) in `wait_for_datanodes`  https://issues.apache.org/jira/browse/HDDS-1793  ## How was this patch tested?  ``` $ cd hadoop-ozone/dist/target/ozone-0.5.0-SNAPSHOT/compose/ozone-topology $ ./test.sh Removing network ozone-topology_net WARNING: Network ozone-topology_net not found. Creating network ""ozone-topology_net"" with driver ""bridge"" Creating ozone-topology_om_1         ... done Creating ozone-topology_scm_1        ... done Creating ozone-topology_datanode_2_1 ... done Creating ozone-topology_datanode_1_1 ... done Creating ozone-topology_datanode_3_1 ... done Creating ozone-topology_datanode_4_1 ... done 0 datanode is up and healthy (until now) 0 datanode is up and healthy (until now) 4 datanodes are up and registered to the scm ============================================================================== ozone-topology-auditparser ============================================================================== ozone-topology-auditparser.Auditparser :: Smoketest ozone cluster startup ============================================================================== Initiating freon to generate data                                     | PASS | ------------------------------------------------------------------------------ Testing audit parser                                                  | PASS | ------------------------------------------------------------------------------ ozone-topology-auditparser.Auditparser :: Smoketest ozone cluster ... | PASS | 2 critical tests, 2 passed, 0 failed 2 tests total, 2 passed, 0 failed ============================================================================== ozone-topology-auditparser                                            | PASS | 2 critical tests, 2 passed, 0 failed 2 tests total, 2 passed, 0 failed ============================================================================== Output:  /tmp/smoketest/ozone-topology/result/robot-ozone-topology-ozone-topology-auditparser-om.xml ============================================================================== ozone-topology-basic :: Smoketest ozone cluster startup ============================================================================== Check webui static resources                                          | PASS | ------------------------------------------------------------------------------ Start freon testing                                                   | PASS | ------------------------------------------------------------------------------ ozone-topology-basic :: Smoketest ozone cluster startup               | PASS | 2 critical tests, 2 passed, 0 failed 2 tests total, 2 passed, 0 failed ============================================================================== Output:  /tmp/smoketest/ozone-topology/result/robot-ozone-topology-ozone-topology-basic-scm.xml Stopping ozone-topology_datanode_1_1 ... done Stopping ozone-topology_datanode_2_1 ... done Stopping ozone-topology_datanode_3_1 ... done Stopping ozone-topology_datanode_4_1 ... done Stopping ozone-topology_scm_1        ... done Stopping ozone-topology_om_1         ... done Removing ozone-topology_datanode_1_1 ... done Removing ozone-topology_datanode_2_1 ... done Removing ozone-topology_datanode_3_1 ... done Removing ozone-topology_datanode_4_1 ... done Removing ozone-topology_scm_1        ... done Removing ozone-topology_om_1         ... done Removing network ozone-topology_net Log:     hadoop-ozone/dist/target/ozone-0.5.0-SNAPSHOT/compose/ozone-topology/result/log.html Report:  hadoop-ozone/dist/target/ozone-0.5.0-SNAPSHOT/compose/ozone-topology/result/report.html ```","closed","ozone,","adoroszlai","2019-07-15T13:56:15Z","2019-07-25T16:16:15Z"
"","1585","HDDS-2230. Invalid entries in ozonesecure-mr config","## What changes were proposed in this pull request?  1. Fix invalid entries in `docker-config` of `ozonesecure-mr`.  These variables:    * did not follow the naming convention of `envtoconf` (eg. missing `_`) and were ignored, or    * had typos in the filename portion (eg. `YARN_SITE.XML` instead of `YARN-SITE.XML`), and so were generated into the wrong config files. 2. Disable `LinuxContainerExecutor`, which requires `root` ownership of the config directory and does not work with the `ozone-runner` image. 3. Avoid `_` in hostname and domain name of Timeline History Server, because `URI` parsing fails in the client.  This is achieved by using a custom container name (for `jhs` only) and network name (for all services in the compose env).  Thanks @xiaoyuyao for finding the cause and fix for (2).  https://issues.apache.org/jira/browse/HDDS-2230  ## How was this patch tested?  Ran acceptance test in `ozonesecure-mr`.","closed","ozone,","adoroszlai","2019-10-03T18:47:45Z","2019-10-04T17:36:27Z"
"","1179","HDDS-1870. ConcurrentModification at PrometheusMetricsSink","## What changes were proposed in this pull request?  1. Fix `ConcurrentModification` due to plain `HashMap` 2. Improve string building a bit  https://issues.apache.org/jira/browse/HDDS-1870  ## How was this patch tested?  Ran freon in `ozoneperf` env.  Checked `/prom` endpoints.  Verified that no CME appears in logs.","closed","ozone,","adoroszlai","2019-07-29T10:55:51Z","2019-08-05T09:10:05Z"
"","1607","HDDS-2264. Improve output of TestOzoneContainer","## What changes were proposed in this pull request?  1. Compare exception result via assertion 2. Log the exception in case of failure 3. Use `LambdaTestUtils` instead of `try-catch`  https://issues.apache.org/jira/browse/HDDS-2264  ## How was this patch tested?  Temporarily changed `KeyValueContainer` to not catch `DiskOutOfSpaceException`.  Verified that the exception is logged and the test fails.  ``` Expected :DISK_OUT_OF_SPACE Actual   :CONTAINER_INTERNAL_ERROR ```","closed","ozone,","adoroszlai","2019-10-07T11:12:33Z","2019-10-08T06:36:24Z"
"","1553","HDDS-2211. Collect docker logs if env fails to start","## What changes were proposed in this pull request?  1. Collect docker logs if environment fails to start up (previously it was collected only after actual test run) 2. Copy docker logs to aggregate result directory 3. Fail fast if datanodes cannot be started 4. Avoid [ANSI codes in output](https://github.com/elek/ozone-ci-q4/blob/f700ebb2254527527960593496f15008245094d6/trunk/trunk-nightly-extra-20190930-74rp4/acceptance/output.log#L3774) 5. Sort test cases for consistent run ordering (Robot summary table is already sorted)  https://issues.apache.org/jira/browse/HDDS-2211  ## How was this patch tested?  Ran `acceptance.sh` locally.  Also simulated failure during datanode startup, verified that docker log is saved.","closed","ozone,","adoroszlai","2019-09-30T19:49:57Z","2019-10-03T19:47:24Z"
"","1287","HDDS-1956. Aged IO Thread exits on first read","## What changes were proposed in this pull request?  1. Aged IO thread exits on first read due to `ArrayIndexOutOfBoundsException`.  This is caused by using `index` as the key name, while `readKey` expects a string separated by `_`. 2. After fixing the above, it randomly exits due to `OMException: Key not found`.  This is an off-by-one error.  The first key written has `index=1`, but the test randomly attempts to read `index=0`. 3. Add trace level message for read/write/delete operations. 4. Include thread name in log output pattern for `integration-test`. 5. Fix some log messages in `MiniOzoneChaosCluster`  https://issues.apache.org/jira/browse/HDDS-1956  ## How was this patch tested?  Manually ran `TestMiniChaosOzoneCluster`:  ``` mvn -Phdds -pl :hadoop-ozone-integration-test -Dtest=TestMiniChaosOzoneCluster test ```  Stopped it after a few minutes (see [HDDS-1952](https://issues.apache.org/jira/browse/HDDS-1952)).  Verified that aged IO thread was writing and reading keys (until it started failing due to chaos):  ``` 2019-08-13 10:19:18,307 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:writeData(138)) - LOADGEN: Writing key pool-245-thread-1_0 2019-08-13 10:19:18,433 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:writeData(143)) - LOADGEN: Written key pool-245-thread-1_0 2019-08-13 10:19:22,473 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:readData(154)) - LOADGEN: Reading key pool-245-thread-1_0 2019-08-13 10:19:22,992 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:readData(176)) - LOADGEN: Read key pool-245-thread-1_0 ... 2019-08-13 10:19:23,837 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:readData(154)) - LOADGEN: Reading key pool-245-thread-1_0 2019-08-13 10:19:23,866 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:readData(176)) - LOADGEN: Read key pool-245-thread-1_0 2019-08-13 10:19:23,866 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:writeData(138)) - LOADGEN: Writing key pool-245-thread-1_1 2019-08-13 10:19:23,870 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:writeData(143)) - LOADGEN: Written key pool-245-thread-1_1 2019-08-13 10:19:23,891 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:readData(154)) - LOADGEN: Reading key pool-245-thread-1_1 2019-08-13 10:19:23,933 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:readData(176)) - LOADGEN: Read key pool-245-thread-1_1 2019-08-13 10:19:23,933 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:readData(154)) - LOADGEN: Reading key pool-245-thread-1_0 2019-08-13 10:19:23,960 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:readData(176)) - LOADGEN: Read key pool-245-thread-1_0 2019-08-13 10:19:23,960 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:readData(154)) - LOADGEN: Reading key pool-245-thread-1_0 2019-08-13 10:19:23,974 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:readData(176)) - LOADGEN: Read key pool-245-thread-1_0 2019-08-13 10:19:23,974 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:readData(154)) - LOADGEN: Reading key pool-245-thread-1_0 2019-08-13 10:19:24,017 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:readData(176)) - LOADGEN: Read key pool-245-thread-1_0 2019-08-13 10:19:24,017 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:readData(154)) - LOADGEN: Reading key pool-245-thread-1_1 2019-08-13 10:19:24,044 [pool-245-thread-1] TRACE ozone.MiniOzoneLoadGenerator (MiniOzoneLoadGenerator.java:readData(176)) - LOADGEN: Read key pool-245-thread-1_1 ```","closed","ozone,","adoroszlai","2019-08-13T08:35:41Z","2019-08-14T05:33:41Z"
"","1590","HDDS-2238. Container Data Scrubber spams log in empty cluster","## What changes were proposed in this pull request?  1. Add configurable interval for container data scan iterations (`hdds.containerscrub.data.scan.interval`).  A small delay will not affect scanning if there is enough I/O work to do.  However, it prevents the scanner threads from keeping CPU busy when there are no or few healthy closed containers to be scanned. 2. Only count iterations where at least one container was scanned. 3. Some code cleanup:    * get rid of raw `Container` usage (add generic parameter `` where needed)    * fix some javadoc (add `@param` descriptions, remove `@throws` without description)  https://issues.apache.org/jira/browse/HDDS-2238  ## How was this patch tested?  Test script:  ``` cd hadoop-ozone/dist/target/ozone-0.5.0-SNAPSHOT/compose/ozone  echo 'OZONE-SITE.XML_hdds.containerscrub.enabled=true' >> docker-config echo 'OZONE-SITE.XML_hdds.containerscrub.data.scan.interval=1' >> docker-config  KEEP_RUNNING=true ./test.sh  for i in 1 2; do   docker-compose exec scm ozone scmcli container close ${i}   sleep 10 done  docker-compose logs datanode | grep \   -e 'Completed an iteration of container data scrubber' \   -e 'Container .* is closed' ```  Result:  ``` datanode_1  | 2019-10-04 07:01:00 INFO  Container:335 - Container 1 is closed with bcsId 0. datanode_1  | 2019-10-04 07:01:00 INFO  ContainerDataScanner:115 - Completed an iteration of container data scrubber in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 1 datanode_1  | 2019-10-04 07:01:10 INFO  Container:335 - Container 2 is closed with bcsId 0. datanode_1  | 2019-10-04 07:01:10 INFO  ContainerDataScanner:115 - Completed an iteration of container data scrubber in 0 minutes. Number of iterations (since the data-node restart) : 2, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 1 ```","closed","ozone,","adoroszlai","2019-10-04T07:35:05Z","2019-10-08T06:35:52Z"
"","1461","HDDS-2142. OM metrics mismatch (abort multipart request)","## What changes were proposed in this pull request?  * Fix wrong call to increment `AbortMultipartUploadFails` * Add missing call to increment `AbortMultipartUploads`  https://issues.apache.org/jira/browse/HDDS-2142  ## How was this patch tested?  Ran `ozones3` acceptance test, verified OM metrics page.","closed","ozone,","adoroszlai","2019-09-17T12:15:26Z","2019-09-18T08:27:06Z"
"","1365","HDDS-1949. Missing or error-prone test cleanup","## What changes were proposed in this pull request?   * Make sure mini cluster is shutdown, even on test failure  * Adjust cluster ""path"" when cluster ID is changed (to avoid dangling directories)  https://issues.apache.org/jira/browse/HDDS-1949  ## How was this patch tested?  Ran `integration-test`, verified that no large directories are left (only few KB due to metrics output).","closed","ozone,","adoroszlai","2019-08-28T11:27:00Z","2019-09-20T17:26:27Z"
"","1338","HDDS-1808. TestRatisPipelineCreateAndDestory times out","## What changes were proposed in this pull request?   * Increase timeout of the test cases (both of them are prone to intermittent timeout).  Rationale: (1) there is already a timeout on `waitForPipelines()`, which was increased in `0d62753da96` without increasing overall test timeout, (2) test timeout needs to account for mini cluster startup.  * Fix typo in class name.  https://issues.apache.org/jira/browse/HDDS-1808  ## How was this patch tested?  Ran the test several times.  It passed in all cases.  It took as long as 77 seconds in one case, so one of the two test cases would have failed with the original 30 second timeout.","closed","ozone,","adoroszlai","2019-08-22T16:54:52Z","2019-08-23T08:59:54Z"
"","728","HDDS-1419. Fix shellcheck errors in start-chaos.sh","## What changes were proposed in this pull request?   * Fix shellcheck errors in `start-chaos.sh`  * Enclose all remaining variables in `{}`  * Fix typo in enclosure of variable: `{$heapdumpfile}` -> `${heapdumpfile}`  https://issues.apache.org/jira/browse/HDDS-1419  ## How was this patch tested?  Verified that shellcheck no longer reports any problems about `start-chaos.sh`.  Also ran `start-chaos.sh`:  ``` $ cd hadoop-ozone/integration-test $ src/test/bin/start-chaos.sh logging to /tmp/04-11-19-17:07:58.MiniOzoneChaosCluster.log heapdump to /tmp/04-11-19-17:07:58.dump Starting MiniOzoneChaosCluster ```  Verified that `HeapDumpPath` passed to the `java` process is the same as shown by `start-chaos.sh`.  ``` $ ps x | grep -o '[H]eapDumpPath[^ ]*' HeapDumpPath=/tmp/04-11-19-17:07:58.dump ```","closed","","adoroszlai","2019-04-11T15:16:12Z","2019-04-12T11:01:32Z"
"","1453","HDDS-2135. OM Metric mismatch (MultipartUpload failures)","## What changes were proposed in this pull request?   * Fix metric mismatch (wrong metric being incremented)  * Remove unused metric `numAddAllocateBlockCallFails` (leftover from [HDDS-1736](https://issues.apache.org/jira/browse/HDDS-1736))  https://issues.apache.org/jira/browse/HDDS-2135","closed","ozone,","adoroszlai","2019-09-16T12:10:28Z","2019-09-17T10:48:39Z"
"","1102","HDDS-1803. shellcheck.sh does not work on Mac","## What changes were proposed in this pull request?   * Filter for file permission on Mac.  * Merge two separate `find` calls to avoid overwriting output (and eliminate code duplication).  https://issues.apache.org/jira/browse/HDDS-1803  ## How was this patch tested?  ``` $ hadoop-ozone/dev-support/checks/shellcheck.sh | wc      133     600    6065  $ wc target/shell-problems.txt      133     600    6065 target/shell-problems.txt ```","closed","ozone,","adoroszlai","2019-07-16T03:18:50Z","2019-07-23T06:01:54Z"
"","1659","YARN-9906. Fix Docker container multi volume mounts bug","## NOTICE YARN-9906. Fix Docker container multi volume mounts bug","open","","lynnyuan-arch","2019-10-16T09:40:26Z","2021-04-19T07:47:30Z"
"","1673","HDFS-14638. [Dynamometer] Fix scripts to refer to current build structure.","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","tasanuma","2019-10-24T03:15:20Z","2019-10-25T01:04:33Z"
"","1672","HDFS-14910. Rename Snapshot with Pre Descendants Fail With IllegalArgumentException","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","jojochuang","2019-10-23T22:29:15Z","2019-10-24T20:09:53Z"
"","1669","HDFS-14802. The feature of protect directories should be used in RenameOp","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","ferhui","2019-10-23T01:54:38Z","2019-11-15T20:35:38Z"
"","1640","HADOOP-16637. Fix findbugs warnings in hadoop-cos.","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","cxorm","2019-10-10T14:09:30Z","2020-10-19T06:07:44Z"
"","1629","HADOOP-16579 - Upgrade to Apache Curator 4.2.0 and ZooKeeper 3.5.5","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","nkalmar","2019-10-09T15:02:05Z","2019-10-14T08:50:43Z"
"","1628","Hadoop 16631: Backport HADOOP-16578 - ABFS: fileSystemExists() should not call container level apis","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","snvijaya","2019-10-09T10:48:25Z","2019-10-09T23:55:53Z"
"","1617","MAPREDUCE-7240.Exception 'Invalid event: TA_TOO_MANY_FETCH_FAILURE at SUCCESS_FINISHING_CONTAINER' cause job error","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","chimney-lee","2019-10-08T12:07:28Z","2019-10-08T12:08:25Z"
"","1592","Hadoop 16630 : Backport of Hadoop-16548 : Disable Flush() over config","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","snvijaya","2019-10-04T09:17:24Z","2019-10-10T00:00:26Z"
"","1562","HDFS-14546-Block Placement Policy Doc","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","hdfs,","Amithsha","2019-10-01T14:15:23Z","2020-08-27T07:00:36Z"
"","1561","HDFS-14546 - Document block placement policies","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","Amithsha","2019-10-01T13:45:07Z","2019-10-01T14:14:40Z"
"","1559","HDDS-1737. Add Volume check in KeyManager and File Operations.","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","ozone,","cxorm","2019-10-01T07:42:51Z","2019-10-16T12:58:13Z"
"","1550","HDDS-2207. Update Ratis to latest snapshot.","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","ozone,","bshashikant","2019-09-30T10:50:35Z","2019-09-30T15:06:28Z"
"","1544","HDDS-2203 Race condition in ByteStringHelper.init()","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","ozone,","fapifta","2019-09-28T14:47:05Z","2019-10-02T16:58:02Z"
"","1532","HDDS-2183. Container and pipline subcommands of scmcli should be grouped.","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","ozone,","cxorm","2019-09-26T14:10:37Z","2019-09-30T13:00:12Z"
"","1487","HADOOP-16591 Fix S3A ITest*MRjob failures.","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","sidseth","2019-09-20T19:10:18Z","2019-09-24T07:17:35Z"
"","1474","HDDS-2153. Add a config to tune max pending requests in Ratis leader.","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","ozone,","bshashikant","2019-09-19T08:25:59Z","2019-09-30T13:41:40Z"
"","1459","HDDS-730. Ozone fs cli prints hadoop fs in usage.","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","cxorm","2019-09-17T09:57:56Z","2019-09-17T16:49:40Z"
"","1425","HADOOP-16555. Update commons-compress to 1.19.","## NOTICE  Please create an issue in ASF JIRA before opening a pull request, and you need to set the title of the pull request which starts with the corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.) For more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute","closed","","cxorm","2019-09-11T07:14:37Z","2019-09-13T18:11:05Z"
"","1693","HDFS-14825. [Dynamometer] Workload doesn't start unless an absolute path of Mapper class given.","","closed","","tasanuma","2019-11-05T03:39:49Z","2019-12-04T03:46:36Z"
"","1692","HADOOP-16678: Review of ArrayWritable","","closed","","belugabehr","2019-11-04T18:24:34Z","2019-11-04T22:25:17Z"
"","1690","HADOOP-16680. Add MicrosoftGraphGroupsMapping GroupMappingServiceProvider","","closed","","lukmajercak","2019-11-01T22:51:53Z","2021-07-05T20:12:44Z"
"","1689","HADOOP-16679. Switch to okhttp3","","open","","lukmajercak","2019-11-01T21:19:40Z","2021-09-28T15:49:59Z"
"","1687","HADOOP-16677. Recalculate the remaining timeout millis correctly while throwing an InterupptedException in SocketIOWithTimeout.","","closed","","iamcaoxudong","2019-10-31T11:19:16Z","2019-11-12T22:19:40Z"
"","1686","Recalculate the remaining timeout millis correctly while throwing an InterupptedException in SocketIOWithTimeout.","","closed","","iamcaoxudong","2019-10-31T10:43:11Z","2019-10-31T13:38:06Z"
"","1685","HDFS-14824. [Dynamometer] Dynamometer in org.apache.hadoop.tools does not output the benchmark results.","","closed","","tasanuma","2019-10-30T05:27:10Z","2019-12-12T02:27:06Z"
"","1680","HDFS-14907. [Dynamometer] DataNode can't find junit jar when using Hadoop-3 binary","","closed","","tasanuma","2019-10-28T08:03:31Z","2019-10-30T01:36:09Z"
"","1666","HDDS-2348.Remove log4j properties for org.apache.hadoop.ozone","","closed","","chimney-lee","2019-10-22T13:29:49Z","2019-10-24T06:42:17Z"
"","1665","HDFS-11639. PROVIDED Phase 2. Encode the BlockAlias in the client protocol","","closed","","ehiggs","2019-10-21T09:42:33Z","2019-11-30T00:10:49Z"
"","1636","HDFS-14894. Add balancer parameter to balance top used nodes.","","closed","","LeonGao91","2019-10-10T05:57:14Z","2020-01-24T01:02:48Z"
"","1567","HDDS-2224. Fix loadup cache for cache cleanup policy NEVER.","","closed","ozone,","bharatviswa504","2019-10-01T17:37:07Z","2019-10-02T22:18:44Z"
"","1555","HDDS-1984. Fix listBucket API.","","closed","ozone,","bharatviswa504","2019-10-01T02:14:04Z","2019-10-10T19:34:17Z"
"","1541","HDDS-1146. Adding container related metrics in SCM.","","closed","ozone,","bharatviswa504","2019-09-27T19:53:20Z","2019-09-27T22:26:01Z"
"","1535","HADOOP-16593. [YARN] Polish the protobuf plugin for hadoop-yarn-csi","","open","","Apache9","2019-09-27T03:25:01Z","2019-11-18T07:35:52Z"
"","1534","HDDS-2193. Adding container related metrics in SCM.","","closed","ozone,","bharatviswa504","2019-09-26T22:23:11Z","2019-09-27T04:49:31Z"
"","1530","HDFS-14869 Copy renamed files which are not excluded anymore by filter","","closed","hdfs,","aasha","2019-09-26T10:17:21Z","2019-12-06T12:11:26Z"
"","1529","HDDS-2182. Fix checkstyle violations introduced by HDDS-1738","","closed","ozone,","vivekratnavel","2019-09-26T06:40:19Z","2019-09-26T10:15:34Z"
"","1523","HADOOP-16611. Make test4tests vote for -0 instead of -1","","closed","","Apache9","2019-09-25T14:40:07Z","2019-09-26T12:12:37Z"
"","1511","HDDS-2162. Make OM Generic related configuration support HA style config.","","closed","ozone,","bharatviswa504","2019-09-24T00:49:33Z","2019-10-02T22:09:33Z"
"","1506","HDDS-2081 : Fix TestRatisPipelineProvider#testCreatePipelinesDnExclude.","","closed","ozone,","avijayanhwx","2019-09-23T15:08:47Z","2019-09-24T07:29:52Z"
"","1497","HDDS-2001. Update Ratis version to 0.4.0.","","closed","ozone,","nandakumar131","2019-09-22T10:10:02Z","2019-10-01T04:15:16Z"
"","1490","HDDS-2160. Add acceptance test for ozonesecure-mr compose. Contribute…","","closed","ozone,","xiaoyuyao","2019-09-20T21:35:53Z","2019-09-23T20:28:39Z"
"","1479","HDDS-2156. Fix alignment issues in HDDS doc pages","","closed","ozone,","vivekratnavel","2019-09-19T23:41:47Z","2019-09-20T05:40:51Z"
"","1465","HDDS-2143. Rename classes under package org.apache.hadoop.utils.","","closed","ozone,","bharatviswa504","2019-09-17T22:48:12Z","2019-09-18T14:57:50Z"
"","1455","HDDS-2137 : OzoneUtils to verify resourceName using HddsClientUtils","","closed","ozone,","virajjasani","2019-09-16T17:43:08Z","2019-09-18T14:49:01Z"
"","1454","HADOOP-16565. Region must be provided when requesting session credentials or SdkClientException will be thrown","","closed","","bgaborg","2019-09-16T13:01:30Z","2019-09-23T10:18:20Z"
"","1450","MAPREDUCE-7234. Fixed typo in isSplitable methods","","closed","","HorizonNet","2019-09-14T23:27:31Z","2019-09-20T07:32:20Z"
"","1445","HDDS-2128. Make ozone sh command work with OM HA service ids","","closed","","smengcl","2019-09-13T22:35:23Z","2019-09-20T21:22:56Z"
"","1444","HDDS-2078. Get/Renew DelegationToken NPE after HDDS-1909. Contributed…","","closed","ozone,","xiaoyuyao","2019-09-13T21:26:26Z","2019-09-16T14:57:46Z"
"","1440","HDDS-2114: Rename does not preserve non-explicitly created interim directories","","closed","ozone,","lokeshj1703","2019-09-13T14:07:42Z","2019-09-17T06:54:13Z"
"","1438","HDDS-2126. Ozone 0.4.1 branch build issue.","","closed","ozone,","nandakumar131","2019-09-13T13:23:12Z","2019-09-14T06:18:59Z"
"","1432","HADOOP-16557. [pb-upgrade] Upgrade protobuf.version to 3.7.1","","closed","","vinayakumarb","2019-09-12T11:45:14Z","2019-10-02T14:31:01Z"
"","1430","HDDS-2117. ContainerStateMachine#writeStateMachineData times out.","","closed","ozone,","bshashikant","2019-09-12T09:06:47Z","2019-09-17T11:20:03Z"
"","1429","HADOOP-16562. [pb-upgrade] Update docker image to have 3.7.1 protoc executable","","closed","","vinayakumarb","2019-09-12T09:00:21Z","2019-09-12T11:46:03Z"
"","1427","HDDS-2096. Ozone ACL document missing AddAcl API. Contributed by Xiao…","","closed","ozone,","xiaoyuyao","2019-09-11T18:57:24Z","2019-09-16T12:55:49Z"
"","1420","HDDS-2032. Ozone client should retry writes in case of any ratis/stateMachine exceptions.","","closed","ozone,","bshashikant","2019-09-10T07:59:14Z","2019-09-18T17:00:51Z"
"","1417","Hdds 2044 new","","closed","","shwetayakkali","2019-09-09T22:35:19Z","2021-02-10T23:55:08Z"
"","1414","HDFS-14835. RBF: Secured Router should not run when it can't initialize DelegationTokenSecretManager","","closed","","tasanuma","2019-09-09T11:01:47Z","2019-09-11T01:32:12Z"
"","1410","HDDS-2076. Read fails because the block cannot be located in the container","","closed","ozone,","bshashikant","2019-09-06T12:26:53Z","2019-09-12T15:47:49Z"
"","1408","HADOOP-13363. Upgrade protobuf from 2.5.0 to something newer","","open","","vinayakumarb","2019-09-05T21:59:40Z","2019-09-12T07:36:50Z"
"","1406","[HDDS-1708] Add container scrubber metrics","","closed","","hgadre","2019-09-05T17:06:32Z","2019-09-05T21:44:51Z"
"","1405","In yarn UI2, if the Spark task we submitted is still running,  the finishedTime returned by the server is 0, and the time shown on the UI2 page is always '1970/01/01 08:00'","","closed","","echohlne","2019-09-05T10:28:29Z","2019-09-23T14:34:15Z"
"","1404","HDFS-13660 Copy file till the source file length during distcp","","closed","","mukund-thakur","2019-09-05T10:26:39Z","2020-01-06T17:15:09Z"
"","1400","HDDS-2079. Fix TestSecureOzoneManager. Contributed by Xiaoyu Yao.","","closed","ozone,","xiaoyuyao","2019-09-04T04:25:45Z","2019-09-04T22:33:14Z"
"","1396","HDDS-2077. Add maven-gpg-plugin.version to pom.ozone.xml.","","closed","ozone,","nandakumar131","2019-09-03T12:18:53Z","2019-09-04T10:00:26Z"
"","1391","HDFS-13157: Round-Robin From Storages in BlockIterator","","open","hdfs,","belugabehr","2019-09-02T00:43:36Z","2020-07-31T20:59:53Z"
"","1389","YARN-9792. Document examples of SchedulerConf with Node Labels.","","open","","PrabhuJoseph","2019-08-31T13:19:06Z","2020-07-31T16:23:04Z"
"","1387","HDDS-2065. Implement OMNodeDetails#toString","","closed","ozone,","smengcl","2019-08-30T22:57:56Z","2019-09-18T15:48:13Z"
"","1386","HDDS-2015. Encrypt/decrypt key using symmetric key while writing/reading","","closed","ozone,","dineshchitlangia","2019-08-30T22:10:31Z","2019-09-06T21:17:17Z"
"","1380","fixed typo: CONTINOUS","","open","","The-Alchemist","2019-08-29T19:25:59Z","2022-01-27T19:57:32Z"
"","1376","HDDS-2058. Remove hadoop dependencies in ozone build.","","closed","ozone,","nandakumar131","2019-08-29T11:05:25Z","2019-08-30T17:32:08Z"
"","1371","HDDS-2018. Handle Set DtService of token for OM HA.","","closed","ozone,","bharatviswa504","2019-08-28T18:27:50Z","2019-09-03T21:06:15Z"
"","1370","HDFS-14492. Snapshot memory leak. Contributed by Wei-Chiu Chuang.","","closed","hdfs,","jojochuang","2019-08-28T17:20:54Z","2019-10-01T15:46:47Z"
"","1369","HDDS-2020. Remove mTLS from Ozone GRPC. Contributed by Xiaoyu Yao.","","closed","ozone,","xiaoyuyao","2019-08-28T16:27:24Z","2019-09-20T05:54:24Z"
"","1364","HDDS-1843. Undetectable corruption after restart of a datanode.","","closed","","bshashikant","2019-08-28T06:17:32Z","2019-09-10T07:26:47Z"
"","1362","HDDS-2014. Create Symmetric Key for GDPR","","closed","ozone,","dineshchitlangia","2019-08-28T03:48:02Z","2019-08-30T17:34:25Z"
"","1352","HDDS-2037. Fix hadoop version in pom.ozone.xml.","","closed","ozone,","nandakumar131","2019-08-26T15:23:23Z","2019-08-28T10:13:52Z"
"","1351","HDDS-2037. Fix hadoop version in pom.ozone.xml.","","closed","ozone,","nandakumar131","2019-08-26T15:01:59Z","2019-08-28T10:15:02Z"
"","1347","Check report","","closed","","elek","2019-08-24T11:31:20Z","2021-02-10T23:53:36Z"
"","1346","HDDS-2029. Fix license issues on ozone-0.4.1.","","closed","ozone,","nandakumar131","2019-08-24T11:15:12Z","2019-08-25T17:55:35Z"
"","1345","HDDS-2013. Add flag gdprEnabled for BucketInfo in OzoneManager proto","","closed","ozone,","dineshchitlangia","2019-08-23T19:31:44Z","2019-08-28T04:24:38Z"
"","1342","HDDS-2023. Fix rat check failures in trunk","","closed","ozone,","vivekratnavel","2019-08-23T09:13:06Z","2019-08-23T11:21:47Z"
"","1340","HDDS-2021. Upgrade Guava library to v26 in hdds project","","closed","ozone,","dineshchitlangia","2019-08-23T03:21:21Z","2019-09-19T04:02:17Z"
"","1335","HDFS-14763. Fix package name of audit log class in Dynamometer document","","closed","","tasanuma","2019-08-22T07:50:20Z","2019-08-22T09:59:06Z"
"","1334","HDFS-14761. RBF: MountTableResolver cannot invalidate cache correctly","","closed","","Cosss7","2019-08-22T07:44:44Z","2019-08-23T17:46:40Z"
"","1331","HDDS-2002. Update documentation for 0.4.1 release.","","closed","ozone,","nandakumar131","2019-08-21T17:18:59Z","2019-08-24T07:12:24Z"
"","1326","HDDS-1898. GrpcReplicationService#download cannot replicate the container.","","closed","ozone,","nandakumar131","2019-08-21T10:55:20Z","2019-09-05T12:52:00Z"
"","1321","HDDS-165. Add unit test for OzoneHddsDatanodeService","","closed","ozone,","pingsutw","2019-08-20T12:55:00Z","2019-08-29T07:38:52Z"
"","1320","HDFS-14755. [Dynamometer] Hadoop-2 DataNode fail to start","","closed","","tasanuma","2019-08-20T10:33:09Z","2019-08-23T00:58:33Z"
"","1318","HDDS-1753. Datanode unable to find chunk while replication data using ratis.","","closed","ozone,","bshashikant","2019-08-20T09:31:09Z","2019-08-28T05:51:13Z"
"","1316","HDDS-1973. Implement OM RenewDelegationToken request to use Cache and DoubleBuffer.","","closed","ozone,","bharatviswa504","2019-08-20T01:02:03Z","2019-08-21T19:01:28Z"
"","1315","HDDS-1975. Implement default acls for bucket/volume/key for OM HA code.","","closed","ozone,","bharatviswa504","2019-08-19T20:37:01Z","2019-08-26T18:05:41Z"
"","1313","HDFS-13118. SnapshotDiffReport should provide the INode type.","","open","hdfs,","ehiggs","2019-08-18T13:53:09Z","2019-11-29T22:39:09Z"
"","1310","HDDS-1978. Create helper script to run blockade tests.","","closed","ozone,","nandakumar131","2019-08-17T17:59:12Z","2019-08-23T16:56:36Z"
"","1308","HDDS-1974. Implement OM CancelDelegationToken request to use Cache and DoubleBuffer.","","closed","ozone,","bharatviswa504","2019-08-16T22:08:43Z","2019-08-18T17:06:01Z"
"","1306","HDDS-1971. Update document for HDDS-1891: Ozone fs shell command should work with default port when port number is not specified","","closed","","smengcl","2019-08-15T22:00:11Z","2019-08-19T01:29:53Z"
"","1305","HDDS-1938. Change omPort parameter type from String to int in BasicOzoneFileSystem#createAdapter","","closed","ozone,","smengcl","2019-08-15T21:30:19Z","2019-08-18T04:54:49Z"
"","1301","HDDS-1959. Decrement purge interval for Ratis logs in datanode","","closed","ozone,","pingsutw","2019-08-15T09:44:59Z","2019-08-17T11:40:25Z"
"","1299","HDDS-1959. Decrement purge interval for Ratis logs","","closed","ozone,","pingsutw","2019-08-15T03:01:53Z","2019-08-15T09:40:28Z"
"","1296","HDDS-1969. Implement OM GetDelegationToken request to use Cache and DoubleBuffer.","","closed","ozone,","bharatviswa504","2019-08-14T20:01:33Z","2019-08-16T20:22:04Z"
"","1288","HDDS-1961. TestStorageContainerManager#testScmProcessDatanodeHeartbeat is flaky.","","closed","ozone,","nandakumar131","2019-08-13T16:35:22Z","2019-08-14T05:15:03Z"
"","1281","HDDS-1955. TestBlockOutputStreamWithFailures#test2DatanodesFailure failing because of assertion error. Contributed by Mukul Kumar Singh.","","closed","ozone,","mukul1987","2019-08-12T16:41:13Z","2019-08-14T15:09:18Z"
"","1274","HDFS-14148. HDFS OIV ReverseXML SnapshotSection parser throws exception when there are more than one snapshottable directory","","closed","","smengcl","2019-08-10T14:40:36Z","2019-08-13T00:26:21Z"
"","1272","HADOOP-16276. Fix jsvc startup command in hadoop-functions.sh due to jsvc >= 1.0.11 changed default current working directory","","closed","","smengcl","2019-08-10T13:13:04Z","2019-11-21T00:44:45Z"
"","1270","HDFS-14718. HttpFS: Sort response by key names as WebHDFS does","","open","hdfs,","smengcl","2019-08-10T10:38:05Z","2021-08-16T06:34:40Z"
"","1267","HDFS-14665. HttpFS: LISTSTATUS response is missing HDFS-specific fields","","closed","hdfs,","smengcl","2019-08-10T08:03:07Z","2019-08-13T23:27:58Z"
"","1260","HDDS-1906. TestScmSafeMode#testSCMSafeModeRestrictedOp is failing.","","closed","ozone,","nandakumar131","2019-08-09T13:38:14Z","2019-08-11T14:13:18Z"
"","1258","HDFS-12125. Document the missing EC removePolicy command","","closed","hdfs,","smengcl","2019-08-09T05:35:56Z","2019-08-10T06:13:45Z"
"","1253","HDFS-8631. WebHDFS : Support setQuota","","closed","hdfs,","sunchao","2019-08-08T07:58:18Z","2019-09-03T17:53:13Z"
"","1252","HDFS-14678. Allow triggerBlockReport to a specific namenode.","","closed","hdfs,","LeonGao91","2019-08-07T23:18:04Z","2019-08-16T17:10:45Z"
"","1242","HDDS-1553: Add metric for rack aware placement policy","","closed","","chenjunjiedada","2019-08-07T04:04:55Z","2019-08-07T06:53:29Z"
"","1241","HDDS-1553: Add metric for rack aware placement policy","","closed","","chenjunjiedada","2019-08-07T04:00:34Z","2019-08-07T04:00:58Z"
"","1240","HDDS-1919. Fix Javadoc in TestAuditParser","","closed","ozone,","pingsutw","2019-08-06T23:21:40Z","2019-08-07T01:07:31Z"
"","1239","HDDS-1907. TestOzoneRpcClientWithRatis is failing with ACL errors. Co…","","closed","ozone,","xiaoyuyao","2019-08-06T22:08:05Z","2019-08-07T13:06:53Z"
"","1237","HDDS-1920. Place ozone.om.address config key default value in ozone-site.xml","","closed","ozone,","smengcl","2019-08-06T21:15:02Z","2019-08-14T03:30:23Z"
"","1234","HDDS-1917. TestOzoneRpcClientAbstract is failing.","","closed","ozone,","nandakumar131","2019-08-06T09:03:34Z","2019-08-14T05:15:26Z"
"","1228","HDDS-1901. Fix Ozone HTTP WebConsole Authentication. Contributed by X…","","closed","ozone,","xiaoyuyao","2019-08-05T17:13:09Z","2019-08-06T19:07:57Z"
"","1227","HDDS-1905. PipelineActionHandler is not closing the pipeline when close action is received.","","closed","ozone,","nandakumar131","2019-08-05T13:50:45Z","2019-08-06T09:06:09Z"
"","1226","HDDS-1610. applyTransaction failure should not be lost on restart.","","closed","ozone,","bshashikant","2019-08-05T08:21:46Z","2019-08-27T18:10:21Z"
"","1225","HDDS-1909. Use new HA code for Non-HA in OM.","","closed","ozone,","bharatviswa504","2019-08-04T22:30:46Z","2019-09-03T20:28:21Z"
"","1221","HDDS-1488. Scm cli command to start/stop replication manager.","","closed","ozone,","nandakumar131","2019-08-03T13:33:14Z","2019-08-14T05:16:08Z"
"","1220","YARN-9410 Typo in documentation: Using FPGA On YARN","","closed","","pingsutw","2019-08-03T03:36:26Z","2019-08-06T13:29:59Z"
"","1219","HDDS-1900. Remove UpdateBucket handler which supports add/remove Acl.","","closed","ozone,","bharatviswa504","2019-08-02T23:00:35Z","2019-08-08T02:38:07Z"
"","1216","HDDS-1893. Fix bug in removeAcl in Bucket.","","closed","ozone,","bharatviswa504","2019-08-02T18:03:11Z","2019-08-05T17:25:19Z"
"","1214","HDDS-1896. Suppress WARN log from NetworkTopology#getDistanceCost. Co…","","closed","ozone,","xiaoyuyao","2019-08-02T16:29:04Z","2019-08-04T05:33:02Z"
"","1212","YARN-9683 Remove reapDockerContainerNoPid left behind by YARN-9074","","closed","","pingsutw","2019-08-01T21:26:06Z","2019-08-14T17:42:29Z"
"","1211","HDDS-1888. Add containers to node2container map in SCM as part of ICR processing.","","closed","ozone,","nandakumar131","2019-08-01T19:30:31Z","2019-08-08T11:11:01Z"
"","1208","HADOOP-16423. S3Guard fsck: Check metadata consistency between S3 and metadatastore (log)","","closed","fs/s3,","bgaborg","2019-08-01T15:35:17Z","2019-09-12T11:12:47Z"
"","1206","HDDS-1887. Enable all the blockade test-cases.","","closed","ozone,","nandakumar131","2019-08-01T10:43:05Z","2019-08-03T07:14:50Z"
"","1205","HDDS-1886. Use ArrayList#clear to address audit failure scenario","","closed","ozone,","dineshchitlangia","2019-08-01T06:06:59Z","2019-08-13T21:47:56Z"
"","1199","HDDS-1885. Fix bug in checkAcls in OzoneManager.","","closed","ozone,","bharatviswa504","2019-07-31T17:35:38Z","2019-08-01T02:13:41Z"
"","1188","HDDS-1875. Fix failures in TestS3MultipartUploadAbortResponse.","","closed","ozone,","bharatviswa504","2019-07-31T04:00:22Z","2019-07-31T16:37:54Z"
"","1187","HDDS-1829 On OM reload/restart OmMetrics#numKeys should be updated","","closed","ozone,","smengcl","2019-07-31T03:22:52Z","2019-08-08T20:38:11Z"
"","1182","HDDS-1872. Fix entry clean up from openKeyTable during complete MPU.","","closed","ozone,","bharatviswa504","2019-07-29T23:32:30Z","2019-07-30T16:32:13Z"
"","1177","YARN-9711 Missing spaces in NMClientImpl","","closed","","xuchao0903","2019-07-27T09:26:33Z","2019-08-08T13:41:05Z"
"","1174","HDDS-1856. Make required changes for Non-HA to use new HA code in OM.","","closed","ozone,","bharatviswa504","2019-07-26T22:44:57Z","2019-07-31T05:39:04Z"
"","1167","HDDS-1863. Freon RandomKeyGenerator even if keySize is set to 0, it returns some random data to key.","","closed","ozone,","bharatviswa504","2019-07-26T01:13:43Z","2019-08-08T22:40:20Z"
"","1166","HDDS-1856. Merge HA and Non-HA code in OM.","","closed","ozone,","bharatviswa504","2019-07-25T23:22:54Z","2019-07-26T21:31:05Z"
"","1165","HDDS-1861. Fix TableCacheImpl cleanup logic.","","closed","ozone,","bharatviswa504","2019-07-25T23:08:03Z","2019-07-26T05:30:07Z"
"","1164","HDDS-1829 On OM reload/restart OmMetrics#numKeys should be updated","","closed","ozone,","smengcl","2019-07-25T22:47:32Z","2019-07-31T03:23:31Z"
"","1162","HDFS-14670: RBF: Create secret manager instance using FederationUtil#newInstance","","closed","hdfs,","chittshota","2019-07-25T20:25:17Z","2019-07-29T18:01:43Z"
"","1158","HDDS-1839: Change topology sorting related logs in Pipeline from INFO to DEBUG","","closed","ozone,","chenjunjiedada","2019-07-25T06:26:01Z","2019-07-26T15:14:25Z"
"","1156","HDDS-1830 OzoneManagerDoubleBuffer#stop should wait for daemon thread to die","","closed","ozone,","smengcl","2019-07-24T22:00:54Z","2019-07-25T23:20:09Z"
"","1155","HDDS-1842. Implement S3 Abort MPU request to use Cache and DoubleBuffer.","","closed","ozone,","bharatviswa504","2019-07-24T21:07:35Z","2019-07-25T15:51:12Z"
"","1154","[HDDS-1200] Add support for checksum verification in data scrubber","","closed","ozone,","hgadre","2019-07-24T20:55:30Z","2019-09-05T03:39:45Z"
"","1153","HDDS-1855. TestStorageContainerManager#testScmProcessDatanodeHeartbeat is failing.","","closed","ozone,","nandakumar131","2019-07-24T20:08:18Z","2019-07-26T08:50:00Z"
"","1152","HDDS-1817. GetKey fails with IllegalArgumentException.","","closed","ozone,","nandakumar131","2019-07-24T19:13:58Z","2019-07-25T05:17:52Z"
"","1148","HDDS-1848. Fix TestOzoneManagerHA and TestOzoneManagerSnapShotProvider.","","closed","ozone,","bharatviswa504","2019-07-23T22:35:54Z","2019-07-24T03:31:01Z"
"","1147","HDDS-1619. Support volume acl operations for OM HA. Contributed by…","","closed","ozone,","xiaoyuyao","2019-07-23T19:34:08Z","2019-08-08T16:56:19Z"
"","1141","HDDS-1845. OMVolumeSetQuota|OwnerRequest#validateAndUpdateCache return response.","","closed","ozone,","bharatviswa504","2019-07-23T01:05:15Z","2019-07-23T23:33:51Z"
"","1140","HDDS-1819. Implement S3 Commit MPU request to use Cache and DoubleBuffer.","","closed","ozone,","bharatviswa504","2019-07-23T00:53:29Z","2019-07-24T21:04:04Z"
"","1139","HDDS-1846. Default value for checksum bytes is different in ozone-site.xml and code.","","closed","ozone,","bharatviswa504","2019-07-23T00:30:55Z","2019-07-23T19:42:38Z"
"","1137","YARN-9688. Variable description error of method in stateMachine class","","open","","wuyinxian124","2019-07-21T05:20:27Z","2020-07-31T18:28:11Z"
"","1136","HDDS-1841. Fix TestSecureContainerServer.","","closed","ozone,","bharatviswa504","2019-07-19T23:05:29Z","2019-07-20T15:14:24Z"
"","1135","HDDS-1840. Fix TestSecureOzoneContainer.","","closed","ozone,","bharatviswa504","2019-07-19T22:57:03Z","2019-07-22T17:23:49Z"
"","1133","HDDS-1836. Change the default value of ratis leader election min timeout to a lower value","","closed","","bshashikant","2019-07-19T10:22:28Z","2019-08-15T04:43:38Z"
"","1130","HDDS-1827. Load Snapshot info when OM Ratis server starts.","","closed","ozone,","hanishakoneru","2019-07-19T07:44:33Z","2019-08-23T20:19:14Z"
"","1125","HADOOP-13868. [s3a] New default for S3A multi-part configuration","","closed","","mackrorysd","2019-07-18T22:52:57Z","2019-07-19T15:50:00Z"
"","1122","YARN-9679. Regular code cleanup in TestResourcePluginManager","","closed","","adamantal","2019-07-18T15:46:53Z","2019-08-15T15:32:07Z"
"","1116","HDDS-1820. Fix numKeys metrics in OM HA.","","closed","ozone,","bharatviswa504","2019-07-17T22:58:13Z","2019-07-18T16:36:16Z"
"","1111","HDFS-9913 DistCp to add -useTrash to move deleted files to Trash","","open","","asagjj","2019-07-17T13:07:23Z","2020-07-31T18:30:23Z"
"","1106","HADOOP-16380. S3A non-recursive deletion of root to return false","","closed","fs/s3,","bgaborg","2019-07-16T17:15:35Z","2019-07-19T13:55:32Z"
"","1100","HDDS-1802. Add Eviction policy for table cache.","","closed","ozone,","bharatviswa504","2019-07-16T00:24:09Z","2019-08-01T02:13:26Z"
"","1099","HDDS-1802. Add Eviction policy for table cache.","","closed","","bharatviswa504","2019-07-16T00:20:40Z","2019-07-16T01:53:56Z"
"","1090","SUBMARINE-72 Kill and destroy the job through the submarine client","","closed","","pingsutw","2019-07-14T07:00:26Z","2019-08-08T10:25:00Z"
"","1088","HDDS-1689. Implement S3 Create Bucket request to use Cache and DoubleBuffer.","","closed","ozone,","bharatviswa504","2019-07-12T22:47:21Z","2019-07-18T04:46:29Z"
"","1084","HDDS-1492. Generated chunk size name too long.","","closed","ozone,","bshashikant","2019-07-12T11:14:24Z","2019-07-16T12:31:47Z"
"","1077","HADOOP-XXXXX. S3Guard tombstones can mislead about directory empty status and other fixes - wip","-","closed","fs/s3,","bgaborg","2019-07-11T08:16:34Z","2019-07-29T13:25:47Z"
"","1076","HDDS-1782. Add an option to MiniOzoneChaosCluster to read files multiple times. Contributed by Mukul Kumar Singh.","","closed","ozone,","mukul1987","2019-07-11T03:23:30Z","2019-08-02T16:20:40Z"
"","1075","HADOOP-15729. [s3a] Allow core threads to time out.","","closed","fs/s3,","mackrorysd","2019-07-10T19:47:55Z","2019-07-17T00:14:24Z"
"","1074","HDDS-1544. Support default Acls for volume, bucket, keys and prefix. Contributed by Ajay Kumar.","","closed","ozone,","ajayydv","2019-07-10T19:12:49Z","2019-07-16T20:08:18Z"
"","1073","HDDS-1780. TestFailureHandlingByClient tests are flaky.","","closed","ozone,","bshashikant","2019-07-10T13:12:37Z","2019-07-18T10:33:54Z"
"","1071","HDDS-1779. TestWatchForCommit tests are flaky.","","closed","ozone,","bshashikant","2019-07-10T12:24:00Z","2019-07-18T14:28:33Z"
"","1069","HDDS-1779. TestWatchForCommit tests are flaky.","","closed","","bshashikant","2019-07-10T11:51:43Z","2019-07-10T11:58:27Z"
"","1068","HDDS-1778. Fix existing blockade tests.","","closed","ozone,","nandakumar131","2019-07-10T09:46:25Z","2019-07-10T16:43:59Z"
"","1063","HDDS-1775. Make OM KeyDeletingService compatible with HA model","","closed","ozone,","hanishakoneru","2019-07-09T01:49:44Z","2019-07-17T02:00:46Z"
"","1057","HDDS-1742 Merge ozone-perf and ozonetrace example clusters","","closed","ozone,","fapifta","2019-07-04T00:54:30Z","2019-07-09T15:26:40Z"
"","1053","HDDS-1712.  Test pull request acl.","","closed","ozone,","eyanghwx","2019-07-03T21:09:54Z","2019-07-16T09:53:29Z"
"","1052","HDDS-1761. Fix class hierarchy for KeyRequest and FileRequest classes.","","closed","ozone,","bharatviswa504","2019-07-03T20:53:20Z","2019-07-16T00:53:20Z"
"","1048","HDDS-1757. Use ExecutorService in OzoneManagerStateMachine.","","closed","ozone,","bharatviswa504","2019-07-02T18:57:56Z","2019-07-02T23:02:27Z"
"","1045","HDDS-1741 Fix prometheus configuration in ozoneperf example cluster","","closed","ozone,","fapifta","2019-07-01T23:06:31Z","2019-07-03T21:38:05Z"
"","1044","HDDS-1731. Implement File CreateFile Request to use Cache and DoubleBuffer.","","closed","ozone,","bharatviswa504","2019-07-01T22:07:31Z","2019-07-03T21:51:41Z"
"","1043","HADOOP-16396. Allow authoritative mode on a subdirectory.","","closed","","mackrorysd","2019-07-01T15:29:05Z","2019-07-03T18:04:48Z"
"","1038","HDDS-1736. Cleanup 2phase old HA code for Key requests.","","closed","ozone,","bharatviswa504","2019-06-29T22:14:29Z","2019-07-16T06:44:51Z"
"","1037","HADOOP-15847 limit the r/w capacity","","closed","","lqjack","2019-06-29T15:35:44Z","2019-09-10T01:16:33Z"
"","1031","HDDS-1733. Fix Ozone documentation","","closed","","dineshchitlangia","2019-06-28T19:48:10Z","2019-06-28T23:04:18Z"
"","1027","Changing abfs default blocksize to 256 MB","","open","","singharun02101990","2019-06-28T11:24:03Z","2019-07-19T12:05:30Z"
"","1025","HDDS-373. Genconf tool must generate ozone-site.xml with sample values","","closed","","dineshchitlangia","2019-06-27T22:11:09Z","2019-07-01T15:58:48Z"
"","1024","HDDS-1729. Ozone Client should timeout if the put block futures are taking a long time. Contributed by Mukul Kumar Singh.","","closed","ozone,","mukul1987","2019-06-27T14:43:32Z","2019-07-05T12:08:49Z"
"","981","HDDS-1696. RocksDB use separate Write-ahead-log location for OM RocksDB.","","closed","ozone,","bharatviswa504","2019-06-17T19:10:14Z","2019-06-24T23:31:40Z"
"","974","HDFS-9913. DistCp to add -useTrash to move deleted files to Trash","","closed","","asagjj","2019-06-15T08:59:19Z","2019-08-19T06:15:11Z"
"","973","HDDS-1611. Evaluate ACL on volume bucket key and prefix to authorize access. Contributed by Ajay Kumar.","","closed","ozone,","ajayydv","2019-06-15T01:31:23Z","2019-07-10T18:03:59Z"
"","972","HDDS-1601. Implement updating lastAppliedIndex after buffer flush to OM DB.","","closed","ozone,","bharatviswa504","2019-06-14T21:01:01Z","2019-06-15T20:47:08Z"
"","968","HADOOP-16373. Fix typo in FileSystemShell#test documentation","","closed","","dineshchitlangia","2019-06-14T05:23:05Z","2019-06-14T22:22:39Z"
"","967","HADOOP-16372. Fix typo in DFSUtil getHttpPolicy method","","closed","","dineshchitlangia","2019-06-14T05:09:59Z","2019-06-14T14:19:56Z"
"","965","HDDS-1684. OM should create Ratis related dirs only if ratis is enabled","","closed","ozone,","hanishakoneru","2019-06-13T22:58:57Z","2019-06-18T23:09:45Z"
"","960","HDDS-1679. debug patch","","closed","ozone,","mukul1987","2019-06-13T09:57:45Z","2019-08-14T18:07:02Z"
"","953","YARN-5727. Support visibility semantic in MapReduce.","","open","","JohnZZGithub","2019-06-12T20:34:11Z","2019-07-26T15:50:59Z"
"","949","HDDS-1672. Improve locking in OzoneManager.","","closed","ozone,","bharatviswa504","2019-06-12T05:54:23Z","2019-06-26T00:57:56Z"
"","942","HDDS-1587. Support dynamically adding delegated classes from to isolated class loader.","","closed","ozone,","chenjunjiedada","2019-06-11T02:56:22Z","2019-06-13T03:08:16Z"
"","938","HDFS-14556: Spelling Mistake ""gloablly""","","closed","","mpicker90","2019-06-10T15:33:26Z","2019-06-17T01:32:43Z"
"","935","HADOOP-16336. finish variable is unused in ZStandardCompressor","","closed","","cxorm","2019-06-10T09:02:05Z","2019-08-02T15:36:18Z"
"","929","HDDS-1651 Create a http.policy config for Ozone","","closed","","shwetayakkali","2019-06-07T23:08:38Z","2019-06-08T03:39:09Z"
"","926","HDDS-1657. Fix parallelStream usage in volume and key native acl. Contributed by Ajay Kumar.","","closed","ozone,","ajayydv","2019-06-07T17:27:57Z","2019-06-08T04:47:31Z"
"","923","HDDS-1654. Ensure container state on datanode gets synced to disk whennever state change happens.","","closed","ozone,","bshashikant","2019-06-07T10:18:35Z","2019-07-18T11:40:19Z"
"","921","HADOOP-16344 Make DurationInfo public unstable with import fix","","closed","","kai33","2019-06-07T02:26:20Z","2019-06-07T11:57:07Z"
"","920","HDDS-1545. Cli to add,remove,get and delete acls for Ozone objects. Contributed by Ajay Kumar.","","closed","ozone,","ajayydv","2019-06-06T16:12:30Z","2019-06-12T13:51:35Z"
"","911","HADOOP-16344 Make DurationInfo ""public unstable","","closed","","pingsutw","2019-06-05T17:14:58Z","2019-06-06T16:29:05Z"
"","898","HDDS-1490. Support configurable container placement policy","","closed","ozone,","ChenSammi","2019-06-04T01:11:48Z","2019-09-05T06:39:15Z"
"","897","YARN-9591 Expand all entries in JAR archive","","open","","chtyim","2019-06-03T18:55:12Z","2019-09-03T03:45:26Z"
"","891","HDDS-1633. Update rat from 0.12 to 0.13 in hadoop-runner build script","","closed","","elek","2019-06-03T08:32:26Z","2019-06-04T06:22:13Z"
"","889","Docker hadoop runner","","closed","","elek","2019-06-03T08:22:28Z","2022-04-01T22:58:34Z"
"","888","HDDS-1630. Copy default configuration files to the writeable directory","","closed","ozone,","elek","2019-06-03T08:02:08Z","2019-06-11T18:07:13Z"
"","885","HDDS-1541. Implement addAcl,removeAcl,setAcl,getAcl for Key. Contributed by Ajay Kumat.","","closed","ozone,","ajayydv","2019-06-01T02:45:18Z","2019-06-05T21:42:11Z"
"","881","YARN-2774. support secure clusters in shared cache manager","","open","","JohnZZGithub","2019-05-31T18:44:52Z","2021-10-07T04:08:57Z"
"","875","HDDS-1608. Support Ozone Prefix ACLs in OM metadata table. Contribute…","","closed","ozone,","xiaoyuyao","2019-05-30T18:14:26Z","2019-05-30T23:44:46Z"
"","874","HDDS-1540. Implement addAcl,removeAcl,setAcl,getAcl for Bucket. Contributed by Ajay Kumar.","","closed","ozone,","ajayydv","2019-05-30T07:21:33Z","2019-05-31T21:08:29Z"
"","870","HDDS-1542. Create Radix tree to support ozone prefix ACLs. Contribute…","","closed","ozone,","xiaoyuyao","2019-05-29T16:40:25Z","2019-05-29T20:48:35Z"
"","856","HDDS-1599. Fix TestReplicationManager.","","closed","ozone,","bharatviswa504","2019-05-27T18:05:09Z","2019-05-28T01:14:06Z"
"","855","HDDS-1599. Fix TestReplicationManager and checkstyle issues.","","closed","ozone,","bharatviswa504","2019-05-27T17:30:37Z","2019-05-27T21:02:35Z"
"","853","HDDS-1558. IllegalArgumentException while processing container Reports.","","closed","ozone,","bshashikant","2019-05-27T09:59:41Z","2019-06-03T19:30:37Z"
"","851","HDDS-1231. Add ChillMode metrics.","","closed","ozone,","bharatviswa504","2019-05-24T23:40:54Z","2019-05-29T18:56:38Z"
"","847","HDDS-1539. Implement addAcl,removeAcl,setAcl,getAcl for Volume. Contributed Ajay Kumar.","","closed","ozone,","ajayydv","2019-05-24T01:46:24Z","2019-05-30T06:18:06Z"
"","845","HDDS-1584. Fix TestFailureHandlingByClient tests","","closed","ozone,","bshashikant","2019-05-22T18:28:17Z","2019-05-27T10:58:28Z"
"","842","HDDS-1580.Obtain Handler reference in ContainerScrubber","","closed","ozone,","shwetayakkali","2019-05-22T00:36:04Z","2019-05-28T18:14:25Z"
"","833","HDDS-1502. Add metrics for Ozone Ratis performance.","","closed","","bshashikant","2019-05-20T10:36:46Z","2019-05-30T10:52:18Z"
"","828","HDDS-1538. Update ozone protobuf message for ACLs. Contributed by Ajay Kumar.","","closed","ozone,","ajayydv","2019-05-17T00:52:03Z","2019-05-21T22:54:04Z"
"","827","HDDS-1551. Implement Bucket Write Requests to use Cache and DoubleBuffer.","","closed","ozone,","bharatviswa504","2019-05-17T00:10:55Z","2019-05-24T21:00:10Z"
"","826","HDDS-1517. AllocateBlock call fails with ContainerNotFoundException.","","closed","","bshashikant","2019-05-16T13:16:35Z","2019-05-22T11:55:17Z"
"","820","HDDS-1531. Disable the sync flag by default during chunk writes in Datanode.","","closed","ozone,","bshashikant","2019-05-15T05:51:28Z","2019-05-16T13:11:06Z"
"","805","HDDS-1509. TestBlockOutputStreamWithFailures#test2DatanodesFailure fails intermittently","","closed","","bshashikant","2019-05-09T13:37:52Z","2019-05-27T11:03:08Z"
"","798","HDDS-1499. OzoneManager Cache.","","closed","ozone,","bharatviswa504","2019-05-07T17:35:53Z","2019-05-20T02:23:02Z"
"","795","HDDS-1491. Ozone KeyInputStream seek() should not read the chunk file.","","closed","ozone,","hanishakoneru","2019-05-05T22:12:26Z","2019-05-14T03:49:53Z"
"","793","HDDS-1224. Restructure code to validate the response from server in the Read path.","","closed","","bshashikant","2019-05-02T15:27:22Z","2019-05-09T13:56:03Z"
"","790","HDDS-1483:Fix javadoc","","closed","ozone,","dineshchitlangia","2019-05-02T03:02:43Z","2019-05-02T21:15:47Z"
"","789","HDDS-1482. Use strongly typed codec implementations for the S3Table.","","closed","ozone,","bharatviswa504","2019-05-01T18:29:33Z","2019-05-02T12:13:28Z"
"","779","HDDS-1476. Fix logIfNeeded logic in EndPointStateMachine.","","closed","ozone,","swagle","2019-04-27T16:22:21Z","2019-04-29T19:05:39Z"
"","778","HDDS-1472. Add retry to kinit command in smoketests. Contributed by Ajay Kumar.","","closed","ozone,","ajayydv","2019-04-26T20:35:27Z","2019-05-20T16:44:31Z"
"","777","HDDS-1471. Update ratis dependency to 0.3.0. Contributed by Ajay Kumar.","","closed","ozone,","ajayydv","2019-04-26T20:30:43Z","2019-04-29T04:00:06Z"
"","774","HADOOP-16256: HTTPFileSystem disallows users from configuring the connectionTimeout and readTimeout of HttpClient","","open","","shanthoosh","2019-04-25T15:38:36Z","2020-07-31T21:00:35Z"
"","762","HDDS-1455. Inconsistent naming convention with Ozone Kerberos configu…","","closed","ozone,","xiaoyuyao","2019-04-23T19:06:57Z","2019-04-29T18:18:12Z"
"","761","HADOOP-13386 Upgrade avro version in Hadoop","","open","","KalmanJantner","2019-04-23T11:46:16Z","2021-07-16T04:15:03Z"
"","759","HDDS-1453. Fix unit test TestConfigurationFields broken on trunk. (swagle)","","closed","ozone,","swagle","2019-04-23T04:34:13Z","2019-04-23T23:12:13Z"
"","757","HDDS-1450. Fix nightly run failures after HDDS-976. Contributed by Xi…","","closed","ozone,","xiaoyuyao","2019-04-22T17:33:26Z","2019-04-26T06:06:01Z"
"","754","HDDS-1065. OM and DN should persist SCM certificate as the trust root. Contributed by Ajay Kumar.","","closed","ozone,","ajayydv","2019-04-19T00:21:41Z","2019-05-20T16:20:24Z"
"","752","HDDS-1430. NPE if secure ozone if KMS uri is not defined. Contributed by Ajay Kumar.","","closed","ozone,","ajayydv","2019-04-18T22:01:33Z","2019-04-29T21:07:24Z"
"","749","HDDS-1395. Key write fails with BlockOutputStream has been closed exception","","closed","ozone,","bshashikant","2019-04-17T09:55:26Z","2019-05-07T19:32:16Z"
"","748","HDFS-14432. dfs.datanode.shared.file.descriptor.paths duplicated in hdfs-default.xml","","closed","","puleya77","2019-04-17T06:45:51Z","2019-04-17T17:03:20Z"
"","746","HDDS-1442. add spark container to ozonesecure-mr compose files. Contributed by Ajay Kumar.","","closed","ozone,","ajayydv","2019-04-17T04:35:51Z","2019-05-21T15:12:29Z"
"","745","HDDS-1441. Remove usage of getRetryFailureException. (swagle)","","closed","ozone,","swagle","2019-04-16T07:16:20Z","2019-06-06T15:49:36Z"
"","744","HDDS-1400. Convert all OM Key related operations to HA model.","","closed","ozone,","bharatviswa504","2019-04-15T23:46:01Z","2019-06-13T22:58:58Z"
"","739","HDDS-1432. Ozone client list command truncates response without any indication","","closed","ozone,","swagle","2019-04-14T04:17:06Z","2019-04-16T08:24:53Z"
"","737","HDDS-1198. Rename chill mode to safe mode. Contributed by Siddharth Wagle.","","closed","ozone,","arp7","2019-04-12T22:13:13Z","2019-04-13T14:27:04Z"
"","736","YARN-9469. Fix typo in YarnConfiguration.","","closed","","hextriclosan","2019-04-12T19:54:38Z","2019-05-23T17:02:37Z"
"","735","HDDS-1374. ContainerStateMap cannot find container while allocating blocks.","","closed","ozone,","bharatviswa504","2019-04-12T19:52:41Z","2019-04-16T20:53:28Z"
"","734","YARN-9469. Fix typo in YarnConfiguration.","","closed","","hextriclosan","2019-04-12T14:38:32Z","2019-04-12T19:50:53Z"
"","729","HDDS-1373. KeyOutputStream, close after write request fails after retries, runs into IllegalArgumentException","","closed","","bshashikant","2019-04-11T16:54:01Z","2019-04-17T08:57:41Z"
"","724","HDDS-1376. Datanode exits while executing client command when scmId is null","","closed","ozone,","hanishakoneru","2019-04-11T00:53:51Z","2019-04-16T20:51:40Z"
"","717","YARN-9468:Fix inaccurate documentations in Placement Constraints","","open","","hunshenshi","2019-04-10T07:14:54Z","2022-07-18T21:49:32Z"
"","716","HADOOP-16205 Backporting ABFS driver from trunk to branch 2.0","","closed","","kowon2008","2019-04-10T02:58:37Z","2019-04-25T18:12:10Z"
"","714","HDDS-1406. Avoid usage of commonPool in RatisPipelineUtils.","","closed","ozone,","bharatviswa504","2019-04-09T19:47:27Z","2019-05-22T01:50:30Z"
"","713","HDDS-1192. Support -conf command line argument in GenericCli","","closed","ozone,","kittinanasi","2019-04-09T13:23:30Z","2019-04-24T13:44:50Z"
"","705","YARN-9455. SchedulerInvalidResoureRequestException has a typo in its class (and file) name","","closed","","vietanh85","2019-04-08T03:16:47Z","2019-08-02T08:09:16Z"
"","704","HDDS-1393. Convert all OM Bucket related operations to HA model.","","closed","ozone,","bharatviswa504","2019-04-05T22:27:55Z","2019-04-09T21:57:33Z"
"","703","HDDS-1371. Download RocksDB checkpoint from OM Leader to Follower.","","closed","ozone,","hanishakoneru","2019-04-05T19:21:11Z","2019-06-07T02:44:27Z"
"","696","HDDS-1389. Fix testSCMChillModeRestrictedOp.","","closed","ozone,","nandakumar131","2019-04-04T18:25:05Z","2019-04-09T09:49:01Z"